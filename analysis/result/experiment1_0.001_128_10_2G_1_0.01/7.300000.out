2019-10-15 07:45:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-10-15 07:45:59 INFO  SparkContext:54 - Running Spark version 2.3.1
2019-10-15 07:45:59 INFO  SparkContext:54 - Submitted application: lenet5
2019-10-15 07:45:59 INFO  SecurityManager:54 - Changing view acls to: martijn01_vermeulen
2019-10-15 07:45:59 INFO  SecurityManager:54 - Changing modify acls to: martijn01_vermeulen
2019-10-15 07:45:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-10-15 07:45:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-10-15 07:45:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(martijn01_vermeulen); groups with view permissions: Set(); users  with modify permissions: Set(martijn01_vermeulen); groups with modify permissions: Set()
2019-10-15 07:45:59 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45357.
2019-10-15 07:45:59 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-10-15 07:45:59 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-10-15 07:45:59 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-15 07:45:59 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-10-15 07:45:59 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-df5e8aed-a4d0-4f3f-941a-782fc645571f
2019-10-15 07:45:59 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-10-15 07:45:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-10-15 07:46:00 INFO  log:192 - Logging initialized @3512ms
2019-10-15 07:46:00 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-10-15 07:46:00 INFO  Server:414 - Started @3650ms
2019-10-15 07:46:00 INFO  AbstractConnector:278 - Started ServerConnector@3df7b7cb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-15 07:46:00 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45871085{/jobs,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a906e0b{/jobs/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3fa09e24{/jobs/job,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fb34437{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@362a9bfc{/stages,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@dc072a3{/stages/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60b30e37{/stages/stage,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@59b8c1f6{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2102ae40{/stages/pool,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@378785a6{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f0a2ae9{/storage,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60a2e38f{/storage/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54663175{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fc734ea{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@71b41099{/environment,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67d2bbb{/environment/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63754f98{/executors,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f34778{/executors/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5492bf87{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bdd765d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@721de731{/static,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f45d53c{/,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e8c3310{/api,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cd5589c{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4db4bcfe{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-15 07:46:00 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:4040
2019-10-15 07:46:00 INFO  SparkContext:54 - Added JAR file:///home/test/bd/spark/lib/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:45357/jars/bigdl-SPARK_2.3-0.8.0-jar-with-dependencies.jar with timestamp 1571125560516
2019-10-15 07:46:00 INFO  SparkContext:54 - Added file file:/home/test/bd/codes/lenet5.py at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:45357/files/lenet5.py with timestamp 1571125560559
2019-10-15 07:46:00 INFO  Utils:54 - Copying /home/test/bd/codes/lenet5.py to /tmp/spark-baf66e8d-f668-4cc7-af1a-8de26fe0b958/userFiles-e0014855-1f3c-4eda-bce1-9bc5ed61c589/lenet5.py
2019-10-15 07:46:00 INFO  SparkContext:54 - Added file file:///home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip at spark://project-group-85cf.europe-west4-a.c.quantitative-performance.internal:45357/files/bigdl-0.8.0-python-api.zip with timestamp 1571125560574
2019-10-15 07:46:00 INFO  Utils:54 - Copying /home/test/bd/spark/lib/bigdl-0.8.0-python-api.zip to /tmp/spark-baf66e8d-f668-4cc7-af1a-8de26fe0b958/userFiles-e0014855-1f3c-4eda-bce1-9bc5ed61c589/bigdl-0.8.0-python-api.zip
2019-10-15 07:46:00 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://10.164.0.2:7077...
2019-10-15 07:46:00 INFO  TransportClientFactory:267 - Successfully created connection to /10.164.0.2:7077 after 74 ms (0 ms spent in bootstraps)
2019-10-15 07:46:00 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20191015074600-0120
2019-10-15 07:46:00 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20191015074600-0120/0 on worker-20191014155229-10.164.0.3-45141 (10.164.0.3:45141) with 1 core(s)
2019-10-15 07:46:00 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20191015074600-0120/0 on hostPort 10.164.0.3:45141 with 1 core(s), 2.0 GB RAM
2019-10-15 07:46:00 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39013.
2019-10-15 07:46:00 INFO  NettyBlockTransferService:54 - Server created on project-group-85cf.europe-west4-a.c.quantitative-performance.internal:39013
2019-10-15 07:46:00 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-15 07:46:00 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20191015074600-0120/0 is now RUNNING
2019-10-15 07:46:01 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 39013, None)
2019-10-15 07:46:01 INFO  BlockManagerMasterEndpoint:54 - Registering block manager project-group-85cf.europe-west4-a.c.quantitative-performance.internal:39013 with 366.3 MB RAM, BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 39013, None)
2019-10-15 07:46:01 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 39013, None)
2019-10-15 07:46:01 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, project-group-85cf.europe-west4-a.c.quantitative-performance.internal, 39013, None)
2019-10-15 07:46:01 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e410e0e{/metrics/json,null,AVAILABLE,@Spark}
2019-10-15 07:46:03 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.0.3:57158) with ID 0
2019-10-15 07:46:03 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 1.0
2019-10-15 07:46:03 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.164.0.3:37071 with 1007.8 MB RAM, BlockManagerId(0, 10.164.0.3, 37071, None)
2019-10-15 07:46:03 INFO  Engine$:112 - Auto detect executor number and executor cores number
2019-10-15 07:46:03 INFO  Engine$:114 - Executor number is 1 and executor cores number is 1
2019-10-15 07:46:04 INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 18
2019-10-15 07:46:04 INFO  Engine$:402 - Find existing spark context. Checking the spark conf...
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
0.001
('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createSequential
creating: createReshape
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createSpatialConvolution
creating: createTanh
creating: createSpatialMaxPooling
creating: createReshape
creating: createLinear
creating: createTanh
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createDefault
creating: createSGD
creating: createMaxEpoch
creating: createDistriOptimizer
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createEveryEpoch
2019-10-15 07:46:06 INFO  DistriOptimizer$:784 - caching training rdd ...
2019-10-15 07:46:21 INFO  DistriOptimizer$:624 - Cache thread models...
2019-10-15 07:46:22 INFO  DistriOptimizer$:626 - Cache thread models... done
2019-10-15 07:46:22 INFO  DistriOptimizer$:154 - Count dataset
2019-10-15 07:46:22 INFO  DistriOptimizer$:158 - Count dataset complete. Time elapsed: 0.377231825s
2019-10-15 07:46:22 INFO  DistriOptimizer$:166 - config  {
	computeThresholdbatchSize: 100
	maxDropPercentage: 0.0
	warmupIterationNum: 200
	isLayerwiseScaled: false
	dropPercentage: 0.0
 }
2019-10-15 07:46:22 INFO  DistriOptimizer$:170 - Shuffle data
2019-10-15 07:46:22 INFO  DistriOptimizer$:173 - Shuffle data complete. Takes 0.03988745s
2019-10-15 07:46:23 INFO  DistriOptimizer$:408 - [Epoch 1 128/60000][Iteration 1][Wall Clock 0.738338307s] Trained 128 records in 0.738338307 seconds. Throughput is 173.36227 records/second. Loss is 2.3038716. Sequentialb692dd65's hyper parameters: Current learning rate is 0.001. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:23 INFO  DistriOptimizer$:408 - [Epoch 1 256/60000][Iteration 2][Wall Clock 1.020207696s] Trained 128 records in 0.281869389 seconds. Throughput is 454.11105 records/second. Loss is 2.3119698. Sequentialb692dd65's hyper parameters: Current learning rate is 9.990009990009992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:23 INFO  DistriOptimizer$:408 - [Epoch 1 384/60000][Iteration 3][Wall Clock 1.276883864s] Trained 128 records in 0.256676168 seconds. Throughput is 498.68283 records/second. Loss is 2.3291328. Sequentialb692dd65's hyper parameters: Current learning rate is 9.98003992015968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:24 INFO  DistriOptimizer$:408 - [Epoch 1 512/60000][Iteration 4][Wall Clock 1.530454791s] Trained 128 records in 0.253570927 seconds. Throughput is 504.78976 records/second. Loss is 2.3191297. Sequentialb692dd65's hyper parameters: Current learning rate is 9.970089730807579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:24 INFO  DistriOptimizer$:408 - [Epoch 1 640/60000][Iteration 5][Wall Clock 1.747491055s] Trained 128 records in 0.217036264 seconds. Throughput is 589.7632 records/second. Loss is 2.3277967. Sequentialb692dd65's hyper parameters: Current learning rate is 9.9601593625498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:24 INFO  DistriOptimizer$:408 - [Epoch 1 768/60000][Iteration 6][Wall Clock 1.953571707s] Trained 128 records in 0.206080652 seconds. Throughput is 621.1161 records/second. Loss is 2.3223617. Sequentialb692dd65's hyper parameters: Current learning rate is 9.950248756218907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:24 INFO  DistriOptimizer$:408 - [Epoch 1 896/60000][Iteration 7][Wall Clock 2.133710389s] Trained 128 records in 0.180138682 seconds. Throughput is 710.56366 records/second. Loss is 2.3034356. Sequentialb692dd65's hyper parameters: Current learning rate is 9.940357852882705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1024/60000][Iteration 8][Wall Clock 2.354253679s] Trained 128 records in 0.22054329 seconds. Throughput is 580.3849 records/second. Loss is 2.3161118. Sequentialb692dd65's hyper parameters: Current learning rate is 9.9304865938431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1152/60000][Iteration 9][Wall Clock 2.572035753s] Trained 128 records in 0.217782074 seconds. Throughput is 587.74347 records/second. Loss is 2.3103201. Sequentialb692dd65's hyper parameters: Current learning rate is 9.92063492063492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1280/60000][Iteration 10][Wall Clock 2.74737131s] Trained 128 records in 0.175335557 seconds. Throughput is 730.02875 records/second. Loss is 2.3235893. Sequentialb692dd65's hyper parameters: Current learning rate is 9.91080277502478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1408/60000][Iteration 11][Wall Clock 2.928232906s] Trained 128 records in 0.180861596 seconds. Throughput is 707.7235 records/second. Loss is 2.322691. Sequentialb692dd65's hyper parameters: Current learning rate is 9.900990099009901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1536/60000][Iteration 12][Wall Clock 3.078480704s] Trained 128 records in 0.150247798 seconds. Throughput is 851.92596 records/second. Loss is 2.315633. Sequentialb692dd65's hyper parameters: Current learning rate is 9.891196834817015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:25 INFO  DistriOptimizer$:408 - [Epoch 1 1664/60000][Iteration 13][Wall Clock 3.260021101s] Trained 128 records in 0.181540397 seconds. Throughput is 705.0772 records/second. Loss is 2.3311222. Sequentialb692dd65's hyper parameters: Current learning rate is 9.881422924901185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:26 INFO  DistriOptimizer$:408 - [Epoch 1 1792/60000][Iteration 14][Wall Clock 3.424860108s] Trained 128 records in 0.164839007 seconds. Throughput is 776.5152 records/second. Loss is 2.3178325. Sequentialb692dd65's hyper parameters: Current learning rate is 9.87166831194472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:26 INFO  DistriOptimizer$:408 - [Epoch 1 1920/60000][Iteration 15][Wall Clock 3.690405173s] Trained 128 records in 0.265545065 seconds. Throughput is 482.0274 records/second. Loss is 2.3096535. Sequentialb692dd65's hyper parameters: Current learning rate is 9.861932938856016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:26 INFO  DistriOptimizer$:408 - [Epoch 1 2048/60000][Iteration 16][Wall Clock 3.863316847s] Trained 128 records in 0.172911674 seconds. Throughput is 740.2623 records/second. Loss is 2.303333. Sequentialb692dd65's hyper parameters: Current learning rate is 9.852216748768474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:26 INFO  DistriOptimizer$:408 - [Epoch 1 2176/60000][Iteration 17][Wall Clock 4.039900892s] Trained 128 records in 0.176584045 seconds. Throughput is 724.8673 records/second. Loss is 2.3273501. Sequentialb692dd65's hyper parameters: Current learning rate is 9.84251968503937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:26 INFO  DistriOptimizer$:408 - [Epoch 1 2304/60000][Iteration 18][Wall Clock 4.198240535s] Trained 128 records in 0.158339643 seconds. Throughput is 808.3888 records/second. Loss is 2.3241014. Sequentialb692dd65's hyper parameters: Current learning rate is 9.832841691248771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 2432/60000][Iteration 19][Wall Clock 4.345398131s] Trained 128 records in 0.147157596 seconds. Throughput is 869.8158 records/second. Loss is 2.3213544. Sequentialb692dd65's hyper parameters: Current learning rate is 9.823182711198428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 2560/60000][Iteration 20][Wall Clock 4.504254308s] Trained 128 records in 0.158856177 seconds. Throughput is 805.76025 records/second. Loss is 2.2973874. Sequentialb692dd65's hyper parameters: Current learning rate is 9.813542688910698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 2688/60000][Iteration 21][Wall Clock 4.729710824s] Trained 128 records in 0.225456516 seconds. Throughput is 567.73694 records/second. Loss is 2.3092792. Sequentialb692dd65's hyper parameters: Current learning rate is 9.80392156862745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 2816/60000][Iteration 22][Wall Clock 4.900849204s] Trained 128 records in 0.17113838 seconds. Throughput is 747.9328 records/second. Loss is 2.310575. Sequentialb692dd65's hyper parameters: Current learning rate is 9.794319294809011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 2944/60000][Iteration 23][Wall Clock 5.040783286s] Trained 128 records in 0.139934082 seconds. Throughput is 914.71643 records/second. Loss is 2.3178036. Sequentialb692dd65's hyper parameters: Current learning rate is 9.784735812133072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:27 INFO  DistriOptimizer$:408 - [Epoch 1 3072/60000][Iteration 24][Wall Clock 5.198625652s] Trained 128 records in 0.157842366 seconds. Throughput is 810.9356 records/second. Loss is 2.2967327. Sequentialb692dd65's hyper parameters: Current learning rate is 9.775171065493646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3200/60000][Iteration 25][Wall Clock 5.352187816s] Trained 128 records in 0.153562164 seconds. Throughput is 833.5387 records/second. Loss is 2.3210793. Sequentialb692dd65's hyper parameters: Current learning rate is 9.765625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3328/60000][Iteration 26][Wall Clock 5.512609176s] Trained 128 records in 0.16042136 seconds. Throughput is 797.89874 records/second. Loss is 2.3112545. Sequentialb692dd65's hyper parameters: Current learning rate is 9.756097560975611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3456/60000][Iteration 27][Wall Clock 5.674041937s] Trained 128 records in 0.161432761 seconds. Throughput is 792.8998 records/second. Loss is 2.322041. Sequentialb692dd65's hyper parameters: Current learning rate is 9.746588693957114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3584/60000][Iteration 28][Wall Clock 5.819778051s] Trained 128 records in 0.145736114 seconds. Throughput is 878.2998 records/second. Loss is 2.320078. Sequentialb692dd65's hyper parameters: Current learning rate is 9.737098344693283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3712/60000][Iteration 29][Wall Clock 5.98075672s] Trained 128 records in 0.160978669 seconds. Throughput is 795.13635 records/second. Loss is 2.3244264. Sequentialb692dd65's hyper parameters: Current learning rate is 9.727626459143969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3840/60000][Iteration 30][Wall Clock 6.138652689s] Trained 128 records in 0.157895969 seconds. Throughput is 810.66034 records/second. Loss is 2.3155222. Sequentialb692dd65's hyper parameters: Current learning rate is 9.718172983479106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:28 INFO  DistriOptimizer$:408 - [Epoch 1 3968/60000][Iteration 31][Wall Clock 6.289136471s] Trained 128 records in 0.150483782 seconds. Throughput is 850.58997 records/second. Loss is 2.3146257. Sequentialb692dd65's hyper parameters: Current learning rate is 9.70873786407767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4096/60000][Iteration 32][Wall Clock 6.414701365s] Trained 128 records in 0.125564894 seconds. Throughput is 1019.39325 records/second. Loss is 2.3122444. Sequentialb692dd65's hyper parameters: Current learning rate is 9.699321047526674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4224/60000][Iteration 33][Wall Clock 6.605105723s] Trained 128 records in 0.190404358 seconds. Throughput is 672.25354 records/second. Loss is 2.317313. Sequentialb692dd65's hyper parameters: Current learning rate is 9.689922480620155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4352/60000][Iteration 34][Wall Clock 6.759545539s] Trained 128 records in 0.154439816 seconds. Throughput is 828.80176 records/second. Loss is 2.3200593. Sequentialb692dd65's hyper parameters: Current learning rate is 9.680542110358181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4480/60000][Iteration 35][Wall Clock 6.890882684s] Trained 128 records in 0.131337145 seconds. Throughput is 974.59094 records/second. Loss is 2.3293188. Sequentialb692dd65's hyper parameters: Current learning rate is 9.671179883945841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4608/60000][Iteration 36][Wall Clock 7.039208057s] Trained 128 records in 0.148325373 seconds. Throughput is 862.9677 records/second. Loss is 2.3346355. Sequentialb692dd65's hyper parameters: Current learning rate is 9.661835748792271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:29 INFO  DistriOptimizer$:408 - [Epoch 1 4736/60000][Iteration 37][Wall Clock 7.186078965s] Trained 128 records in 0.146870908 seconds. Throughput is 871.5136 records/second. Loss is 2.3209465. Sequentialb692dd65's hyper parameters: Current learning rate is 9.652509652509653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 4864/60000][Iteration 38][Wall Clock 7.330529943s] Trained 128 records in 0.144450978 seconds. Throughput is 886.1138 records/second. Loss is 2.320584. Sequentialb692dd65's hyper parameters: Current learning rate is 9.643201542912248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 4992/60000][Iteration 39][Wall Clock 7.505681703s] Trained 128 records in 0.17515176 seconds. Throughput is 730.7948 records/second. Loss is 2.2977283. Sequentialb692dd65's hyper parameters: Current learning rate is 9.633911368015414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 5120/60000][Iteration 40][Wall Clock 7.654000602s] Trained 128 records in 0.148318899 seconds. Throughput is 863.0053 records/second. Loss is 2.3145177. Sequentialb692dd65's hyper parameters: Current learning rate is 9.624639076034649E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 5248/60000][Iteration 41][Wall Clock 7.809592559s] Trained 128 records in 0.155591957 seconds. Throughput is 822.6647 records/second. Loss is 2.3048892. Sequentialb692dd65's hyper parameters: Current learning rate is 9.615384615384615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 5376/60000][Iteration 42][Wall Clock 7.939342144s] Trained 128 records in 0.129749585 seconds. Throughput is 986.5157 records/second. Loss is 2.3186257. Sequentialb692dd65's hyper parameters: Current learning rate is 9.606147934678195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 5504/60000][Iteration 43][Wall Clock 8.079937386s] Trained 128 records in 0.140595242 seconds. Throughput is 910.41486 records/second. Loss is 2.2966003. Sequentialb692dd65's hyper parameters: Current learning rate is 9.596928982725527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:30 INFO  DistriOptimizer$:408 - [Epoch 1 5632/60000][Iteration 44][Wall Clock 8.230141892s] Trained 128 records in 0.150204506 seconds. Throughput is 852.1715 records/second. Loss is 2.3074446. Sequentialb692dd65's hyper parameters: Current learning rate is 9.587727708533078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 5760/60000][Iteration 45][Wall Clock 8.371698724s] Trained 128 records in 0.141556832 seconds. Throughput is 904.23047 records/second. Loss is 2.3021667. Sequentialb692dd65's hyper parameters: Current learning rate is 9.578544061302681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 5888/60000][Iteration 46][Wall Clock 8.484035068s] Trained 128 records in 0.112336344 seconds. Throughput is 1139.4353 records/second. Loss is 2.3051817. Sequentialb692dd65's hyper parameters: Current learning rate is 9.569377990430623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 6016/60000][Iteration 47][Wall Clock 8.604709015s] Trained 128 records in 0.120673947 seconds. Throughput is 1060.7095 records/second. Loss is 2.3009439. Sequentialb692dd65's hyper parameters: Current learning rate is 9.560229445506692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 6144/60000][Iteration 48][Wall Clock 8.756682624s] Trained 128 records in 0.151973609 seconds. Throughput is 842.2515 records/second. Loss is 2.3087003. Sequentialb692dd65's hyper parameters: Current learning rate is 9.551098376313277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 6272/60000][Iteration 49][Wall Clock 8.911429372s] Trained 128 records in 0.154746748 seconds. Throughput is 827.15796 records/second. Loss is 2.3169687. Sequentialb692dd65's hyper parameters: Current learning rate is 9.541984732824427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 6400/60000][Iteration 50][Wall Clock 9.034893697s] Trained 128 records in 0.123464325 seconds. Throughput is 1036.7367 records/second. Loss is 2.3231173. Sequentialb692dd65's hyper parameters: Current learning rate is 9.532888465204958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:31 INFO  DistriOptimizer$:408 - [Epoch 1 6528/60000][Iteration 51][Wall Clock 9.181509515s] Trained 128 records in 0.146615818 seconds. Throughput is 873.02997 records/second. Loss is 2.3221798. Sequentialb692dd65's hyper parameters: Current learning rate is 9.523809523809524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 6656/60000][Iteration 52][Wall Clock 9.342904056s] Trained 128 records in 0.161394541 seconds. Throughput is 793.0876 records/second. Loss is 2.3073373. Sequentialb692dd65's hyper parameters: Current learning rate is 9.514747859181732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 6784/60000][Iteration 53][Wall Clock 9.471276724s] Trained 128 records in 0.128372668 seconds. Throughput is 997.097 records/second. Loss is 2.307528. Sequentialb692dd65's hyper parameters: Current learning rate is 9.505703422053232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 6912/60000][Iteration 54][Wall Clock 9.593695213s] Trained 128 records in 0.122418489 seconds. Throughput is 1045.5938 records/second. Loss is 2.3302574. Sequentialb692dd65's hyper parameters: Current learning rate is 9.49667616334283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 7040/60000][Iteration 55][Wall Clock 9.723323933s] Trained 128 records in 0.12962872 seconds. Throughput is 987.43555 records/second. Loss is 2.278697. Sequentialb692dd65's hyper parameters: Current learning rate is 9.487666034155598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 7168/60000][Iteration 56][Wall Clock 9.86498375s] Trained 128 records in 0.141659817 seconds. Throughput is 903.5731 records/second. Loss is 2.319442. Sequentialb692dd65's hyper parameters: Current learning rate is 9.478672985781991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 7296/60000][Iteration 57][Wall Clock 10.012707982s] Trained 128 records in 0.147724232 seconds. Throughput is 866.47943 records/second. Loss is 2.299793. Sequentialb692dd65's hyper parameters: Current learning rate is 9.46969696969697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 7424/60000][Iteration 58][Wall Clock 10.142392663s] Trained 128 records in 0.129684681 seconds. Throughput is 987.00934 records/second. Loss is 2.3034344. Sequentialb692dd65's hyper parameters: Current learning rate is 9.460737937559131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:32 INFO  DistriOptimizer$:408 - [Epoch 1 7552/60000][Iteration 59][Wall Clock 10.259340126s] Trained 128 records in 0.116947463 seconds. Throughput is 1094.5085 records/second. Loss is 2.3040724. Sequentialb692dd65's hyper parameters: Current learning rate is 9.45179584120983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 7680/60000][Iteration 60][Wall Clock 10.411000397s] Trained 128 records in 0.151660271 seconds. Throughput is 843.9916 records/second. Loss is 2.3015542. Sequentialb692dd65's hyper parameters: Current learning rate is 9.442870632672333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 7808/60000][Iteration 61][Wall Clock 10.531172656s] Trained 128 records in 0.120172259 seconds. Throughput is 1065.1377 records/second. Loss is 2.3349483. Sequentialb692dd65's hyper parameters: Current learning rate is 9.433962264150943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 7936/60000][Iteration 62][Wall Clock 10.653817837s] Trained 128 records in 0.122645181 seconds. Throughput is 1043.661 records/second. Loss is 2.3092105. Sequentialb692dd65's hyper parameters: Current learning rate is 9.425070688030161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 8064/60000][Iteration 63][Wall Clock 10.804533859s] Trained 128 records in 0.150716022 seconds. Throughput is 849.2793 records/second. Loss is 2.304009. Sequentialb692dd65's hyper parameters: Current learning rate is 9.416195856873823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 8192/60000][Iteration 64][Wall Clock 10.949058728s] Trained 128 records in 0.144524869 seconds. Throughput is 885.6607 records/second. Loss is 2.3145654. Sequentialb692dd65's hyper parameters: Current learning rate is 9.407337723424271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 8320/60000][Iteration 65][Wall Clock 11.059204055s] Trained 128 records in 0.110145327 seconds. Throughput is 1162.101 records/second. Loss is 2.3079453. Sequentialb692dd65's hyper parameters: Current learning rate is 9.398496240601503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 8448/60000][Iteration 66][Wall Clock 11.179941606s] Trained 128 records in 0.120737551 seconds. Throughput is 1060.1506 records/second. Loss is 2.3110285. Sequentialb692dd65's hyper parameters: Current learning rate is 9.389671361502348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:33 INFO  DistriOptimizer$:408 - [Epoch 1 8576/60000][Iteration 67][Wall Clock 11.289087718s] Trained 128 records in 0.109146112 seconds. Throughput is 1172.7399 records/second. Loss is 2.3175004. Sequentialb692dd65's hyper parameters: Current learning rate is 9.380863039399625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 8704/60000][Iteration 68][Wall Clock 11.404618983s] Trained 128 records in 0.115531265 seconds. Throughput is 1107.9252 records/second. Loss is 2.299205. Sequentialb692dd65's hyper parameters: Current learning rate is 9.372071227741331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 8832/60000][Iteration 69][Wall Clock 11.528047299s] Trained 128 records in 0.123428316 seconds. Throughput is 1037.0392 records/second. Loss is 2.3188858. Sequentialb692dd65's hyper parameters: Current learning rate is 9.363295880149813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 8960/60000][Iteration 70][Wall Clock 11.675032413s] Trained 128 records in 0.146985114 seconds. Throughput is 870.8365 records/second. Loss is 2.3090062. Sequentialb692dd65's hyper parameters: Current learning rate is 9.354536950420954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 9088/60000][Iteration 71][Wall Clock 11.825162371s] Trained 128 records in 0.150129958 seconds. Throughput is 852.59467 records/second. Loss is 2.3020341. Sequentialb692dd65's hyper parameters: Current learning rate is 9.345794392523364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 9216/60000][Iteration 72][Wall Clock 11.938571s] Trained 128 records in 0.113408629 seconds. Throughput is 1128.6619 records/second. Loss is 2.3110623. Sequentialb692dd65's hyper parameters: Current learning rate is 9.337068160597573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 9344/60000][Iteration 73][Wall Clock 12.072894658s] Trained 128 records in 0.134323658 seconds. Throughput is 952.92224 records/second. Loss is 2.3038943. Sequentialb692dd65's hyper parameters: Current learning rate is 9.328358208955224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:34 INFO  DistriOptimizer$:408 - [Epoch 1 9472/60000][Iteration 74][Wall Clock 12.204670884s] Trained 128 records in 0.131776226 seconds. Throughput is 971.3436 records/second. Loss is 2.309059. Sequentialb692dd65's hyper parameters: Current learning rate is 9.319664492078286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 9600/60000][Iteration 75][Wall Clock 12.307947247s] Trained 128 records in 0.103276363 seconds. Throughput is 1239.393 records/second. Loss is 2.3073442. Sequentialb692dd65's hyper parameters: Current learning rate is 9.31098696461825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 9728/60000][Iteration 76][Wall Clock 12.42210588s] Trained 128 records in 0.114158633 seconds. Throughput is 1121.2468 records/second. Loss is 2.309974. Sequentialb692dd65's hyper parameters: Current learning rate is 9.302325581395349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 9856/60000][Iteration 77][Wall Clock 12.560458419s] Trained 128 records in 0.138352539 seconds. Throughput is 925.1727 records/second. Loss is 2.3129532. Sequentialb692dd65's hyper parameters: Current learning rate is 9.293680297397769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 9984/60000][Iteration 78][Wall Clock 12.686172789s] Trained 128 records in 0.12571437 seconds. Throughput is 1018.1811 records/second. Loss is 2.323327. Sequentialb692dd65's hyper parameters: Current learning rate is 9.285051067780873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 10112/60000][Iteration 79][Wall Clock 12.785992479s] Trained 128 records in 0.09981969 seconds. Throughput is 1282.3121 records/second. Loss is 2.3438575. Sequentialb692dd65's hyper parameters: Current learning rate is 9.276437847866418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 10240/60000][Iteration 80][Wall Clock 12.898512127s] Trained 128 records in 0.112519648 seconds. Throughput is 1137.5791 records/second. Loss is 2.2995825. Sequentialb692dd65's hyper parameters: Current learning rate is 9.267840593141798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 10368/60000][Iteration 81][Wall Clock 13.010771207s] Trained 128 records in 0.11225908 seconds. Throughput is 1140.2196 records/second. Loss is 2.3191056. Sequentialb692dd65's hyper parameters: Current learning rate is 9.259259259259259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 10496/60000][Iteration 82][Wall Clock 13.134551813s] Trained 128 records in 0.123780606 seconds. Throughput is 1034.0876 records/second. Loss is 2.2951748. Sequentialb692dd65's hyper parameters: Current learning rate is 9.250693802035153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:35 INFO  DistriOptimizer$:408 - [Epoch 1 10624/60000][Iteration 83][Wall Clock 13.267452078s] Trained 128 records in 0.132900265 seconds. Throughput is 963.12823 records/second. Loss is 2.301063. Sequentialb692dd65's hyper parameters: Current learning rate is 9.242144177449168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 10752/60000][Iteration 84][Wall Clock 13.405579829s] Trained 128 records in 0.138127751 seconds. Throughput is 926.6784 records/second. Loss is 2.2974913. Sequentialb692dd65's hyper parameters: Current learning rate is 9.233610341643583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 10880/60000][Iteration 85][Wall Clock 13.524445134s] Trained 128 records in 0.118865305 seconds. Throughput is 1076.8491 records/second. Loss is 2.2953374. Sequentialb692dd65's hyper parameters: Current learning rate is 9.225092250922509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11008/60000][Iteration 86][Wall Clock 13.667532454s] Trained 128 records in 0.14308732 seconds. Throughput is 894.5587 records/second. Loss is 2.313277. Sequentialb692dd65's hyper parameters: Current learning rate is 9.216589861751152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11136/60000][Iteration 87][Wall Clock 13.784858494s] Trained 128 records in 0.11732604 seconds. Throughput is 1090.9769 records/second. Loss is 2.298991. Sequentialb692dd65's hyper parameters: Current learning rate is 9.208103130755064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11264/60000][Iteration 88][Wall Clock 13.894158083s] Trained 128 records in 0.109299589 seconds. Throughput is 1171.0931 records/second. Loss is 2.3197703. Sequentialb692dd65's hyper parameters: Current learning rate is 9.199632014719412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11392/60000][Iteration 89][Wall Clock 14.015132714s] Trained 128 records in 0.120974631 seconds. Throughput is 1058.0731 records/second. Loss is 2.2972538. Sequentialb692dd65's hyper parameters: Current learning rate is 9.191176470588235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11520/60000][Iteration 90][Wall Clock 14.12390892s] Trained 128 records in 0.108776206 seconds. Throughput is 1176.7279 records/second. Loss is 2.3206248. Sequentialb692dd65's hyper parameters: Current learning rate is 9.182736455463729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:36 INFO  DistriOptimizer$:408 - [Epoch 1 11648/60000][Iteration 91][Wall Clock 14.244435934s] Trained 128 records in 0.120527014 seconds. Throughput is 1062.0026 records/second. Loss is 2.2988162. Sequentialb692dd65's hyper parameters: Current learning rate is 9.174311926605504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 11776/60000][Iteration 92][Wall Clock 14.369356594s] Trained 128 records in 0.12492066 seconds. Throughput is 1024.6504 records/second. Loss is 2.3130333. Sequentialb692dd65's hyper parameters: Current learning rate is 9.165902841429881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 11904/60000][Iteration 93][Wall Clock 14.471049066s] Trained 128 records in 0.101692472 seconds. Throughput is 1258.6969 records/second. Loss is 2.3027124. Sequentialb692dd65's hyper parameters: Current learning rate is 9.157509157509158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12032/60000][Iteration 94][Wall Clock 14.57706869s] Trained 128 records in 0.106019624 seconds. Throughput is 1207.3236 records/second. Loss is 2.2982304. Sequentialb692dd65's hyper parameters: Current learning rate is 9.149130832570906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12160/60000][Iteration 95][Wall Clock 14.677619463s] Trained 128 records in 0.100550773 seconds. Throughput is 1272.9888 records/second. Loss is 2.3089013. Sequentialb692dd65's hyper parameters: Current learning rate is 9.140767824497258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12288/60000][Iteration 96][Wall Clock 14.782473928s] Trained 128 records in 0.104854465 seconds. Throughput is 1220.7396 records/second. Loss is 2.3031375. Sequentialb692dd65's hyper parameters: Current learning rate is 9.132420091324202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12416/60000][Iteration 97][Wall Clock 14.909683232s] Trained 128 records in 0.127209304 seconds. Throughput is 1006.2157 records/second. Loss is 2.309267. Sequentialb692dd65's hyper parameters: Current learning rate is 9.124087591240876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12544/60000][Iteration 98][Wall Clock 15.015877275s] Trained 128 records in 0.106194043 seconds. Throughput is 1205.3407 records/second. Loss is 2.2995324. Sequentialb692dd65's hyper parameters: Current learning rate is 9.11577028258888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12672/60000][Iteration 99][Wall Clock 15.138714186s] Trained 128 records in 0.122836911 seconds. Throughput is 1042.0321 records/second. Loss is 2.2932618. Sequentialb692dd65's hyper parameters: Current learning rate is 9.107468123861566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:37 INFO  DistriOptimizer$:408 - [Epoch 1 12800/60000][Iteration 100][Wall Clock 15.265561977s] Trained 128 records in 0.126847791 seconds. Throughput is 1009.08344 records/second. Loss is 2.2956147. Sequentialb692dd65's hyper parameters: Current learning rate is 9.099181073703367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 12928/60000][Iteration 101][Wall Clock 15.401642783s] Trained 128 records in 0.136080806 seconds. Throughput is 940.6176 records/second. Loss is 2.2958047. Sequentialb692dd65's hyper parameters: Current learning rate is 9.090909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13056/60000][Iteration 102][Wall Clock 15.524610564s] Trained 128 records in 0.122967781 seconds. Throughput is 1040.9231 records/second. Loss is 2.2973726. Sequentialb692dd65's hyper parameters: Current learning rate is 9.082652134423252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13184/60000][Iteration 103][Wall Clock 15.627589544s] Trained 128 records in 0.10297898 seconds. Throughput is 1242.972 records/second. Loss is 2.2889624. Sequentialb692dd65's hyper parameters: Current learning rate is 9.074410163339383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13312/60000][Iteration 104][Wall Clock 15.742309902s] Trained 128 records in 0.114720358 seconds. Throughput is 1115.7566 records/second. Loss is 2.3042693. Sequentialb692dd65's hyper parameters: Current learning rate is 9.066183136899365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13440/60000][Iteration 105][Wall Clock 15.855142752s] Trained 128 records in 0.11283285 seconds. Throughput is 1134.4214 records/second. Loss is 2.314828. Sequentialb692dd65's hyper parameters: Current learning rate is 9.057971014492753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13568/60000][Iteration 106][Wall Clock 15.961035217s] Trained 128 records in 0.105892465 seconds. Throughput is 1208.7734 records/second. Loss is 2.3096418. Sequentialb692dd65's hyper parameters: Current learning rate is 9.049773755656109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13696/60000][Iteration 107][Wall Clock 16.065848989s] Trained 128 records in 0.104813772 seconds. Throughput is 1221.2136 records/second. Loss is 2.3063803. Sequentialb692dd65's hyper parameters: Current learning rate is 9.041591320072332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:38 INFO  DistriOptimizer$:408 - [Epoch 1 13824/60000][Iteration 108][Wall Clock 16.186171847s] Trained 128 records in 0.120322858 seconds. Throughput is 1063.8044 records/second. Loss is 2.3066776. Sequentialb692dd65's hyper parameters: Current learning rate is 9.03342366757001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 13952/60000][Iteration 109][Wall Clock 16.300410551s] Trained 128 records in 0.114238704 seconds. Throughput is 1120.4609 records/second. Loss is 2.304228. Sequentialb692dd65's hyper parameters: Current learning rate is 9.025270758122743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14080/60000][Iteration 110][Wall Clock 16.407086995s] Trained 128 records in 0.106676444 seconds. Throughput is 1199.89 records/second. Loss is 2.3158433. Sequentialb692dd65's hyper parameters: Current learning rate is 9.017132551848513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14208/60000][Iteration 111][Wall Clock 16.516530452s] Trained 128 records in 0.109443457 seconds. Throughput is 1169.5537 records/second. Loss is 2.296093. Sequentialb692dd65's hyper parameters: Current learning rate is 9.009009009009008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14336/60000][Iteration 112][Wall Clock 16.64720513s] Trained 128 records in 0.130674678 seconds. Throughput is 979.5318 records/second. Loss is 2.3096356. Sequentialb692dd65's hyper parameters: Current learning rate is 9.000900090009002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14464/60000][Iteration 113][Wall Clock 16.757376123s] Trained 128 records in 0.110170993 seconds. Throughput is 1161.8303 records/second. Loss is 2.3155265. Sequentialb692dd65's hyper parameters: Current learning rate is 8.992805755395683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14592/60000][Iteration 114][Wall Clock 16.86221681s] Trained 128 records in 0.104840687 seconds. Throughput is 1220.9 records/second. Loss is 2.2987947. Sequentialb692dd65's hyper parameters: Current learning rate is 8.984725965858042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14720/60000][Iteration 115][Wall Clock 16.980012912s] Trained 128 records in 0.117796102 seconds. Throughput is 1086.6234 records/second. Loss is 2.3092132. Sequentialb692dd65's hyper parameters: Current learning rate is 8.976660682226211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:39 INFO  DistriOptimizer$:408 - [Epoch 1 14848/60000][Iteration 116][Wall Clock 17.126201732s] Trained 128 records in 0.14618882 seconds. Throughput is 875.5799 records/second. Loss is 2.3083267. Sequentialb692dd65's hyper parameters: Current learning rate is 8.968609865470852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 14976/60000][Iteration 117][Wall Clock 17.273912025s] Trained 128 records in 0.147710293 seconds. Throughput is 866.56116 records/second. Loss is 2.3025863. Sequentialb692dd65's hyper parameters: Current learning rate is 8.960573476702508E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15104/60000][Iteration 118][Wall Clock 17.397610447s] Trained 128 records in 0.123698422 seconds. Throughput is 1034.7748 records/second. Loss is 2.2886648. Sequentialb692dd65's hyper parameters: Current learning rate is 8.952551477170994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15232/60000][Iteration 119][Wall Clock 17.518826375s] Trained 128 records in 0.121215928 seconds. Throughput is 1055.9669 records/second. Loss is 2.2862236. Sequentialb692dd65's hyper parameters: Current learning rate is 8.944543828264757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15360/60000][Iteration 120][Wall Clock 17.633253165s] Trained 128 records in 0.11442679 seconds. Throughput is 1118.6191 records/second. Loss is 2.3031704. Sequentialb692dd65's hyper parameters: Current learning rate is 8.936550491510277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15488/60000][Iteration 121][Wall Clock 17.755941938s] Trained 128 records in 0.122688773 seconds. Throughput is 1043.2903 records/second. Loss is 2.310268. Sequentialb692dd65's hyper parameters: Current learning rate is 8.928571428571428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15616/60000][Iteration 122][Wall Clock 17.87845024s] Trained 128 records in 0.122508302 seconds. Throughput is 1044.8271 records/second. Loss is 2.31075. Sequentialb692dd65's hyper parameters: Current learning rate is 8.920606601248885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15744/60000][Iteration 123][Wall Clock 17.994438776s] Trained 128 records in 0.115988536 seconds. Throughput is 1103.5574 records/second. Loss is 2.303003. Sequentialb692dd65's hyper parameters: Current learning rate is 8.912655971479501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 15872/60000][Iteration 124][Wall Clock 18.13469613s] Trained 128 records in 0.140257354 seconds. Throughput is 912.6081 records/second. Loss is 2.3108304. Sequentialb692dd65's hyper parameters: Current learning rate is 8.904719501335708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:40 INFO  DistriOptimizer$:408 - [Epoch 1 16000/60000][Iteration 125][Wall Clock 18.246604208s] Trained 128 records in 0.111908078 seconds. Throughput is 1143.7959 records/second. Loss is 2.2993755. Sequentialb692dd65's hyper parameters: Current learning rate is 8.896797153024911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16128/60000][Iteration 126][Wall Clock 18.356531231s] Trained 128 records in 0.109927023 seconds. Throughput is 1164.4089 records/second. Loss is 2.2978127. Sequentialb692dd65's hyper parameters: Current learning rate is 8.888888888888889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16256/60000][Iteration 127][Wall Clock 18.481882431s] Trained 128 records in 0.1253512 seconds. Throughput is 1021.131 records/second. Loss is 2.296485. Sequentialb692dd65's hyper parameters: Current learning rate is 8.880994671403199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16384/60000][Iteration 128][Wall Clock 18.618472932s] Trained 128 records in 0.136590501 seconds. Throughput is 937.10767 records/second. Loss is 2.2874644. Sequentialb692dd65's hyper parameters: Current learning rate is 8.873114463176575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16512/60000][Iteration 129][Wall Clock 18.724136294s] Trained 128 records in 0.105663362 seconds. Throughput is 1211.3944 records/second. Loss is 2.311436. Sequentialb692dd65's hyper parameters: Current learning rate is 8.865248226950354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16640/60000][Iteration 130][Wall Clock 18.825742273s] Trained 128 records in 0.101605979 seconds. Throughput is 1259.7683 records/second. Loss is 2.2928886. Sequentialb692dd65's hyper parameters: Current learning rate is 8.857395925597874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16768/60000][Iteration 131][Wall Clock 18.925844189s] Trained 128 records in 0.100101916 seconds. Throughput is 1278.6968 records/second. Loss is 2.3091338. Sequentialb692dd65's hyper parameters: Current learning rate is 8.849557522123895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 16896/60000][Iteration 132][Wall Clock 19.025326693s] Trained 128 records in 0.099482504 seconds. Throughput is 1286.6583 records/second. Loss is 2.2771466. Sequentialb692dd65's hyper parameters: Current learning rate is 8.841732979664015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 17024/60000][Iteration 133][Wall Clock 19.143036922s] Trained 128 records in 0.117710229 seconds. Throughput is 1087.4161 records/second. Loss is 2.3038821. Sequentialb692dd65's hyper parameters: Current learning rate is 8.833922261484098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:41 INFO  DistriOptimizer$:408 - [Epoch 1 17152/60000][Iteration 134][Wall Clock 19.236719189s] Trained 128 records in 0.093682267 seconds. Throughput is 1366.3204 records/second. Loss is 2.307153. Sequentialb692dd65's hyper parameters: Current learning rate is 8.8261253309797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17280/60000][Iteration 135][Wall Clock 19.338614624s] Trained 128 records in 0.101895435 seconds. Throughput is 1256.1897 records/second. Loss is 2.2910202. Sequentialb692dd65's hyper parameters: Current learning rate is 8.818342151675486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17408/60000][Iteration 136][Wall Clock 19.439190921s] Trained 128 records in 0.100576297 seconds. Throughput is 1272.6656 records/second. Loss is 2.3156345. Sequentialb692dd65's hyper parameters: Current learning rate is 8.81057268722467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17536/60000][Iteration 137][Wall Clock 19.554245275s] Trained 128 records in 0.115054354 seconds. Throughput is 1112.5177 records/second. Loss is 2.288474. Sequentialb692dd65's hyper parameters: Current learning rate is 8.80281690140845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17664/60000][Iteration 138][Wall Clock 19.656513946s] Trained 128 records in 0.102268671 seconds. Throughput is 1251.6052 records/second. Loss is 2.3021784. Sequentialb692dd65's hyper parameters: Current learning rate is 8.795074758135445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17792/60000][Iteration 139][Wall Clock 19.758677092s] Trained 128 records in 0.102163146 seconds. Throughput is 1252.8981 records/second. Loss is 2.3030655. Sequentialb692dd65's hyper parameters: Current learning rate is 8.787346221441125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 17920/60000][Iteration 140][Wall Clock 19.862500092s] Trained 128 records in 0.103823 seconds. Throughput is 1232.8674 records/second. Loss is 2.2904494. Sequentialb692dd65's hyper parameters: Current learning rate is 8.77963125548727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 18048/60000][Iteration 141][Wall Clock 19.959008179s] Trained 128 records in 0.096508087 seconds. Throughput is 1326.3137 records/second. Loss is 2.2991004. Sequentialb692dd65's hyper parameters: Current learning rate is 8.771929824561403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 18176/60000][Iteration 142][Wall Clock 20.065685688s] Trained 128 records in 0.106677509 seconds. Throughput is 1199.878 records/second. Loss is 2.3032663. Sequentialb692dd65's hyper parameters: Current learning rate is 8.764241893076249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:42 INFO  DistriOptimizer$:408 - [Epoch 1 18304/60000][Iteration 143][Wall Clock 20.170034546s] Trained 128 records in 0.104348858 seconds. Throughput is 1226.6545 records/second. Loss is 2.2985508. Sequentialb692dd65's hyper parameters: Current learning rate is 8.756567425569178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 18432/60000][Iteration 144][Wall Clock 20.275943663s] Trained 128 records in 0.105909117 seconds. Throughput is 1208.5834 records/second. Loss is 2.3037548. Sequentialb692dd65's hyper parameters: Current learning rate is 8.748906386701663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 18560/60000][Iteration 145][Wall Clock 20.379392452s] Trained 128 records in 0.103448789 seconds. Throughput is 1237.3273 records/second. Loss is 2.3064137. Sequentialb692dd65's hyper parameters: Current learning rate is 8.74125874125874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 18688/60000][Iteration 146][Wall Clock 20.48453841s] Trained 128 records in 0.105145958 seconds. Throughput is 1217.3553 records/second. Loss is 2.2980917. Sequentialb692dd65's hyper parameters: Current learning rate is 8.733624454148472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 18816/60000][Iteration 147][Wall Clock 20.603855056s] Trained 128 records in 0.119316646 seconds. Throughput is 1072.7758 records/second. Loss is 2.3003886. Sequentialb692dd65's hyper parameters: Current learning rate is 8.726003490401397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 18944/60000][Iteration 148][Wall Clock 20.707715279s] Trained 128 records in 0.103860223 seconds. Throughput is 1232.4257 records/second. Loss is 2.2917633. Sequentialb692dd65's hyper parameters: Current learning rate is 8.718395815170009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 19072/60000][Iteration 149][Wall Clock 20.814899849s] Trained 128 records in 0.10718457 seconds. Throughput is 1194.2018 records/second. Loss is 2.2864714. Sequentialb692dd65's hyper parameters: Current learning rate is 8.710801393728224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 19200/60000][Iteration 150][Wall Clock 20.917647934s] Trained 128 records in 0.102748085 seconds. Throughput is 1245.7653 records/second. Loss is 2.2989266. Sequentialb692dd65's hyper parameters: Current learning rate is 8.703220191470844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 19328/60000][Iteration 151][Wall Clock 21.029910428s] Trained 128 records in 0.112262494 seconds. Throughput is 1140.1849 records/second. Loss is 2.2979074. Sequentialb692dd65's hyper parameters: Current learning rate is 8.695652173913044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 19456/60000][Iteration 152][Wall Clock 21.127298269s] Trained 128 records in 0.097387841 seconds. Throughput is 1314.3324 records/second. Loss is 2.2990627. Sequentialb692dd65's hyper parameters: Current learning rate is 8.688097306689834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:43 INFO  DistriOptimizer$:408 - [Epoch 1 19584/60000][Iteration 153][Wall Clock 21.222839837s] Trained 128 records in 0.095541568 seconds. Throughput is 1339.731 records/second. Loss is 2.2947612. Sequentialb692dd65's hyper parameters: Current learning rate is 8.680555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 19712/60000][Iteration 154][Wall Clock 21.325936567s] Trained 128 records in 0.10309673 seconds. Throughput is 1241.5525 records/second. Loss is 2.3048022. Sequentialb692dd65's hyper parameters: Current learning rate is 8.673026886383347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 19840/60000][Iteration 155][Wall Clock 21.421914291s] Trained 128 records in 0.095977724 seconds. Throughput is 1333.6428 records/second. Loss is 2.299146. Sequentialb692dd65's hyper parameters: Current learning rate is 8.665511265164645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 19968/60000][Iteration 156][Wall Clock 21.526292428s] Trained 128 records in 0.104378137 seconds. Throughput is 1226.3104 records/second. Loss is 2.286179. Sequentialb692dd65's hyper parameters: Current learning rate is 8.658008658008658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20096/60000][Iteration 157][Wall Clock 21.623583601s] Trained 128 records in 0.097291173 seconds. Throughput is 1315.6384 records/second. Loss is 2.3017719. Sequentialb692dd65's hyper parameters: Current learning rate is 8.65051903114187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20224/60000][Iteration 158][Wall Clock 21.735469495s] Trained 128 records in 0.111885894 seconds. Throughput is 1144.0227 records/second. Loss is 2.2893736. Sequentialb692dd65's hyper parameters: Current learning rate is 8.64304235090752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20352/60000][Iteration 159][Wall Clock 21.841075321s] Trained 128 records in 0.105605826 seconds. Throughput is 1212.0543 records/second. Loss is 2.2876782. Sequentialb692dd65's hyper parameters: Current learning rate is 8.635578583765113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20480/60000][Iteration 160][Wall Clock 21.953102973s] Trained 128 records in 0.112027652 seconds. Throughput is 1142.5751 records/second. Loss is 2.2860422. Sequentialb692dd65's hyper parameters: Current learning rate is 8.628127696289905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20608/60000][Iteration 161][Wall Clock 22.052990456s] Trained 128 records in 0.099887483 seconds. Throughput is 1281.4419 records/second. Loss is 2.2897916. Sequentialb692dd65's hyper parameters: Current learning rate is 8.620689655172415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:44 INFO  DistriOptimizer$:408 - [Epoch 1 20736/60000][Iteration 162][Wall Clock 22.149969035s] Trained 128 records in 0.096978579 seconds. Throughput is 1319.879 records/second. Loss is 2.2999284. Sequentialb692dd65's hyper parameters: Current learning rate is 8.613264427217916E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 20864/60000][Iteration 163][Wall Clock 22.248469209s] Trained 128 records in 0.098500174 seconds. Throughput is 1299.49 records/second. Loss is 2.2859628. Sequentialb692dd65's hyper parameters: Current learning rate is 8.605851979345956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 20992/60000][Iteration 164][Wall Clock 22.348321993s] Trained 128 records in 0.099852784 seconds. Throughput is 1281.8871 records/second. Loss is 2.292561. Sequentialb692dd65's hyper parameters: Current learning rate is 8.598452278589854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21120/60000][Iteration 165][Wall Clock 22.473425417s] Trained 128 records in 0.125103424 seconds. Throughput is 1023.1534 records/second. Loss is 2.2978475. Sequentialb692dd65's hyper parameters: Current learning rate is 8.591065292096221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21248/60000][Iteration 166][Wall Clock 22.570873046s] Trained 128 records in 0.097447629 seconds. Throughput is 1313.5261 records/second. Loss is 2.282114. Sequentialb692dd65's hyper parameters: Current learning rate is 8.583690987124463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21376/60000][Iteration 167][Wall Clock 22.678144188s] Trained 128 records in 0.107271142 seconds. Throughput is 1193.2379 records/second. Loss is 2.2940655. Sequentialb692dd65's hyper parameters: Current learning rate is 8.576329331046313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21504/60000][Iteration 168][Wall Clock 22.801045254s] Trained 128 records in 0.122901066 seconds. Throughput is 1041.4882 records/second. Loss is 2.3000817. Sequentialb692dd65's hyper parameters: Current learning rate is 8.568980291345329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21632/60000][Iteration 169][Wall Clock 22.896770367s] Trained 128 records in 0.095725113 seconds. Throughput is 1337.1622 records/second. Loss is 2.2822132. Sequentialb692dd65's hyper parameters: Current learning rate is 8.561643835616439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21760/60000][Iteration 170][Wall Clock 23.016445236s] Trained 128 records in 0.119674869 seconds. Throughput is 1069.5646 records/second. Loss is 2.311716. Sequentialb692dd65's hyper parameters: Current learning rate is 8.55431993156544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:45 INFO  DistriOptimizer$:408 - [Epoch 1 21888/60000][Iteration 171][Wall Clock 23.117080082s] Trained 128 records in 0.100634846 seconds. Throughput is 1271.9253 records/second. Loss is 2.2993226. Sequentialb692dd65's hyper parameters: Current learning rate is 8.547008547008548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22016/60000][Iteration 172][Wall Clock 23.234670781s] Trained 128 records in 0.117590699 seconds. Throughput is 1088.5215 records/second. Loss is 2.304604. Sequentialb692dd65's hyper parameters: Current learning rate is 8.539709649871904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22144/60000][Iteration 173][Wall Clock 23.337868812s] Trained 128 records in 0.103198031 seconds. Throughput is 1240.3337 records/second. Loss is 2.2934363. Sequentialb692dd65's hyper parameters: Current learning rate is 8.532423208191127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22272/60000][Iteration 174][Wall Clock 23.440647045s] Trained 128 records in 0.102778233 seconds. Throughput is 1245.3999 records/second. Loss is 2.3062894. Sequentialb692dd65's hyper parameters: Current learning rate is 8.525149190110827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22400/60000][Iteration 175][Wall Clock 23.546172931s] Trained 128 records in 0.105525886 seconds. Throughput is 1212.9725 records/second. Loss is 2.296922. Sequentialb692dd65's hyper parameters: Current learning rate is 8.517887563884158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22528/60000][Iteration 176][Wall Clock 23.644318517s] Trained 128 records in 0.098145586 seconds. Throughput is 1304.1849 records/second. Loss is 2.2794437. Sequentialb692dd65's hyper parameters: Current learning rate is 8.51063829787234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22656/60000][Iteration 177][Wall Clock 23.744364482s] Trained 128 records in 0.100045965 seconds. Throughput is 1279.412 records/second. Loss is 2.2839487. Sequentialb692dd65's hyper parameters: Current learning rate is 8.503401360544218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22784/60000][Iteration 178][Wall Clock 23.846593545s] Trained 128 records in 0.102229063 seconds. Throughput is 1252.0901 records/second. Loss is 2.2897472. Sequentialb692dd65's hyper parameters: Current learning rate is 8.496176720475786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 22912/60000][Iteration 179][Wall Clock 23.957566196s] Trained 128 records in 0.110972651 seconds. Throughput is 1153.4374 records/second. Loss is 2.2828786. Sequentialb692dd65's hyper parameters: Current learning rate is 8.488964346349746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 23040/60000][Iteration 180][Wall Clock 24.067137845s] Trained 128 records in 0.109571649 seconds. Throughput is 1168.1854 records/second. Loss is 2.2949364. Sequentialb692dd65's hyper parameters: Current learning rate is 8.481764206955047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:46 INFO  DistriOptimizer$:408 - [Epoch 1 23168/60000][Iteration 181][Wall Clock 24.17121317s] Trained 128 records in 0.104075325 seconds. Throughput is 1229.8784 records/second. Loss is 2.2987556. Sequentialb692dd65's hyper parameters: Current learning rate is 8.474576271186442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23296/60000][Iteration 182][Wall Clock 24.282829086s] Trained 128 records in 0.111615916 seconds. Throughput is 1146.7898 records/second. Loss is 2.2939892. Sequentialb692dd65's hyper parameters: Current learning rate is 8.46740050804403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23424/60000][Iteration 183][Wall Clock 24.393637263s] Trained 128 records in 0.110808177 seconds. Throughput is 1155.1494 records/second. Loss is 2.2954614. Sequentialb692dd65's hyper parameters: Current learning rate is 8.460236886632827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23552/60000][Iteration 184][Wall Clock 24.513231765s] Trained 128 records in 0.119594502 seconds. Throughput is 1070.2833 records/second. Loss is 2.3185573. Sequentialb692dd65's hyper parameters: Current learning rate is 8.453085376162299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23680/60000][Iteration 185][Wall Clock 24.619732719s] Trained 128 records in 0.106500954 seconds. Throughput is 1201.8672 records/second. Loss is 2.2883549. Sequentialb692dd65's hyper parameters: Current learning rate is 8.445945945945946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23808/60000][Iteration 186][Wall Clock 24.727162169s] Trained 128 records in 0.10742945 seconds. Throughput is 1191.4796 records/second. Loss is 2.2924473. Sequentialb692dd65's hyper parameters: Current learning rate is 8.438818565400844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 23936/60000][Iteration 187][Wall Clock 24.837970006s] Trained 128 records in 0.110807837 seconds. Throughput is 1155.153 records/second. Loss is 2.2738824. Sequentialb692dd65's hyper parameters: Current learning rate is 8.431703204047218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 24064/60000][Iteration 188][Wall Clock 24.940844066s] Trained 128 records in 0.10287406 seconds. Throughput is 1244.2397 records/second. Loss is 2.2893188. Sequentialb692dd65's hyper parameters: Current learning rate is 8.424599831508003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 24192/60000][Iteration 189][Wall Clock 25.041841907s] Trained 128 records in 0.100997841 seconds. Throughput is 1267.3538 records/second. Loss is 2.2808144. Sequentialb692dd65's hyper parameters: Current learning rate is 8.417508417508418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:47 INFO  DistriOptimizer$:408 - [Epoch 1 24320/60000][Iteration 190][Wall Clock 25.145097352s] Trained 128 records in 0.103255445 seconds. Throughput is 1239.644 records/second. Loss is 2.2837915. Sequentialb692dd65's hyper parameters: Current learning rate is 8.410428931875525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 24448/60000][Iteration 191][Wall Clock 25.238580725s] Trained 128 records in 0.093483373 seconds. Throughput is 1369.2274 records/second. Loss is 2.3088987. Sequentialb692dd65's hyper parameters: Current learning rate is 8.403361344537816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 24576/60000][Iteration 192][Wall Clock 25.360363867s] Trained 128 records in 0.121783142 seconds. Throughput is 1051.0486 records/second. Loss is 2.293327. Sequentialb692dd65's hyper parameters: Current learning rate is 8.396305625524769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 24704/60000][Iteration 193][Wall Clock 25.458902008s] Trained 128 records in 0.098538141 seconds. Throughput is 1298.9894 records/second. Loss is 2.2887816. Sequentialb692dd65's hyper parameters: Current learning rate is 8.389261744966444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 24832/60000][Iteration 194][Wall Clock 25.556466801s] Trained 128 records in 0.097564793 seconds. Throughput is 1311.9486 records/second. Loss is 2.2991912. Sequentialb692dd65's hyper parameters: Current learning rate is 8.382229673093043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 24960/60000][Iteration 195][Wall Clock 25.67156457s] Trained 128 records in 0.115097769 seconds. Throughput is 1112.098 records/second. Loss is 2.2777777. Sequentialb692dd65's hyper parameters: Current learning rate is 8.375209380234506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 25088/60000][Iteration 196][Wall Clock 25.766798235s] Trained 128 records in 0.095233665 seconds. Throughput is 1344.0625 records/second. Loss is 2.289393. Sequentialb692dd65's hyper parameters: Current learning rate is 8.368200836820083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 25216/60000][Iteration 197][Wall Clock 25.860575333s] Trained 128 records in 0.093777098 seconds. Throughput is 1364.9388 records/second. Loss is 2.277482. Sequentialb692dd65's hyper parameters: Current learning rate is 8.361204013377927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 25344/60000][Iteration 198][Wall Clock 25.958801121s] Trained 128 records in 0.098225788 seconds. Throughput is 1303.1201 records/second. Loss is 2.295294. Sequentialb692dd65's hyper parameters: Current learning rate is 8.35421888053467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 25472/60000][Iteration 199][Wall Clock 26.057591706s] Trained 128 records in 0.098790585 seconds. Throughput is 1295.67 records/second. Loss is 2.2798357. Sequentialb692dd65's hyper parameters: Current learning rate is 8.347245409015025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:48 INFO  DistriOptimizer$:408 - [Epoch 1 25600/60000][Iteration 200][Wall Clock 26.153076039s] Trained 128 records in 0.095484333 seconds. Throughput is 1340.534 records/second. Loss is 2.287803. Sequentialb692dd65's hyper parameters: Current learning rate is 8.340283569641367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 25728/60000][Iteration 201][Wall Clock 26.250549869s] Trained 128 records in 0.09747383 seconds. Throughput is 1313.173 records/second. Loss is 2.2820458. Sequentialb692dd65's hyper parameters: Current learning rate is 8.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 25856/60000][Iteration 202][Wall Clock 26.346965739s] Trained 128 records in 0.09641587 seconds. Throughput is 1327.5823 records/second. Loss is 2.2900412. Sequentialb692dd65's hyper parameters: Current learning rate is 8.326394671107411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 25984/60000][Iteration 203][Wall Clock 26.443866757s] Trained 128 records in 0.096901018 seconds. Throughput is 1320.9355 records/second. Loss is 2.2889295. Sequentialb692dd65's hyper parameters: Current learning rate is 8.319467554076539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26112/60000][Iteration 204][Wall Clock 26.542149457s] Trained 128 records in 0.0982827 seconds. Throughput is 1302.3655 records/second. Loss is 2.2959337. Sequentialb692dd65's hyper parameters: Current learning rate is 8.312551953449709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26240/60000][Iteration 205][Wall Clock 26.635281905s] Trained 128 records in 0.093132448 seconds. Throughput is 1374.3867 records/second. Loss is 2.3025877. Sequentialb692dd65's hyper parameters: Current learning rate is 8.305647840531562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26368/60000][Iteration 206][Wall Clock 26.737832006s] Trained 128 records in 0.102550101 seconds. Throughput is 1248.1704 records/second. Loss is 2.2895398. Sequentialb692dd65's hyper parameters: Current learning rate is 8.298755186721991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26496/60000][Iteration 207][Wall Clock 26.846532606s] Trained 128 records in 0.1087006 seconds. Throughput is 1177.5464 records/second. Loss is 2.285842. Sequentialb692dd65's hyper parameters: Current learning rate is 8.291873963515755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26624/60000][Iteration 208][Wall Clock 26.947263773s] Trained 128 records in 0.100731167 seconds. Throughput is 1270.709 records/second. Loss is 2.3115182. Sequentialb692dd65's hyper parameters: Current learning rate is 8.285004142502071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26752/60000][Iteration 209][Wall Clock 27.060988437s] Trained 128 records in 0.113724664 seconds. Throughput is 1125.5254 records/second. Loss is 2.2859058. Sequentialb692dd65's hyper parameters: Current learning rate is 8.278145695364238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:49 INFO  DistriOptimizer$:408 - [Epoch 1 26880/60000][Iteration 210][Wall Clock 27.160613853s] Trained 128 records in 0.099625416 seconds. Throughput is 1284.8127 records/second. Loss is 2.2941828. Sequentialb692dd65's hyper parameters: Current learning rate is 8.271298593879239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27008/60000][Iteration 211][Wall Clock 27.25376807s] Trained 128 records in 0.093154217 seconds. Throughput is 1374.0656 records/second. Loss is 2.3242755. Sequentialb692dd65's hyper parameters: Current learning rate is 8.264462809917356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27136/60000][Iteration 212][Wall Clock 27.370768236s] Trained 128 records in 0.117000166 seconds. Throughput is 1094.0156 records/second. Loss is 2.287912. Sequentialb692dd65's hyper parameters: Current learning rate is 8.257638315441783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27264/60000][Iteration 213][Wall Clock 27.488573495s] Trained 128 records in 0.117805259 seconds. Throughput is 1086.539 records/second. Loss is 2.2826538. Sequentialb692dd65's hyper parameters: Current learning rate is 8.250825082508251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27392/60000][Iteration 214][Wall Clock 27.583438506s] Trained 128 records in 0.094865011 seconds. Throughput is 1349.2856 records/second. Loss is 2.28183. Sequentialb692dd65's hyper parameters: Current learning rate is 8.244023083264633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27520/60000][Iteration 215][Wall Clock 27.681391202s] Trained 128 records in 0.097952696 seconds. Throughput is 1306.7533 records/second. Loss is 2.2901053. Sequentialb692dd65's hyper parameters: Current learning rate is 8.237232289950577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27648/60000][Iteration 216][Wall Clock 27.78666085s] Trained 128 records in 0.105269648 seconds. Throughput is 1215.925 records/second. Loss is 2.2951484. Sequentialb692dd65's hyper parameters: Current learning rate is 8.230452674897119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27776/60000][Iteration 217][Wall Clock 27.880949987s] Trained 128 records in 0.094289137 seconds. Throughput is 1357.5265 records/second. Loss is 2.2766705. Sequentialb692dd65's hyper parameters: Current learning rate is 8.223684210526316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 27904/60000][Iteration 218][Wall Clock 27.998677322s] Trained 128 records in 0.117727335 seconds. Throughput is 1087.2582 records/second. Loss is 2.306333. Sequentialb692dd65's hyper parameters: Current learning rate is 8.216926869350862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 28032/60000][Iteration 219][Wall Clock 28.094356199s] Trained 128 records in 0.095678877 seconds. Throughput is 1337.8083 records/second. Loss is 2.29025. Sequentialb692dd65's hyper parameters: Current learning rate is 8.210180623973728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:50 INFO  DistriOptimizer$:408 - [Epoch 1 28160/60000][Iteration 220][Wall Clock 28.191463883s] Trained 128 records in 0.097107684 seconds. Throughput is 1318.1243 records/second. Loss is 2.2960675. Sequentialb692dd65's hyper parameters: Current learning rate is 8.203445447087776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28288/60000][Iteration 221][Wall Clock 28.305580248s] Trained 128 records in 0.114116365 seconds. Throughput is 1121.6621 records/second. Loss is 2.2893114. Sequentialb692dd65's hyper parameters: Current learning rate is 8.19672131147541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28416/60000][Iteration 222][Wall Clock 28.411405461s] Trained 128 records in 0.105825213 seconds. Throughput is 1209.5416 records/second. Loss is 2.3127158. Sequentialb692dd65's hyper parameters: Current learning rate is 8.190008190008189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28544/60000][Iteration 223][Wall Clock 28.506461816s] Trained 128 records in 0.095056355 seconds. Throughput is 1346.5696 records/second. Loss is 2.2917173. Sequentialb692dd65's hyper parameters: Current learning rate is 8.183306055646482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28672/60000][Iteration 224][Wall Clock 28.605770831s] Trained 128 records in 0.099309015 seconds. Throughput is 1288.9061 records/second. Loss is 2.3096902. Sequentialb692dd65's hyper parameters: Current learning rate is 8.176614881439083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28800/60000][Iteration 225][Wall Clock 28.721505776s] Trained 128 records in 0.115734945 seconds. Throughput is 1105.9755 records/second. Loss is 2.2824223. Sequentialb692dd65's hyper parameters: Current learning rate is 8.169934640522876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 28928/60000][Iteration 226][Wall Clock 28.815135165s] Trained 128 records in 0.093629389 seconds. Throughput is 1367.0922 records/second. Loss is 2.2781856. Sequentialb692dd65's hyper parameters: Current learning rate is 8.163265306122448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 29056/60000][Iteration 227][Wall Clock 28.908708408s] Trained 128 records in 0.093573243 seconds. Throughput is 1367.9125 records/second. Loss is 2.2916863. Sequentialb692dd65's hyper parameters: Current learning rate is 8.156606851549756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 29184/60000][Iteration 228][Wall Clock 29.017087987s] Trained 128 records in 0.108379579 seconds. Throughput is 1181.0343 records/second. Loss is 2.3118527. Sequentialb692dd65's hyper parameters: Current learning rate is 8.149959250203749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:51 INFO  DistriOptimizer$:408 - [Epoch 1 29312/60000][Iteration 229][Wall Clock 29.137740281s] Trained 128 records in 0.120652294 seconds. Throughput is 1060.8998 records/second. Loss is 2.2920148. Sequentialb692dd65's hyper parameters: Current learning rate is 8.143322475570033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 29440/60000][Iteration 230][Wall Clock 29.232026196s] Trained 128 records in 0.094285915 seconds. Throughput is 1357.5729 records/second. Loss is 2.2795317. Sequentialb692dd65's hyper parameters: Current learning rate is 8.136696501220504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 29568/60000][Iteration 231][Wall Clock 29.326422371s] Trained 128 records in 0.094396175 seconds. Throughput is 1355.9872 records/second. Loss is 2.27878. Sequentialb692dd65's hyper parameters: Current learning rate is 8.130081300813008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 29696/60000][Iteration 232][Wall Clock 29.420807036s] Trained 128 records in 0.094384665 seconds. Throughput is 1356.1526 records/second. Loss is 2.2827141. Sequentialb692dd65's hyper parameters: Current learning rate is 8.123476848090983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 29824/60000][Iteration 233][Wall Clock 29.516650123s] Trained 128 records in 0.095843087 seconds. Throughput is 1335.5162 records/second. Loss is 2.291384. Sequentialb692dd65's hyper parameters: Current learning rate is 8.116883116883117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 29952/60000][Iteration 234][Wall Clock 29.615682473s] Trained 128 records in 0.09903235 seconds. Throughput is 1292.507 records/second. Loss is 2.29166. Sequentialb692dd65's hyper parameters: Current learning rate is 8.110300081103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 30080/60000][Iteration 235][Wall Clock 29.738352017s] Trained 128 records in 0.122669544 seconds. Throughput is 1043.4539 records/second. Loss is 2.2953951. Sequentialb692dd65's hyper parameters: Current learning rate is 8.103727714748785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 30208/60000][Iteration 236][Wall Clock 29.839828426s] Trained 128 records in 0.101476409 seconds. Throughput is 1261.377 records/second. Loss is 2.2571032. Sequentialb692dd65's hyper parameters: Current learning rate is 8.097165991902834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 30336/60000][Iteration 237][Wall Clock 29.939000751s] Trained 128 records in 0.099172325 seconds. Throughput is 1290.6826 records/second. Loss is 2.277561. Sequentialb692dd65's hyper parameters: Current learning rate is 8.090614886731392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 30464/60000][Iteration 238][Wall Clock 30.037331687s] Trained 128 records in 0.098330936 seconds. Throughput is 1301.7267 records/second. Loss is 2.2864752. Sequentialb692dd65's hyper parameters: Current learning rate is 8.084074373484236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:52 INFO  DistriOptimizer$:408 - [Epoch 1 30592/60000][Iteration 239][Wall Clock 30.134936811s] Trained 128 records in 0.097605124 seconds. Throughput is 1311.4066 records/second. Loss is 2.2976284. Sequentialb692dd65's hyper parameters: Current learning rate is 8.077544426494346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 30720/60000][Iteration 240][Wall Clock 30.229881412s] Trained 128 records in 0.094944601 seconds. Throughput is 1348.1545 records/second. Loss is 2.2809455. Sequentialb692dd65's hyper parameters: Current learning rate is 8.071025020177562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 30848/60000][Iteration 241][Wall Clock 30.339143475s] Trained 128 records in 0.109262063 seconds. Throughput is 1171.4954 records/second. Loss is 2.2884548. Sequentialb692dd65's hyper parameters: Current learning rate is 8.064516129032258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 30976/60000][Iteration 242][Wall Clock 30.458562586s] Trained 128 records in 0.119419111 seconds. Throughput is 1071.8552 records/second. Loss is 2.2881021. Sequentialb692dd65's hyper parameters: Current learning rate is 8.058017727639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31104/60000][Iteration 243][Wall Clock 30.57627167s] Trained 128 records in 0.117709084 seconds. Throughput is 1087.4266 records/second. Loss is 2.282839. Sequentialb692dd65's hyper parameters: Current learning rate is 8.051529790660225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31232/60000][Iteration 244][Wall Clock 30.699222035s] Trained 128 records in 0.122950365 seconds. Throughput is 1041.0704 records/second. Loss is 2.2818496. Sequentialb692dd65's hyper parameters: Current learning rate is 8.045052292839904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31360/60000][Iteration 245][Wall Clock 30.823942432s] Trained 128 records in 0.124720397 seconds. Throughput is 1026.2957 records/second. Loss is 2.2969902. Sequentialb692dd65's hyper parameters: Current learning rate is 8.038585209003215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31488/60000][Iteration 246][Wall Clock 30.920523911s] Trained 128 records in 0.096581479 seconds. Throughput is 1325.3058 records/second. Loss is 2.2918265. Sequentialb692dd65's hyper parameters: Current learning rate is 8.032128514056224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31616/60000][Iteration 247][Wall Clock 31.015390402s] Trained 128 records in 0.094866491 seconds. Throughput is 1349.2646 records/second. Loss is 2.2781658. Sequentialb692dd65's hyper parameters: Current learning rate is 8.025682182985554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:53 INFO  DistriOptimizer$:408 - [Epoch 1 31744/60000][Iteration 248][Wall Clock 31.126762224s] Trained 128 records in 0.111371822 seconds. Throughput is 1149.3032 records/second. Loss is 2.292279. Sequentialb692dd65's hyper parameters: Current learning rate is 8.01924619085806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 31872/60000][Iteration 249][Wall Clock 31.281467981s] Trained 128 records in 0.154705757 seconds. Throughput is 827.3771 records/second. Loss is 2.2951605. Sequentialb692dd65's hyper parameters: Current learning rate is 8.012820512820513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32000/60000][Iteration 250][Wall Clock 31.384719632s] Trained 128 records in 0.103251651 seconds. Throughput is 1239.6896 records/second. Loss is 2.2870932. Sequentialb692dd65's hyper parameters: Current learning rate is 8.006405124099279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32128/60000][Iteration 251][Wall Clock 31.494719124s] Trained 128 records in 0.109999492 seconds. Throughput is 1163.6417 records/second. Loss is 2.2931244. Sequentialb692dd65's hyper parameters: Current learning rate is 8.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32256/60000][Iteration 252][Wall Clock 31.606088806s] Trained 128 records in 0.111369682 seconds. Throughput is 1149.3253 records/second. Loss is 2.2819347. Sequentialb692dd65's hyper parameters: Current learning rate is 7.993605115907275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32384/60000][Iteration 253][Wall Clock 31.735112918s] Trained 128 records in 0.129024112 seconds. Throughput is 992.06256 records/second. Loss is 2.2802792. Sequentialb692dd65's hyper parameters: Current learning rate is 7.987220447284345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32512/60000][Iteration 254][Wall Clock 31.844721189s] Trained 128 records in 0.109608271 seconds. Throughput is 1167.795 records/second. Loss is 2.2865877. Sequentialb692dd65's hyper parameters: Current learning rate is 7.980845969672785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32640/60000][Iteration 255][Wall Clock 31.946007856s] Trained 128 records in 0.101286667 seconds. Throughput is 1263.7399 records/second. Loss is 2.2807934. Sequentialb692dd65's hyper parameters: Current learning rate is 7.974481658692185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:54 INFO  DistriOptimizer$:408 - [Epoch 1 32768/60000][Iteration 256][Wall Clock 32.062748877s] Trained 128 records in 0.116741021 seconds. Throughput is 1096.4441 records/second. Loss is 2.2856753. Sequentialb692dd65's hyper parameters: Current learning rate is 7.968127490039842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 32896/60000][Iteration 257][Wall Clock 32.184512895s] Trained 128 records in 0.121764018 seconds. Throughput is 1051.2136 records/second. Loss is 2.3115795. Sequentialb692dd65's hyper parameters: Current learning rate is 7.961783439490446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33024/60000][Iteration 258][Wall Clock 32.278361012s] Trained 128 records in 0.093848117 seconds. Throughput is 1363.9059 records/second. Loss is 2.284857. Sequentialb692dd65's hyper parameters: Current learning rate is 7.955449482895783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33152/60000][Iteration 259][Wall Clock 32.378318664s] Trained 128 records in 0.099957652 seconds. Throughput is 1280.5422 records/second. Loss is 2.302774. Sequentialb692dd65's hyper parameters: Current learning rate is 7.94912559618442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33280/60000][Iteration 260][Wall Clock 32.478138465s] Trained 128 records in 0.099819801 seconds. Throughput is 1282.3107 records/second. Loss is 2.290394. Sequentialb692dd65's hyper parameters: Current learning rate is 7.942811755361399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33408/60000][Iteration 261][Wall Clock 32.57765201s] Trained 128 records in 0.099513545 seconds. Throughput is 1286.2571 records/second. Loss is 2.295108. Sequentialb692dd65's hyper parameters: Current learning rate is 7.936507936507937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33536/60000][Iteration 262][Wall Clock 32.670170645s] Trained 128 records in 0.092518635 seconds. Throughput is 1383.505 records/second. Loss is 2.2833128. Sequentialb692dd65's hyper parameters: Current learning rate is 7.930214115781125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33664/60000][Iteration 263][Wall Clock 32.763749276s] Trained 128 records in 0.093578631 seconds. Throughput is 1367.8336 records/second. Loss is 2.2999744. Sequentialb692dd65's hyper parameters: Current learning rate is 7.92393026941363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33792/60000][Iteration 264][Wall Clock 32.868250407s] Trained 128 records in 0.104501131 seconds. Throughput is 1224.8672 records/second. Loss is 2.290986. Sequentialb692dd65's hyper parameters: Current learning rate is 7.917656373713382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 33920/60000][Iteration 265][Wall Clock 32.960115323s] Trained 128 records in 0.091864916 seconds. Throughput is 1393.3502 records/second. Loss is 2.287145. Sequentialb692dd65's hyper parameters: Current learning rate is 7.911392405063291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 34048/60000][Iteration 266][Wall Clock 33.050176419s] Trained 128 records in 0.090061096 seconds. Throughput is 1421.2573 records/second. Loss is 2.296607. Sequentialb692dd65's hyper parameters: Current learning rate is 7.905138339920949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:55 INFO  DistriOptimizer$:408 - [Epoch 1 34176/60000][Iteration 267][Wall Clock 33.141925569s] Trained 128 records in 0.09174915 seconds. Throughput is 1395.1084 records/second. Loss is 2.281529. Sequentialb692dd65's hyper parameters: Current learning rate is 7.898894154818325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34304/60000][Iteration 268][Wall Clock 33.263906714s] Trained 128 records in 0.121981145 seconds. Throughput is 1049.3425 records/second. Loss is 2.287383. Sequentialb692dd65's hyper parameters: Current learning rate is 7.892659826361485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34432/60000][Iteration 269][Wall Clock 33.367335052s] Trained 128 records in 0.103428338 seconds. Throughput is 1237.5718 records/second. Loss is 2.2779753. Sequentialb692dd65's hyper parameters: Current learning rate is 7.886435331230284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34560/60000][Iteration 270][Wall Clock 33.460385862s] Trained 128 records in 0.09305081 seconds. Throughput is 1375.5925 records/second. Loss is 2.2691355. Sequentialb692dd65's hyper parameters: Current learning rate is 7.880220646178092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34688/60000][Iteration 271][Wall Clock 33.559628957s] Trained 128 records in 0.099243095 seconds. Throughput is 1289.7622 records/second. Loss is 2.291956. Sequentialb692dd65's hyper parameters: Current learning rate is 7.874015748031496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34816/60000][Iteration 272][Wall Clock 33.686102307s] Trained 128 records in 0.12647335 seconds. Throughput is 1012.0709 records/second. Loss is 2.2820723. Sequentialb692dd65's hyper parameters: Current learning rate is 7.867820613690009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 34944/60000][Iteration 273][Wall Clock 33.782493893s] Trained 128 records in 0.096391586 seconds. Throughput is 1327.9167 records/second. Loss is 2.2913582. Sequentialb692dd65's hyper parameters: Current learning rate is 7.861635220125787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 35072/60000][Iteration 274][Wall Clock 33.877363475s] Trained 128 records in 0.094869582 seconds. Throughput is 1349.2206 records/second. Loss is 2.2920823. Sequentialb692dd65's hyper parameters: Current learning rate is 7.855459544383346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 35200/60000][Iteration 275][Wall Clock 33.969600313s] Trained 128 records in 0.092236838 seconds. Throughput is 1387.7318 records/second. Loss is 2.2707527. Sequentialb692dd65's hyper parameters: Current learning rate is 7.849293563579278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:56 INFO  DistriOptimizer$:408 - [Epoch 1 35328/60000][Iteration 276][Wall Clock 34.08455898s] Trained 128 records in 0.114958667 seconds. Throughput is 1113.4437 records/second. Loss is 2.2729986. Sequentialb692dd65's hyper parameters: Current learning rate is 7.843137254901962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 35456/60000][Iteration 277][Wall Clock 34.201471371s] Trained 128 records in 0.116912391 seconds. Throughput is 1094.8369 records/second. Loss is 2.2841432. Sequentialb692dd65's hyper parameters: Current learning rate is 7.836990595611285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 35584/60000][Iteration 278][Wall Clock 34.291917046s] Trained 128 records in 0.090445675 seconds. Throughput is 1415.2141 records/second. Loss is 2.2734284. Sequentialb692dd65's hyper parameters: Current learning rate is 7.83085356303837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 35712/60000][Iteration 279][Wall Clock 34.382762586s] Trained 128 records in 0.09084554 seconds. Throughput is 1408.985 records/second. Loss is 2.2826684. Sequentialb692dd65's hyper parameters: Current learning rate is 7.82472613458529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 35840/60000][Iteration 280][Wall Clock 34.486263512s] Trained 128 records in 0.103500926 seconds. Throughput is 1236.704 records/second. Loss is 2.2754533. Sequentialb692dd65's hyper parameters: Current learning rate is 7.818608287724786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 35968/60000][Iteration 281][Wall Clock 34.58366097s] Trained 128 records in 0.097397458 seconds. Throughput is 1314.2026 records/second. Loss is 2.2879338. Sequentialb692dd65's hyper parameters: Current learning rate is 7.8125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36096/60000][Iteration 282][Wall Clock 34.676918131s] Trained 128 records in 0.093257161 seconds. Throughput is 1372.5488 records/second. Loss is 2.2838867. Sequentialb692dd65's hyper parameters: Current learning rate is 7.806401249024199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36224/60000][Iteration 283][Wall Clock 34.769465998s] Trained 128 records in 0.092547867 seconds. Throughput is 1383.0681 records/second. Loss is 2.2787. Sequentialb692dd65's hyper parameters: Current learning rate is 7.8003120124805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36352/60000][Iteration 284][Wall Clock 34.862846883s] Trained 128 records in 0.093380885 seconds. Throughput is 1370.7302 records/second. Loss is 2.2821107. Sequentialb692dd65's hyper parameters: Current learning rate is 7.79423226812159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36480/60000][Iteration 285][Wall Clock 34.958318364s] Trained 128 records in 0.095471481 seconds. Throughput is 1340.7146 records/second. Loss is 2.3078244. Sequentialb692dd65's hyper parameters: Current learning rate is 7.78816199376947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36608/60000][Iteration 286][Wall Clock 35.053914015s] Trained 128 records in 0.095595651 seconds. Throughput is 1338.973 records/second. Loss is 2.281252. Sequentialb692dd65's hyper parameters: Current learning rate is 7.782101167315175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:57 INFO  DistriOptimizer$:408 - [Epoch 1 36736/60000][Iteration 287][Wall Clock 35.149624652s] Trained 128 records in 0.095710637 seconds. Throughput is 1337.3644 records/second. Loss is 2.2941632. Sequentialb692dd65's hyper parameters: Current learning rate is 7.776049766718507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 36864/60000][Iteration 288][Wall Clock 35.246936407s] Trained 128 records in 0.097311755 seconds. Throughput is 1315.3601 records/second. Loss is 2.2671168. Sequentialb692dd65's hyper parameters: Current learning rate is 7.770007770007771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 36992/60000][Iteration 289][Wall Clock 35.338741588s] Trained 128 records in 0.091805181 seconds. Throughput is 1394.2568 records/second. Loss is 2.2656915. Sequentialb692dd65's hyper parameters: Current learning rate is 7.763975155279503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37120/60000][Iteration 290][Wall Clock 35.437668402s] Trained 128 records in 0.098926814 seconds. Throughput is 1293.8859 records/second. Loss is 2.2768078. Sequentialb692dd65's hyper parameters: Current learning rate is 7.757951900698217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37248/60000][Iteration 291][Wall Clock 35.531605909s] Trained 128 records in 0.093937507 seconds. Throughput is 1362.608 records/second. Loss is 2.2620778. Sequentialb692dd65's hyper parameters: Current learning rate is 7.751937984496124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37376/60000][Iteration 292][Wall Clock 35.621760972s] Trained 128 records in 0.090155063 seconds. Throughput is 1419.776 records/second. Loss is 2.2755494. Sequentialb692dd65's hyper parameters: Current learning rate is 7.74593338497289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37504/60000][Iteration 293][Wall Clock 35.718173314s] Trained 128 records in 0.096412342 seconds. Throughput is 1327.6309 records/second. Loss is 2.2692993. Sequentialb692dd65's hyper parameters: Current learning rate is 7.739938080495357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37632/60000][Iteration 294][Wall Clock 35.811969592s] Trained 128 records in 0.093796278 seconds. Throughput is 1364.6598 records/second. Loss is 2.2854762. Sequentialb692dd65's hyper parameters: Current learning rate is 7.733952049497294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37760/60000][Iteration 295][Wall Clock 35.918228081s] Trained 128 records in 0.106258489 seconds. Throughput is 1204.6096 records/second. Loss is 2.2824967. Sequentialb692dd65's hyper parameters: Current learning rate is 7.727975270479134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 37888/60000][Iteration 296][Wall Clock 36.034368037s] Trained 128 records in 0.116139956 seconds. Throughput is 1102.1185 records/second. Loss is 2.2777069. Sequentialb692dd65's hyper parameters: Current learning rate is 7.722007722007723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:58 INFO  DistriOptimizer$:408 - [Epoch 1 38016/60000][Iteration 297][Wall Clock 36.129558398s] Trained 128 records in 0.095190361 seconds. Throughput is 1344.674 records/second. Loss is 2.2637105. Sequentialb692dd65's hyper parameters: Current learning rate is 7.716049382716049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38144/60000][Iteration 298][Wall Clock 36.230734173s] Trained 128 records in 0.101175775 seconds. Throughput is 1265.125 records/second. Loss is 2.2845967. Sequentialb692dd65's hyper parameters: Current learning rate is 7.710100231303008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38272/60000][Iteration 299][Wall Clock 36.32547162s] Trained 128 records in 0.094737447 seconds. Throughput is 1351.1024 records/second. Loss is 2.295601. Sequentialb692dd65's hyper parameters: Current learning rate is 7.704160246533128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38400/60000][Iteration 300][Wall Clock 36.417711524s] Trained 128 records in 0.092239904 seconds. Throughput is 1387.6858 records/second. Loss is 2.3123024. Sequentialb692dd65's hyper parameters: Current learning rate is 7.698229407236336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38528/60000][Iteration 301][Wall Clock 36.510744186s] Trained 128 records in 0.093032662 seconds. Throughput is 1375.8608 records/second. Loss is 2.2725604. Sequentialb692dd65's hyper parameters: Current learning rate is 7.692307692307692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38656/60000][Iteration 302][Wall Clock 36.602381496s] Trained 128 records in 0.09163731 seconds. Throughput is 1396.8109 records/second. Loss is 2.2786531. Sequentialb692dd65's hyper parameters: Current learning rate is 7.686395080707148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38784/60000][Iteration 303][Wall Clock 36.713895106s] Trained 128 records in 0.11151361 seconds. Throughput is 1147.842 records/second. Loss is 2.2743905. Sequentialb692dd65's hyper parameters: Current learning rate is 7.680491551459293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 38912/60000][Iteration 304][Wall Clock 36.839526433s] Trained 128 records in 0.125631327 seconds. Throughput is 1018.8541 records/second. Loss is 2.2809267. Sequentialb692dd65's hyper parameters: Current learning rate is 7.674597083653109E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 39040/60000][Iteration 305][Wall Clock 36.929032971s] Trained 128 records in 0.089506538 seconds. Throughput is 1430.0631 records/second. Loss is 2.2626064. Sequentialb692dd65's hyper parameters: Current learning rate is 7.668711656441718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 39168/60000][Iteration 306][Wall Clock 37.023121156s] Trained 128 records in 0.094088185 seconds. Throughput is 1360.4259 records/second. Loss is 2.2766283. Sequentialb692dd65's hyper parameters: Current learning rate is 7.662835249042146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:46:59 INFO  DistriOptimizer$:408 - [Epoch 1 39296/60000][Iteration 307][Wall Clock 37.118574003s] Trained 128 records in 0.095452847 seconds. Throughput is 1340.9763 records/second. Loss is 2.2634184. Sequentialb692dd65's hyper parameters: Current learning rate is 7.656967840735069E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 39424/60000][Iteration 308][Wall Clock 37.231319324s] Trained 128 records in 0.112745321 seconds. Throughput is 1135.3021 records/second. Loss is 2.2829275. Sequentialb692dd65's hyper parameters: Current learning rate is 7.651109410864576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 39552/60000][Iteration 309][Wall Clock 37.324428728s] Trained 128 records in 0.093109404 seconds. Throughput is 1374.7268 records/second. Loss is 2.2885673. Sequentialb692dd65's hyper parameters: Current learning rate is 7.645259938837921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 39680/60000][Iteration 310][Wall Clock 37.424522344s] Trained 128 records in 0.100093616 seconds. Throughput is 1278.8029 records/second. Loss is 2.276084. Sequentialb692dd65's hyper parameters: Current learning rate is 7.639419404125287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 39808/60000][Iteration 311][Wall Clock 37.519976927s] Trained 128 records in 0.095454583 seconds. Throughput is 1340.9519 records/second. Loss is 2.296075. Sequentialb692dd65's hyper parameters: Current learning rate is 7.633587786259542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 39936/60000][Iteration 312][Wall Clock 37.613888575s] Trained 128 records in 0.093911648 seconds. Throughput is 1362.9833 records/second. Loss is 2.292039. Sequentialb692dd65's hyper parameters: Current learning rate is 7.627765064836003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 40064/60000][Iteration 313][Wall Clock 37.708961585s] Trained 128 records in 0.09507301 seconds. Throughput is 1346.3337 records/second. Loss is 2.263751. Sequentialb692dd65's hyper parameters: Current learning rate is 7.621951219512195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 40192/60000][Iteration 314][Wall Clock 37.81412369s] Trained 128 records in 0.105162105 seconds. Throughput is 1217.1685 records/second. Loss is 2.2773304. Sequentialb692dd65's hyper parameters: Current learning rate is 7.616146230007616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 40320/60000][Iteration 315][Wall Clock 37.904298841s] Trained 128 records in 0.090175151 seconds. Throughput is 1419.4597 records/second. Loss is 2.2700057. Sequentialb692dd65's hyper parameters: Current learning rate is 7.6103500761035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 40448/60000][Iteration 316][Wall Clock 37.998116336s] Trained 128 records in 0.093817495 seconds. Throughput is 1364.3511 records/second. Loss is 2.2635114. Sequentialb692dd65's hyper parameters: Current learning rate is 7.604562737642586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:00 INFO  DistriOptimizer$:408 - [Epoch 1 40576/60000][Iteration 317][Wall Clock 38.091266445s] Trained 128 records in 0.093150109 seconds. Throughput is 1374.1261 records/second. Loss is 2.2822456. Sequentialb692dd65's hyper parameters: Current learning rate is 7.598784194528875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 40704/60000][Iteration 318][Wall Clock 38.189455551s] Trained 128 records in 0.098189106 seconds. Throughput is 1303.6069 records/second. Loss is 2.2710938. Sequentialb692dd65's hyper parameters: Current learning rate is 7.593014426727411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 40832/60000][Iteration 319][Wall Clock 38.290873898s] Trained 128 records in 0.101418347 seconds. Throughput is 1262.0991 records/second. Loss is 2.2943392. Sequentialb692dd65's hyper parameters: Current learning rate is 7.587253414264037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 40960/60000][Iteration 320][Wall Clock 38.382356808s] Trained 128 records in 0.09148291 seconds. Throughput is 1399.1685 records/second. Loss is 2.2912421. Sequentialb692dd65's hyper parameters: Current learning rate is 7.58150113722517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41088/60000][Iteration 321][Wall Clock 38.493789369s] Trained 128 records in 0.111432561 seconds. Throughput is 1148.6769 records/second. Loss is 2.2686868. Sequentialb692dd65's hyper parameters: Current learning rate is 7.575757575757576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41216/60000][Iteration 322][Wall Clock 38.589770063s] Trained 128 records in 0.095980694 seconds. Throughput is 1333.6014 records/second. Loss is 2.2862706. Sequentialb692dd65's hyper parameters: Current learning rate is 7.57002271006813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41344/60000][Iteration 323][Wall Clock 38.681205585s] Trained 128 records in 0.091435522 seconds. Throughput is 1399.8936 records/second. Loss is 2.275497. Sequentialb692dd65's hyper parameters: Current learning rate is 7.564296520423601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41472/60000][Iteration 324][Wall Clock 38.773163994s] Trained 128 records in 0.091958409 seconds. Throughput is 1391.9336 records/second. Loss is 2.2919302. Sequentialb692dd65's hyper parameters: Current learning rate is 7.558578987150416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41600/60000][Iteration 325][Wall Clock 38.869649616s] Trained 128 records in 0.096485622 seconds. Throughput is 1326.6226 records/second. Loss is 2.2764277. Sequentialb692dd65's hyper parameters: Current learning rate is 7.552870090634441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41728/60000][Iteration 326][Wall Clock 38.958509229s] Trained 128 records in 0.088859613 seconds. Throughput is 1440.4745 records/second. Loss is 2.2842026. Sequentialb692dd65's hyper parameters: Current learning rate is 7.547169811320755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:01 INFO  DistriOptimizer$:408 - [Epoch 1 41856/60000][Iteration 327][Wall Clock 39.065708741s] Trained 128 records in 0.107199512 seconds. Throughput is 1194.0353 records/second. Loss is 2.2715824. Sequentialb692dd65's hyper parameters: Current learning rate is 7.541478129713424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 41984/60000][Iteration 328][Wall Clock 39.158170387s] Trained 128 records in 0.092461646 seconds. Throughput is 1384.3578 records/second. Loss is 2.2586012. Sequentialb692dd65's hyper parameters: Current learning rate is 7.535795026375283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42112/60000][Iteration 329][Wall Clock 39.249764352s] Trained 128 records in 0.091593965 seconds. Throughput is 1397.4719 records/second. Loss is 2.2779412. Sequentialb692dd65's hyper parameters: Current learning rate is 7.53012048192771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42240/60000][Iteration 330][Wall Clock 39.351969003s] Trained 128 records in 0.102204651 seconds. Throughput is 1252.3892 records/second. Loss is 2.2763186. Sequentialb692dd65's hyper parameters: Current learning rate is 7.524454477050415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42368/60000][Iteration 331][Wall Clock 39.442987341s] Trained 128 records in 0.091018338 seconds. Throughput is 1406.3099 records/second. Loss is 2.279424. Sequentialb692dd65's hyper parameters: Current learning rate is 7.518796992481202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42496/60000][Iteration 332][Wall Clock 39.531792816s] Trained 128 records in 0.088805475 seconds. Throughput is 1441.3525 records/second. Loss is 2.2852728. Sequentialb692dd65's hyper parameters: Current learning rate is 7.513148009015778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42624/60000][Iteration 333][Wall Clock 39.623738888s] Trained 128 records in 0.091946072 seconds. Throughput is 1392.1204 records/second. Loss is 2.2777896. Sequentialb692dd65's hyper parameters: Current learning rate is 7.507507507507507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42752/60000][Iteration 334][Wall Clock 39.716206689s] Trained 128 records in 0.092467801 seconds. Throughput is 1384.2656 records/second. Loss is 2.2856076. Sequentialb692dd65's hyper parameters: Current learning rate is 7.501875468867217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 42880/60000][Iteration 335][Wall Clock 39.809924949s] Trained 128 records in 0.09371826 seconds. Throughput is 1365.7958 records/second. Loss is 2.2740312. Sequentialb692dd65's hyper parameters: Current learning rate is 7.496251874062968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 43008/60000][Iteration 336][Wall Clock 39.905684988s] Trained 128 records in 0.095760039 seconds. Throughput is 1336.6744 records/second. Loss is 2.2710798. Sequentialb692dd65's hyper parameters: Current learning rate is 7.49063670411985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 43136/60000][Iteration 337][Wall Clock 39.996074718s] Trained 128 records in 0.09038973 seconds. Throughput is 1416.0901 records/second. Loss is 2.295634. Sequentialb692dd65's hyper parameters: Current learning rate is 7.48502994011976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:02 INFO  DistriOptimizer$:408 - [Epoch 1 43264/60000][Iteration 338][Wall Clock 40.085865939s] Trained 128 records in 0.089791221 seconds. Throughput is 1425.529 records/second. Loss is 2.2685287. Sequentialb692dd65's hyper parameters: Current learning rate is 7.479431563201197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 43392/60000][Iteration 339][Wall Clock 40.172687444s] Trained 128 records in 0.086821505 seconds. Throughput is 1474.2892 records/second. Loss is 2.2931333. Sequentialb692dd65's hyper parameters: Current learning rate is 7.473841554559044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 43520/60000][Iteration 340][Wall Clock 40.263476307s] Trained 128 records in 0.090788863 seconds. Throughput is 1409.8645 records/second. Loss is 2.2632468. Sequentialb692dd65's hyper parameters: Current learning rate is 7.468259895444362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 43648/60000][Iteration 341][Wall Clock 40.357181312s] Trained 128 records in 0.093705005 seconds. Throughput is 1365.9889 records/second. Loss is 2.2805102. Sequentialb692dd65's hyper parameters: Current learning rate is 7.462686567164179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 43776/60000][Iteration 342][Wall Clock 40.476001293s] Trained 128 records in 0.118819981 seconds. Throughput is 1077.2599 records/second. Loss is 2.2542648. Sequentialb692dd65's hyper parameters: Current learning rate is 7.457121551081283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 43904/60000][Iteration 343][Wall Clock 40.579718199s] Trained 128 records in 0.103716906 seconds. Throughput is 1234.1287 records/second. Loss is 2.2756295. Sequentialb692dd65's hyper parameters: Current learning rate is 7.451564828614009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44032/60000][Iteration 344][Wall Clock 40.664760302s] Trained 128 records in 0.085042103 seconds. Throughput is 1505.1368 records/second. Loss is 2.2788439. Sequentialb692dd65's hyper parameters: Current learning rate is 7.446016381236039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44160/60000][Iteration 345][Wall Clock 40.751725828s] Trained 128 records in 0.086965526 seconds. Throughput is 1471.8477 records/second. Loss is 2.2779386. Sequentialb692dd65's hyper parameters: Current learning rate is 7.44047619047619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44288/60000][Iteration 346][Wall Clock 40.839648641s] Trained 128 records in 0.087922813 seconds. Throughput is 1455.8224 records/second. Loss is 2.297511. Sequentialb692dd65's hyper parameters: Current learning rate is 7.434944237918215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44416/60000][Iteration 347][Wall Clock 40.929758137s] Trained 128 records in 0.090109496 seconds. Throughput is 1420.494 records/second. Loss is 2.2716117. Sequentialb692dd65's hyper parameters: Current learning rate is 7.429420505200594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44544/60000][Iteration 348][Wall Clock 41.018662976s] Trained 128 records in 0.088904839 seconds. Throughput is 1439.7417 records/second. Loss is 2.2669268. Sequentialb692dd65's hyper parameters: Current learning rate is 7.423904974016333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:03 INFO  DistriOptimizer$:408 - [Epoch 1 44672/60000][Iteration 349][Wall Clock 41.109895562s] Trained 128 records in 0.091232586 seconds. Throughput is 1403.0076 records/second. Loss is 2.2576168. Sequentialb692dd65's hyper parameters: Current learning rate is 7.418397626112759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 44800/60000][Iteration 350][Wall Clock 41.221902485s] Trained 128 records in 0.112006923 seconds. Throughput is 1142.7865 records/second. Loss is 2.2914364. Sequentialb692dd65's hyper parameters: Current learning rate is 7.412898443291328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 44928/60000][Iteration 351][Wall Clock 41.314567338s] Trained 128 records in 0.092664853 seconds. Throughput is 1381.322 records/second. Loss is 2.2835248. Sequentialb692dd65's hyper parameters: Current learning rate is 7.407407407407407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45056/60000][Iteration 352][Wall Clock 41.437588304s] Trained 128 records in 0.123020966 seconds. Throughput is 1040.473 records/second. Loss is 2.2727575. Sequentialb692dd65's hyper parameters: Current learning rate is 7.401924500370097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45184/60000][Iteration 353][Wall Clock 41.536471307s] Trained 128 records in 0.098883003 seconds. Throughput is 1294.4591 records/second. Loss is 2.264953. Sequentialb692dd65's hyper parameters: Current learning rate is 7.396449704142013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45312/60000][Iteration 354][Wall Clock 41.630271317s] Trained 128 records in 0.09380001 seconds. Throughput is 1364.6055 records/second. Loss is 2.2834873. Sequentialb692dd65's hyper parameters: Current learning rate is 7.390983000739098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45440/60000][Iteration 355][Wall Clock 41.72472895s] Trained 128 records in 0.094457633 seconds. Throughput is 1355.1049 records/second. Loss is 2.2784278. Sequentialb692dd65's hyper parameters: Current learning rate is 7.385524372230428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45568/60000][Iteration 356][Wall Clock 41.813676441s] Trained 128 records in 0.088947491 seconds. Throughput is 1439.0513 records/second. Loss is 2.2698174. Sequentialb692dd65's hyper parameters: Current learning rate is 7.380073800738007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45696/60000][Iteration 357][Wall Clock 41.9068637s] Trained 128 records in 0.093187259 seconds. Throughput is 1373.5784 records/second. Loss is 2.2816994. Sequentialb692dd65's hyper parameters: Current learning rate is 7.374631268436579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45824/60000][Iteration 358][Wall Clock 42.004133205s] Trained 128 records in 0.097269505 seconds. Throughput is 1315.9314 records/second. Loss is 2.2847905. Sequentialb692dd65's hyper parameters: Current learning rate is 7.369196757553427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:04 INFO  DistriOptimizer$:408 - [Epoch 1 45952/60000][Iteration 359][Wall Clock 42.101471574s] Trained 128 records in 0.097338369 seconds. Throughput is 1315.0005 records/second. Loss is 2.2691226. Sequentialb692dd65's hyper parameters: Current learning rate is 7.363770250368188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46080/60000][Iteration 360][Wall Clock 42.196438682s] Trained 128 records in 0.094967108 seconds. Throughput is 1347.8351 records/second. Loss is 2.273059. Sequentialb692dd65's hyper parameters: Current learning rate is 7.358351729212656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46208/60000][Iteration 361][Wall Clock 42.29046196s] Trained 128 records in 0.094023278 seconds. Throughput is 1361.365 records/second. Loss is 2.273384. Sequentialb692dd65's hyper parameters: Current learning rate is 7.352941176470589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46336/60000][Iteration 362][Wall Clock 42.385122763s] Trained 128 records in 0.094660803 seconds. Throughput is 1352.1964 records/second. Loss is 2.2641685. Sequentialb692dd65's hyper parameters: Current learning rate is 7.347538574577517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46464/60000][Iteration 363][Wall Clock 42.480545709s] Trained 128 records in 0.095422946 seconds. Throughput is 1341.3965 records/second. Loss is 2.2820523. Sequentialb692dd65's hyper parameters: Current learning rate is 7.342143906020558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46592/60000][Iteration 364][Wall Clock 42.573805732s] Trained 128 records in 0.093260023 seconds. Throughput is 1372.5067 records/second. Loss is 2.2731602. Sequentialb692dd65's hyper parameters: Current learning rate is 7.336757153338225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46720/60000][Iteration 365][Wall Clock 42.668016085s] Trained 128 records in 0.094210353 seconds. Throughput is 1358.6616 records/second. Loss is 2.258703. Sequentialb692dd65's hyper parameters: Current learning rate is 7.331378299120236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46848/60000][Iteration 366][Wall Clock 42.759011836s] Trained 128 records in 0.090995751 seconds. Throughput is 1406.659 records/second. Loss is 2.2863193. Sequentialb692dd65's hyper parameters: Current learning rate is 7.326007326007326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 46976/60000][Iteration 367][Wall Clock 42.849576521s] Trained 128 records in 0.090564685 seconds. Throughput is 1413.3545 records/second. Loss is 2.271979. Sequentialb692dd65's hyper parameters: Current learning rate is 7.320644216691068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 47104/60000][Iteration 368][Wall Clock 42.948117529s] Trained 128 records in 0.098541008 seconds. Throughput is 1298.9517 records/second. Loss is 2.275406. Sequentialb692dd65's hyper parameters: Current learning rate is 7.31528895391368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:05 INFO  DistriOptimizer$:408 - [Epoch 1 47232/60000][Iteration 369][Wall Clock 43.059340559s] Trained 128 records in 0.11122303 seconds. Throughput is 1150.8408 records/second. Loss is 2.268938. Sequentialb692dd65's hyper parameters: Current learning rate is 7.309941520467837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 47360/60000][Iteration 370][Wall Clock 43.148769503s] Trained 128 records in 0.089428944 seconds. Throughput is 1431.304 records/second. Loss is 2.2627997. Sequentialb692dd65's hyper parameters: Current learning rate is 7.304601899196494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 47488/60000][Iteration 371][Wall Clock 43.237516235s] Trained 128 records in 0.088746732 seconds. Throughput is 1442.3066 records/second. Loss is 2.2877345. Sequentialb692dd65's hyper parameters: Current learning rate is 7.2992700729927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 47616/60000][Iteration 372][Wall Clock 43.327972467s] Trained 128 records in 0.090456232 seconds. Throughput is 1415.049 records/second. Loss is 2.2641366. Sequentialb692dd65's hyper parameters: Current learning rate is 7.293946024799417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 47744/60000][Iteration 373][Wall Clock 43.423988864s] Trained 128 records in 0.096016397 seconds. Throughput is 1333.1056 records/second. Loss is 2.265434. Sequentialb692dd65's hyper parameters: Current learning rate is 7.28862973760933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 47872/60000][Iteration 374][Wall Clock 43.516677134s] Trained 128 records in 0.09268827 seconds. Throughput is 1380.973 records/second. Loss is 2.2651958. Sequentialb692dd65's hyper parameters: Current learning rate is 7.283321194464676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 48000/60000][Iteration 375][Wall Clock 43.611199663s] Trained 128 records in 0.094522529 seconds. Throughput is 1354.1746 records/second. Loss is 2.2686405. Sequentialb692dd65's hyper parameters: Current learning rate is 7.278020378457059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 48128/60000][Iteration 376][Wall Clock 43.712024897s] Trained 128 records in 0.100825234 seconds. Throughput is 1269.5234 records/second. Loss is 2.2809272. Sequentialb692dd65's hyper parameters: Current learning rate is 7.272727272727273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 48256/60000][Iteration 377][Wall Clock 43.839943572s] Trained 128 records in 0.127918675 seconds. Throughput is 1000.63574 records/second. Loss is 2.2795763. Sequentialb692dd65's hyper parameters: Current learning rate is 7.267441860465117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 48384/60000][Iteration 378][Wall Clock 43.956846281s] Trained 128 records in 0.116902709 seconds. Throughput is 1094.9276 records/second. Loss is 2.284778. Sequentialb692dd65's hyper parameters: Current learning rate is 7.262164124909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:06 INFO  DistriOptimizer$:408 - [Epoch 1 48512/60000][Iteration 379][Wall Clock 44.046564014s] Trained 128 records in 0.089717733 seconds. Throughput is 1426.6968 records/second. Loss is 2.26661. Sequentialb692dd65's hyper parameters: Current learning rate is 7.25689404934688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 48640/60000][Iteration 380][Wall Clock 44.140438451s] Trained 128 records in 0.093874437 seconds. Throughput is 1363.5234 records/second. Loss is 2.269742. Sequentialb692dd65's hyper parameters: Current learning rate is 7.251631617113851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 48768/60000][Iteration 381][Wall Clock 44.230669675s] Trained 128 records in 0.090231224 seconds. Throughput is 1418.5776 records/second. Loss is 2.2650912. Sequentialb692dd65's hyper parameters: Current learning rate is 7.246376811594204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 48896/60000][Iteration 382][Wall Clock 44.329459661s] Trained 128 records in 0.098789986 seconds. Throughput is 1295.678 records/second. Loss is 2.2923656. Sequentialb692dd65's hyper parameters: Current learning rate is 7.241129616220131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49024/60000][Iteration 383][Wall Clock 44.430040238s] Trained 128 records in 0.100580577 seconds. Throughput is 1272.6115 records/second. Loss is 2.2619097. Sequentialb692dd65's hyper parameters: Current learning rate is 7.23589001447178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49152/60000][Iteration 384][Wall Clock 44.53289628s] Trained 128 records in 0.102856042 seconds. Throughput is 1244.4578 records/second. Loss is 2.2797103. Sequentialb692dd65's hyper parameters: Current learning rate is 7.230657989877079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49280/60000][Iteration 385][Wall Clock 44.627737072s] Trained 128 records in 0.094840792 seconds. Throughput is 1349.6302 records/second. Loss is 2.2716284. Sequentialb692dd65's hyper parameters: Current learning rate is 7.225433526011561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49408/60000][Iteration 386][Wall Clock 44.716555881s] Trained 128 records in 0.088818809 seconds. Throughput is 1441.1361 records/second. Loss is 2.2643147. Sequentialb692dd65's hyper parameters: Current learning rate is 7.220216606498195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49536/60000][Iteration 387][Wall Clock 44.805120895s] Trained 128 records in 0.088565014 seconds. Throughput is 1445.266 records/second. Loss is 2.275439. Sequentialb692dd65's hyper parameters: Current learning rate is 7.215007215007215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49664/60000][Iteration 388][Wall Clock 44.895261974s] Trained 128 records in 0.090141079 seconds. Throughput is 1419.9963 records/second. Loss is 2.2843451. Sequentialb692dd65's hyper parameters: Current learning rate is 7.209805335255948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49792/60000][Iteration 389][Wall Clock 44.986502515s] Trained 128 records in 0.091240541 seconds. Throughput is 1402.8851 records/second. Loss is 2.2576244. Sequentialb692dd65's hyper parameters: Current learning rate is 7.204610951008646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:07 INFO  DistriOptimizer$:408 - [Epoch 1 49920/60000][Iteration 390][Wall Clock 45.076422194s] Trained 128 records in 0.089919679 seconds. Throughput is 1423.4927 records/second. Loss is 2.2778704. Sequentialb692dd65's hyper parameters: Current learning rate is 7.199424046076314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50048/60000][Iteration 391][Wall Clock 45.168636552s] Trained 128 records in 0.092214358 seconds. Throughput is 1388.0702 records/second. Loss is 2.2603004. Sequentialb692dd65's hyper parameters: Current learning rate is 7.194244604316546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50176/60000][Iteration 392][Wall Clock 45.254833049s] Trained 128 records in 0.086196497 seconds. Throughput is 1484.9791 records/second. Loss is 2.2624252. Sequentialb692dd65's hyper parameters: Current learning rate is 7.189072609633358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50304/60000][Iteration 393][Wall Clock 45.357550649s] Trained 128 records in 0.1027176 seconds. Throughput is 1246.135 records/second. Loss is 2.2710311. Sequentialb692dd65's hyper parameters: Current learning rate is 7.183908045977012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50432/60000][Iteration 394][Wall Clock 45.44725252s] Trained 128 records in 0.089701871 seconds. Throughput is 1426.9491 records/second. Loss is 2.2698174. Sequentialb692dd65's hyper parameters: Current learning rate is 7.178750897343862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50560/60000][Iteration 395][Wall Clock 45.534888404s] Trained 128 records in 0.087635884 seconds. Throughput is 1460.589 records/second. Loss is 2.2757635. Sequentialb692dd65's hyper parameters: Current learning rate is 7.173601147776183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50688/60000][Iteration 396][Wall Clock 45.619437054s] Trained 128 records in 0.08454865 seconds. Throughput is 1513.9213 records/second. Loss is 2.2781923. Sequentialb692dd65's hyper parameters: Current learning rate is 7.168458781362007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50816/60000][Iteration 397][Wall Clock 45.710222599s] Trained 128 records in 0.090785545 seconds. Throughput is 1409.916 records/second. Loss is 2.274245. Sequentialb692dd65's hyper parameters: Current learning rate is 7.163323782234958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 50944/60000][Iteration 398][Wall Clock 45.801575631s] Trained 128 records in 0.091353032 seconds. Throughput is 1401.1577 records/second. Loss is 2.2806745. Sequentialb692dd65's hyper parameters: Current learning rate is 7.158196134574087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 51072/60000][Iteration 399][Wall Clock 45.895649667s] Trained 128 records in 0.094074036 seconds. Throughput is 1360.6305 records/second. Loss is 2.2736647. Sequentialb692dd65's hyper parameters: Current learning rate is 7.15307582260372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:08 INFO  DistriOptimizer$:408 - [Epoch 1 51200/60000][Iteration 400][Wall Clock 45.987006165s] Trained 128 records in 0.091356498 seconds. Throughput is 1401.1045 records/second. Loss is 2.28671. Sequentialb692dd65's hyper parameters: Current learning rate is 7.147962830593281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51328/60000][Iteration 401][Wall Clock 46.094977103s] Trained 128 records in 0.107970938 seconds. Throughput is 1185.5042 records/second. Loss is 2.2805989. Sequentialb692dd65's hyper parameters: Current learning rate is 7.142857142857144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51456/60000][Iteration 402][Wall Clock 46.186977966s] Trained 128 records in 0.092000863 seconds. Throughput is 1391.2913 records/second. Loss is 2.2477484. Sequentialb692dd65's hyper parameters: Current learning rate is 7.137758743754461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51584/60000][Iteration 403][Wall Clock 46.276333794s] Trained 128 records in 0.089355828 seconds. Throughput is 1432.4751 records/second. Loss is 2.2690685. Sequentialb692dd65's hyper parameters: Current learning rate is 7.132667617689015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51712/60000][Iteration 404][Wall Clock 46.366495487s] Trained 128 records in 0.090161693 seconds. Throughput is 1419.6716 records/second. Loss is 2.2511482. Sequentialb692dd65's hyper parameters: Current learning rate is 7.127583749109052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51840/60000][Iteration 405][Wall Clock 46.457214655s] Trained 128 records in 0.090719168 seconds. Throughput is 1410.9476 records/second. Loss is 2.2627068. Sequentialb692dd65's hyper parameters: Current learning rate is 7.122507122507123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 51968/60000][Iteration 406][Wall Clock 46.546021779s] Trained 128 records in 0.088807124 seconds. Throughput is 1441.3258 records/second. Loss is 2.2642004. Sequentialb692dd65's hyper parameters: Current learning rate is 7.117437722419929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 52096/60000][Iteration 407][Wall Clock 46.63672942s] Trained 128 records in 0.090707641 seconds. Throughput is 1411.1271 records/second. Loss is 2.2768326. Sequentialb692dd65's hyper parameters: Current learning rate is 7.112375533428164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 52224/60000][Iteration 408][Wall Clock 46.735648894s] Trained 128 records in 0.098919474 seconds. Throughput is 1293.9818 records/second. Loss is 2.26599. Sequentialb692dd65's hyper parameters: Current learning rate is 7.107320540156361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 52352/60000][Iteration 409][Wall Clock 46.825126487s] Trained 128 records in 0.089477593 seconds. Throughput is 1430.5258 records/second. Loss is 2.2600462. Sequentialb692dd65's hyper parameters: Current learning rate is 7.102272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 52480/60000][Iteration 410][Wall Clock 46.928159096s] Trained 128 records in 0.103032609 seconds. Throughput is 1242.3251 records/second. Loss is 2.2653399. Sequentialb692dd65's hyper parameters: Current learning rate is 7.097232079489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:09 INFO  DistriOptimizer$:408 - [Epoch 1 52608/60000][Iteration 411][Wall Clock 47.019800617s] Trained 128 records in 0.091641521 seconds. Throughput is 1396.7467 records/second. Loss is 2.262459. Sequentialb692dd65's hyper parameters: Current learning rate is 7.092198581560283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 52736/60000][Iteration 412][Wall Clock 47.134196995s] Trained 128 records in 0.114396378 seconds. Throughput is 1118.9165 records/second. Loss is 2.2622705. Sequentialb692dd65's hyper parameters: Current learning rate is 7.087172218284905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 52864/60000][Iteration 413][Wall Clock 47.225849124s] Trained 128 records in 0.091652129 seconds. Throughput is 1396.5851 records/second. Loss is 2.2587953. Sequentialb692dd65's hyper parameters: Current learning rate is 7.08215297450425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 52992/60000][Iteration 414][Wall Clock 47.340267769s] Trained 128 records in 0.114418645 seconds. Throughput is 1118.6987 records/second. Loss is 2.2664568. Sequentialb692dd65's hyper parameters: Current learning rate is 7.077140835102619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53120/60000][Iteration 415][Wall Clock 47.453579874s] Trained 128 records in 0.113312105 seconds. Throughput is 1129.6234 records/second. Loss is 2.2604573. Sequentialb692dd65's hyper parameters: Current learning rate is 7.072135785007071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53248/60000][Iteration 416][Wall Clock 47.568644236s] Trained 128 records in 0.115064362 seconds. Throughput is 1112.4209 records/second. Loss is 2.2722623. Sequentialb692dd65's hyper parameters: Current learning rate is 7.067137809187279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53376/60000][Iteration 417][Wall Clock 47.656190726s] Trained 128 records in 0.08754649 seconds. Throughput is 1462.0803 records/second. Loss is 2.2718694. Sequentialb692dd65's hyper parameters: Current learning rate is 7.062146892655368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53504/60000][Iteration 418][Wall Clock 47.767197377s] Trained 128 records in 0.111006651 seconds. Throughput is 1153.0841 records/second. Loss is 2.2743518. Sequentialb692dd65's hyper parameters: Current learning rate is 7.057163020465773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53632/60000][Iteration 419][Wall Clock 47.858037456s] Trained 128 records in 0.090840079 seconds. Throughput is 1409.0697 records/second. Loss is 2.254454. Sequentialb692dd65's hyper parameters: Current learning rate is 7.052186177715093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53760/60000][Iteration 420][Wall Clock 47.939795075s] Trained 128 records in 0.081757619 seconds. Throughput is 1565.6033 records/second. Loss is 2.2655451. Sequentialb692dd65's hyper parameters: Current learning rate is 7.047216349541931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:10 INFO  DistriOptimizer$:408 - [Epoch 1 53888/60000][Iteration 421][Wall Clock 48.03020304s] Trained 128 records in 0.090407965 seconds. Throughput is 1415.8044 records/second. Loss is 2.279612. Sequentialb692dd65's hyper parameters: Current learning rate is 7.042253521126761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54016/60000][Iteration 422][Wall Clock 48.119911054s] Trained 128 records in 0.089708014 seconds. Throughput is 1426.8513 records/second. Loss is 2.2768035. Sequentialb692dd65's hyper parameters: Current learning rate is 7.037297677691766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54144/60000][Iteration 423][Wall Clock 48.207055646s] Trained 128 records in 0.087144592 seconds. Throughput is 1468.8232 records/second. Loss is 2.2699494. Sequentialb692dd65's hyper parameters: Current learning rate is 7.032348804500703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54272/60000][Iteration 424][Wall Clock 48.310742279s] Trained 128 records in 0.103686633 seconds. Throughput is 1234.4889 records/second. Loss is 2.2560725. Sequentialb692dd65's hyper parameters: Current learning rate is 7.027406886858749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54400/60000][Iteration 425][Wall Clock 48.402245994s] Trained 128 records in 0.091503715 seconds. Throughput is 1398.8502 records/second. Loss is 2.2749074. Sequentialb692dd65's hyper parameters: Current learning rate is 7.02247191011236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54528/60000][Iteration 426][Wall Clock 48.496603679s] Trained 128 records in 0.094357685 seconds. Throughput is 1356.5403 records/second. Loss is 2.2778413. Sequentialb692dd65's hyper parameters: Current learning rate is 7.017543859649122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54656/60000][Iteration 427][Wall Clock 48.583371705s] Trained 128 records in 0.086768026 seconds. Throughput is 1475.1979 records/second. Loss is 2.279036. Sequentialb692dd65's hyper parameters: Current learning rate is 7.012622720897617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54784/60000][Iteration 428][Wall Clock 48.669225415s] Trained 128 records in 0.08585371 seconds. Throughput is 1490.9082 records/second. Loss is 2.2470202. Sequentialb692dd65's hyper parameters: Current learning rate is 7.00770847932726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 54912/60000][Iteration 429][Wall Clock 48.761394055s] Trained 128 records in 0.09216864 seconds. Throughput is 1388.7588 records/second. Loss is 2.2778432. Sequentialb692dd65's hyper parameters: Current learning rate is 7.002801120448179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 55040/60000][Iteration 430][Wall Clock 48.852966727s] Trained 128 records in 0.091572672 seconds. Throughput is 1397.7969 records/second. Loss is 2.2785344. Sequentialb692dd65's hyper parameters: Current learning rate is 6.997900629811056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 55168/60000][Iteration 431][Wall Clock 48.946134972s] Trained 128 records in 0.093168245 seconds. Throughput is 1373.8586 records/second. Loss is 2.2639556. Sequentialb692dd65's hyper parameters: Current learning rate is 6.993006993006993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:11 INFO  DistriOptimizer$:408 - [Epoch 1 55296/60000][Iteration 432][Wall Clock 49.049128512s] Trained 128 records in 0.10299354 seconds. Throughput is 1242.7964 records/second. Loss is 2.258683. Sequentialb692dd65's hyper parameters: Current learning rate is 6.988120195667365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 55424/60000][Iteration 433][Wall Clock 49.140023805s] Trained 128 records in 0.090895293 seconds. Throughput is 1408.2137 records/second. Loss is 2.2772138. Sequentialb692dd65's hyper parameters: Current learning rate is 6.983240223463687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 55552/60000][Iteration 434][Wall Clock 49.235438682s] Trained 128 records in 0.095414877 seconds. Throughput is 1341.5099 records/second. Loss is 2.2598295. Sequentialb692dd65's hyper parameters: Current learning rate is 6.978367062107466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 55680/60000][Iteration 435][Wall Clock 49.325546657s] Trained 128 records in 0.090107975 seconds. Throughput is 1420.518 records/second. Loss is 2.2693272. Sequentialb692dd65's hyper parameters: Current learning rate is 6.973500697350071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 55808/60000][Iteration 436][Wall Clock 49.414641273s] Trained 128 records in 0.089094616 seconds. Throughput is 1436.6749 records/second. Loss is 2.2805088. Sequentialb692dd65's hyper parameters: Current learning rate is 6.968641114982578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 55936/60000][Iteration 437][Wall Clock 49.504254111s] Trained 128 records in 0.089612838 seconds. Throughput is 1428.3667 records/second. Loss is 2.2671437. Sequentialb692dd65's hyper parameters: Current learning rate is 6.963788300835655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 56064/60000][Iteration 438][Wall Clock 49.61307406s] Trained 128 records in 0.108819949 seconds. Throughput is 1176.2549 records/second. Loss is 2.2673635. Sequentialb692dd65's hyper parameters: Current learning rate is 6.958942240779402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 56192/60000][Iteration 439][Wall Clock 49.702509774s] Trained 128 records in 0.089435714 seconds. Throughput is 1431.1957 records/second. Loss is 2.2680275. Sequentialb692dd65's hyper parameters: Current learning rate is 6.954102920723227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 56320/60000][Iteration 440][Wall Clock 49.79087952s] Trained 128 records in 0.088369746 seconds. Throughput is 1448.4595 records/second. Loss is 2.2502344. Sequentialb692dd65's hyper parameters: Current learning rate is 6.949270326615705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 56448/60000][Iteration 441][Wall Clock 49.881751278s] Trained 128 records in 0.090871758 seconds. Throughput is 1408.5785 records/second. Loss is 2.2676978. Sequentialb692dd65's hyper parameters: Current learning rate is 6.944444444444445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:12 INFO  DistriOptimizer$:408 - [Epoch 1 56576/60000][Iteration 442][Wall Clock 49.972971621s] Trained 128 records in 0.091220343 seconds. Throughput is 1403.1958 records/second. Loss is 2.260536. Sequentialb692dd65's hyper parameters: Current learning rate is 6.939625260235947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 56704/60000][Iteration 443][Wall Clock 50.071847182s] Trained 128 records in 0.098875561 seconds. Throughput is 1294.5565 records/second. Loss is 2.2629824. Sequentialb692dd65's hyper parameters: Current learning rate is 6.934812760055479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 56832/60000][Iteration 444][Wall Clock 50.165366365s] Trained 128 records in 0.093519183 seconds. Throughput is 1368.7031 records/second. Loss is 2.2706552. Sequentialb692dd65's hyper parameters: Current learning rate is 6.93000693000693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 56960/60000][Iteration 445][Wall Clock 50.254304876s] Trained 128 records in 0.088938511 seconds. Throughput is 1439.1965 records/second. Loss is 2.2652943. Sequentialb692dd65's hyper parameters: Current learning rate is 6.925207756232687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57088/60000][Iteration 446][Wall Clock 50.344009083s] Trained 128 records in 0.089704207 seconds. Throughput is 1426.9119 records/second. Loss is 2.277991. Sequentialb692dd65's hyper parameters: Current learning rate is 6.920415224913495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57216/60000][Iteration 447][Wall Clock 50.440598114s] Trained 128 records in 0.096589031 seconds. Throughput is 1325.2023 records/second. Loss is 2.2586746. Sequentialb692dd65's hyper parameters: Current learning rate is 6.915629322268327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57344/60000][Iteration 448][Wall Clock 50.543772242s] Trained 128 records in 0.103174128 seconds. Throughput is 1240.6211 records/second. Loss is 2.2651448. Sequentialb692dd65's hyper parameters: Current learning rate is 6.91085003455425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57472/60000][Iteration 449][Wall Clock 50.640049638s] Trained 128 records in 0.096277396 seconds. Throughput is 1329.4917 records/second. Loss is 2.2663627. Sequentialb692dd65's hyper parameters: Current learning rate is 6.906077348066299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57600/60000][Iteration 450][Wall Clock 50.726645651s] Trained 128 records in 0.086596013 seconds. Throughput is 1478.1282 records/second. Loss is 2.2585983. Sequentialb692dd65's hyper parameters: Current learning rate is 6.901311249137336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57728/60000][Iteration 451][Wall Clock 50.831491535s] Trained 128 records in 0.104845884 seconds. Throughput is 1220.8396 records/second. Loss is 2.2659783. Sequentialb692dd65's hyper parameters: Current learning rate is 6.896551724137932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57856/60000][Iteration 452][Wall Clock 50.924752586s] Trained 128 records in 0.093261051 seconds. Throughput is 1372.4916 records/second. Loss is 2.2577443. Sequentialb692dd65's hyper parameters: Current learning rate is 6.891798759476223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:13 INFO  DistriOptimizer$:408 - [Epoch 1 57984/60000][Iteration 453][Wall Clock 51.013769554s] Trained 128 records in 0.089016968 seconds. Throughput is 1437.9281 records/second. Loss is 2.269546. Sequentialb692dd65's hyper parameters: Current learning rate is 6.887052341597796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58112/60000][Iteration 454][Wall Clock 51.103863845s] Trained 128 records in 0.090094291 seconds. Throughput is 1420.7338 records/second. Loss is 2.2620823. Sequentialb692dd65's hyper parameters: Current learning rate is 6.882312456985547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58240/60000][Iteration 455][Wall Clock 51.192524126s] Trained 128 records in 0.088660281 seconds. Throughput is 1443.713 records/second. Loss is 2.2570024. Sequentialb692dd65's hyper parameters: Current learning rate is 6.87757909215956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58368/60000][Iteration 456][Wall Clock 51.285627211s] Trained 128 records in 0.093103085 seconds. Throughput is 1374.8201 records/second. Loss is 2.2413964. Sequentialb692dd65's hyper parameters: Current learning rate is 6.872852233676975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58496/60000][Iteration 457][Wall Clock 51.375549789s] Trained 128 records in 0.089922578 seconds. Throughput is 1423.4468 records/second. Loss is 2.2590842. Sequentialb692dd65's hyper parameters: Current learning rate is 6.868131868131869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58624/60000][Iteration 458][Wall Clock 51.463496703s] Trained 128 records in 0.087946914 seconds. Throughput is 1455.4235 records/second. Loss is 2.277372. Sequentialb692dd65's hyper parameters: Current learning rate is 6.863417982155113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58752/60000][Iteration 459][Wall Clock 51.551644564s] Trained 128 records in 0.088147861 seconds. Throughput is 1452.1055 records/second. Loss is 2.2622228. Sequentialb692dd65's hyper parameters: Current learning rate is 6.858710562414267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 58880/60000][Iteration 460][Wall Clock 51.640543762s] Trained 128 records in 0.088899198 seconds. Throughput is 1439.833 records/second. Loss is 2.261631. Sequentialb692dd65's hyper parameters: Current learning rate is 6.854009595613433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 59008/60000][Iteration 461][Wall Clock 51.731606898s] Trained 128 records in 0.091063136 seconds. Throughput is 1405.6182 records/second. Loss is 2.2607846. Sequentialb692dd65's hyper parameters: Current learning rate is 6.849315068493151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 59136/60000][Iteration 462][Wall Clock 51.819921887s] Trained 128 records in 0.088314989 seconds. Throughput is 1449.3577 records/second. Loss is 2.249187. Sequentialb692dd65's hyper parameters: Current learning rate is 6.844626967830253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 59264/60000][Iteration 463][Wall Clock 51.904793969s] Trained 128 records in 0.084872082 seconds. Throughput is 1508.152 records/second. Loss is 2.274484. Sequentialb692dd65's hyper parameters: Current learning rate is 6.839945280437756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:14 INFO  DistriOptimizer$:408 - [Epoch 1 59392/60000][Iteration 464][Wall Clock 51.998730918s] Trained 128 records in 0.093936949 seconds. Throughput is 1362.6161 records/second. Loss is 2.2823849. Sequentialb692dd65's hyper parameters: Current learning rate is 6.835269993164729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:408 - [Epoch 1 59520/60000][Iteration 465][Wall Clock 52.090817765s] Trained 128 records in 0.092086847 seconds. Throughput is 1389.9923 records/second. Loss is 2.2644186. Sequentialb692dd65's hyper parameters: Current learning rate is 6.830601092896175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:408 - [Epoch 1 59648/60000][Iteration 466][Wall Clock 52.17846329s] Trained 128 records in 0.087645525 seconds. Throughput is 1460.4282 records/second. Loss is 2.2710948. Sequentialb692dd65's hyper parameters: Current learning rate is 6.825938566552901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:408 - [Epoch 1 59776/60000][Iteration 467][Wall Clock 52.267044777s] Trained 128 records in 0.088581487 seconds. Throughput is 1444.9972 records/second. Loss is 2.2535837. Sequentialb692dd65's hyper parameters: Current learning rate is 6.821282401091405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:408 - [Epoch 1 59904/60000][Iteration 468][Wall Clock 52.370011627s] Trained 128 records in 0.10296685 seconds. Throughput is 1243.1185 records/second. Loss is 2.2507195. Sequentialb692dd65's hyper parameters: Current learning rate is 6.816632583503749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:408 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.460138318s] Trained 128 records in 0.090126691 seconds. Throughput is 1420.223 records/second. Loss is 2.253907. Sequentialb692dd65's hyper parameters: Current learning rate is 6.811989100817438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:15 INFO  DistriOptimizer$:452 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.460138318s] Epoch finished. Wall clock time is 52794.947251 ms
2019-10-15 07:47:15 INFO  DistriOptimizer$:111 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.460138318s] Validate model...
2019-10-15 07:47:16 INFO  DistriOptimizer$:178 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.460138318s] validate model throughput is 9872.877 records/second
2019-10-15 07:47:16 INFO  DistriOptimizer$:181 - [Epoch 1 60032/60000][Iteration 469][Wall Clock 52.460138318s] Top1Accuracy is Accuracy(correct: 2387, count: 10000, accuracy: 0.2387)
2019-10-15 07:47:16 INFO  DistriOptimizer$:221 - [Wall Clock 52.794947251s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:47:16 INFO  DistriOptimizer$:226 - [Wall Clock 52.794947251s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:47:16 INFO  DistriOptimizer$:408 - [Epoch 2 128/60000][Iteration 470][Wall Clock 52.944027841s] Trained 128 records in 0.14908059 seconds. Throughput is 858.596 records/second. Loss is 2.26711. Sequentialb692dd65's hyper parameters: Current learning rate is 6.807351940095302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:16 INFO  DistriOptimizer$:408 - [Epoch 2 256/60000][Iteration 471][Wall Clock 53.041255603s] Trained 128 records in 0.097227762 seconds. Throughput is 1316.4965 records/second. Loss is 2.2673867. Sequentialb692dd65's hyper parameters: Current learning rate is 6.802721088435375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:16 INFO  DistriOptimizer$:408 - [Epoch 2 384/60000][Iteration 472][Wall Clock 53.144491971s] Trained 128 records in 0.103236368 seconds. Throughput is 1239.8732 records/second. Loss is 2.2836714. Sequentialb692dd65's hyper parameters: Current learning rate is 6.798096532970768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 512/60000][Iteration 473][Wall Clock 53.250971705s] Trained 128 records in 0.106479734 seconds. Throughput is 1202.1067 records/second. Loss is 2.2696323. Sequentialb692dd65's hyper parameters: Current learning rate is 6.793478260869565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 640/60000][Iteration 474][Wall Clock 53.362002326s] Trained 128 records in 0.111030621 seconds. Throughput is 1152.8351 records/second. Loss is 2.2587633. Sequentialb692dd65's hyper parameters: Current learning rate is 6.788866259334691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 768/60000][Iteration 475][Wall Clock 53.45149352s] Trained 128 records in 0.089491194 seconds. Throughput is 1430.3083 records/second. Loss is 2.2632864. Sequentialb692dd65's hyper parameters: Current learning rate is 6.7842605156038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 896/60000][Iteration 476][Wall Clock 53.54230196s] Trained 128 records in 0.09080844 seconds. Throughput is 1409.5605 records/second. Loss is 2.2610972. Sequentialb692dd65's hyper parameters: Current learning rate is 6.779661016949152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1024/60000][Iteration 477][Wall Clock 53.642532338s] Trained 128 records in 0.100230378 seconds. Throughput is 1277.0579 records/second. Loss is 2.2738962. Sequentialb692dd65's hyper parameters: Current learning rate is 6.775067750677507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1152/60000][Iteration 478][Wall Clock 53.734598499s] Trained 128 records in 0.092066161 seconds. Throughput is 1390.3046 records/second. Loss is 2.2750087. Sequentialb692dd65's hyper parameters: Current learning rate is 6.770480704129993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1280/60000][Iteration 479][Wall Clock 53.824021787s] Trained 128 records in 0.089423288 seconds. Throughput is 1431.3944 records/second. Loss is 2.2619913. Sequentialb692dd65's hyper parameters: Current learning rate is 6.765899864682003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1408/60000][Iteration 480][Wall Clock 53.917925589s] Trained 128 records in 0.093903802 seconds. Throughput is 1363.097 records/second. Loss is 2.267912. Sequentialb692dd65's hyper parameters: Current learning rate is 6.76132521974307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1536/60000][Iteration 481][Wall Clock 54.011967338s] Trained 128 records in 0.094041749 seconds. Throughput is 1361.0977 records/second. Loss is 2.272891. Sequentialb692dd65's hyper parameters: Current learning rate is 6.756756756756757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1664/60000][Iteration 482][Wall Clock 54.101513235s] Trained 128 records in 0.089545897 seconds. Throughput is 1429.4346 records/second. Loss is 2.2514575. Sequentialb692dd65's hyper parameters: Current learning rate is 6.752194463200541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:17 INFO  DistriOptimizer$:408 - [Epoch 2 1792/60000][Iteration 483][Wall Clock 54.187623597s] Trained 128 records in 0.086110362 seconds. Throughput is 1486.4646 records/second. Loss is 2.2429757. Sequentialb692dd65's hyper parameters: Current learning rate is 6.747638326585695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 1920/60000][Iteration 484][Wall Clock 54.275658193s] Trained 128 records in 0.088034596 seconds. Throughput is 1453.9739 records/second. Loss is 2.2687914. Sequentialb692dd65's hyper parameters: Current learning rate is 6.743088334457181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2048/60000][Iteration 485][Wall Clock 54.366507772s] Trained 128 records in 0.090849579 seconds. Throughput is 1408.9224 records/second. Loss is 2.2635472. Sequentialb692dd65's hyper parameters: Current learning rate is 6.738544474393531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2176/60000][Iteration 486][Wall Clock 54.458427334s] Trained 128 records in 0.091919562 seconds. Throughput is 1392.5219 records/second. Loss is 2.2610722. Sequentialb692dd65's hyper parameters: Current learning rate is 6.734006734006734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2304/60000][Iteration 487][Wall Clock 54.548543998s] Trained 128 records in 0.090116664 seconds. Throughput is 1420.381 records/second. Loss is 2.2677233. Sequentialb692dd65's hyper parameters: Current learning rate is 6.729475100942127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2432/60000][Iteration 488][Wall Clock 54.639244054s] Trained 128 records in 0.090700056 seconds. Throughput is 1411.245 records/second. Loss is 2.271519. Sequentialb692dd65's hyper parameters: Current learning rate is 6.724949562878278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2560/60000][Iteration 489][Wall Clock 54.730433366s] Trained 128 records in 0.091189312 seconds. Throughput is 1403.6733 records/second. Loss is 2.2583268. Sequentialb692dd65's hyper parameters: Current learning rate is 6.720430107526882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2688/60000][Iteration 490][Wall Clock 54.821957181s] Trained 128 records in 0.091523815 seconds. Throughput is 1398.5431 records/second. Loss is 2.2666926. Sequentialb692dd65's hyper parameters: Current learning rate is 6.71591672263264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2816/60000][Iteration 491][Wall Clock 54.924848008s] Trained 128 records in 0.102890827 seconds. Throughput is 1244.037 records/second. Loss is 2.2606304. Sequentialb692dd65's hyper parameters: Current learning rate is 6.711409395973154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 2944/60000][Iteration 492][Wall Clock 55.011782316s] Trained 128 records in 0.086934308 seconds. Throughput is 1472.3762 records/second. Loss is 2.2527192. Sequentialb692dd65's hyper parameters: Current learning rate is 6.706908115358819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 3072/60000][Iteration 493][Wall Clock 55.107389772s] Trained 128 records in 0.095607456 seconds. Throughput is 1338.8076 records/second. Loss is 2.260092. Sequentialb692dd65's hyper parameters: Current learning rate is 6.702412868632708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:18 INFO  DistriOptimizer$:408 - [Epoch 2 3200/60000][Iteration 494][Wall Clock 55.197045525s] Trained 128 records in 0.089655753 seconds. Throughput is 1427.6831 records/second. Loss is 2.269399. Sequentialb692dd65's hyper parameters: Current learning rate is 6.697923643670463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3328/60000][Iteration 495][Wall Clock 55.287536753s] Trained 128 records in 0.090491228 seconds. Throughput is 1414.5017 records/second. Loss is 2.2677104. Sequentialb692dd65's hyper parameters: Current learning rate is 6.693440428380187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3456/60000][Iteration 496][Wall Clock 55.403419897s] Trained 128 records in 0.115883144 seconds. Throughput is 1104.561 records/second. Loss is 2.2563667. Sequentialb692dd65's hyper parameters: Current learning rate is 6.688963210702341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3584/60000][Iteration 497][Wall Clock 55.49571361s] Trained 128 records in 0.092293713 seconds. Throughput is 1386.8767 records/second. Loss is 2.268557. Sequentialb692dd65's hyper parameters: Current learning rate is 6.684491978609626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3712/60000][Iteration 498][Wall Clock 55.596351167s] Trained 128 records in 0.100637557 seconds. Throughput is 1271.891 records/second. Loss is 2.2681077. Sequentialb692dd65's hyper parameters: Current learning rate is 6.680026720106881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3840/60000][Iteration 499][Wall Clock 55.691100297s] Trained 128 records in 0.09474913 seconds. Throughput is 1350.9359 records/second. Loss is 2.2506828. Sequentialb692dd65's hyper parameters: Current learning rate is 6.675567423230974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 3968/60000][Iteration 500][Wall Clock 55.783071998s] Trained 128 records in 0.091971701 seconds. Throughput is 1391.7324 records/second. Loss is 2.2546566. Sequentialb692dd65's hyper parameters: Current learning rate is 6.6711140760507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 4096/60000][Iteration 501][Wall Clock 55.892048951s] Trained 128 records in 0.108976953 seconds. Throughput is 1174.5603 records/second. Loss is 2.2504256. Sequentialb692dd65's hyper parameters: Current learning rate is 6.666666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 4224/60000][Iteration 502][Wall Clock 55.985804683s] Trained 128 records in 0.093755732 seconds. Throughput is 1365.2499 records/second. Loss is 2.246374. Sequentialb692dd65's hyper parameters: Current learning rate is 6.662225183211193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 4352/60000][Iteration 503][Wall Clock 56.083222673s] Trained 128 records in 0.09741799 seconds. Throughput is 1313.9258 records/second. Loss is 2.2628374. Sequentialb692dd65's hyper parameters: Current learning rate is 6.657789613848203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:19 INFO  DistriOptimizer$:408 - [Epoch 2 4480/60000][Iteration 504][Wall Clock 56.171213914s] Trained 128 records in 0.087991241 seconds. Throughput is 1454.6903 records/second. Loss is 2.2751162. Sequentialb692dd65's hyper parameters: Current learning rate is 6.653359946773121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 4608/60000][Iteration 505][Wall Clock 56.264089817s] Trained 128 records in 0.092875903 seconds. Throughput is 1378.1831 records/second. Loss is 2.243672. Sequentialb692dd65's hyper parameters: Current learning rate is 6.648936170212766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 4736/60000][Iteration 506][Wall Clock 56.359455366s] Trained 128 records in 0.095365549 seconds. Throughput is 1342.2039 records/second. Loss is 2.2506065. Sequentialb692dd65's hyper parameters: Current learning rate is 6.64451827242525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 4864/60000][Iteration 507][Wall Clock 56.447144692s] Trained 128 records in 0.087689326 seconds. Throughput is 1459.6987 records/second. Loss is 2.2581258. Sequentialb692dd65's hyper parameters: Current learning rate is 6.640106241699868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 4992/60000][Iteration 508][Wall Clock 56.535525021s] Trained 128 records in 0.088380329 seconds. Throughput is 1448.2861 records/second. Loss is 2.266641. Sequentialb692dd65's hyper parameters: Current learning rate is 6.635700066357001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5120/60000][Iteration 509][Wall Clock 56.62997871s] Trained 128 records in 0.094453689 seconds. Throughput is 1355.1614 records/second. Loss is 2.2611024. Sequentialb692dd65's hyper parameters: Current learning rate is 6.63129973474801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5248/60000][Iteration 510][Wall Clock 56.730475052s] Trained 128 records in 0.100496342 seconds. Throughput is 1273.6782 records/second. Loss is 2.2583992. Sequentialb692dd65's hyper parameters: Current learning rate is 6.626905235255137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5376/60000][Iteration 511][Wall Clock 56.822500223s] Trained 128 records in 0.092025171 seconds. Throughput is 1390.9238 records/second. Loss is 2.269427. Sequentialb692dd65's hyper parameters: Current learning rate is 6.622516556291391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5504/60000][Iteration 512][Wall Clock 56.929251279s] Trained 128 records in 0.106751056 seconds. Throughput is 1199.0514 records/second. Loss is 2.2609124. Sequentialb692dd65's hyper parameters: Current learning rate is 6.618133686300463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5632/60000][Iteration 513][Wall Clock 57.019587355s] Trained 128 records in 0.090336076 seconds. Throughput is 1416.9312 records/second. Loss is 2.2620971. Sequentialb692dd65's hyper parameters: Current learning rate is 6.613756613756613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:20 INFO  DistriOptimizer$:408 - [Epoch 2 5760/60000][Iteration 514][Wall Clock 57.107587023s] Trained 128 records in 0.087999668 seconds. Throughput is 1454.5509 records/second. Loss is 2.252744. Sequentialb692dd65's hyper parameters: Current learning rate is 6.609385327164574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 5888/60000][Iteration 515][Wall Clock 57.205762565s] Trained 128 records in 0.098175542 seconds. Throughput is 1303.7871 records/second. Loss is 2.2501054. Sequentialb692dd65's hyper parameters: Current learning rate is 6.605019815059445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6016/60000][Iteration 516][Wall Clock 57.289990938s] Trained 128 records in 0.084228373 seconds. Throughput is 1519.6779 records/second. Loss is 2.2684135. Sequentialb692dd65's hyper parameters: Current learning rate is 6.600660066006601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6144/60000][Iteration 517][Wall Clock 57.378466818s] Trained 128 records in 0.08847588 seconds. Throughput is 1446.7219 records/second. Loss is 2.2619114. Sequentialb692dd65's hyper parameters: Current learning rate is 6.596306068601583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6272/60000][Iteration 518][Wall Clock 57.4706694s] Trained 128 records in 0.092202582 seconds. Throughput is 1388.2474 records/second. Loss is 2.2524934. Sequentialb692dd65's hyper parameters: Current learning rate is 6.591957811470007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6400/60000][Iteration 519][Wall Clock 57.562089987s] Trained 128 records in 0.091420587 seconds. Throughput is 1400.1223 records/second. Loss is 2.2619808. Sequentialb692dd65's hyper parameters: Current learning rate is 6.587615283267457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6528/60000][Iteration 520][Wall Clock 57.660023466s] Trained 128 records in 0.097933479 seconds. Throughput is 1307.0096 records/second. Loss is 2.2574098. Sequentialb692dd65's hyper parameters: Current learning rate is 6.583278472679394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6656/60000][Iteration 521][Wall Clock 57.751347512s] Trained 128 records in 0.091324046 seconds. Throughput is 1401.6024 records/second. Loss is 2.2697897. Sequentialb692dd65's hyper parameters: Current learning rate is 6.578947368421052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6784/60000][Iteration 522][Wall Clock 57.839103651s] Trained 128 records in 0.087756139 seconds. Throughput is 1458.5874 records/second. Loss is 2.2763052. Sequentialb692dd65's hyper parameters: Current learning rate is 6.574621959237344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 6912/60000][Iteration 523][Wall Clock 57.940865763s] Trained 128 records in 0.101762112 seconds. Throughput is 1257.8356 records/second. Loss is 2.270496. Sequentialb692dd65's hyper parameters: Current learning rate is 6.57030223390276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 7040/60000][Iteration 524][Wall Clock 58.025386844s] Trained 128 records in 0.084521081 seconds. Throughput is 1514.4152 records/second. Loss is 2.250902. Sequentialb692dd65's hyper parameters: Current learning rate is 6.565988181221273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:21 INFO  DistriOptimizer$:408 - [Epoch 2 7168/60000][Iteration 525][Wall Clock 58.117271888s] Trained 128 records in 0.091885044 seconds. Throughput is 1393.0449 records/second. Loss is 2.2501333. Sequentialb692dd65's hyper parameters: Current learning rate is 6.561679790026247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7296/60000][Iteration 526][Wall Clock 58.213017715s] Trained 128 records in 0.095745827 seconds. Throughput is 1336.8729 records/second. Loss is 2.2541664. Sequentialb692dd65's hyper parameters: Current learning rate is 6.557377049180328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7424/60000][Iteration 527][Wall Clock 58.312765742s] Trained 128 records in 0.099748027 seconds. Throughput is 1283.2334 records/second. Loss is 2.2571228. Sequentialb692dd65's hyper parameters: Current learning rate is 6.55307994757536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7552/60000][Iteration 528][Wall Clock 58.40346208s] Trained 128 records in 0.090696338 seconds. Throughput is 1411.3029 records/second. Loss is 2.2680125. Sequentialb692dd65's hyper parameters: Current learning rate is 6.548788474132285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7680/60000][Iteration 529][Wall Clock 58.492664822s] Trained 128 records in 0.089202742 seconds. Throughput is 1434.9335 records/second. Loss is 2.2559948. Sequentialb692dd65's hyper parameters: Current learning rate is 6.544502617801048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7808/60000][Iteration 530][Wall Clock 58.589637749s] Trained 128 records in 0.096972927 seconds. Throughput is 1319.956 records/second. Loss is 2.2566907. Sequentialb692dd65's hyper parameters: Current learning rate is 6.540222367560497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 7936/60000][Iteration 531][Wall Clock 58.676157651s] Trained 128 records in 0.086519902 seconds. Throughput is 1479.4283 records/second. Loss is 2.2576451. Sequentialb692dd65's hyper parameters: Current learning rate is 6.5359477124183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 8064/60000][Iteration 532][Wall Clock 58.770766295s] Trained 128 records in 0.094608644 seconds. Throughput is 1352.9419 records/second. Loss is 2.254262. Sequentialb692dd65's hyper parameters: Current learning rate is 6.531678641410842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 8192/60000][Iteration 533][Wall Clock 58.870226174s] Trained 128 records in 0.099459879 seconds. Throughput is 1286.951 records/second. Loss is 2.2583978. Sequentialb692dd65's hyper parameters: Current learning rate is 6.527415143603133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 8320/60000][Iteration 534][Wall Clock 58.991894667s] Trained 128 records in 0.121668493 seconds. Throughput is 1052.039 records/second. Loss is 2.2426558. Sequentialb692dd65's hyper parameters: Current learning rate is 6.523157208088716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 8448/60000][Iteration 535][Wall Clock 59.086225563s] Trained 128 records in 0.094330896 seconds. Throughput is 1356.9254 records/second. Loss is 2.2541356. Sequentialb692dd65's hyper parameters: Current learning rate is 6.51890482398957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:22 INFO  DistriOptimizer$:408 - [Epoch 2 8576/60000][Iteration 536][Wall Clock 59.176046806s] Trained 128 records in 0.089821243 seconds. Throughput is 1425.0526 records/second. Loss is 2.2463193. Sequentialb692dd65's hyper parameters: Current learning rate is 6.514657980456025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 8704/60000][Iteration 537][Wall Clock 59.288461042s] Trained 128 records in 0.112414236 seconds. Throughput is 1138.6459 records/second. Loss is 2.252045. Sequentialb692dd65's hyper parameters: Current learning rate is 6.510416666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 8832/60000][Iteration 538][Wall Clock 59.381849052s] Trained 128 records in 0.09338801 seconds. Throughput is 1370.6256 records/second. Loss is 2.256748. Sequentialb692dd65's hyper parameters: Current learning rate is 6.506180871828237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 8960/60000][Iteration 539][Wall Clock 59.46873041s] Trained 128 records in 0.086881358 seconds. Throughput is 1473.2736 records/second. Loss is 2.2611837. Sequentialb692dd65's hyper parameters: Current learning rate is 6.501950585175553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9088/60000][Iteration 540][Wall Clock 59.556369809s] Trained 128 records in 0.087639399 seconds. Throughput is 1460.5303 records/second. Loss is 2.2569797. Sequentialb692dd65's hyper parameters: Current learning rate is 6.49772579597141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9216/60000][Iteration 541][Wall Clock 59.648041614s] Trained 128 records in 0.091671805 seconds. Throughput is 1396.2854 records/second. Loss is 2.2535014. Sequentialb692dd65's hyper parameters: Current learning rate is 6.493506493506494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9344/60000][Iteration 542][Wall Clock 59.744629167s] Trained 128 records in 0.096587553 seconds. Throughput is 1325.2225 records/second. Loss is 2.256324. Sequentialb692dd65's hyper parameters: Current learning rate is 6.489292667099287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9472/60000][Iteration 543][Wall Clock 59.858478203s] Trained 128 records in 0.113849036 seconds. Throughput is 1124.2959 records/second. Loss is 2.27583. Sequentialb692dd65's hyper parameters: Current learning rate is 6.485084306095979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9600/60000][Iteration 544][Wall Clock 59.946273111s] Trained 128 records in 0.087794908 seconds. Throughput is 1457.9434 records/second. Loss is 2.2667937. Sequentialb692dd65's hyper parameters: Current learning rate is 6.480881399870381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9728/60000][Iteration 545][Wall Clock 60.040280769s] Trained 128 records in 0.094007658 seconds. Throughput is 1361.5912 records/second. Loss is 2.2481017. Sequentialb692dd65's hyper parameters: Current learning rate is 6.476683937823834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:23 INFO  DistriOptimizer$:408 - [Epoch 2 9856/60000][Iteration 546][Wall Clock 60.132771345s] Trained 128 records in 0.092490576 seconds. Throughput is 1383.9248 records/second. Loss is 2.2530472. Sequentialb692dd65's hyper parameters: Current learning rate is 6.472491909385113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 9984/60000][Iteration 547][Wall Clock 60.227049588s] Trained 128 records in 0.094278243 seconds. Throughput is 1357.6833 records/second. Loss is 2.264628. Sequentialb692dd65's hyper parameters: Current learning rate is 6.468305304010349E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10112/60000][Iteration 548][Wall Clock 60.32556201s] Trained 128 records in 0.098512422 seconds. Throughput is 1299.3286 records/second. Loss is 2.263633. Sequentialb692dd65's hyper parameters: Current learning rate is 6.464124111182935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10240/60000][Iteration 549][Wall Clock 60.443582527s] Trained 128 records in 0.118020517 seconds. Throughput is 1084.5571 records/second. Loss is 2.2627792. Sequentialb692dd65's hyper parameters: Current learning rate is 6.459948320413437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10368/60000][Iteration 550][Wall Clock 60.537802289s] Trained 128 records in 0.094219762 seconds. Throughput is 1358.5261 records/second. Loss is 2.255521. Sequentialb692dd65's hyper parameters: Current learning rate is 6.45577792123951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10496/60000][Iteration 551][Wall Clock 60.626810426s] Trained 128 records in 0.089008137 seconds. Throughput is 1438.0708 records/second. Loss is 2.26123. Sequentialb692dd65's hyper parameters: Current learning rate is 6.451612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10624/60000][Iteration 552][Wall Clock 60.719456753s] Trained 128 records in 0.092646327 seconds. Throughput is 1381.5981 records/second. Loss is 2.2513857. Sequentialb692dd65's hyper parameters: Current learning rate is 6.447453255963893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10752/60000][Iteration 553][Wall Clock 60.809523651s] Trained 128 records in 0.090066898 seconds. Throughput is 1421.1659 records/second. Loss is 2.2561736. Sequentialb692dd65's hyper parameters: Current learning rate is 6.443298969072165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 10880/60000][Iteration 554][Wall Clock 60.903059103s] Trained 128 records in 0.093535452 seconds. Throughput is 1368.4651 records/second. Loss is 2.249422. Sequentialb692dd65's hyper parameters: Current learning rate is 6.439150032195751E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 11008/60000][Iteration 555][Wall Clock 61.018694261s] Trained 128 records in 0.115635158 seconds. Throughput is 1106.9298 records/second. Loss is 2.2507498. Sequentialb692dd65's hyper parameters: Current learning rate is 6.435006435006435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:24 INFO  DistriOptimizer$:408 - [Epoch 2 11136/60000][Iteration 556][Wall Clock 61.107469749s] Trained 128 records in 0.088775488 seconds. Throughput is 1441.8395 records/second. Loss is 2.2454972. Sequentialb692dd65's hyper parameters: Current learning rate is 6.430868167202571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11264/60000][Iteration 557][Wall Clock 61.19914894s] Trained 128 records in 0.091679191 seconds. Throughput is 1396.1729 records/second. Loss is 2.2522936. Sequentialb692dd65's hyper parameters: Current learning rate is 6.426735218508997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11392/60000][Iteration 558][Wall Clock 61.285434906s] Trained 128 records in 0.086285966 seconds. Throughput is 1483.4395 records/second. Loss is 2.2548716. Sequentialb692dd65's hyper parameters: Current learning rate is 6.422607578676943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11520/60000][Iteration 559][Wall Clock 61.374277981s] Trained 128 records in 0.088843075 seconds. Throughput is 1440.7426 records/second. Loss is 2.2452018. Sequentialb692dd65's hyper parameters: Current learning rate is 6.418485237483953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11648/60000][Iteration 560][Wall Clock 61.462026459s] Trained 128 records in 0.087748478 seconds. Throughput is 1458.7148 records/second. Loss is 2.2553952. Sequentialb692dd65's hyper parameters: Current learning rate is 6.414368184733803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11776/60000][Iteration 561][Wall Clock 61.548603186s] Trained 128 records in 0.086576727 seconds. Throughput is 1478.4573 records/second. Loss is 2.2695267. Sequentialb692dd65's hyper parameters: Current learning rate is 6.41025641025641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 11904/60000][Iteration 562][Wall Clock 61.635384964s] Trained 128 records in 0.086781778 seconds. Throughput is 1474.964 records/second. Loss is 2.2512944. Sequentialb692dd65's hyper parameters: Current learning rate is 6.406149903907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 12032/60000][Iteration 563][Wall Clock 61.725703594s] Trained 128 records in 0.09031863 seconds. Throughput is 1417.2048 records/second. Loss is 2.2581687. Sequentialb692dd65's hyper parameters: Current learning rate is 6.402048655569782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 12160/60000][Iteration 564][Wall Clock 61.811828339s] Trained 128 records in 0.086124745 seconds. Throughput is 1486.2163 records/second. Loss is 2.2486436. Sequentialb692dd65's hyper parameters: Current learning rate is 6.397952655150352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 12288/60000][Iteration 565][Wall Clock 61.899772197s] Trained 128 records in 0.087943858 seconds. Throughput is 1455.474 records/second. Loss is 2.2479365. Sequentialb692dd65's hyper parameters: Current learning rate is 6.39386189258312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 12416/60000][Iteration 566][Wall Clock 62.004835533s] Trained 128 records in 0.105063336 seconds. Throughput is 1218.3127 records/second. Loss is 2.2688613. Sequentialb692dd65's hyper parameters: Current learning rate is 6.389776357827476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:25 INFO  DistriOptimizer$:408 - [Epoch 2 12544/60000][Iteration 567][Wall Clock 62.097368082s] Trained 128 records in 0.092532549 seconds. Throughput is 1383.2971 records/second. Loss is 2.2439625. Sequentialb692dd65's hyper parameters: Current learning rate is 6.385696040868455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 12672/60000][Iteration 568][Wall Clock 62.183107646s] Trained 128 records in 0.085739564 seconds. Throughput is 1492.8931 records/second. Loss is 2.2556808. Sequentialb692dd65's hyper parameters: Current learning rate is 6.381620931716655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 12800/60000][Iteration 569][Wall Clock 62.271146056s] Trained 128 records in 0.08803841 seconds. Throughput is 1453.9109 records/second. Loss is 2.245312. Sequentialb692dd65's hyper parameters: Current learning rate is 6.377551020408163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 12928/60000][Iteration 570][Wall Clock 62.361516349s] Trained 128 records in 0.090370293 seconds. Throughput is 1416.3947 records/second. Loss is 2.2451932. Sequentialb692dd65's hyper parameters: Current learning rate is 6.373486297004462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13056/60000][Iteration 571][Wall Clock 62.449496389s] Trained 128 records in 0.08798004 seconds. Throughput is 1454.8755 records/second. Loss is 2.2586083. Sequentialb692dd65's hyper parameters: Current learning rate is 6.369426751592356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13184/60000][Iteration 572][Wall Clock 62.542496644s] Trained 128 records in 0.093000255 seconds. Throughput is 1376.3403 records/second. Loss is 2.2436516. Sequentialb692dd65's hyper parameters: Current learning rate is 6.365372374283895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13312/60000][Iteration 573][Wall Clock 62.642180391s] Trained 128 records in 0.099683747 seconds. Throughput is 1284.0609 records/second. Loss is 2.256327. Sequentialb692dd65's hyper parameters: Current learning rate is 6.361323155216284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13440/60000][Iteration 574][Wall Clock 62.731156719s] Trained 128 records in 0.088976328 seconds. Throughput is 1438.5848 records/second. Loss is 2.245716. Sequentialb692dd65's hyper parameters: Current learning rate is 6.357279084551812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13568/60000][Iteration 575][Wall Clock 62.824423226s] Trained 128 records in 0.093266507 seconds. Throughput is 1372.4111 records/second. Loss is 2.2420342. Sequentialb692dd65's hyper parameters: Current learning rate is 6.353240152477764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13696/60000][Iteration 576][Wall Clock 62.920336525s] Trained 128 records in 0.095913299 seconds. Throughput is 1334.5386 records/second. Loss is 2.2417645. Sequentialb692dd65's hyper parameters: Current learning rate is 6.349206349206348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13824/60000][Iteration 577][Wall Clock 63.010056734s] Trained 128 records in 0.089720209 seconds. Throughput is 1426.6573 records/second. Loss is 2.2466743. Sequentialb692dd65's hyper parameters: Current learning rate is 6.345177664974619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:26 INFO  DistriOptimizer$:408 - [Epoch 2 13952/60000][Iteration 578][Wall Clock 63.108142698s] Trained 128 records in 0.098085964 seconds. Throughput is 1304.9778 records/second. Loss is 2.2637815. Sequentialb692dd65's hyper parameters: Current learning rate is 6.341154090044388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14080/60000][Iteration 579][Wall Clock 63.19595708s] Trained 128 records in 0.087814382 seconds. Throughput is 1457.62 records/second. Loss is 2.245384. Sequentialb692dd65's hyper parameters: Current learning rate is 6.337135614702155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14208/60000][Iteration 580][Wall Clock 63.282446105s] Trained 128 records in 0.086489025 seconds. Throughput is 1479.9567 records/second. Loss is 2.2388225. Sequentialb692dd65's hyper parameters: Current learning rate is 6.333122229259025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14336/60000][Iteration 581][Wall Clock 63.373054592s] Trained 128 records in 0.090608487 seconds. Throughput is 1412.6713 records/second. Loss is 2.2415414. Sequentialb692dd65's hyper parameters: Current learning rate is 6.329113924050633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14464/60000][Iteration 582][Wall Clock 63.460336645s] Trained 128 records in 0.087282053 seconds. Throughput is 1466.5099 records/second. Loss is 2.2592568. Sequentialb692dd65's hyper parameters: Current learning rate is 6.325110689437065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14592/60000][Iteration 583][Wall Clock 63.549425599s] Trained 128 records in 0.089088954 seconds. Throughput is 1436.7662 records/second. Loss is 2.2504768. Sequentialb692dd65's hyper parameters: Current learning rate is 6.321112515802782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14720/60000][Iteration 584][Wall Clock 63.637810212s] Trained 128 records in 0.088384613 seconds. Throughput is 1448.2158 records/second. Loss is 2.2464516. Sequentialb692dd65's hyper parameters: Current learning rate is 6.317119393556539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14848/60000][Iteration 585][Wall Clock 63.723635015s] Trained 128 records in 0.085824803 seconds. Throughput is 1491.4104 records/second. Loss is 2.2479866. Sequentialb692dd65's hyper parameters: Current learning rate is 6.313131313131313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 14976/60000][Iteration 586][Wall Clock 63.808927394s] Trained 128 records in 0.085292379 seconds. Throughput is 1500.7203 records/second. Loss is 2.251185. Sequentialb692dd65's hyper parameters: Current learning rate is 6.309148264984228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 15104/60000][Iteration 587][Wall Clock 63.896189221s] Trained 128 records in 0.087261827 seconds. Throughput is 1466.8499 records/second. Loss is 2.2569168. Sequentialb692dd65's hyper parameters: Current learning rate is 6.30517023959647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 15232/60000][Iteration 588][Wall Clock 63.984898189s] Trained 128 records in 0.088708968 seconds. Throughput is 1442.9207 records/second. Loss is 2.2469482. Sequentialb692dd65's hyper parameters: Current learning rate is 6.30119722747322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:27 INFO  DistriOptimizer$:408 - [Epoch 2 15360/60000][Iteration 589][Wall Clock 64.07094501s] Trained 128 records in 0.086046821 seconds. Throughput is 1487.5623 records/second. Loss is 2.2575514. Sequentialb692dd65's hyper parameters: Current learning rate is 6.297229219143577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 15488/60000][Iteration 590][Wall Clock 64.159362508s] Trained 128 records in 0.088417498 seconds. Throughput is 1447.6772 records/second. Loss is 2.2603276. Sequentialb692dd65's hyper parameters: Current learning rate is 6.293266205160479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 15616/60000][Iteration 591][Wall Clock 64.286982087s] Trained 128 records in 0.127619579 seconds. Throughput is 1002.9809 records/second. Loss is 2.2658281. Sequentialb692dd65's hyper parameters: Current learning rate is 6.28930817610063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 15744/60000][Iteration 592][Wall Clock 64.377528534s] Trained 128 records in 0.090546447 seconds. Throughput is 1413.6392 records/second. Loss is 2.2505393. Sequentialb692dd65's hyper parameters: Current learning rate is 6.285355122564425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 15872/60000][Iteration 593][Wall Clock 64.466144138s] Trained 128 records in 0.088615604 seconds. Throughput is 1444.4409 records/second. Loss is 2.2495704. Sequentialb692dd65's hyper parameters: Current learning rate is 6.28140703517588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16000/60000][Iteration 594][Wall Clock 64.55800525s] Trained 128 records in 0.091861112 seconds. Throughput is 1393.4078 records/second. Loss is 2.2566917. Sequentialb692dd65's hyper parameters: Current learning rate is 6.277463904582549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16128/60000][Iteration 595][Wall Clock 64.649146588s] Trained 128 records in 0.091141338 seconds. Throughput is 1404.4121 records/second. Loss is 2.2449782. Sequentialb692dd65's hyper parameters: Current learning rate is 6.273525721455459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16256/60000][Iteration 596][Wall Clock 64.737315114s] Trained 128 records in 0.088168526 seconds. Throughput is 1451.7653 records/second. Loss is 2.2510898. Sequentialb692dd65's hyper parameters: Current learning rate is 6.269592476489029E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16384/60000][Iteration 597][Wall Clock 64.827458795s] Trained 128 records in 0.090143681 seconds. Throughput is 1419.9553 records/second. Loss is 2.2469823. Sequentialb692dd65's hyper parameters: Current learning rate is 6.265664160401002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16512/60000][Iteration 598][Wall Clock 64.929853178s] Trained 128 records in 0.102394383 seconds. Throughput is 1250.0686 records/second. Loss is 2.2444136. Sequentialb692dd65's hyper parameters: Current learning rate is 6.261740763932373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16640/60000][Iteration 599][Wall Clock 65.016073311s] Trained 128 records in 0.086220133 seconds. Throughput is 1484.5721 records/second. Loss is 2.2725136. Sequentialb692dd65's hyper parameters: Current learning rate is 6.257822277847309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:28 INFO  DistriOptimizer$:408 - [Epoch 2 16768/60000][Iteration 600][Wall Clock 65.099391392s] Trained 128 records in 0.083318081 seconds. Throughput is 1536.2811 records/second. Loss is 2.2554247. Sequentialb692dd65's hyper parameters: Current learning rate is 6.253908692933083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 16896/60000][Iteration 601][Wall Clock 65.19110374s] Trained 128 records in 0.091712348 seconds. Throughput is 1395.6681 records/second. Loss is 2.243231. Sequentialb692dd65's hyper parameters: Current learning rate is 6.25E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17024/60000][Iteration 602][Wall Clock 65.277490419s] Trained 128 records in 0.086386679 seconds. Throughput is 1481.71 records/second. Loss is 2.26233. Sequentialb692dd65's hyper parameters: Current learning rate is 6.246096189881325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17152/60000][Iteration 603][Wall Clock 65.366194934s] Trained 128 records in 0.088704515 seconds. Throughput is 1442.9932 records/second. Loss is 2.2504716. Sequentialb692dd65's hyper parameters: Current learning rate is 6.24219725343321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17280/60000][Iteration 604][Wall Clock 65.452825186s] Trained 128 records in 0.086630252 seconds. Throughput is 1477.5438 records/second. Loss is 2.2470038. Sequentialb692dd65's hyper parameters: Current learning rate is 6.238303181534623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17408/60000][Iteration 605][Wall Clock 65.541710138s] Trained 128 records in 0.088884952 seconds. Throughput is 1440.0638 records/second. Loss is 2.2425506. Sequentialb692dd65's hyper parameters: Current learning rate is 6.234413965087282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17536/60000][Iteration 606][Wall Clock 65.628723446s] Trained 128 records in 0.087013308 seconds. Throughput is 1471.0393 records/second. Loss is 2.2459219. Sequentialb692dd65's hyper parameters: Current learning rate is 6.230529595015577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17664/60000][Iteration 607][Wall Clock 65.718093763s] Trained 128 records in 0.089370317 seconds. Throughput is 1432.2429 records/second. Loss is 2.2470062. Sequentialb692dd65's hyper parameters: Current learning rate is 6.226650062266502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17792/60000][Iteration 608][Wall Clock 65.807545582s] Trained 128 records in 0.089451819 seconds. Throughput is 1430.9379 records/second. Loss is 2.2536201. Sequentialb692dd65's hyper parameters: Current learning rate is 6.222775357809583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 17920/60000][Iteration 609][Wall Clock 65.893477738s] Trained 128 records in 0.085932156 seconds. Throughput is 1489.5471 records/second. Loss is 2.2623045. Sequentialb692dd65's hyper parameters: Current learning rate is 6.218905472636816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 18048/60000][Iteration 610][Wall Clock 65.987044088s] Trained 128 records in 0.09356635 seconds. Throughput is 1368.0132 records/second. Loss is 2.2586973. Sequentialb692dd65's hyper parameters: Current learning rate is 6.215040397762586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:29 INFO  DistriOptimizer$:408 - [Epoch 2 18176/60000][Iteration 611][Wall Clock 66.079815941s] Trained 128 records in 0.092771853 seconds. Throughput is 1379.7289 records/second. Loss is 2.2346616. Sequentialb692dd65's hyper parameters: Current learning rate is 6.211180124223603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18304/60000][Iteration 612][Wall Clock 66.173836465s] Trained 128 records in 0.094020524 seconds. Throughput is 1361.4049 records/second. Loss is 2.2496455. Sequentialb692dd65's hyper parameters: Current learning rate is 6.207324643078833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18432/60000][Iteration 613][Wall Clock 66.266445274s] Trained 128 records in 0.092608809 seconds. Throughput is 1382.158 records/second. Loss is 2.2526774. Sequentialb692dd65's hyper parameters: Current learning rate is 6.203473945409429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18560/60000][Iteration 614][Wall Clock 66.362384225s] Trained 128 records in 0.095938951 seconds. Throughput is 1334.1818 records/second. Loss is 2.2629354. Sequentialb692dd65's hyper parameters: Current learning rate is 6.199628022318661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18688/60000][Iteration 615][Wall Clock 66.451602124s] Trained 128 records in 0.089217899 seconds. Throughput is 1434.6897 records/second. Loss is 2.2470021. Sequentialb692dd65's hyper parameters: Current learning rate is 6.195786864931846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18816/60000][Iteration 616][Wall Clock 66.553569197s] Trained 128 records in 0.101967073 seconds. Throughput is 1255.3071 records/second. Loss is 2.2428932. Sequentialb692dd65's hyper parameters: Current learning rate is 6.191950464396285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 18944/60000][Iteration 617][Wall Clock 66.636557752s] Trained 128 records in 0.082988555 seconds. Throughput is 1542.3813 records/second. Loss is 2.2682762. Sequentialb692dd65's hyper parameters: Current learning rate is 6.188118811881188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 19072/60000][Iteration 618][Wall Clock 66.732022224s] Trained 128 records in 0.095464472 seconds. Throughput is 1340.8129 records/second. Loss is 2.2450352. Sequentialb692dd65's hyper parameters: Current learning rate is 6.184291898577613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 19200/60000][Iteration 619][Wall Clock 66.824998637s] Trained 128 records in 0.092976413 seconds. Throughput is 1376.6932 records/second. Loss is 2.2642286. Sequentialb692dd65's hyper parameters: Current learning rate is 6.180469715698394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 19328/60000][Iteration 620][Wall Clock 66.943339643s] Trained 128 records in 0.118341006 seconds. Throughput is 1081.62 records/second. Loss is 2.2648635. Sequentialb692dd65's hyper parameters: Current learning rate is 6.176652254478073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 19456/60000][Iteration 621][Wall Clock 67.032241082s] Trained 128 records in 0.088901439 seconds. Throughput is 1439.7968 records/second. Loss is 2.2511141. Sequentialb692dd65's hyper parameters: Current learning rate is 6.172839506172839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:30 INFO  DistriOptimizer$:408 - [Epoch 2 19584/60000][Iteration 622][Wall Clock 67.119196032s] Trained 128 records in 0.08695495 seconds. Throughput is 1472.0266 records/second. Loss is 2.2314332. Sequentialb692dd65's hyper parameters: Current learning rate is 6.169031462060457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 19712/60000][Iteration 623][Wall Clock 67.214331422s] Trained 128 records in 0.09513539 seconds. Throughput is 1345.4509 records/second. Loss is 2.2472432. Sequentialb692dd65's hyper parameters: Current learning rate is 6.165228113440197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 19840/60000][Iteration 624][Wall Clock 67.317522032s] Trained 128 records in 0.10319061 seconds. Throughput is 1240.423 records/second. Loss is 2.234244. Sequentialb692dd65's hyper parameters: Current learning rate is 6.161429451632779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 19968/60000][Iteration 625][Wall Clock 67.406226508s] Trained 128 records in 0.088704476 seconds. Throughput is 1442.9938 records/second. Loss is 2.2520392. Sequentialb692dd65's hyper parameters: Current learning rate is 6.157635467980296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20096/60000][Iteration 626][Wall Clock 67.49687741s] Trained 128 records in 0.090650902 seconds. Throughput is 1412.0103 records/second. Loss is 2.2546153. Sequentialb692dd65's hyper parameters: Current learning rate is 6.153846153846154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20224/60000][Iteration 627][Wall Clock 67.585247449s] Trained 128 records in 0.088370039 seconds. Throughput is 1448.4547 records/second. Loss is 2.2453933. Sequentialb692dd65's hyper parameters: Current learning rate is 6.150061500615006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20352/60000][Iteration 628][Wall Clock 67.675367941s] Trained 128 records in 0.090120492 seconds. Throughput is 1420.3207 records/second. Loss is 2.254381. Sequentialb692dd65's hyper parameters: Current learning rate is 6.146281499692687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20480/60000][Iteration 629][Wall Clock 67.789361827s] Trained 128 records in 0.113993886 seconds. Throughput is 1122.8673 records/second. Loss is 2.2525663. Sequentialb692dd65's hyper parameters: Current learning rate is 6.142506142506142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20608/60000][Iteration 630][Wall Clock 67.879685679s] Trained 128 records in 0.090323852 seconds. Throughput is 1417.1229 records/second. Loss is 2.243764. Sequentialb692dd65's hyper parameters: Current learning rate is 6.138735420503377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20736/60000][Iteration 631][Wall Clock 67.971241266s] Trained 128 records in 0.091555587 seconds. Throughput is 1398.0577 records/second. Loss is 2.2465718. Sequentialb692dd65's hyper parameters: Current learning rate is 6.134969325153375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:31 INFO  DistriOptimizer$:408 - [Epoch 2 20864/60000][Iteration 632][Wall Clock 68.058976085s] Trained 128 records in 0.087734819 seconds. Throughput is 1458.9419 records/second. Loss is 2.2459612. Sequentialb692dd65's hyper parameters: Current learning rate is 6.131207847946045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 20992/60000][Iteration 633][Wall Clock 68.153055193s] Trained 128 records in 0.094079108 seconds. Throughput is 1360.5571 records/second. Loss is 2.2492123. Sequentialb692dd65's hyper parameters: Current learning rate is 6.127450980392157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21120/60000][Iteration 634][Wall Clock 68.242604408s] Trained 128 records in 0.089549215 seconds. Throughput is 1429.3816 records/second. Loss is 2.2614539. Sequentialb692dd65's hyper parameters: Current learning rate is 6.12369871402327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21248/60000][Iteration 635][Wall Clock 68.335964067s] Trained 128 records in 0.093359659 seconds. Throughput is 1371.0419 records/second. Loss is 2.2413485. Sequentialb692dd65's hyper parameters: Current learning rate is 6.119951040391677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21376/60000][Iteration 636][Wall Clock 68.425457419s] Trained 128 records in 0.089493352 seconds. Throughput is 1430.2739 records/second. Loss is 2.2518811. Sequentialb692dd65's hyper parameters: Current learning rate is 6.116207951070336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21504/60000][Iteration 637][Wall Clock 68.515951124s] Trained 128 records in 0.090493705 seconds. Throughput is 1414.4631 records/second. Loss is 2.2466607. Sequentialb692dd65's hyper parameters: Current learning rate is 6.112469437652812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21632/60000][Iteration 638][Wall Clock 68.632742435s] Trained 128 records in 0.116791311 seconds. Throughput is 1095.9719 records/second. Loss is 2.2363615. Sequentialb692dd65's hyper parameters: Current learning rate is 6.108735491753207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21760/60000][Iteration 639][Wall Clock 68.747107329s] Trained 128 records in 0.114364894 seconds. Throughput is 1119.2246 records/second. Loss is 2.2422168. Sequentialb692dd65's hyper parameters: Current learning rate is 6.105006105006105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 21888/60000][Iteration 640][Wall Clock 68.85783936s] Trained 128 records in 0.110732031 seconds. Throughput is 1155.9437 records/second. Loss is 2.2611437. Sequentialb692dd65's hyper parameters: Current learning rate is 6.101281269066504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 22016/60000][Iteration 641][Wall Clock 68.963830043s] Trained 128 records in 0.105990683 seconds. Throughput is 1207.6533 records/second. Loss is 2.2451513. Sequentialb692dd65's hyper parameters: Current learning rate is 6.097560975609756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:32 INFO  DistriOptimizer$:408 - [Epoch 2 22144/60000][Iteration 642][Wall Clock 69.056739592s] Trained 128 records in 0.092909549 seconds. Throughput is 1377.684 records/second. Loss is 2.2392292. Sequentialb692dd65's hyper parameters: Current learning rate is 6.093845216331506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22272/60000][Iteration 643][Wall Clock 69.171978215s] Trained 128 records in 0.115238623 seconds. Throughput is 1110.7388 records/second. Loss is 2.2545857. Sequentialb692dd65's hyper parameters: Current learning rate is 6.090133982947626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22400/60000][Iteration 644][Wall Clock 69.260149563s] Trained 128 records in 0.088171348 seconds. Throughput is 1451.7188 records/second. Loss is 2.2345018. Sequentialb692dd65's hyper parameters: Current learning rate is 6.086427267194157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22528/60000][Iteration 645][Wall Clock 69.351328516s] Trained 128 records in 0.091178953 seconds. Throughput is 1403.8328 records/second. Loss is 2.2308323. Sequentialb692dd65's hyper parameters: Current learning rate is 6.082725060827251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22656/60000][Iteration 646][Wall Clock 69.447034656s] Trained 128 records in 0.09570614 seconds. Throughput is 1337.4272 records/second. Loss is 2.2445195. Sequentialb692dd65's hyper parameters: Current learning rate is 6.079027355623101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22784/60000][Iteration 647][Wall Clock 69.546613347s] Trained 128 records in 0.099578691 seconds. Throughput is 1285.4155 records/second. Loss is 2.238219. Sequentialb692dd65's hyper parameters: Current learning rate is 6.075334143377886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 22912/60000][Iteration 648][Wall Clock 69.649098712s] Trained 128 records in 0.102485365 seconds. Throughput is 1248.9587 records/second. Loss is 2.2499356. Sequentialb692dd65's hyper parameters: Current learning rate is 6.071645415907711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 23040/60000][Iteration 649][Wall Clock 69.736543218s] Trained 128 records in 0.087444506 seconds. Throughput is 1463.7855 records/second. Loss is 2.2501686. Sequentialb692dd65's hyper parameters: Current learning rate is 6.067961165048543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 23168/60000][Iteration 650][Wall Clock 69.83081969s] Trained 128 records in 0.094276472 seconds. Throughput is 1357.7089 records/second. Loss is 2.2468097. Sequentialb692dd65's hyper parameters: Current learning rate is 6.064281382656155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 23296/60000][Iteration 651][Wall Clock 69.92024776s] Trained 128 records in 0.08942807 seconds. Throughput is 1431.318 records/second. Loss is 2.2620883. Sequentialb692dd65's hyper parameters: Current learning rate is 6.060606060606061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 23424/60000][Iteration 652][Wall Clock 70.008439066s] Trained 128 records in 0.088191306 seconds. Throughput is 1451.3901 records/second. Loss is 2.2338367. Sequentialb692dd65's hyper parameters: Current learning rate is 6.056935190793458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:33 INFO  DistriOptimizer$:408 - [Epoch 2 23552/60000][Iteration 653][Wall Clock 70.096048939s] Trained 128 records in 0.087609873 seconds. Throughput is 1461.0226 records/second. Loss is 2.2535195. Sequentialb692dd65's hyper parameters: Current learning rate is 6.053268765133171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 23680/60000][Iteration 654][Wall Clock 70.189718388s] Trained 128 records in 0.093669449 seconds. Throughput is 1366.5074 records/second. Loss is 2.2606366. Sequentialb692dd65's hyper parameters: Current learning rate is 6.049606775559589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 23808/60000][Iteration 655][Wall Clock 70.279280124s] Trained 128 records in 0.089561736 seconds. Throughput is 1429.1818 records/second. Loss is 2.256706. Sequentialb692dd65's hyper parameters: Current learning rate is 6.045949214026603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 23936/60000][Iteration 656][Wall Clock 70.367470873s] Trained 128 records in 0.088190749 seconds. Throughput is 1451.3994 records/second. Loss is 2.2423806. Sequentialb692dd65's hyper parameters: Current learning rate is 6.042296072507553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24064/60000][Iteration 657][Wall Clock 70.458936619s] Trained 128 records in 0.091465746 seconds. Throughput is 1399.4309 records/second. Loss is 2.248215. Sequentialb692dd65's hyper parameters: Current learning rate is 6.038647342995169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24192/60000][Iteration 658][Wall Clock 70.56173781s] Trained 128 records in 0.102801191 seconds. Throughput is 1245.1218 records/second. Loss is 2.244514. Sequentialb692dd65's hyper parameters: Current learning rate is 6.035003017501509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24320/60000][Iteration 659][Wall Clock 70.655479788s] Trained 128 records in 0.093741978 seconds. Throughput is 1365.4502 records/second. Loss is 2.2535949. Sequentialb692dd65's hyper parameters: Current learning rate is 6.031363088057902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24448/60000][Iteration 660][Wall Clock 70.746364642s] Trained 128 records in 0.090884854 seconds. Throughput is 1408.3755 records/second. Loss is 2.2340572. Sequentialb692dd65's hyper parameters: Current learning rate is 6.027727546714888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24576/60000][Iteration 661][Wall Clock 70.838061146s] Trained 128 records in 0.091696504 seconds. Throughput is 1395.9093 records/second. Loss is 2.2525845. Sequentialb692dd65's hyper parameters: Current learning rate is 6.024096385542168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24704/60000][Iteration 662][Wall Clock 70.930725266s] Trained 128 records in 0.09266412 seconds. Throughput is 1381.3329 records/second. Loss is 2.2384014. Sequentialb692dd65's hyper parameters: Current learning rate is 6.020469596628537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:34 INFO  DistriOptimizer$:408 - [Epoch 2 24832/60000][Iteration 663][Wall Clock 71.049198606s] Trained 128 records in 0.11847334 seconds. Throughput is 1080.4119 records/second. Loss is 2.2524452. Sequentialb692dd65's hyper parameters: Current learning rate is 6.016847172081829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 24960/60000][Iteration 664][Wall Clock 71.137439533s] Trained 128 records in 0.088240927 seconds. Throughput is 1450.574 records/second. Loss is 2.2404313. Sequentialb692dd65's hyper parameters: Current learning rate is 6.013229104028864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25088/60000][Iteration 665][Wall Clock 71.2261185s] Trained 128 records in 0.088678967 seconds. Throughput is 1443.4088 records/second. Loss is 2.2395203. Sequentialb692dd65's hyper parameters: Current learning rate is 6.009615384615384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25216/60000][Iteration 666][Wall Clock 71.335657812s] Trained 128 records in 0.109539312 seconds. Throughput is 1168.5303 records/second. Loss is 2.2390993. Sequentialb692dd65's hyper parameters: Current learning rate is 6.006006006006006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25344/60000][Iteration 667][Wall Clock 71.428730489s] Trained 128 records in 0.093072677 seconds. Throughput is 1375.2694 records/second. Loss is 2.2393188. Sequentialb692dd65's hyper parameters: Current learning rate is 6.002400960384154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25472/60000][Iteration 668][Wall Clock 71.541107501s] Trained 128 records in 0.112377012 seconds. Throughput is 1139.023 records/second. Loss is 2.2407875. Sequentialb692dd65's hyper parameters: Current learning rate is 5.998800239952009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25600/60000][Iteration 669][Wall Clock 71.657438436s] Trained 128 records in 0.116330935 seconds. Throughput is 1100.3092 records/second. Loss is 2.2548344. Sequentialb692dd65's hyper parameters: Current learning rate is 5.995203836930455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25728/60000][Iteration 670][Wall Clock 71.744247814s] Trained 128 records in 0.086809378 seconds. Throughput is 1474.4951 records/second. Loss is 2.2430239. Sequentialb692dd65's hyper parameters: Current learning rate is 5.991611743559018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25856/60000][Iteration 671][Wall Clock 71.835107367s] Trained 128 records in 0.090859553 seconds. Throughput is 1408.7676 records/second. Loss is 2.2167935. Sequentialb692dd65's hyper parameters: Current learning rate is 5.988023952095808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 25984/60000][Iteration 672][Wall Clock 71.927854048s] Trained 128 records in 0.092746681 seconds. Throughput is 1380.1033 records/second. Loss is 2.2427444. Sequentialb692dd65's hyper parameters: Current learning rate is 5.984440454817474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:35 INFO  DistriOptimizer$:408 - [Epoch 2 26112/60000][Iteration 673][Wall Clock 72.042385089s] Trained 128 records in 0.114531041 seconds. Throughput is 1117.601 records/second. Loss is 2.2502742. Sequentialb692dd65's hyper parameters: Current learning rate is 5.980861244019139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26240/60000][Iteration 674][Wall Clock 72.144585434s] Trained 128 records in 0.102200345 seconds. Throughput is 1252.442 records/second. Loss is 2.2366662. Sequentialb692dd65's hyper parameters: Current learning rate is 5.977286312014345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26368/60000][Iteration 675][Wall Clock 72.233270867s] Trained 128 records in 0.088685433 seconds. Throughput is 1443.3036 records/second. Loss is 2.2578814. Sequentialb692dd65's hyper parameters: Current learning rate is 5.973715651135007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26496/60000][Iteration 676][Wall Clock 72.322722605s] Trained 128 records in 0.089451738 seconds. Throughput is 1430.9392 records/second. Loss is 2.2447197. Sequentialb692dd65's hyper parameters: Current learning rate is 5.970149253731343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26624/60000][Iteration 677][Wall Clock 72.414163435s] Trained 128 records in 0.09144083 seconds. Throughput is 1399.8124 records/second. Loss is 2.229251. Sequentialb692dd65's hyper parameters: Current learning rate is 5.966587112171837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26752/60000][Iteration 678][Wall Clock 72.505124574s] Trained 128 records in 0.090961139 seconds. Throughput is 1407.1943 records/second. Loss is 2.234836. Sequentialb692dd65's hyper parameters: Current learning rate is 5.963029218843172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 26880/60000][Iteration 679][Wall Clock 72.593787415s] Trained 128 records in 0.088662841 seconds. Throughput is 1443.6713 records/second. Loss is 2.245997. Sequentialb692dd65's hyper parameters: Current learning rate is 5.95947556615018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 27008/60000][Iteration 680][Wall Clock 72.684338073s] Trained 128 records in 0.090550658 seconds. Throughput is 1413.5734 records/second. Loss is 2.2376974. Sequentialb692dd65's hyper parameters: Current learning rate is 5.955926146515783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 27136/60000][Iteration 681][Wall Clock 72.771908707s] Trained 128 records in 0.087570634 seconds. Throughput is 1461.6771 records/second. Loss is 2.2449381. Sequentialb692dd65's hyper parameters: Current learning rate is 5.952380952380952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 27264/60000][Iteration 682][Wall Clock 72.860405546s] Trained 128 records in 0.088496839 seconds. Throughput is 1446.3793 records/second. Loss is 2.2420096. Sequentialb692dd65's hyper parameters: Current learning rate is 5.94883997620464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 27392/60000][Iteration 683][Wall Clock 72.955773346s] Trained 128 records in 0.0953678 seconds. Throughput is 1342.1721 records/second. Loss is 2.2357807. Sequentialb692dd65's hyper parameters: Current learning rate is 5.945303210463734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:36 INFO  DistriOptimizer$:408 - [Epoch 2 27520/60000][Iteration 684][Wall Clock 73.068331619s] Trained 128 records in 0.112558273 seconds. Throughput is 1137.1887 records/second. Loss is 2.2522376. Sequentialb692dd65's hyper parameters: Current learning rate is 5.941770647653001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 27648/60000][Iteration 685][Wall Clock 73.183520357s] Trained 128 records in 0.115188738 seconds. Throughput is 1111.2197 records/second. Loss is 2.259112. Sequentialb692dd65's hyper parameters: Current learning rate is 5.938242280285035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 27776/60000][Iteration 686][Wall Clock 73.290157178s] Trained 128 records in 0.106636821 seconds. Throughput is 1200.3358 records/second. Loss is 2.2404914. Sequentialb692dd65's hyper parameters: Current learning rate is 5.934718100890207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 27904/60000][Iteration 687][Wall Clock 73.38198925s] Trained 128 records in 0.091832072 seconds. Throughput is 1393.8485 records/second. Loss is 2.249841. Sequentialb692dd65's hyper parameters: Current learning rate is 5.931198102016608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28032/60000][Iteration 688][Wall Clock 73.471955559s] Trained 128 records in 0.089966309 seconds. Throughput is 1422.7548 records/second. Loss is 2.2550864. Sequentialb692dd65's hyper parameters: Current learning rate is 5.927682276229994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28160/60000][Iteration 689][Wall Clock 73.560129909s] Trained 128 records in 0.08817435 seconds. Throughput is 1451.6693 records/second. Loss is 2.2518334. Sequentialb692dd65's hyper parameters: Current learning rate is 5.924170616113743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28288/60000][Iteration 690][Wall Clock 73.648940364s] Trained 128 records in 0.088810455 seconds. Throughput is 1441.2719 records/second. Loss is 2.2383106. Sequentialb692dd65's hyper parameters: Current learning rate is 5.920663114268798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28416/60000][Iteration 691][Wall Clock 73.745922805s] Trained 128 records in 0.096982441 seconds. Throughput is 1319.8265 records/second. Loss is 2.2394574. Sequentialb692dd65's hyper parameters: Current learning rate is 5.91715976331361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28544/60000][Iteration 692][Wall Clock 73.84404006s] Trained 128 records in 0.098117255 seconds. Throughput is 1304.5615 records/second. Loss is 2.2487707. Sequentialb692dd65's hyper parameters: Current learning rate is 5.913660555884092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28672/60000][Iteration 693][Wall Clock 73.934083235s] Trained 128 records in 0.090043175 seconds. Throughput is 1421.5403 records/second. Loss is 2.2372143. Sequentialb692dd65's hyper parameters: Current learning rate is 5.91016548463357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:37 INFO  DistriOptimizer$:408 - [Epoch 2 28800/60000][Iteration 694][Wall Clock 74.049146183s] Trained 128 records in 0.115062948 seconds. Throughput is 1112.4346 records/second. Loss is 2.2390084. Sequentialb692dd65's hyper parameters: Current learning rate is 5.906674542232723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 28928/60000][Iteration 695][Wall Clock 74.156468238s] Trained 128 records in 0.107322055 seconds. Throughput is 1192.672 records/second. Loss is 2.2426026. Sequentialb692dd65's hyper parameters: Current learning rate is 5.90318772136954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29056/60000][Iteration 696][Wall Clock 74.243213418s] Trained 128 records in 0.08674518 seconds. Throughput is 1475.5863 records/second. Loss is 2.241842. Sequentialb692dd65's hyper parameters: Current learning rate is 5.899705014749262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29184/60000][Iteration 697][Wall Clock 74.332899342s] Trained 128 records in 0.089685924 seconds. Throughput is 1427.2028 records/second. Loss is 2.2390487. Sequentialb692dd65's hyper parameters: Current learning rate is 5.896226415094339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29312/60000][Iteration 698][Wall Clock 74.428351644s] Trained 128 records in 0.095452302 seconds. Throughput is 1340.9839 records/second. Loss is 2.233432. Sequentialb692dd65's hyper parameters: Current learning rate is 5.892751915144372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29440/60000][Iteration 699][Wall Clock 74.527895596s] Trained 128 records in 0.099543952 seconds. Throughput is 1285.8641 records/second. Loss is 2.2578168. Sequentialb692dd65's hyper parameters: Current learning rate is 5.889281507656067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29568/60000][Iteration 700][Wall Clock 74.619639967s] Trained 128 records in 0.091744371 seconds. Throughput is 1395.1809 records/second. Loss is 2.2340622. Sequentialb692dd65's hyper parameters: Current learning rate is 5.885815185403178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29696/60000][Iteration 701][Wall Clock 74.707956448s] Trained 128 records in 0.088316481 seconds. Throughput is 1449.3331 records/second. Loss is 2.2376196. Sequentialb692dd65's hyper parameters: Current learning rate is 5.88235294117647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29824/60000][Iteration 702][Wall Clock 74.795719255s] Trained 128 records in 0.087762807 seconds. Throughput is 1458.4766 records/second. Loss is 2.2454598. Sequentialb692dd65's hyper parameters: Current learning rate is 5.878894767783657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 29952/60000][Iteration 703][Wall Clock 74.882025908s] Trained 128 records in 0.086306653 seconds. Throughput is 1483.0837 records/second. Loss is 2.2398028. Sequentialb692dd65's hyper parameters: Current learning rate is 5.875440658049354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 30080/60000][Iteration 704][Wall Clock 74.968705924s] Trained 128 records in 0.086680016 seconds. Throughput is 1476.6956 records/second. Loss is 2.2323828. Sequentialb692dd65's hyper parameters: Current learning rate is 5.871990604815032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:38 INFO  DistriOptimizer$:408 - [Epoch 2 30208/60000][Iteration 705][Wall Clock 75.057640964s] Trained 128 records in 0.08893504 seconds. Throughput is 1439.2527 records/second. Loss is 2.2400057. Sequentialb692dd65's hyper parameters: Current learning rate is 5.868544600938967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30336/60000][Iteration 706][Wall Clock 75.145838876s] Trained 128 records in 0.088197912 seconds. Throughput is 1451.2816 records/second. Loss is 2.2342818. Sequentialb692dd65's hyper parameters: Current learning rate is 5.865102639296188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30464/60000][Iteration 707][Wall Clock 75.237155899s] Trained 128 records in 0.091317023 seconds. Throughput is 1401.7102 records/second. Loss is 2.2382019. Sequentialb692dd65's hyper parameters: Current learning rate is 5.86166471277843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30592/60000][Iteration 708][Wall Clock 75.325748283s] Trained 128 records in 0.088592384 seconds. Throughput is 1444.8195 records/second. Loss is 2.24707. Sequentialb692dd65's hyper parameters: Current learning rate is 5.858230814294084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30720/60000][Iteration 709][Wall Clock 75.415548615s] Trained 128 records in 0.089800332 seconds. Throughput is 1425.3844 records/second. Loss is 2.2391229. Sequentialb692dd65's hyper parameters: Current learning rate is 5.85480093676815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30848/60000][Iteration 710][Wall Clock 75.515789748s] Trained 128 records in 0.100241133 seconds. Throughput is 1276.9209 records/second. Loss is 2.2235844. Sequentialb692dd65's hyper parameters: Current learning rate is 5.851375073142189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 30976/60000][Iteration 711][Wall Clock 75.604159804s] Trained 128 records in 0.088370056 seconds. Throughput is 1448.4545 records/second. Loss is 2.2426736. Sequentialb692dd65's hyper parameters: Current learning rate is 5.847953216374269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 31104/60000][Iteration 712][Wall Clock 75.709110735s] Trained 128 records in 0.104950931 seconds. Throughput is 1219.6176 records/second. Loss is 2.2263796. Sequentialb692dd65's hyper parameters: Current learning rate is 5.844535359438925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 31232/60000][Iteration 713][Wall Clock 75.796887678s] Trained 128 records in 0.087776943 seconds. Throughput is 1458.2417 records/second. Loss is 2.2355554. Sequentialb692dd65's hyper parameters: Current learning rate is 5.841121495327103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 31360/60000][Iteration 714][Wall Clock 75.884356126s] Trained 128 records in 0.087468448 seconds. Throughput is 1463.3849 records/second. Loss is 2.2270863. Sequentialb692dd65's hyper parameters: Current learning rate is 5.837711617046118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 31488/60000][Iteration 715][Wall Clock 75.969460833s] Trained 128 records in 0.085104707 seconds. Throughput is 1504.0297 records/second. Loss is 2.2433271. Sequentialb692dd65's hyper parameters: Current learning rate is 5.834305717619604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:39 INFO  DistriOptimizer$:408 - [Epoch 2 31616/60000][Iteration 716][Wall Clock 76.066325779s] Trained 128 records in 0.096864946 seconds. Throughput is 1321.4275 records/second. Loss is 2.2526114. Sequentialb692dd65's hyper parameters: Current learning rate is 5.830903790087465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 31744/60000][Iteration 717][Wall Clock 76.149917862s] Trained 128 records in 0.083592083 seconds. Throughput is 1531.2456 records/second. Loss is 2.2480812. Sequentialb692dd65's hyper parameters: Current learning rate is 5.827505827505828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 31872/60000][Iteration 718][Wall Clock 76.238363015s] Trained 128 records in 0.088445153 seconds. Throughput is 1447.2246 records/second. Loss is 2.2474976. Sequentialb692dd65's hyper parameters: Current learning rate is 5.824111822947001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32000/60000][Iteration 719][Wall Clock 76.32302217s] Trained 128 records in 0.084659155 seconds. Throughput is 1511.9452 records/second. Loss is 2.2423074. Sequentialb692dd65's hyper parameters: Current learning rate is 5.820721769499418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32128/60000][Iteration 720][Wall Clock 76.411735411s] Trained 128 records in 0.088713241 seconds. Throughput is 1442.8511 records/second. Loss is 2.240924. Sequentialb692dd65's hyper parameters: Current learning rate is 5.817335660267598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32256/60000][Iteration 721][Wall Clock 76.500676595s] Trained 128 records in 0.088941184 seconds. Throughput is 1439.1533 records/second. Loss is 2.2635722. Sequentialb692dd65's hyper parameters: Current learning rate is 5.813953488372093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32384/60000][Iteration 722][Wall Clock 76.5883048s] Trained 128 records in 0.087628205 seconds. Throughput is 1460.7168 records/second. Loss is 2.2406976. Sequentialb692dd65's hyper parameters: Current learning rate is 5.810575246949448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32512/60000][Iteration 723][Wall Clock 76.674405767s] Trained 128 records in 0.086100967 seconds. Throughput is 1486.6267 records/second. Loss is 2.232276. Sequentialb692dd65's hyper parameters: Current learning rate is 5.807200929152149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32640/60000][Iteration 724][Wall Clock 76.767111976s] Trained 128 records in 0.092706209 seconds. Throughput is 1380.7058 records/second. Loss is 2.234526. Sequentialb692dd65's hyper parameters: Current learning rate is 5.803830528148578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32768/60000][Iteration 725][Wall Clock 76.858261144s] Trained 128 records in 0.091149168 seconds. Throughput is 1404.2915 records/second. Loss is 2.2285929. Sequentialb692dd65's hyper parameters: Current learning rate is 5.80046403712297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 32896/60000][Iteration 726][Wall Clock 76.942868329s] Trained 128 records in 0.084607185 seconds. Throughput is 1512.8739 records/second. Loss is 2.2321649. Sequentialb692dd65's hyper parameters: Current learning rate is 5.797101449275362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:40 INFO  DistriOptimizer$:408 - [Epoch 2 33024/60000][Iteration 727][Wall Clock 77.031966533s] Trained 128 records in 0.089098204 seconds. Throughput is 1436.617 records/second. Loss is 2.236551. Sequentialb692dd65's hyper parameters: Current learning rate is 5.793742757821553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33152/60000][Iteration 728][Wall Clock 77.120273147s] Trained 128 records in 0.088306614 seconds. Throughput is 1449.4951 records/second. Loss is 2.2425644. Sequentialb692dd65's hyper parameters: Current learning rate is 5.790387955993052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33280/60000][Iteration 729][Wall Clock 77.204907235s] Trained 128 records in 0.084634088 seconds. Throughput is 1512.393 records/second. Loss is 2.2321963. Sequentialb692dd65's hyper parameters: Current learning rate is 5.787037037037037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33408/60000][Iteration 730][Wall Clock 77.29123422s] Trained 128 records in 0.086326985 seconds. Throughput is 1482.7345 records/second. Loss is 2.2399507. Sequentialb692dd65's hyper parameters: Current learning rate is 5.78368999421631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33536/60000][Iteration 731][Wall Clock 77.37951678s] Trained 128 records in 0.08828256 seconds. Throughput is 1449.8899 records/second. Loss is 2.236709. Sequentialb692dd65's hyper parameters: Current learning rate is 5.780346820809249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33664/60000][Iteration 732][Wall Clock 77.465749704s] Trained 128 records in 0.086232924 seconds. Throughput is 1484.3518 records/second. Loss is 2.2347271. Sequentialb692dd65's hyper parameters: Current learning rate is 5.777007510109764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33792/60000][Iteration 733][Wall Clock 77.55174339s] Trained 128 records in 0.085993686 seconds. Throughput is 1488.4814 records/second. Loss is 2.239467. Sequentialb692dd65's hyper parameters: Current learning rate is 5.773672055427252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 33920/60000][Iteration 734][Wall Clock 77.639867345s] Trained 128 records in 0.088123955 seconds. Throughput is 1452.4995 records/second. Loss is 2.2447433. Sequentialb692dd65's hyper parameters: Current learning rate is 5.770340450086555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 34048/60000][Iteration 735][Wall Clock 77.723745597s] Trained 128 records in 0.083878252 seconds. Throughput is 1526.0214 records/second. Loss is 2.236044. Sequentialb692dd65's hyper parameters: Current learning rate is 5.767012687427913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 34176/60000][Iteration 736][Wall Clock 77.813223143s] Trained 128 records in 0.089477546 seconds. Throughput is 1430.5265 records/second. Loss is 2.2304587. Sequentialb692dd65's hyper parameters: Current learning rate is 5.763688760806917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 34304/60000][Iteration 737][Wall Clock 77.901666819s] Trained 128 records in 0.088443676 seconds. Throughput is 1447.2488 records/second. Loss is 2.2307196. Sequentialb692dd65's hyper parameters: Current learning rate is 5.76036866359447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 34432/60000][Iteration 738][Wall Clock 77.992754754s] Trained 128 records in 0.091087935 seconds. Throughput is 1405.2355 records/second. Loss is 2.237799. Sequentialb692dd65's hyper parameters: Current learning rate is 5.757052389176741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:41 INFO  DistriOptimizer$:408 - [Epoch 2 34560/60000][Iteration 739][Wall Clock 78.081769481s] Trained 128 records in 0.089014727 seconds. Throughput is 1437.9644 records/second. Loss is 2.2407637. Sequentialb692dd65's hyper parameters: Current learning rate is 5.753739930955121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 34688/60000][Iteration 740][Wall Clock 78.172420461s] Trained 128 records in 0.09065098 seconds. Throughput is 1412.0089 records/second. Loss is 2.2440388. Sequentialb692dd65's hyper parameters: Current learning rate is 5.750431282346176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 34816/60000][Iteration 741][Wall Clock 78.27170001s] Trained 128 records in 0.099279549 seconds. Throughput is 1289.2887 records/second. Loss is 2.2341826. Sequentialb692dd65's hyper parameters: Current learning rate is 5.747126436781609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 34944/60000][Iteration 742][Wall Clock 78.366572579s] Trained 128 records in 0.094872569 seconds. Throughput is 1349.1781 records/second. Loss is 2.2419493. Sequentialb692dd65's hyper parameters: Current learning rate is 5.743825387708214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35072/60000][Iteration 743][Wall Clock 78.443683611s] Trained 128 records in 0.077111032 seconds. Throughput is 1659.944 records/second. Loss is 2.2435424. Sequentialb692dd65's hyper parameters: Current learning rate is 5.74052812858783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35200/60000][Iteration 744][Wall Clock 78.538733766s] Trained 128 records in 0.095050155 seconds. Throughput is 1346.6575 records/second. Loss is 2.2460194. Sequentialb692dd65's hyper parameters: Current learning rate is 5.737234652897304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35328/60000][Iteration 745][Wall Clock 78.624236274s] Trained 128 records in 0.085502508 seconds. Throughput is 1497.0321 records/second. Loss is 2.2420218. Sequentialb692dd65's hyper parameters: Current learning rate is 5.733944954128441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35456/60000][Iteration 746][Wall Clock 78.71070069s] Trained 128 records in 0.086464416 seconds. Throughput is 1480.3778 records/second. Loss is 2.238446. Sequentialb692dd65's hyper parameters: Current learning rate is 5.730659025787965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35584/60000][Iteration 747][Wall Clock 78.798770206s] Trained 128 records in 0.088069516 seconds. Throughput is 1453.3973 records/second. Loss is 2.2371345. Sequentialb692dd65's hyper parameters: Current learning rate is 5.72737686139748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35712/60000][Iteration 748][Wall Clock 78.887000719s] Trained 128 records in 0.088230513 seconds. Throughput is 1450.7452 records/second. Loss is 2.227146. Sequentialb692dd65's hyper parameters: Current learning rate is 5.724098454493418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35840/60000][Iteration 749][Wall Clock 78.985015696s] Trained 128 records in 0.098014977 seconds. Throughput is 1305.9229 records/second. Loss is 2.231758. Sequentialb692dd65's hyper parameters: Current learning rate is 5.720823798627002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:42 INFO  DistriOptimizer$:408 - [Epoch 2 35968/60000][Iteration 750][Wall Clock 79.072636323s] Trained 128 records in 0.087620627 seconds. Throughput is 1460.8433 records/second. Loss is 2.2360332. Sequentialb692dd65's hyper parameters: Current learning rate is 5.717552887364208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36096/60000][Iteration 751][Wall Clock 79.160366307s] Trained 128 records in 0.087729984 seconds. Throughput is 1459.0223 records/second. Loss is 2.2520375. Sequentialb692dd65's hyper parameters: Current learning rate is 5.714285714285715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36224/60000][Iteration 752][Wall Clock 79.250406864s] Trained 128 records in 0.090040557 seconds. Throughput is 1421.5817 records/second. Loss is 2.238438. Sequentialb692dd65's hyper parameters: Current learning rate is 5.711022272986865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36352/60000][Iteration 753][Wall Clock 79.344088024s] Trained 128 records in 0.09368116 seconds. Throughput is 1366.3367 records/second. Loss is 2.2430496. Sequentialb692dd65's hyper parameters: Current learning rate is 5.707762557077625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36480/60000][Iteration 754][Wall Clock 79.433520756s] Trained 128 records in 0.089432732 seconds. Throughput is 1431.2433 records/second. Loss is 2.2237315. Sequentialb692dd65's hyper parameters: Current learning rate is 5.704506560182544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36608/60000][Iteration 755][Wall Clock 79.523058171s] Trained 128 records in 0.089537415 seconds. Throughput is 1429.5701 records/second. Loss is 2.2275062. Sequentialb692dd65's hyper parameters: Current learning rate is 5.701254275940707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36736/60000][Iteration 756][Wall Clock 79.614017391s] Trained 128 records in 0.09095922 seconds. Throughput is 1407.224 records/second. Loss is 2.2421403. Sequentialb692dd65's hyper parameters: Current learning rate is 5.698005698005699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36864/60000][Iteration 757][Wall Clock 79.707549718s] Trained 128 records in 0.093532327 seconds. Throughput is 1368.5109 records/second. Loss is 2.239793. Sequentialb692dd65's hyper parameters: Current learning rate is 5.694760820045558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 36992/60000][Iteration 758][Wall Clock 79.797369118s] Trained 128 records in 0.0898194 seconds. Throughput is 1425.0819 records/second. Loss is 2.2318144. Sequentialb692dd65's hyper parameters: Current learning rate is 5.691519635742744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 37120/60000][Iteration 759][Wall Clock 79.887087928s] Trained 128 records in 0.08971881 seconds. Throughput is 1426.6796 records/second. Loss is 2.233832. Sequentialb692dd65's hyper parameters: Current learning rate is 5.688282138794084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 37248/60000][Iteration 760][Wall Clock 79.976512082s] Trained 128 records in 0.089424154 seconds. Throughput is 1431.3806 records/second. Loss is 2.2531762. Sequentialb692dd65's hyper parameters: Current learning rate is 5.685048322910746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:43 INFO  DistriOptimizer$:408 - [Epoch 2 37376/60000][Iteration 761][Wall Clock 80.069523722s] Trained 128 records in 0.09301164 seconds. Throughput is 1376.1719 records/second. Loss is 2.2432199. Sequentialb692dd65's hyper parameters: Current learning rate is 5.681818181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 37504/60000][Iteration 762][Wall Clock 80.156623753s] Trained 128 records in 0.087100031 seconds. Throughput is 1469.5747 records/second. Loss is 2.227795. Sequentialb692dd65's hyper parameters: Current learning rate is 5.678591709256105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 37632/60000][Iteration 763][Wall Clock 80.245217268s] Trained 128 records in 0.088593515 seconds. Throughput is 1444.801 records/second. Loss is 2.2464037. Sequentialb692dd65's hyper parameters: Current learning rate is 5.675368898978433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 37760/60000][Iteration 764][Wall Clock 80.335630819s] Trained 128 records in 0.090413551 seconds. Throughput is 1415.717 records/second. Loss is 2.2231348. Sequentialb692dd65's hyper parameters: Current learning rate is 5.672149744753262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 37888/60000][Iteration 765][Wall Clock 80.431860302s] Trained 128 records in 0.096229483 seconds. Throughput is 1330.1537 records/second. Loss is 2.2469447. Sequentialb692dd65's hyper parameters: Current learning rate is 5.668934240362812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38016/60000][Iteration 766][Wall Clock 80.519031063s] Trained 128 records in 0.087170761 seconds. Throughput is 1468.3823 records/second. Loss is 2.23809. Sequentialb692dd65's hyper parameters: Current learning rate is 5.665722379603399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38144/60000][Iteration 767][Wall Clock 80.6231528s] Trained 128 records in 0.104121737 seconds. Throughput is 1229.3302 records/second. Loss is 2.2386844. Sequentialb692dd65's hyper parameters: Current learning rate is 5.662514156285391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38272/60000][Iteration 768][Wall Clock 80.718554691s] Trained 128 records in 0.095401891 seconds. Throughput is 1341.6925 records/second. Loss is 2.2247813. Sequentialb692dd65's hyper parameters: Current learning rate is 5.659309564233164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38400/60000][Iteration 769][Wall Clock 80.804312794s] Trained 128 records in 0.085758103 seconds. Throughput is 1492.5703 records/second. Loss is 2.2316022. Sequentialb692dd65's hyper parameters: Current learning rate is 5.656108597285068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38528/60000][Iteration 770][Wall Clock 80.894714747s] Trained 128 records in 0.090401953 seconds. Throughput is 1415.8986 records/second. Loss is 2.2234654. Sequentialb692dd65's hyper parameters: Current learning rate is 5.652911249293386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:44 INFO  DistriOptimizer$:408 - [Epoch 2 38656/60000][Iteration 771][Wall Clock 80.982826999s] Trained 128 records in 0.088112252 seconds. Throughput is 1452.6925 records/second. Loss is 2.2449183. Sequentialb692dd65's hyper parameters: Current learning rate is 5.649717514124294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 38784/60000][Iteration 772][Wall Clock 81.076917856s] Trained 128 records in 0.094090857 seconds. Throughput is 1360.3872 records/second. Loss is 2.2182643. Sequentialb692dd65's hyper parameters: Current learning rate is 5.646527385657821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 38912/60000][Iteration 773][Wall Clock 81.166310357s] Trained 128 records in 0.089392501 seconds. Throughput is 1431.8875 records/second. Loss is 2.2282104. Sequentialb692dd65's hyper parameters: Current learning rate is 5.64334085778781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39040/60000][Iteration 774][Wall Clock 81.256150065s] Trained 128 records in 0.089839708 seconds. Throughput is 1424.7598 records/second. Loss is 2.2398338. Sequentialb692dd65's hyper parameters: Current learning rate is 5.640157924421883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39168/60000][Iteration 775][Wall Clock 81.356818468s] Trained 128 records in 0.100668403 seconds. Throughput is 1271.5012 records/second. Loss is 2.2365675. Sequentialb692dd65's hyper parameters: Current learning rate is 5.636978579481398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39296/60000][Iteration 776][Wall Clock 81.444516558s] Trained 128 records in 0.08769809 seconds. Throughput is 1459.553 records/second. Loss is 2.2259145. Sequentialb692dd65's hyper parameters: Current learning rate is 5.633802816901409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39424/60000][Iteration 777][Wall Clock 81.533107519s] Trained 128 records in 0.088590961 seconds. Throughput is 1444.8427 records/second. Loss is 2.2281451. Sequentialb692dd65's hyper parameters: Current learning rate is 5.630630630630631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39552/60000][Iteration 778][Wall Clock 81.61908598s] Trained 128 records in 0.085978461 seconds. Throughput is 1488.7449 records/second. Loss is 2.2106264. Sequentialb692dd65's hyper parameters: Current learning rate is 5.6274620146314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39680/60000][Iteration 779][Wall Clock 81.706773136s] Trained 128 records in 0.087687156 seconds. Throughput is 1459.7349 records/second. Loss is 2.2384558. Sequentialb692dd65's hyper parameters: Current learning rate is 5.624296962879641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39808/60000][Iteration 780][Wall Clock 81.794513886s] Trained 128 records in 0.08774075 seconds. Throughput is 1458.8433 records/second. Loss is 2.2275631. Sequentialb692dd65's hyper parameters: Current learning rate is 5.621135469364812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 39936/60000][Iteration 781][Wall Clock 81.884572646s] Trained 128 records in 0.09005876 seconds. Throughput is 1421.2943 records/second. Loss is 2.2405562. Sequentialb692dd65's hyper parameters: Current learning rate is 5.617977528089888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:45 INFO  DistriOptimizer$:408 - [Epoch 2 40064/60000][Iteration 782][Wall Clock 81.974923758s] Trained 128 records in 0.090351112 seconds. Throughput is 1416.6953 records/second. Loss is 2.237997. Sequentialb692dd65's hyper parameters: Current learning rate is 5.614823133071308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40192/60000][Iteration 783][Wall Clock 82.062660653s] Trained 128 records in 0.087736895 seconds. Throughput is 1458.9073 records/second. Loss is 2.239795. Sequentialb692dd65's hyper parameters: Current learning rate is 5.611672278338945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40320/60000][Iteration 784][Wall Clock 82.168973687s] Trained 128 records in 0.106313034 seconds. Throughput is 1203.9916 records/second. Loss is 2.2215323. Sequentialb692dd65's hyper parameters: Current learning rate is 5.608524957936063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40448/60000][Iteration 785][Wall Clock 82.256752694s] Trained 128 records in 0.087779007 seconds. Throughput is 1458.2074 records/second. Loss is 2.2271984. Sequentialb692dd65's hyper parameters: Current learning rate is 5.605381165919282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40576/60000][Iteration 786][Wall Clock 82.345873555s] Trained 128 records in 0.089120861 seconds. Throughput is 1436.2518 records/second. Loss is 2.2333627. Sequentialb692dd65's hyper parameters: Current learning rate is 5.602240896358543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40704/60000][Iteration 787][Wall Clock 82.43745221s] Trained 128 records in 0.091578655 seconds. Throughput is 1397.7056 records/second. Loss is 2.225763. Sequentialb692dd65's hyper parameters: Current learning rate is 5.599104143337066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40832/60000][Iteration 788][Wall Clock 82.526740121s] Trained 128 records in 0.089287911 seconds. Throughput is 1433.5647 records/second. Loss is 2.220087. Sequentialb692dd65's hyper parameters: Current learning rate is 5.595970900951316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 40960/60000][Iteration 789][Wall Clock 82.61880106s] Trained 128 records in 0.092060939 seconds. Throughput is 1390.3834 records/second. Loss is 2.2223516. Sequentialb692dd65's hyper parameters: Current learning rate is 5.592841163310962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 41088/60000][Iteration 790][Wall Clock 82.707640049s] Trained 128 records in 0.088838989 seconds. Throughput is 1440.8088 records/second. Loss is 2.2319732. Sequentialb692dd65's hyper parameters: Current learning rate is 5.589714924538849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 41216/60000][Iteration 791][Wall Clock 82.798484682s] Trained 128 records in 0.090844633 seconds. Throughput is 1408.999 records/second. Loss is 2.2353835. Sequentialb692dd65's hyper parameters: Current learning rate is 5.586592178770949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 41344/60000][Iteration 792][Wall Clock 82.894620869s] Trained 128 records in 0.096136187 seconds. Throughput is 1331.4445 records/second. Loss is 2.2410884. Sequentialb692dd65's hyper parameters: Current learning rate is 5.583472920156337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:46 INFO  DistriOptimizer$:408 - [Epoch 2 41472/60000][Iteration 793][Wall Clock 82.976546878s] Trained 128 records in 0.081926009 seconds. Throughput is 1562.3854 records/second. Loss is 2.2201025. Sequentialb692dd65's hyper parameters: Current learning rate is 5.580357142857143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 41600/60000][Iteration 794][Wall Clock 83.063387127s] Trained 128 records in 0.086840249 seconds. Throughput is 1473.971 records/second. Loss is 2.2235117. Sequentialb692dd65's hyper parameters: Current learning rate is 5.577244841048521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 41728/60000][Iteration 795][Wall Clock 83.154138749s] Trained 128 records in 0.090751622 seconds. Throughput is 1410.4431 records/second. Loss is 2.23197. Sequentialb692dd65's hyper parameters: Current learning rate is 5.574136008918618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 41856/60000][Iteration 796][Wall Clock 83.250973779s] Trained 128 records in 0.09683503 seconds. Throughput is 1321.8357 records/second. Loss is 2.2320206. Sequentialb692dd65's hyper parameters: Current learning rate is 5.571030640668524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 41984/60000][Iteration 797][Wall Clock 83.34100331s] Trained 128 records in 0.090029531 seconds. Throughput is 1421.7557 records/second. Loss is 2.2414353. Sequentialb692dd65's hyper parameters: Current learning rate is 5.567928730512249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42112/60000][Iteration 798][Wall Clock 83.432442985s] Trained 128 records in 0.091439675 seconds. Throughput is 1399.8301 records/second. Loss is 2.2196882. Sequentialb692dd65's hyper parameters: Current learning rate is 5.564830272676684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42240/60000][Iteration 799][Wall Clock 83.521496516s] Trained 128 records in 0.089053531 seconds. Throughput is 1437.3376 records/second. Loss is 2.230475. Sequentialb692dd65's hyper parameters: Current learning rate is 5.561735261401557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42368/60000][Iteration 800][Wall Clock 83.622043369s] Trained 128 records in 0.100546853 seconds. Throughput is 1273.0383 records/second. Loss is 2.2489963. Sequentialb692dd65's hyper parameters: Current learning rate is 5.558643690939412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42496/60000][Iteration 801][Wall Clock 83.708758696s] Trained 128 records in 0.086715327 seconds. Throughput is 1476.0944 records/second. Loss is 2.2311869. Sequentialb692dd65's hyper parameters: Current learning rate is 5.555555555555556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42624/60000][Iteration 802][Wall Clock 83.796635849s] Trained 128 records in 0.087877153 seconds. Throughput is 1456.5789 records/second. Loss is 2.2395225. Sequentialb692dd65's hyper parameters: Current learning rate is 5.552470849528039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42752/60000][Iteration 803][Wall Clock 83.88502974s] Trained 128 records in 0.088393891 seconds. Throughput is 1448.0638 records/second. Loss is 2.2165582. Sequentialb692dd65's hyper parameters: Current learning rate is 5.549389567147614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:47 INFO  DistriOptimizer$:408 - [Epoch 2 42880/60000][Iteration 804][Wall Clock 83.972727375s] Trained 128 records in 0.087697635 seconds. Throughput is 1459.5605 records/second. Loss is 2.2306223. Sequentialb692dd65's hyper parameters: Current learning rate is 5.546311702717693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43008/60000][Iteration 805][Wall Clock 84.058777994s] Trained 128 records in 0.086050619 seconds. Throughput is 1487.4965 records/second. Loss is 2.2378893. Sequentialb692dd65's hyper parameters: Current learning rate is 5.543237250554324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43136/60000][Iteration 806][Wall Clock 84.145640898s] Trained 128 records in 0.086862904 seconds. Throughput is 1473.5864 records/second. Loss is 2.2296383. Sequentialb692dd65's hyper parameters: Current learning rate is 5.540166204986149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43264/60000][Iteration 807][Wall Clock 84.232015745s] Trained 128 records in 0.086374847 seconds. Throughput is 1481.9128 records/second. Loss is 2.235365. Sequentialb692dd65's hyper parameters: Current learning rate is 5.537098560354374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43392/60000][Iteration 808][Wall Clock 84.318800141s] Trained 128 records in 0.086784396 seconds. Throughput is 1474.9196 records/second. Loss is 2.2269793. Sequentialb692dd65's hyper parameters: Current learning rate is 5.534034311012729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43520/60000][Iteration 809][Wall Clock 84.408217344s] Trained 128 records in 0.089417203 seconds. Throughput is 1431.4918 records/second. Loss is 2.22937. Sequentialb692dd65's hyper parameters: Current learning rate is 5.530973451327434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43648/60000][Iteration 810][Wall Clock 84.49532526s] Trained 128 records in 0.087107916 seconds. Throughput is 1469.4417 records/second. Loss is 2.222731. Sequentialb692dd65's hyper parameters: Current learning rate is 5.52791597567717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43776/60000][Iteration 811][Wall Clock 84.582107403s] Trained 128 records in 0.086782143 seconds. Throughput is 1474.9578 records/second. Loss is 2.2338936. Sequentialb692dd65's hyper parameters: Current learning rate is 5.524861878453039E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 43904/60000][Iteration 812][Wall Clock 84.668150789s] Trained 128 records in 0.086043386 seconds. Throughput is 1487.6216 records/second. Loss is 2.2377574. Sequentialb692dd65's hyper parameters: Current learning rate is 5.521811154058532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 44032/60000][Iteration 813][Wall Clock 84.7536485s] Trained 128 records in 0.085497711 seconds. Throughput is 1497.1161 records/second. Loss is 2.2379546. Sequentialb692dd65's hyper parameters: Current learning rate is 5.518763796909492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 44160/60000][Iteration 814][Wall Clock 84.841052022s] Trained 128 records in 0.087403522 seconds. Throughput is 1464.4719 records/second. Loss is 2.2263422. Sequentialb692dd65's hyper parameters: Current learning rate is 5.515719801434087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 44288/60000][Iteration 815][Wall Clock 84.929079531s] Trained 128 records in 0.088027509 seconds. Throughput is 1454.091 records/second. Loss is 2.2199993. Sequentialb692dd65's hyper parameters: Current learning rate is 5.512679162072767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:48 INFO  DistriOptimizer$:408 - [Epoch 2 44416/60000][Iteration 816][Wall Clock 85.018152376s] Trained 128 records in 0.089072845 seconds. Throughput is 1437.026 records/second. Loss is 2.2176642. Sequentialb692dd65's hyper parameters: Current learning rate is 5.509641873278238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 44544/60000][Iteration 817][Wall Clock 85.107928618s] Trained 128 records in 0.089776242 seconds. Throughput is 1425.767 records/second. Loss is 2.2354429. Sequentialb692dd65's hyper parameters: Current learning rate is 5.506607929515418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 44672/60000][Iteration 818][Wall Clock 85.208363835s] Trained 128 records in 0.100435217 seconds. Throughput is 1274.4534 records/second. Loss is 2.2362845. Sequentialb692dd65's hyper parameters: Current learning rate is 5.50357732526142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 44800/60000][Iteration 819][Wall Clock 85.304104323s] Trained 128 records in 0.095740488 seconds. Throughput is 1336.9474 records/second. Loss is 2.2190018. Sequentialb692dd65's hyper parameters: Current learning rate is 5.5005500550055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 44928/60000][Iteration 820][Wall Clock 85.385729512s] Trained 128 records in 0.081625189 seconds. Throughput is 1568.1434 records/second. Loss is 2.2202003. Sequentialb692dd65's hyper parameters: Current learning rate is 5.497526113249038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45056/60000][Iteration 821][Wall Clock 85.476589741s] Trained 128 records in 0.090860229 seconds. Throughput is 1408.7571 records/second. Loss is 2.2180977. Sequentialb692dd65's hyper parameters: Current learning rate is 5.494505494505495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45184/60000][Iteration 822][Wall Clock 85.569874844s] Trained 128 records in 0.093285103 seconds. Throughput is 1372.1376 records/second. Loss is 2.2378457. Sequentialb692dd65's hyper parameters: Current learning rate is 5.491488193300384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45312/60000][Iteration 823][Wall Clock 85.661423974s] Trained 128 records in 0.09154913 seconds. Throughput is 1398.1564 records/second. Loss is 2.234644. Sequentialb692dd65's hyper parameters: Current learning rate is 5.488474204171241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45440/60000][Iteration 824][Wall Clock 85.75667822s] Trained 128 records in 0.095254246 seconds. Throughput is 1343.7722 records/second. Loss is 2.2391255. Sequentialb692dd65's hyper parameters: Current learning rate is 5.485463521667581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45568/60000][Iteration 825][Wall Clock 85.863676291s] Trained 128 records in 0.106998071 seconds. Throughput is 1196.2832 records/second. Loss is 2.2274077. Sequentialb692dd65's hyper parameters: Current learning rate is 5.482456140350877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45696/60000][Iteration 826][Wall Clock 85.943717113s] Trained 128 records in 0.080040822 seconds. Throughput is 1599.184 records/second. Loss is 2.2303586. Sequentialb692dd65's hyper parameters: Current learning rate is 5.47945205479452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:49 INFO  DistriOptimizer$:408 - [Epoch 2 45824/60000][Iteration 827][Wall Clock 86.028851282s] Trained 128 records in 0.085134169 seconds. Throughput is 1503.509 records/second. Loss is 2.2306156. Sequentialb692dd65's hyper parameters: Current learning rate is 5.47645125958379E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 45952/60000][Iteration 828][Wall Clock 86.114996907s] Trained 128 records in 0.086145625 seconds. Throughput is 1485.8561 records/second. Loss is 2.2304192. Sequentialb692dd65's hyper parameters: Current learning rate is 5.473453749315818E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46080/60000][Iteration 829][Wall Clock 86.205290599s] Trained 128 records in 0.090293692 seconds. Throughput is 1417.5963 records/second. Loss is 2.2331157. Sequentialb692dd65's hyper parameters: Current learning rate is 5.470459518599562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46208/60000][Iteration 830][Wall Clock 86.29428095s] Trained 128 records in 0.088990351 seconds. Throughput is 1438.3582 records/second. Loss is 2.2393525. Sequentialb692dd65's hyper parameters: Current learning rate is 5.467468562055768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46336/60000][Iteration 831][Wall Clock 86.388237858s] Trained 128 records in 0.093956908 seconds. Throughput is 1362.3267 records/second. Loss is 2.2335317. Sequentialb692dd65's hyper parameters: Current learning rate is 5.46448087431694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46464/60000][Iteration 832][Wall Clock 86.479019122s] Trained 128 records in 0.090781264 seconds. Throughput is 1409.9825 records/second. Loss is 2.2170248. Sequentialb692dd65's hyper parameters: Current learning rate is 5.461496450027308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46592/60000][Iteration 833][Wall Clock 86.568993399s] Trained 128 records in 0.089974277 seconds. Throughput is 1422.6288 records/second. Loss is 2.216437. Sequentialb692dd65's hyper parameters: Current learning rate is 5.458515283842794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46720/60000][Iteration 834][Wall Clock 86.658427612s] Trained 128 records in 0.089434213 seconds. Throughput is 1431.2196 records/second. Loss is 2.2284818. Sequentialb692dd65's hyper parameters: Current learning rate is 5.455537370430988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46848/60000][Iteration 835][Wall Clock 86.747117244s] Trained 128 records in 0.088689632 seconds. Throughput is 1443.2352 records/second. Loss is 2.235928. Sequentialb692dd65's hyper parameters: Current learning rate is 5.452562704471102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 46976/60000][Iteration 836][Wall Clock 86.838071744s] Trained 128 records in 0.0909545 seconds. Throughput is 1407.2971 records/second. Loss is 2.2378297. Sequentialb692dd65's hyper parameters: Current learning rate is 5.449591280653951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 47104/60000][Iteration 837][Wall Clock 86.927013579s] Trained 128 records in 0.088941835 seconds. Throughput is 1439.1428 records/second. Loss is 2.2407634. Sequentialb692dd65's hyper parameters: Current learning rate is 5.446623093681918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:50 INFO  DistriOptimizer$:408 - [Epoch 2 47232/60000][Iteration 838][Wall Clock 87.0151347s] Trained 128 records in 0.088121121 seconds. Throughput is 1452.5461 records/second. Loss is 2.2303095. Sequentialb692dd65's hyper parameters: Current learning rate is 5.443658138268917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 47360/60000][Iteration 839][Wall Clock 87.103812365s] Trained 128 records in 0.088677665 seconds. Throughput is 1443.4299 records/second. Loss is 2.212924. Sequentialb692dd65's hyper parameters: Current learning rate is 5.44069640914037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 47488/60000][Iteration 840][Wall Clock 87.194723327s] Trained 128 records in 0.090910962 seconds. Throughput is 1407.971 records/second. Loss is 2.230312. Sequentialb692dd65's hyper parameters: Current learning rate is 5.437737901033171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 47616/60000][Iteration 841][Wall Clock 87.285756245s] Trained 128 records in 0.091032918 seconds. Throughput is 1406.0848 records/second. Loss is 2.2357752. Sequentialb692dd65's hyper parameters: Current learning rate is 5.434782608695652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 47744/60000][Iteration 842][Wall Clock 87.374371779s] Trained 128 records in 0.088615534 seconds. Throughput is 1444.442 records/second. Loss is 2.2300842. Sequentialb692dd65's hyper parameters: Current learning rate is 5.431830526887562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 47872/60000][Iteration 843][Wall Clock 87.472987332s] Trained 128 records in 0.098615553 seconds. Throughput is 1297.9697 records/second. Loss is 2.220394. Sequentialb692dd65's hyper parameters: Current learning rate is 5.428881650380022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48000/60000][Iteration 844][Wall Clock 87.563148092s] Trained 128 records in 0.09016076 seconds. Throughput is 1419.6864 records/second. Loss is 2.2281578. Sequentialb692dd65's hyper parameters: Current learning rate is 5.425935973955507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48128/60000][Iteration 845][Wall Clock 87.650778476s] Trained 128 records in 0.087630384 seconds. Throughput is 1460.6805 records/second. Loss is 2.228051. Sequentialb692dd65's hyper parameters: Current learning rate is 5.422993492407809E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48256/60000][Iteration 846][Wall Clock 87.745180581s] Trained 128 records in 0.094402105 seconds. Throughput is 1355.902 records/second. Loss is 2.224494. Sequentialb692dd65's hyper parameters: Current learning rate is 5.420054200542005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48384/60000][Iteration 847][Wall Clock 87.83588792s] Trained 128 records in 0.090707339 seconds. Throughput is 1411.1317 records/second. Loss is 2.230563. Sequentialb692dd65's hyper parameters: Current learning rate is 5.417118093174431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48512/60000][Iteration 848][Wall Clock 87.923961536s] Trained 128 records in 0.088073616 seconds. Throughput is 1453.3296 records/second. Loss is 2.2229738. Sequentialb692dd65's hyper parameters: Current learning rate is 5.414185165132648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:51 INFO  DistriOptimizer$:408 - [Epoch 2 48640/60000][Iteration 849][Wall Clock 88.011856937s] Trained 128 records in 0.087895401 seconds. Throughput is 1456.2764 records/second. Loss is 2.2247088. Sequentialb692dd65's hyper parameters: Current learning rate is 5.411255411255411E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 48768/60000][Iteration 850][Wall Clock 88.096975609s] Trained 128 records in 0.085118672 seconds. Throughput is 1503.7828 records/second. Loss is 2.2440197. Sequentialb692dd65's hyper parameters: Current learning rate is 5.408328826392645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 48896/60000][Iteration 851][Wall Clock 88.199986617s] Trained 128 records in 0.103011008 seconds. Throughput is 1242.5857 records/second. Loss is 2.215876. Sequentialb692dd65's hyper parameters: Current learning rate is 5.405405405405405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49024/60000][Iteration 852][Wall Clock 88.291831691s] Trained 128 records in 0.091845074 seconds. Throughput is 1393.6512 records/second. Loss is 2.2242222. Sequentialb692dd65's hyper parameters: Current learning rate is 5.402485143165856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49152/60000][Iteration 853][Wall Clock 88.382677399s] Trained 128 records in 0.090845708 seconds. Throughput is 1408.9823 records/second. Loss is 2.217962. Sequentialb692dd65's hyper parameters: Current learning rate is 5.399568034557236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49280/60000][Iteration 854][Wall Clock 88.468029928s] Trained 128 records in 0.085352529 seconds. Throughput is 1499.6626 records/second. Loss is 2.2354052. Sequentialb692dd65's hyper parameters: Current learning rate is 5.396654074473826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49408/60000][Iteration 855][Wall Clock 88.553360466s] Trained 128 records in 0.085330538 seconds. Throughput is 1500.0491 records/second. Loss is 2.2355235. Sequentialb692dd65's hyper parameters: Current learning rate is 5.393743257820927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49536/60000][Iteration 856][Wall Clock 88.642847854s] Trained 128 records in 0.089487388 seconds. Throughput is 1430.3691 records/second. Loss is 2.219136. Sequentialb692dd65's hyper parameters: Current learning rate is 5.390835579514825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49664/60000][Iteration 857][Wall Clock 88.733015353s] Trained 128 records in 0.090167499 seconds. Throughput is 1419.5802 records/second. Loss is 2.2309084. Sequentialb692dd65's hyper parameters: Current learning rate is 5.38793103448276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49792/60000][Iteration 858][Wall Clock 88.821891122s] Trained 128 records in 0.088875769 seconds. Throughput is 1440.2125 records/second. Loss is 2.2256474. Sequentialb692dd65's hyper parameters: Current learning rate is 5.385029617662897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 49920/60000][Iteration 859][Wall Clock 88.911024761s] Trained 128 records in 0.089133639 seconds. Throughput is 1436.0459 records/second. Loss is 2.2318466. Sequentialb692dd65's hyper parameters: Current learning rate is 5.382131324004305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:52 INFO  DistriOptimizer$:408 - [Epoch 2 50048/60000][Iteration 860][Wall Clock 89.001623145s] Trained 128 records in 0.090598384 seconds. Throughput is 1412.8287 records/second. Loss is 2.2276728. Sequentialb692dd65's hyper parameters: Current learning rate is 5.379236148466918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50176/60000][Iteration 861][Wall Clock 89.088637303s] Trained 128 records in 0.087014158 seconds. Throughput is 1471.0249 records/second. Loss is 2.218727. Sequentialb692dd65's hyper parameters: Current learning rate is 5.376344086021505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50304/60000][Iteration 862][Wall Clock 89.175502784s] Trained 128 records in 0.086865481 seconds. Throughput is 1473.5427 records/second. Loss is 2.2171597. Sequentialb692dd65's hyper parameters: Current learning rate is 5.373455131649651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50432/60000][Iteration 863][Wall Clock 89.263260369s] Trained 128 records in 0.087757585 seconds. Throughput is 1458.5634 records/second. Loss is 2.2295375. Sequentialb692dd65's hyper parameters: Current learning rate is 5.370569280343716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50560/60000][Iteration 864][Wall Clock 89.35586869s] Trained 128 records in 0.092608321 seconds. Throughput is 1382.1653 records/second. Loss is 2.2246366. Sequentialb692dd65's hyper parameters: Current learning rate is 5.367686527106817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50688/60000][Iteration 865][Wall Clock 89.441861328s] Trained 128 records in 0.085992638 seconds. Throughput is 1488.4996 records/second. Loss is 2.2395654. Sequentialb692dd65's hyper parameters: Current learning rate is 5.36480686695279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50816/60000][Iteration 866][Wall Clock 89.527272729s] Trained 128 records in 0.085411401 seconds. Throughput is 1498.629 records/second. Loss is 2.2149432. Sequentialb692dd65's hyper parameters: Current learning rate is 5.361930294906167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 50944/60000][Iteration 867][Wall Clock 89.613285474s] Trained 128 records in 0.086012745 seconds. Throughput is 1488.1516 records/second. Loss is 2.2321057. Sequentialb692dd65's hyper parameters: Current learning rate is 5.359056806002144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 51072/60000][Iteration 868][Wall Clock 89.705676226s] Trained 128 records in 0.092390752 seconds. Throughput is 1385.42 records/second. Loss is 2.258208. Sequentialb692dd65's hyper parameters: Current learning rate is 5.356186395286556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 51200/60000][Iteration 869][Wall Clock 89.791879833s] Trained 128 records in 0.086203607 seconds. Throughput is 1484.8567 records/second. Loss is 2.2388024. Sequentialb692dd65's hyper parameters: Current learning rate is 5.353319057815846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 51328/60000][Iteration 870][Wall Clock 89.874803644s] Trained 128 records in 0.082923811 seconds. Throughput is 1543.5856 records/second. Loss is 2.2086377. Sequentialb692dd65's hyper parameters: Current learning rate is 5.350454788657035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:53 INFO  DistriOptimizer$:408 - [Epoch 2 51456/60000][Iteration 871][Wall Clock 89.963301693s] Trained 128 records in 0.088498049 seconds. Throughput is 1446.3596 records/second. Loss is 2.2223694. Sequentialb692dd65's hyper parameters: Current learning rate is 5.347593582887701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 51584/60000][Iteration 872][Wall Clock 90.051768006s] Trained 128 records in 0.088466313 seconds. Throughput is 1446.8784 records/second. Loss is 2.2266572. Sequentialb692dd65's hyper parameters: Current learning rate is 5.344735435595939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 51712/60000][Iteration 873][Wall Clock 90.136804384s] Trained 128 records in 0.085036378 seconds. Throughput is 1505.2382 records/second. Loss is 2.2352705. Sequentialb692dd65's hyper parameters: Current learning rate is 5.341880341880342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 51840/60000][Iteration 874][Wall Clock 90.229256805s] Trained 128 records in 0.092452421 seconds. Throughput is 1384.496 records/second. Loss is 2.2275417. Sequentialb692dd65's hyper parameters: Current learning rate is 5.339028296849973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 51968/60000][Iteration 875][Wall Clock 90.316154967s] Trained 128 records in 0.086898162 seconds. Throughput is 1472.9885 records/second. Loss is 2.234011. Sequentialb692dd65's hyper parameters: Current learning rate is 5.336179295624333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52096/60000][Iteration 876][Wall Clock 90.418075558s] Trained 128 records in 0.101920591 seconds. Throughput is 1255.8798 records/second. Loss is 2.232029. Sequentialb692dd65's hyper parameters: Current learning rate is 5.333333333333334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52224/60000][Iteration 877][Wall Clock 90.50559758s] Trained 128 records in 0.087522022 seconds. Throughput is 1462.489 records/second. Loss is 2.2251952. Sequentialb692dd65's hyper parameters: Current learning rate is 5.330490405117271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52352/60000][Iteration 878][Wall Clock 90.59007929s] Trained 128 records in 0.08448171 seconds. Throughput is 1515.1208 records/second. Loss is 2.2248104. Sequentialb692dd65's hyper parameters: Current learning rate is 5.327650506126798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52480/60000][Iteration 879][Wall Clock 90.676165124s] Trained 128 records in 0.086085834 seconds. Throughput is 1486.8881 records/second. Loss is 2.223482. Sequentialb692dd65's hyper parameters: Current learning rate is 5.324813631522896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52608/60000][Iteration 880][Wall Clock 90.763104014s] Trained 128 records in 0.08693889 seconds. Throughput is 1472.2986 records/second. Loss is 2.2206922. Sequentialb692dd65's hyper parameters: Current learning rate is 5.321979776476849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52736/60000][Iteration 881][Wall Clock 90.84974053s] Trained 128 records in 0.086636516 seconds. Throughput is 1477.4371 records/second. Loss is 2.2397506. Sequentialb692dd65's hyper parameters: Current learning rate is 5.319148936170213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:54 INFO  DistriOptimizer$:408 - [Epoch 2 52864/60000][Iteration 882][Wall Clock 90.936307344s] Trained 128 records in 0.086566814 seconds. Throughput is 1478.6267 records/second. Loss is 2.2299044. Sequentialb692dd65's hyper parameters: Current learning rate is 5.31632110579479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 52992/60000][Iteration 883][Wall Clock 91.02423545s] Trained 128 records in 0.087928106 seconds. Throughput is 1455.7347 records/second. Loss is 2.2309778. Sequentialb692dd65's hyper parameters: Current learning rate is 5.313496280552603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53120/60000][Iteration 884][Wall Clock 91.129032191s] Trained 128 records in 0.104796741 seconds. Throughput is 1221.4121 records/second. Loss is 2.2220035. Sequentialb692dd65's hyper parameters: Current learning rate is 5.310674455655868E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53248/60000][Iteration 885][Wall Clock 91.235194662s] Trained 128 records in 0.106162471 seconds. Throughput is 1205.6991 records/second. Loss is 2.2130847. Sequentialb692dd65's hyper parameters: Current learning rate is 5.307855626326964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53376/60000][Iteration 886][Wall Clock 91.354151792s] Trained 128 records in 0.11895713 seconds. Throughput is 1076.0178 records/second. Loss is 2.2128193. Sequentialb692dd65's hyper parameters: Current learning rate is 5.305039787798409E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53504/60000][Iteration 887][Wall Clock 91.471373062s] Trained 128 records in 0.11722127 seconds. Throughput is 1091.952 records/second. Loss is 2.2172208. Sequentialb692dd65's hyper parameters: Current learning rate is 5.302226935312831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53632/60000][Iteration 888][Wall Clock 91.584415803s] Trained 128 records in 0.113042741 seconds. Throughput is 1132.3151 records/second. Loss is 2.2362719. Sequentialb692dd65's hyper parameters: Current learning rate is 5.299417064122947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53760/60000][Iteration 889][Wall Clock 91.674696395s] Trained 128 records in 0.090280592 seconds. Throughput is 1417.802 records/second. Loss is 2.2134976. Sequentialb692dd65's hyper parameters: Current learning rate is 5.296610169491525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 53888/60000][Iteration 890][Wall Clock 91.776510773s] Trained 128 records in 0.101814378 seconds. Throughput is 1257.1898 records/second. Loss is 2.2021759. Sequentialb692dd65's hyper parameters: Current learning rate is 5.293806246691371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 54016/60000][Iteration 891][Wall Clock 91.869707065s] Trained 128 records in 0.093196292 seconds. Throughput is 1373.4452 records/second. Loss is 2.2351837. Sequentialb692dd65's hyper parameters: Current learning rate is 5.29100529100529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:55 INFO  DistriOptimizer$:408 - [Epoch 2 54144/60000][Iteration 892][Wall Clock 91.961527177s] Trained 128 records in 0.091820112 seconds. Throughput is 1394.03 records/second. Loss is 2.2117362. Sequentialb692dd65's hyper parameters: Current learning rate is 5.288207297726071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54272/60000][Iteration 893][Wall Clock 92.062998057s] Trained 128 records in 0.10147088 seconds. Throughput is 1261.4457 records/second. Loss is 2.2271328. Sequentialb692dd65's hyper parameters: Current learning rate is 5.285412262156448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54400/60000][Iteration 894][Wall Clock 92.182053159s] Trained 128 records in 0.119055102 seconds. Throughput is 1075.1324 records/second. Loss is 2.2304702. Sequentialb692dd65's hyper parameters: Current learning rate is 5.282620179609086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54528/60000][Iteration 895][Wall Clock 92.272016883s] Trained 128 records in 0.089963724 seconds. Throughput is 1422.7957 records/second. Loss is 2.2179205. Sequentialb692dd65's hyper parameters: Current learning rate is 5.279831045406547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54656/60000][Iteration 896][Wall Clock 92.366584132s] Trained 128 records in 0.094567249 seconds. Throughput is 1353.5342 records/second. Loss is 2.2147264. Sequentialb692dd65's hyper parameters: Current learning rate is 5.277044854881266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54784/60000][Iteration 897][Wall Clock 92.464859547s] Trained 128 records in 0.098275415 seconds. Throughput is 1302.462 records/second. Loss is 2.213625. Sequentialb692dd65's hyper parameters: Current learning rate is 5.274261603375528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 54912/60000][Iteration 898][Wall Clock 92.560655526s] Trained 128 records in 0.095795979 seconds. Throughput is 1336.173 records/second. Loss is 2.225477. Sequentialb692dd65's hyper parameters: Current learning rate is 5.271481286241434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 55040/60000][Iteration 899][Wall Clock 92.653411889s] Trained 128 records in 0.092756363 seconds. Throughput is 1379.9592 records/second. Loss is 2.2234461. Sequentialb692dd65's hyper parameters: Current learning rate is 5.268703898840885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 55168/60000][Iteration 900][Wall Clock 92.745326009s] Trained 128 records in 0.09191412 seconds. Throughput is 1392.6044 records/second. Loss is 2.2019353. Sequentialb692dd65's hyper parameters: Current learning rate is 5.26592943654555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 55296/60000][Iteration 901][Wall Clock 92.84391476s] Trained 128 records in 0.098588751 seconds. Throughput is 1298.3226 records/second. Loss is 2.2385678. Sequentialb692dd65's hyper parameters: Current learning rate is 5.263157894736842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:56 INFO  DistriOptimizer$:408 - [Epoch 2 55424/60000][Iteration 902][Wall Clock 92.92926876s] Trained 128 records in 0.085354 seconds. Throughput is 1499.6368 records/second. Loss is 2.2201746. Sequentialb692dd65's hyper parameters: Current learning rate is 5.260389268805891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 55552/60000][Iteration 903][Wall Clock 93.025872084s] Trained 128 records in 0.096603324 seconds. Throughput is 1325.0061 records/second. Loss is 2.2297094. Sequentialb692dd65's hyper parameters: Current learning rate is 5.257623554153522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 55680/60000][Iteration 904][Wall Clock 93.121103337s] Trained 128 records in 0.095231253 seconds. Throughput is 1344.0966 records/second. Loss is 2.2105765. Sequentialb692dd65's hyper parameters: Current learning rate is 5.254860746190226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 55808/60000][Iteration 905][Wall Clock 93.216961225s] Trained 128 records in 0.095857888 seconds. Throughput is 1335.31 records/second. Loss is 2.2117915. Sequentialb692dd65's hyper parameters: Current learning rate is 5.252100840336135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 55936/60000][Iteration 906][Wall Clock 93.308869179s] Trained 128 records in 0.091907954 seconds. Throughput is 1392.6978 records/second. Loss is 2.2180212. Sequentialb692dd65's hyper parameters: Current learning rate is 5.249343832020997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56064/60000][Iteration 907][Wall Clock 93.397064914s] Trained 128 records in 0.088195735 seconds. Throughput is 1451.3174 records/second. Loss is 2.2395918. Sequentialb692dd65's hyper parameters: Current learning rate is 5.246589716684155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56192/60000][Iteration 908][Wall Clock 93.485831023s] Trained 128 records in 0.088766109 seconds. Throughput is 1441.9918 records/second. Loss is 2.2166145. Sequentialb692dd65's hyper parameters: Current learning rate is 5.243838489774515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56320/60000][Iteration 909][Wall Clock 93.572579525s] Trained 128 records in 0.086748502 seconds. Throughput is 1475.5298 records/second. Loss is 2.230841. Sequentialb692dd65's hyper parameters: Current learning rate is 5.241090146750524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56448/60000][Iteration 910][Wall Clock 93.665133186s] Trained 128 records in 0.092553661 seconds. Throughput is 1382.9814 records/second. Loss is 2.219747. Sequentialb692dd65's hyper parameters: Current learning rate is 5.238344683080147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56576/60000][Iteration 911][Wall Clock 93.756902758s] Trained 128 records in 0.091769572 seconds. Throughput is 1394.7979 records/second. Loss is 2.219994. Sequentialb692dd65's hyper parameters: Current learning rate is 5.235602094240837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56704/60000][Iteration 912][Wall Clock 93.846721557s] Trained 128 records in 0.089818799 seconds. Throughput is 1425.0914 records/second. Loss is 2.2193913. Sequentialb692dd65's hyper parameters: Current learning rate is 5.232862375719519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:57 INFO  DistriOptimizer$:408 - [Epoch 2 56832/60000][Iteration 913][Wall Clock 93.93333357s] Trained 128 records in 0.086612013 seconds. Throughput is 1477.855 records/second. Loss is 2.226361. Sequentialb692dd65's hyper parameters: Current learning rate is 5.230125523012553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 56960/60000][Iteration 914][Wall Clock 94.024106693s] Trained 128 records in 0.090773123 seconds. Throughput is 1410.109 records/second. Loss is 2.2232254. Sequentialb692dd65's hyper parameters: Current learning rate is 5.227391531625719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57088/60000][Iteration 915][Wall Clock 94.111377202s] Trained 128 records in 0.087270509 seconds. Throughput is 1466.704 records/second. Loss is 2.218787. Sequentialb692dd65's hyper parameters: Current learning rate is 5.22466039707419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57216/60000][Iteration 916][Wall Clock 94.200575956s] Trained 128 records in 0.089198754 seconds. Throughput is 1434.9977 records/second. Loss is 2.2144315. Sequentialb692dd65's hyper parameters: Current learning rate is 5.221932114882506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57344/60000][Iteration 917][Wall Clock 94.286276331s] Trained 128 records in 0.085700375 seconds. Throughput is 1493.5757 records/second. Loss is 2.2203543. Sequentialb692dd65's hyper parameters: Current learning rate is 5.219206680584552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57472/60000][Iteration 918][Wall Clock 94.3729895s] Trained 128 records in 0.086713169 seconds. Throughput is 1476.131 records/second. Loss is 2.230652. Sequentialb692dd65's hyper parameters: Current learning rate is 5.216484089723526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57600/60000][Iteration 919][Wall Clock 94.470483087s] Trained 128 records in 0.097493587 seconds. Throughput is 1312.9069 records/second. Loss is 2.2070577. Sequentialb692dd65's hyper parameters: Current learning rate is 5.213764337851929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57728/60000][Iteration 920][Wall Clock 94.555732662s] Trained 128 records in 0.085249575 seconds. Throughput is 1501.4738 records/second. Loss is 2.2199674. Sequentialb692dd65's hyper parameters: Current learning rate is 5.211047420531526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57856/60000][Iteration 921][Wall Clock 94.644440012s] Trained 128 records in 0.08870735 seconds. Throughput is 1442.9469 records/second. Loss is 2.2253697. Sequentialb692dd65's hyper parameters: Current learning rate is 5.208333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 57984/60000][Iteration 922][Wall Clock 94.746394576s] Trained 128 records in 0.101954564 seconds. Throughput is 1255.4612 records/second. Loss is 2.2195435. Sequentialb692dd65's hyper parameters: Current learning rate is 5.205622071837585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 58112/60000][Iteration 923][Wall Clock 94.840268982s] Trained 128 records in 0.093874406 seconds. Throughput is 1363.524 records/second. Loss is 2.221911. Sequentialb692dd65's hyper parameters: Current learning rate is 5.202913631633714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:58 INFO  DistriOptimizer$:408 - [Epoch 2 58240/60000][Iteration 924][Wall Clock 94.929014623s] Trained 128 records in 0.088745641 seconds. Throughput is 1442.3243 records/second. Loss is 2.2202358. Sequentialb692dd65's hyper parameters: Current learning rate is 5.200208008320332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 58368/60000][Iteration 925][Wall Clock 95.016172893s] Trained 128 records in 0.08715827 seconds. Throughput is 1468.5927 records/second. Loss is 2.2129354. Sequentialb692dd65's hyper parameters: Current learning rate is 5.197505197505198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 58496/60000][Iteration 926][Wall Clock 95.104268853s] Trained 128 records in 0.08809596 seconds. Throughput is 1452.961 records/second. Loss is 2.205188. Sequentialb692dd65's hyper parameters: Current learning rate is 5.194805194805195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 58624/60000][Iteration 927][Wall Clock 95.212255938s] Trained 128 records in 0.107987085 seconds. Throughput is 1185.3269 records/second. Loss is 2.227103. Sequentialb692dd65's hyper parameters: Current learning rate is 5.192107995846313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 58752/60000][Iteration 928][Wall Clock 95.301795233s] Trained 128 records in 0.089539295 seconds. Throughput is 1429.5399 records/second. Loss is 2.2306142. Sequentialb692dd65's hyper parameters: Current learning rate is 5.189413596263622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 58880/60000][Iteration 929][Wall Clock 95.391882196s] Trained 128 records in 0.090086963 seconds. Throughput is 1420.8494 records/second. Loss is 2.2254405. Sequentialb692dd65's hyper parameters: Current learning rate is 5.186721991701245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59008/60000][Iteration 930][Wall Clock 95.480675544s] Trained 128 records in 0.088793348 seconds. Throughput is 1441.5494 records/second. Loss is 2.2175395. Sequentialb692dd65's hyper parameters: Current learning rate is 5.184033177812338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59136/60000][Iteration 931][Wall Clock 95.566975467s] Trained 128 records in 0.086299923 seconds. Throughput is 1483.1995 records/second. Loss is 2.203807. Sequentialb692dd65's hyper parameters: Current learning rate is 5.181347150259067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59264/60000][Iteration 932][Wall Clock 95.655503895s] Trained 128 records in 0.088528428 seconds. Throughput is 1445.8633 records/second. Loss is 2.2256389. Sequentialb692dd65's hyper parameters: Current learning rate is 5.178663904712584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59392/60000][Iteration 933][Wall Clock 95.744386115s] Trained 128 records in 0.08888222 seconds. Throughput is 1440.108 records/second. Loss is 2.2148814. Sequentialb692dd65's hyper parameters: Current learning rate is 5.175983436853002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59520/60000][Iteration 934][Wall Clock 95.833786104s] Trained 128 records in 0.089399989 seconds. Throughput is 1431.7676 records/second. Loss is 2.2031994. Sequentialb692dd65's hyper parameters: Current learning rate is 5.173305742369374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:47:59 INFO  DistriOptimizer$:408 - [Epoch 2 59648/60000][Iteration 935][Wall Clock 95.925216499s] Trained 128 records in 0.091430395 seconds. Throughput is 1399.972 records/second. Loss is 2.2311814. Sequentialb692dd65's hyper parameters: Current learning rate is 5.170630816959668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:00 INFO  DistriOptimizer$:408 - [Epoch 2 59776/60000][Iteration 936][Wall Clock 96.014232669s] Trained 128 records in 0.08901617 seconds. Throughput is 1437.941 records/second. Loss is 2.2140014. Sequentialb692dd65's hyper parameters: Current learning rate is 5.167958656330749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:00 INFO  DistriOptimizer$:408 - [Epoch 2 59904/60000][Iteration 937][Wall Clock 96.102088942s] Trained 128 records in 0.087856273 seconds. Throughput is 1456.925 records/second. Loss is 2.2156758. Sequentialb692dd65's hyper parameters: Current learning rate is 5.165289256198347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:00 INFO  DistriOptimizer$:408 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.191823071s] Trained 128 records in 0.089734129 seconds. Throughput is 1426.436 records/second. Loss is 2.214965. Sequentialb692dd65's hyper parameters: Current learning rate is 5.162622612287042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:00 INFO  DistriOptimizer$:452 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.191823071s] Epoch finished. Wall clock time is 97594.508745 ms
2019-10-15 07:48:00 INFO  DistriOptimizer$:111 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.191823071s] Validate model...
2019-10-15 07:48:01 INFO  DistriOptimizer$:178 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.191823071s] validate model throughput is 12016.22 records/second
2019-10-15 07:48:01 INFO  DistriOptimizer$:181 - [Epoch 2 60032/60000][Iteration 938][Wall Clock 96.191823071s] Top1Accuracy is Accuracy(correct: 3688, count: 10000, accuracy: 0.3688)
2019-10-15 07:48:01 INFO  DistriOptimizer$:221 - [Wall Clock 97.594508745s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:48:01 INFO  DistriOptimizer$:226 - [Wall Clock 97.594508745s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 128/60000][Iteration 939][Wall Clock 97.723937846s] Trained 128 records in 0.129429101 seconds. Throughput is 988.95844 records/second. Loss is 2.216665. Sequentialb692dd65's hyper parameters: Current learning rate is 5.159958720330237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 256/60000][Iteration 940][Wall Clock 97.813705799s] Trained 128 records in 0.089767953 seconds. Throughput is 1425.8986 records/second. Loss is 2.2058644. Sequentialb692dd65's hyper parameters: Current learning rate is 5.157297576070139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 384/60000][Iteration 941][Wall Clock 97.901928489s] Trained 128 records in 0.08822269 seconds. Throughput is 1450.8739 records/second. Loss is 2.2184377. Sequentialb692dd65's hyper parameters: Current learning rate is 5.154639175257732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 512/60000][Iteration 942][Wall Clock 97.985389166s] Trained 128 records in 0.083460677 seconds. Throughput is 1533.6565 records/second. Loss is 2.2138572. Sequentialb692dd65's hyper parameters: Current learning rate is 5.151983513652757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 640/60000][Iteration 943][Wall Clock 98.082402834s] Trained 128 records in 0.097013668 seconds. Throughput is 1319.4017 records/second. Loss is 2.229747. Sequentialb692dd65's hyper parameters: Current learning rate is 5.149330587023687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 768/60000][Iteration 944][Wall Clock 98.170548189s] Trained 128 records in 0.088145355 seconds. Throughput is 1452.1469 records/second. Loss is 2.2228065. Sequentialb692dd65's hyper parameters: Current learning rate is 5.14668039114771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 896/60000][Iteration 945][Wall Clock 98.265916004s] Trained 128 records in 0.095367815 seconds. Throughput is 1342.1719 records/second. Loss is 2.235098. Sequentialb692dd65's hyper parameters: Current learning rate is 5.1440329218107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 1024/60000][Iteration 946][Wall Clock 98.356242012s] Trained 128 records in 0.090326008 seconds. Throughput is 1417.089 records/second. Loss is 2.2248988. Sequentialb692dd65's hyper parameters: Current learning rate is 5.141388174807198E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:01 INFO  DistriOptimizer$:408 - [Epoch 3 1152/60000][Iteration 947][Wall Clock 98.450896089s] Trained 128 records in 0.094654077 seconds. Throughput is 1352.2925 records/second. Loss is 2.233651. Sequentialb692dd65's hyper parameters: Current learning rate is 5.138746145940391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1280/60000][Iteration 948][Wall Clock 98.540453433s] Trained 128 records in 0.089557344 seconds. Throughput is 1429.2518 records/second. Loss is 2.2289197. Sequentialb692dd65's hyper parameters: Current learning rate is 5.136106831022085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1408/60000][Iteration 949][Wall Clock 98.629808997s] Trained 128 records in 0.089355564 seconds. Throughput is 1432.4794 records/second. Loss is 2.230341. Sequentialb692dd65's hyper parameters: Current learning rate is 5.13347022587269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1536/60000][Iteration 950][Wall Clock 98.726420913s] Trained 128 records in 0.096611916 seconds. Throughput is 1324.8883 records/second. Loss is 2.2056127. Sequentialb692dd65's hyper parameters: Current learning rate is 5.13083632632119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1664/60000][Iteration 951][Wall Clock 98.825126271s] Trained 128 records in 0.098705358 seconds. Throughput is 1296.7888 records/second. Loss is 2.221002. Sequentialb692dd65's hyper parameters: Current learning rate is 5.128205128205128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1792/60000][Iteration 952][Wall Clock 98.917108046s] Trained 128 records in 0.091981775 seconds. Throughput is 1391.58 records/second. Loss is 2.2284913. Sequentialb692dd65's hyper parameters: Current learning rate is 5.125576627370579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 1920/60000][Iteration 953][Wall Clock 99.005857743s] Trained 128 records in 0.088749697 seconds. Throughput is 1442.2584 records/second. Loss is 2.232189. Sequentialb692dd65's hyper parameters: Current learning rate is 5.122950819672131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 2048/60000][Iteration 954][Wall Clock 99.098433127s] Trained 128 records in 0.092575384 seconds. Throughput is 1382.657 records/second. Loss is 2.2205887. Sequentialb692dd65's hyper parameters: Current learning rate is 5.120327700972862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 2176/60000][Iteration 955][Wall Clock 99.189194524s] Trained 128 records in 0.090761397 seconds. Throughput is 1410.2913 records/second. Loss is 2.2274187. Sequentialb692dd65's hyper parameters: Current learning rate is 5.117707267144319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 2304/60000][Iteration 956][Wall Clock 99.282193674s] Trained 128 records in 0.09299915 seconds. Throughput is 1376.3566 records/second. Loss is 2.2203074. Sequentialb692dd65's hyper parameters: Current learning rate is 5.115089514066496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:02 INFO  DistriOptimizer$:408 - [Epoch 3 2432/60000][Iteration 957][Wall Clock 99.37426676s] Trained 128 records in 0.092073086 seconds. Throughput is 1390.2 records/second. Loss is 2.2100537. Sequentialb692dd65's hyper parameters: Current learning rate is 5.112474437627812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 2560/60000][Iteration 958][Wall Clock 99.471164329s] Trained 128 records in 0.096897569 seconds. Throughput is 1320.9825 records/second. Loss is 2.226163. Sequentialb692dd65's hyper parameters: Current learning rate is 5.109862033725089E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 2688/60000][Iteration 959][Wall Clock 99.560969166s] Trained 128 records in 0.089804837 seconds. Throughput is 1425.313 records/second. Loss is 2.2250087. Sequentialb692dd65's hyper parameters: Current learning rate is 5.107252298263534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 2816/60000][Iteration 960][Wall Clock 99.651275412s] Trained 128 records in 0.090306246 seconds. Throughput is 1417.3992 records/second. Loss is 2.2260058. Sequentialb692dd65's hyper parameters: Current learning rate is 5.104645227156713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 2944/60000][Iteration 961][Wall Clock 99.742661348s] Trained 128 records in 0.091385936 seconds. Throughput is 1400.6531 records/second. Loss is 2.208103. Sequentialb692dd65's hyper parameters: Current learning rate is 5.102040816326531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3072/60000][Iteration 962][Wall Clock 99.830862507s] Trained 128 records in 0.088201159 seconds. Throughput is 1451.2281 records/second. Loss is 2.2099597. Sequentialb692dd65's hyper parameters: Current learning rate is 5.099439061703213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3200/60000][Iteration 963][Wall Clock 99.919310674s] Trained 128 records in 0.088448167 seconds. Throughput is 1447.1753 records/second. Loss is 2.2193737. Sequentialb692dd65's hyper parameters: Current learning rate is 5.096839959225281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3328/60000][Iteration 964][Wall Clock 100.006862671s] Trained 128 records in 0.087551997 seconds. Throughput is 1461.9884 records/second. Loss is 2.2174287. Sequentialb692dd65's hyper parameters: Current learning rate is 5.094243504839531E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3456/60000][Iteration 965][Wall Clock 100.096011252s] Trained 128 records in 0.089148581 seconds. Throughput is 1435.8053 records/second. Loss is 2.2190866. Sequentialb692dd65's hyper parameters: Current learning rate is 5.091649694501019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3584/60000][Iteration 966][Wall Clock 100.186637408s] Trained 128 records in 0.090626156 seconds. Throughput is 1412.3958 records/second. Loss is 2.2080219. Sequentialb692dd65's hyper parameters: Current learning rate is 5.089058524173028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3712/60000][Iteration 967][Wall Clock 100.281292818s] Trained 128 records in 0.09465541 seconds. Throughput is 1352.2734 records/second. Loss is 2.225876. Sequentialb692dd65's hyper parameters: Current learning rate is 5.08646998982706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:03 INFO  DistriOptimizer$:408 - [Epoch 3 3840/60000][Iteration 968][Wall Clock 100.384782577s] Trained 128 records in 0.103489759 seconds. Throughput is 1236.8374 records/second. Loss is 2.2206774. Sequentialb692dd65's hyper parameters: Current learning rate is 5.083884087442806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 3968/60000][Iteration 969][Wall Clock 100.480609808s] Trained 128 records in 0.095827231 seconds. Throughput is 1335.7373 records/second. Loss is 2.220113. Sequentialb692dd65's hyper parameters: Current learning rate is 5.081300813008131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4096/60000][Iteration 970][Wall Clock 100.575393925s] Trained 128 records in 0.094784117 seconds. Throughput is 1350.4373 records/second. Loss is 2.217205. Sequentialb692dd65's hyper parameters: Current learning rate is 5.078720162519046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4224/60000][Iteration 971][Wall Clock 100.678593332s] Trained 128 records in 0.103199407 seconds. Throughput is 1240.3171 records/second. Loss is 2.2100625. Sequentialb692dd65's hyper parameters: Current learning rate is 5.076142131979696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4352/60000][Iteration 972][Wall Clock 100.766420724s] Trained 128 records in 0.087827392 seconds. Throughput is 1457.404 records/second. Loss is 2.2093503. Sequentialb692dd65's hyper parameters: Current learning rate is 5.073566717402334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4480/60000][Iteration 973][Wall Clock 100.855964692s] Trained 128 records in 0.089543968 seconds. Throughput is 1429.4653 records/second. Loss is 2.1914644. Sequentialb692dd65's hyper parameters: Current learning rate is 5.070993914807302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4608/60000][Iteration 974][Wall Clock 100.948671481s] Trained 128 records in 0.092706789 seconds. Throughput is 1380.6971 records/second. Loss is 2.2082813. Sequentialb692dd65's hyper parameters: Current learning rate is 5.068423720223011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4736/60000][Iteration 975][Wall Clock 101.0408059s] Trained 128 records in 0.092134419 seconds. Throughput is 1389.2745 records/second. Loss is 2.2268562. Sequentialb692dd65's hyper parameters: Current learning rate is 5.065856129685917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4864/60000][Iteration 976][Wall Clock 101.144259911s] Trained 128 records in 0.103454011 seconds. Throughput is 1237.2648 records/second. Loss is 2.208677. Sequentialb692dd65's hyper parameters: Current learning rate is 5.063291139240507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 4992/60000][Iteration 977][Wall Clock 101.236374274s] Trained 128 records in 0.092114363 seconds. Throughput is 1389.5769 records/second. Loss is 2.2138863. Sequentialb692dd65's hyper parameters: Current learning rate is 5.060728744939271E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 5120/60000][Iteration 978][Wall Clock 101.324127853s] Trained 128 records in 0.087753579 seconds. Throughput is 1458.63 records/second. Loss is 2.2136936. Sequentialb692dd65's hyper parameters: Current learning rate is 5.058168942842691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:04 INFO  DistriOptimizer$:408 - [Epoch 3 5248/60000][Iteration 979][Wall Clock 101.416934825s] Trained 128 records in 0.092806972 seconds. Throughput is 1379.2067 records/second. Loss is 2.2242243. Sequentialb692dd65's hyper parameters: Current learning rate is 5.055611729019212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 5376/60000][Iteration 980][Wall Clock 101.510283594s] Trained 128 records in 0.093348769 seconds. Throughput is 1371.2018 records/second. Loss is 2.2267613. Sequentialb692dd65's hyper parameters: Current learning rate is 5.053057099545225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 5504/60000][Iteration 981][Wall Clock 101.601158847s] Trained 128 records in 0.090875253 seconds. Throughput is 1408.5243 records/second. Loss is 2.210005. Sequentialb692dd65's hyper parameters: Current learning rate is 5.05050505050505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 5632/60000][Iteration 982][Wall Clock 101.693355679s] Trained 128 records in 0.092196832 seconds. Throughput is 1388.3341 records/second. Loss is 2.2142937. Sequentialb692dd65's hyper parameters: Current learning rate is 5.047955577990914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 5760/60000][Iteration 983][Wall Clock 101.784822189s] Trained 128 records in 0.09146651 seconds. Throughput is 1399.4193 records/second. Loss is 2.2182639. Sequentialb692dd65's hyper parameters: Current learning rate is 5.045408678102926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 5888/60000][Iteration 984][Wall Clock 101.875112852s] Trained 128 records in 0.090290663 seconds. Throughput is 1417.6438 records/second. Loss is 2.2220626. Sequentialb692dd65's hyper parameters: Current learning rate is 5.042864346949066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 6016/60000][Iteration 985][Wall Clock 101.965752348s] Trained 128 records in 0.090639496 seconds. Throughput is 1412.188 records/second. Loss is 2.2067804. Sequentialb692dd65's hyper parameters: Current learning rate is 5.040322580645161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 6144/60000][Iteration 986][Wall Clock 102.059328032s] Trained 128 records in 0.093575684 seconds. Throughput is 1367.8767 records/second. Loss is 2.2393427. Sequentialb692dd65's hyper parameters: Current learning rate is 5.037783375314862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 6272/60000][Iteration 987][Wall Clock 102.156663204s] Trained 128 records in 0.097335172 seconds. Throughput is 1315.0436 records/second. Loss is 2.2106488. Sequentialb692dd65's hyper parameters: Current learning rate is 5.035246727089627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 6400/60000][Iteration 988][Wall Clock 102.251835069s] Trained 128 records in 0.095171865 seconds. Throughput is 1344.9353 records/second. Loss is 2.205917. Sequentialb692dd65's hyper parameters: Current learning rate is 5.032712632108706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:05 INFO  DistriOptimizer$:408 - [Epoch 3 6528/60000][Iteration 989][Wall Clock 102.34371207s] Trained 128 records in 0.091877001 seconds. Throughput is 1393.167 records/second. Loss is 2.2136822. Sequentialb692dd65's hyper parameters: Current learning rate is 5.030181086519115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 6656/60000][Iteration 990][Wall Clock 102.436689754s] Trained 128 records in 0.092977684 seconds. Throughput is 1376.6743 records/second. Loss is 2.2041578. Sequentialb692dd65's hyper parameters: Current learning rate is 5.027652086475616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 6784/60000][Iteration 991][Wall Clock 102.530502642s] Trained 128 records in 0.093812888 seconds. Throughput is 1364.4181 records/second. Loss is 2.20746. Sequentialb692dd65's hyper parameters: Current learning rate is 5.025125628140704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 6912/60000][Iteration 992][Wall Clock 102.620994547s] Trained 128 records in 0.090491905 seconds. Throughput is 1414.4912 records/second. Loss is 2.223477. Sequentialb692dd65's hyper parameters: Current learning rate is 5.02260170768458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7040/60000][Iteration 993][Wall Clock 102.713721891s] Trained 128 records in 0.092727344 seconds. Throughput is 1380.3911 records/second. Loss is 2.2257516. Sequentialb692dd65's hyper parameters: Current learning rate is 5.020080321285141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7168/60000][Iteration 994][Wall Clock 102.817068217s] Trained 128 records in 0.103346326 seconds. Throughput is 1238.554 records/second. Loss is 2.206495. Sequentialb692dd65's hyper parameters: Current learning rate is 5.017561465127949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7296/60000][Iteration 995][Wall Clock 102.934866264s] Trained 128 records in 0.117798047 seconds. Throughput is 1086.6055 records/second. Loss is 2.2227423. Sequentialb692dd65's hyper parameters: Current learning rate is 5.015045135406219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7424/60000][Iteration 996][Wall Clock 103.028954771s] Trained 128 records in 0.094088507 seconds. Throughput is 1360.4211 records/second. Loss is 2.2001166. Sequentialb692dd65's hyper parameters: Current learning rate is 5.012531328320802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7552/60000][Iteration 997][Wall Clock 103.126329334s] Trained 128 records in 0.097374563 seconds. Throughput is 1314.5116 records/second. Loss is 2.216504. Sequentialb692dd65's hyper parameters: Current learning rate is 5.01002004008016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7680/60000][Iteration 998][Wall Clock 103.219554685s] Trained 128 records in 0.093225351 seconds. Throughput is 1373.0171 records/second. Loss is 2.2220879. Sequentialb692dd65's hyper parameters: Current learning rate is 5.007511266900351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7808/60000][Iteration 999][Wall Clock 103.310762557s] Trained 128 records in 0.091207872 seconds. Throughput is 1403.3877 records/second. Loss is 2.2094352. Sequentialb692dd65's hyper parameters: Current learning rate is 5.005005005005005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:06 INFO  DistriOptimizer$:408 - [Epoch 3 7936/60000][Iteration 1000][Wall Clock 103.400769377s] Trained 128 records in 0.09000682 seconds. Throughput is 1422.1145 records/second. Loss is 2.2281828. Sequentialb692dd65's hyper parameters: Current learning rate is 5.002501250625312E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8064/60000][Iteration 1001][Wall Clock 103.492924031s] Trained 128 records in 0.092154654 seconds. Throughput is 1388.9695 records/second. Loss is 2.1948724. Sequentialb692dd65's hyper parameters: Current learning rate is 5.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8192/60000][Iteration 1002][Wall Clock 103.592489231s] Trained 128 records in 0.0995652 seconds. Throughput is 1285.5897 records/second. Loss is 2.221296. Sequentialb692dd65's hyper parameters: Current learning rate is 4.997501249375311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8320/60000][Iteration 1003][Wall Clock 103.688974226s] Trained 128 records in 0.096484995 seconds. Throughput is 1326.6311 records/second. Loss is 2.229551. Sequentialb692dd65's hyper parameters: Current learning rate is 4.995004995004996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8448/60000][Iteration 1004][Wall Clock 103.783418897s] Trained 128 records in 0.094444671 seconds. Throughput is 1355.2909 records/second. Loss is 2.2134895. Sequentialb692dd65's hyper parameters: Current learning rate is 4.992511233150274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8576/60000][Iteration 1005][Wall Clock 103.874848097s] Trained 128 records in 0.0914292 seconds. Throughput is 1399.9905 records/second. Loss is 2.1933417. Sequentialb692dd65's hyper parameters: Current learning rate is 4.99001996007984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8704/60000][Iteration 1006][Wall Clock 103.967087838s] Trained 128 records in 0.092239741 seconds. Throughput is 1387.6882 records/second. Loss is 2.209189. Sequentialb692dd65's hyper parameters: Current learning rate is 4.987531172069826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8832/60000][Iteration 1007][Wall Clock 104.060180483s] Trained 128 records in 0.093092645 seconds. Throughput is 1374.9744 records/second. Loss is 2.203653. Sequentialb692dd65's hyper parameters: Current learning rate is 4.985044865403788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 8960/60000][Iteration 1008][Wall Clock 104.150629536s] Trained 128 records in 0.090449053 seconds. Throughput is 1415.1614 records/second. Loss is 2.220434. Sequentialb692dd65's hyper parameters: Current learning rate is 4.982561036372695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 9088/60000][Iteration 1009][Wall Clock 104.238107716s] Trained 128 records in 0.08747818 seconds. Throughput is 1463.2219 records/second. Loss is 2.206173. Sequentialb692dd65's hyper parameters: Current learning rate is 4.9800796812749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:07 INFO  DistriOptimizer$:408 - [Epoch 3 9216/60000][Iteration 1010][Wall Clock 104.335783902s] Trained 128 records in 0.097676186 seconds. Throughput is 1310.4525 records/second. Loss is 2.225613. Sequentialb692dd65's hyper parameters: Current learning rate is 4.977600796416126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9344/60000][Iteration 1011][Wall Clock 104.428906238s] Trained 128 records in 0.093122336 seconds. Throughput is 1374.536 records/second. Loss is 2.208437. Sequentialb692dd65's hyper parameters: Current learning rate is 4.975124378109454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9472/60000][Iteration 1012][Wall Clock 104.523695284s] Trained 128 records in 0.094789046 seconds. Throughput is 1350.3671 records/second. Loss is 2.218657. Sequentialb692dd65's hyper parameters: Current learning rate is 4.972650422675286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9600/60000][Iteration 1013][Wall Clock 104.615609532s] Trained 128 records in 0.091914248 seconds. Throughput is 1392.6023 records/second. Loss is 2.1980395. Sequentialb692dd65's hyper parameters: Current learning rate is 4.970178926441352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9728/60000][Iteration 1014][Wall Clock 104.707833555s] Trained 128 records in 0.092224023 seconds. Throughput is 1387.9247 records/second. Loss is 2.2122023. Sequentialb692dd65's hyper parameters: Current learning rate is 4.967709885742673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9856/60000][Iteration 1015][Wall Clock 104.800647758s] Trained 128 records in 0.092814203 seconds. Throughput is 1379.0994 records/second. Loss is 2.2251365. Sequentialb692dd65's hyper parameters: Current learning rate is 4.965243296921549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 9984/60000][Iteration 1016][Wall Clock 104.893640523s] Trained 128 records in 0.092992765 seconds. Throughput is 1376.4512 records/second. Loss is 2.218744. Sequentialb692dd65's hyper parameters: Current learning rate is 4.962779156327543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 10112/60000][Iteration 1017][Wall Clock 104.982116019s] Trained 128 records in 0.088475496 seconds. Throughput is 1446.7283 records/second. Loss is 2.2174776. Sequentialb692dd65's hyper parameters: Current learning rate is 4.96031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 10240/60000][Iteration 1018][Wall Clock 105.07230619s] Trained 128 records in 0.090190171 seconds. Throughput is 1419.2234 records/second. Loss is 2.20802. Sequentialb692dd65's hyper parameters: Current learning rate is 4.957858205255329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 10368/60000][Iteration 1019][Wall Clock 105.178538327s] Trained 128 records in 0.106232137 seconds. Throughput is 1204.9084 records/second. Loss is 2.1958945. Sequentialb692dd65's hyper parameters: Current learning rate is 4.95540138751239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:08 INFO  DistriOptimizer$:408 - [Epoch 3 10496/60000][Iteration 1020][Wall Clock 105.299907518s] Trained 128 records in 0.121369191 seconds. Throughput is 1054.6334 records/second. Loss is 2.2198303. Sequentialb692dd65's hyper parameters: Current learning rate is 4.952947003467063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 10624/60000][Iteration 1021][Wall Clock 105.415250035s] Trained 128 records in 0.115342517 seconds. Throughput is 1109.7382 records/second. Loss is 2.1959145. Sequentialb692dd65's hyper parameters: Current learning rate is 4.950495049504951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 10752/60000][Iteration 1022][Wall Clock 105.512344085s] Trained 128 records in 0.09709405 seconds. Throughput is 1318.3094 records/second. Loss is 2.2115934. Sequentialb692dd65's hyper parameters: Current learning rate is 4.948045522018803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 10880/60000][Iteration 1023][Wall Clock 105.60445269s] Trained 128 records in 0.092108605 seconds. Throughput is 1389.6638 records/second. Loss is 2.2174132. Sequentialb692dd65's hyper parameters: Current learning rate is 4.945598417408506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11008/60000][Iteration 1024][Wall Clock 105.69831509s] Trained 128 records in 0.0938624 seconds. Throughput is 1363.6984 records/second. Loss is 2.2057378. Sequentialb692dd65's hyper parameters: Current learning rate is 4.943153732081067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11136/60000][Iteration 1025][Wall Clock 105.789221514s] Trained 128 records in 0.090906424 seconds. Throughput is 1408.0413 records/second. Loss is 2.1923008. Sequentialb692dd65's hyper parameters: Current learning rate is 4.940711462450593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11264/60000][Iteration 1026][Wall Clock 105.884479498s] Trained 128 records in 0.095257984 seconds. Throughput is 1343.7194 records/second. Loss is 2.206743. Sequentialb692dd65's hyper parameters: Current learning rate is 4.938271604938272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11392/60000][Iteration 1027][Wall Clock 105.987259997s] Trained 128 records in 0.102780499 seconds. Throughput is 1245.3724 records/second. Loss is 2.2132254. Sequentialb692dd65's hyper parameters: Current learning rate is 4.93583415597236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11520/60000][Iteration 1028][Wall Clock 106.082007469s] Trained 128 records in 0.094747472 seconds. Throughput is 1350.9596 records/second. Loss is 2.2326615. Sequentialb692dd65's hyper parameters: Current learning rate is 4.933399111988159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11648/60000][Iteration 1029][Wall Clock 106.177326105s] Trained 128 records in 0.095318636 seconds. Throughput is 1342.8644 records/second. Loss is 2.2002292. Sequentialb692dd65's hyper parameters: Current learning rate is 4.930966469428008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11776/60000][Iteration 1030][Wall Clock 106.275502836s] Trained 128 records in 0.098176731 seconds. Throughput is 1303.7712 records/second. Loss is 2.216575. Sequentialb692dd65's hyper parameters: Current learning rate is 4.928536224741252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:09 INFO  DistriOptimizer$:408 - [Epoch 3 11904/60000][Iteration 1031][Wall Clock 106.367993351s] Trained 128 records in 0.092490515 seconds. Throughput is 1383.9257 records/second. Loss is 2.1961946. Sequentialb692dd65's hyper parameters: Current learning rate is 4.926108374384236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12032/60000][Iteration 1032][Wall Clock 106.460494529s] Trained 128 records in 0.092501178 seconds. Throughput is 1383.7661 records/second. Loss is 2.205446. Sequentialb692dd65's hyper parameters: Current learning rate is 4.923682914820286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12160/60000][Iteration 1033][Wall Clock 106.552235332s] Trained 128 records in 0.091740803 seconds. Throughput is 1395.2352 records/second. Loss is 2.1974466. Sequentialb692dd65's hyper parameters: Current learning rate is 4.921259842519685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12288/60000][Iteration 1034][Wall Clock 106.6437097s] Trained 128 records in 0.091474368 seconds. Throughput is 1399.2991 records/second. Loss is 2.228315. Sequentialb692dd65's hyper parameters: Current learning rate is 4.918839153959666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12416/60000][Iteration 1035][Wall Clock 106.737910344s] Trained 128 records in 0.094200644 seconds. Throughput is 1358.8018 records/second. Loss is 2.2107267. Sequentialb692dd65's hyper parameters: Current learning rate is 4.916420845624386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12544/60000][Iteration 1036][Wall Clock 106.82974916s] Trained 128 records in 0.091838816 seconds. Throughput is 1393.7462 records/second. Loss is 2.2248888. Sequentialb692dd65's hyper parameters: Current learning rate is 4.914004914004914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12672/60000][Iteration 1037][Wall Clock 106.921608514s] Trained 128 records in 0.091859354 seconds. Throughput is 1393.4346 records/second. Loss is 2.2143812. Sequentialb692dd65's hyper parameters: Current learning rate is 4.911591355599214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12800/60000][Iteration 1038][Wall Clock 107.014696807s] Trained 128 records in 0.093088293 seconds. Throughput is 1375.0387 records/second. Loss is 2.2189336. Sequentialb692dd65's hyper parameters: Current learning rate is 4.909180166912126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 12928/60000][Iteration 1039][Wall Clock 107.105446559s] Trained 128 records in 0.090749752 seconds. Throughput is 1410.4722 records/second. Loss is 2.2210329. Sequentialb692dd65's hyper parameters: Current learning rate is 4.906771344455348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 13056/60000][Iteration 1040][Wall Clock 107.202068078s] Trained 128 records in 0.096621519 seconds. Throughput is 1324.7566 records/second. Loss is 2.205709. Sequentialb692dd65's hyper parameters: Current learning rate is 4.904364884747426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 13184/60000][Iteration 1041][Wall Clock 107.292938909s] Trained 128 records in 0.090870831 seconds. Throughput is 1408.5929 records/second. Loss is 2.2031016. Sequentialb692dd65's hyper parameters: Current learning rate is 4.901960784313725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:10 INFO  DistriOptimizer$:408 - [Epoch 3 13312/60000][Iteration 1042][Wall Clock 107.382410909s] Trained 128 records in 0.089472 seconds. Throughput is 1430.6151 records/second. Loss is 2.2161853. Sequentialb692dd65's hyper parameters: Current learning rate is 4.899559039686428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 13440/60000][Iteration 1043][Wall Clock 107.471854914s] Trained 128 records in 0.089444005 seconds. Throughput is 1431.063 records/second. Loss is 2.212685. Sequentialb692dd65's hyper parameters: Current learning rate is 4.897159647404506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 13568/60000][Iteration 1044][Wall Clock 107.575341773s] Trained 128 records in 0.103486859 seconds. Throughput is 1236.8721 records/second. Loss is 2.2172217. Sequentialb692dd65's hyper parameters: Current learning rate is 4.894762604013705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 13696/60000][Iteration 1045][Wall Clock 107.6755236s] Trained 128 records in 0.100181827 seconds. Throughput is 1277.6769 records/second. Loss is 2.2099352. Sequentialb692dd65's hyper parameters: Current learning rate is 4.892367906066536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 13824/60000][Iteration 1046][Wall Clock 107.767442379s] Trained 128 records in 0.091918779 seconds. Throughput is 1392.5337 records/second. Loss is 2.1949055. Sequentialb692dd65's hyper parameters: Current learning rate is 4.88997555012225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 13952/60000][Iteration 1047][Wall Clock 107.849153708s] Trained 128 records in 0.081711329 seconds. Throughput is 1566.4902 records/second. Loss is 2.194144. Sequentialb692dd65's hyper parameters: Current learning rate is 4.887585532746823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 14080/60000][Iteration 1048][Wall Clock 107.942535004s] Trained 128 records in 0.093381296 seconds. Throughput is 1370.7242 records/second. Loss is 2.2220113. Sequentialb692dd65's hyper parameters: Current learning rate is 4.885197850512947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 14208/60000][Iteration 1049][Wall Clock 108.035369798s] Trained 128 records in 0.092834794 seconds. Throughput is 1378.7935 records/second. Loss is 2.2191765. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8828125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 14336/60000][Iteration 1050][Wall Clock 108.124227088s] Trained 128 records in 0.08885729 seconds. Throughput is 1440.5121 records/second. Loss is 2.1920354. Sequentialb692dd65's hyper parameters: Current learning rate is 4.880429477794046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 14464/60000][Iteration 1051][Wall Clock 108.21480757s] Trained 128 records in 0.090580482 seconds. Throughput is 1413.108 records/second. Loss is 2.2181585. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8780487804878054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:11 INFO  DistriOptimizer$:408 - [Epoch 3 14592/60000][Iteration 1052][Wall Clock 108.314777441s] Trained 128 records in 0.099969871 seconds. Throughput is 1280.3857 records/second. Loss is 2.2031846. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8756704046806434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 14720/60000][Iteration 1053][Wall Clock 108.403516003s] Trained 128 records in 0.088738562 seconds. Throughput is 1442.4395 records/second. Loss is 2.2123454. Sequentialb692dd65's hyper parameters: Current learning rate is 4.873294346978557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 14848/60000][Iteration 1054][Wall Clock 108.492965605s] Trained 128 records in 0.089449602 seconds. Throughput is 1430.9734 records/second. Loss is 2.2048864. Sequentialb692dd65's hyper parameters: Current learning rate is 4.870920603994155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 14976/60000][Iteration 1055][Wall Clock 108.584097268s] Trained 128 records in 0.091131663 seconds. Throughput is 1404.5612 records/second. Loss is 2.2232301. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8685491723466403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15104/60000][Iteration 1056][Wall Clock 108.717234568s] Trained 128 records in 0.1331373 seconds. Throughput is 961.4135 records/second. Loss is 2.210642. Sequentialb692dd65's hyper parameters: Current learning rate is 4.866180048661801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15232/60000][Iteration 1057][Wall Clock 108.807139369s] Trained 128 records in 0.089904801 seconds. Throughput is 1423.7281 records/second. Loss is 2.1904218. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8638132295719845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15360/60000][Iteration 1058][Wall Clock 108.898226984s] Trained 128 records in 0.091087615 seconds. Throughput is 1405.2404 records/second. Loss is 2.206857. Sequentialb692dd65's hyper parameters: Current learning rate is 4.861448711716092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15488/60000][Iteration 1059][Wall Clock 109.003940691s] Trained 128 records in 0.105713707 seconds. Throughput is 1210.8174 records/second. Loss is 2.2215533. Sequentialb692dd65's hyper parameters: Current learning rate is 4.859086491739553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15616/60000][Iteration 1060][Wall Clock 109.095985244s] Trained 128 records in 0.092044553 seconds. Throughput is 1390.6309 records/second. Loss is 2.2274854. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8567265662943174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15744/60000][Iteration 1061][Wall Clock 109.186488403s] Trained 128 records in 0.090503159 seconds. Throughput is 1414.3153 records/second. Loss is 2.2012863. Sequentialb692dd65's hyper parameters: Current learning rate is 4.854368932038835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 15872/60000][Iteration 1062][Wall Clock 109.280904871s] Trained 128 records in 0.094416468 seconds. Throughput is 1355.6957 records/second. Loss is 2.195279. Sequentialb692dd65's hyper parameters: Current learning rate is 4.85201358563804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:12 INFO  DistriOptimizer$:408 - [Epoch 3 16000/60000][Iteration 1063][Wall Clock 109.369334719s] Trained 128 records in 0.088429848 seconds. Throughput is 1447.4751 records/second. Loss is 2.2059608. Sequentialb692dd65's hyper parameters: Current learning rate is 4.849660523763336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16128/60000][Iteration 1064][Wall Clock 109.457530685s] Trained 128 records in 0.088195966 seconds. Throughput is 1451.3136 records/second. Loss is 2.2035708. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8473097430925844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16256/60000][Iteration 1065][Wall Clock 109.54662992s] Trained 128 records in 0.089099235 seconds. Throughput is 1436.6005 records/second. Loss is 2.2027006. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8449612403100775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16384/60000][Iteration 1066][Wall Clock 109.634336757s] Trained 128 records in 0.087706837 seconds. Throughput is 1459.4073 records/second. Loss is 2.1951509. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8426150121065375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16512/60000][Iteration 1067][Wall Clock 109.733642072s] Trained 128 records in 0.099305315 seconds. Throughput is 1288.9541 records/second. Loss is 2.1987598. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8402710551790907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16640/60000][Iteration 1068][Wall Clock 109.822257432s] Trained 128 records in 0.08861536 seconds. Throughput is 1444.4448 records/second. Loss is 2.2089314. Sequentialb692dd65's hyper parameters: Current learning rate is 4.837929366231253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16768/60000][Iteration 1069][Wall Clock 109.912550176s] Trained 128 records in 0.090292744 seconds. Throughput is 1417.6111 records/second. Loss is 2.1932883. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8355899419729207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 16896/60000][Iteration 1070][Wall Clock 110.019429745s] Trained 128 records in 0.106879569 seconds. Throughput is 1197.6096 records/second. Loss is 2.2294965. Sequentialb692dd65's hyper parameters: Current learning rate is 4.833252779120348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 17024/60000][Iteration 1071][Wall Clock 110.113939462s] Trained 128 records in 0.094509717 seconds. Throughput is 1354.3582 records/second. Loss is 2.207746. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8309178743961346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 17152/60000][Iteration 1072][Wall Clock 110.202582528s] Trained 128 records in 0.088643066 seconds. Throughput is 1443.9934 records/second. Loss is 2.2345502. Sequentialb692dd65's hyper parameters: Current learning rate is 4.828585224529214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 17280/60000][Iteration 1073][Wall Clock 110.295355666s] Trained 128 records in 0.092773138 seconds. Throughput is 1379.7097 records/second. Loss is 2.2109096. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8262548262548264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:13 INFO  DistriOptimizer$:408 - [Epoch 3 17408/60000][Iteration 1074][Wall Clock 110.384850942s] Trained 128 records in 0.089495276 seconds. Throughput is 1430.243 records/second. Loss is 2.2000473. Sequentialb692dd65's hyper parameters: Current learning rate is 4.82392667631452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 17536/60000][Iteration 1075][Wall Clock 110.477055165s] Trained 128 records in 0.092204223 seconds. Throughput is 1388.2228 records/second. Loss is 2.2075298. Sequentialb692dd65's hyper parameters: Current learning rate is 4.821600771456124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 17664/60000][Iteration 1076][Wall Clock 110.571047135s] Trained 128 records in 0.09399197 seconds. Throughput is 1361.8185 records/second. Loss is 2.206865. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8192771084337347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 17792/60000][Iteration 1077][Wall Clock 110.661956896s] Trained 128 records in 0.090909761 seconds. Throughput is 1407.9896 records/second. Loss is 2.220009. Sequentialb692dd65's hyper parameters: Current learning rate is 4.816955684007707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 17920/60000][Iteration 1078][Wall Clock 110.763434083s] Trained 128 records in 0.101477187 seconds. Throughput is 1261.3673 records/second. Loss is 2.194429. Sequentialb692dd65's hyper parameters: Current learning rate is 4.814636494944632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18048/60000][Iteration 1079][Wall Clock 110.851815809s] Trained 128 records in 0.088381726 seconds. Throughput is 1448.2632 records/second. Loss is 2.215793. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8123195380173235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18176/60000][Iteration 1080][Wall Clock 110.941945055s] Trained 128 records in 0.090129246 seconds. Throughput is 1420.1827 records/second. Loss is 2.201635. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8100048100048107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18304/60000][Iteration 1081][Wall Clock 111.030227579s] Trained 128 records in 0.088282524 seconds. Throughput is 1449.8905 records/second. Loss is 2.2085595. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8076923076923074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18432/60000][Iteration 1082][Wall Clock 111.119700612s] Trained 128 records in 0.089473033 seconds. Throughput is 1430.5986 records/second. Loss is 2.199898. Sequentialb692dd65's hyper parameters: Current learning rate is 4.805382027871216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18560/60000][Iteration 1083][Wall Clock 111.210214677s] Trained 128 records in 0.090514065 seconds. Throughput is 1414.1449 records/second. Loss is 2.2055533. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8030739673390974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:14 INFO  DistriOptimizer$:408 - [Epoch 3 18688/60000][Iteration 1084][Wall Clock 111.307411718s] Trained 128 records in 0.097197041 seconds. Throughput is 1316.9125 records/second. Loss is 2.2191634. Sequentialb692dd65's hyper parameters: Current learning rate is 4.8007681228996637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 18816/60000][Iteration 1085][Wall Clock 111.397248501s] Trained 128 records in 0.089836783 seconds. Throughput is 1424.8062 records/second. Loss is 2.2031596. Sequentialb692dd65's hyper parameters: Current learning rate is 4.798464491362764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 18944/60000][Iteration 1086][Wall Clock 111.487057386s] Trained 128 records in 0.089808885 seconds. Throughput is 1425.2488 records/second. Loss is 2.196233. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7961630695443646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19072/60000][Iteration 1087][Wall Clock 111.580959755s] Trained 128 records in 0.093902369 seconds. Throughput is 1363.1178 records/second. Loss is 2.1989937. Sequentialb692dd65's hyper parameters: Current learning rate is 4.793863854266538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19200/60000][Iteration 1088][Wall Clock 111.671321274s] Trained 128 records in 0.090361519 seconds. Throughput is 1416.5321 records/second. Loss is 2.1845744. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7915668423574516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19328/60000][Iteration 1089][Wall Clock 111.761927227s] Trained 128 records in 0.090605953 seconds. Throughput is 1412.7107 records/second. Loss is 2.2167573. Sequentialb692dd65's hyper parameters: Current learning rate is 4.789272030651341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19456/60000][Iteration 1090][Wall Clock 111.853012145s] Trained 128 records in 0.091084918 seconds. Throughput is 1405.282 records/second. Loss is 2.2064083. Sequentialb692dd65's hyper parameters: Current learning rate is 4.786979415988511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19584/60000][Iteration 1091][Wall Clock 111.940741569s] Trained 128 records in 0.087729424 seconds. Throughput is 1459.0316 records/second. Loss is 2.1931958. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7846889952153117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19712/60000][Iteration 1092][Wall Clock 112.030380961s] Trained 128 records in 0.089639392 seconds. Throughput is 1427.9436 records/second. Loss is 2.206383. Sequentialb692dd65's hyper parameters: Current learning rate is 4.782400765184122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19840/60000][Iteration 1093][Wall Clock 112.117562351s] Trained 128 records in 0.08718139 seconds. Throughput is 1468.2032 records/second. Loss is 2.1961436. Sequentialb692dd65's hyper parameters: Current learning rate is 4.780114722753346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 19968/60000][Iteration 1094][Wall Clock 112.205850819s] Trained 128 records in 0.088288468 seconds. Throughput is 1449.793 records/second. Loss is 2.2113214. Sequentialb692dd65's hyper parameters: Current learning rate is 4.777830864787387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:15 INFO  DistriOptimizer$:408 - [Epoch 3 20096/60000][Iteration 1095][Wall Clock 112.309013969s] Trained 128 records in 0.10316315 seconds. Throughput is 1240.753 records/second. Loss is 2.1980753. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7755491881566373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20224/60000][Iteration 1096][Wall Clock 112.400520226s] Trained 128 records in 0.091506257 seconds. Throughput is 1398.8114 records/second. Loss is 2.213188. Sequentialb692dd65's hyper parameters: Current learning rate is 4.773269689737471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20352/60000][Iteration 1097][Wall Clock 112.510692398s] Trained 128 records in 0.110172172 seconds. Throughput is 1161.8179 records/second. Loss is 2.1807714. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7709923664122136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20480/60000][Iteration 1098][Wall Clock 112.597591397s] Trained 128 records in 0.086898999 seconds. Throughput is 1472.9744 records/second. Loss is 2.2021868. Sequentialb692dd65's hyper parameters: Current learning rate is 4.768717215069147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20608/60000][Iteration 1099][Wall Clock 112.689632665s] Trained 128 records in 0.092041268 seconds. Throughput is 1390.6805 records/second. Loss is 2.2097976. Sequentialb692dd65's hyper parameters: Current learning rate is 4.766444232602479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20736/60000][Iteration 1100][Wall Clock 112.779688457s] Trained 128 records in 0.090055792 seconds. Throughput is 1421.3411 records/second. Loss is 2.2054257. Sequentialb692dd65's hyper parameters: Current learning rate is 4.764173415912339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20864/60000][Iteration 1101][Wall Clock 112.866549831s] Trained 128 records in 0.086861374 seconds. Throughput is 1473.6124 records/second. Loss is 2.2047193. Sequentialb692dd65's hyper parameters: Current learning rate is 4.761904761904762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 20992/60000][Iteration 1102][Wall Clock 112.956284393s] Trained 128 records in 0.089734562 seconds. Throughput is 1426.4292 records/second. Loss is 2.209365. Sequentialb692dd65's hyper parameters: Current learning rate is 4.759638267491671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 21120/60000][Iteration 1103][Wall Clock 113.059927294s] Trained 128 records in 0.103642901 seconds. Throughput is 1235.0098 records/second. Loss is 2.2258837. Sequentialb692dd65's hyper parameters: Current learning rate is 4.757373929590865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 21248/60000][Iteration 1104][Wall Clock 113.147217452s] Trained 128 records in 0.087290158 seconds. Throughput is 1466.3738 records/second. Loss is 2.2037742. Sequentialb692dd65's hyper parameters: Current learning rate is 4.755111745126011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 21376/60000][Iteration 1105][Wall Clock 113.228447461s] Trained 128 records in 0.081230009 seconds. Throughput is 1575.7723 records/second. Loss is 2.1941876. Sequentialb692dd65's hyper parameters: Current learning rate is 4.752851711026616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:16 INFO  DistriOptimizer$:408 - [Epoch 3 21504/60000][Iteration 1106][Wall Clock 113.315578884s] Trained 128 records in 0.087131423 seconds. Throughput is 1469.0452 records/second. Loss is 2.1964262. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7505938242280285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 21632/60000][Iteration 1107][Wall Clock 113.401693732s] Trained 128 records in 0.086114848 seconds. Throughput is 1486.3871 records/second. Loss is 2.197942. Sequentialb692dd65's hyper parameters: Current learning rate is 4.748338081671415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 21760/60000][Iteration 1108][Wall Clock 113.48815379s] Trained 128 records in 0.086460058 seconds. Throughput is 1480.4524 records/second. Loss is 2.1814907. Sequentialb692dd65's hyper parameters: Current learning rate is 4.746084480303749E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 21888/60000][Iteration 1109][Wall Clock 113.577571026s] Trained 128 records in 0.089417236 seconds. Throughput is 1431.4913 records/second. Loss is 2.2029357. Sequentialb692dd65's hyper parameters: Current learning rate is 4.743833017077799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22016/60000][Iteration 1110][Wall Clock 113.665134871s] Trained 128 records in 0.087563845 seconds. Throughput is 1461.7905 records/second. Loss is 2.2173297. Sequentialb692dd65's hyper parameters: Current learning rate is 4.74158368895211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22144/60000][Iteration 1111][Wall Clock 113.752374063s] Trained 128 records in 0.087239192 seconds. Throughput is 1467.2305 records/second. Loss is 2.2141907. Sequentialb692dd65's hyper parameters: Current learning rate is 4.739336492890995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22272/60000][Iteration 1112][Wall Clock 113.843069051s] Trained 128 records in 0.090694988 seconds. Throughput is 1411.3239 records/second. Loss is 2.2169309. Sequentialb692dd65's hyper parameters: Current learning rate is 4.73709142586452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22400/60000][Iteration 1113][Wall Clock 113.929416001s] Trained 128 records in 0.08634695 seconds. Throughput is 1482.3917 records/second. Loss is 2.1978993. Sequentialb692dd65's hyper parameters: Current learning rate is 4.734848484848485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22528/60000][Iteration 1114][Wall Clock 114.012689391s] Trained 128 records in 0.08327339 seconds. Throughput is 1537.1057 records/second. Loss is 2.2074707. Sequentialb692dd65's hyper parameters: Current learning rate is 4.73260766682442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22656/60000][Iteration 1115][Wall Clock 114.098491351s] Trained 128 records in 0.08580196 seconds. Throughput is 1491.8074 records/second. Loss is 2.2141442. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7303689687795653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22784/60000][Iteration 1116][Wall Clock 114.187520574s] Trained 128 records in 0.089029223 seconds. Throughput is 1437.7302 records/second. Loss is 2.195162. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7281323877068556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:17 INFO  DistriOptimizer$:408 - [Epoch 3 22912/60000][Iteration 1117][Wall Clock 114.278477135s] Trained 128 records in 0.090956561 seconds. Throughput is 1407.2651 records/second. Loss is 2.225931. Sequentialb692dd65's hyper parameters: Current learning rate is 4.725897920604915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23040/60000][Iteration 1118][Wall Clock 114.366263494s] Trained 128 records in 0.087786359 seconds. Throughput is 1458.0852 records/second. Loss is 2.204251. Sequentialb692dd65's hyper parameters: Current learning rate is 4.723665564478035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23168/60000][Iteration 1119][Wall Clock 114.454081203s] Trained 128 records in 0.087817709 seconds. Throughput is 1457.5648 records/second. Loss is 2.2114615. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7214353163361653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23296/60000][Iteration 1120][Wall Clock 114.553497088s] Trained 128 records in 0.099415885 seconds. Throughput is 1287.5206 records/second. Loss is 2.2101061. Sequentialb692dd65's hyper parameters: Current learning rate is 4.719207173194904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23424/60000][Iteration 1121][Wall Clock 114.637422552s] Trained 128 records in 0.083925464 seconds. Throughput is 1525.1628 records/second. Loss is 2.2081044. Sequentialb692dd65's hyper parameters: Current learning rate is 4.716981132075472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23552/60000][Iteration 1122][Wall Clock 114.726720165s] Trained 128 records in 0.089297613 seconds. Throughput is 1433.4089 records/second. Loss is 2.2132785. Sequentialb692dd65's hyper parameters: Current learning rate is 4.714757190004715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23680/60000][Iteration 1123][Wall Clock 114.816757154s] Trained 128 records in 0.090036989 seconds. Throughput is 1421.638 records/second. Loss is 2.1974492. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7125353440150805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23808/60000][Iteration 1124][Wall Clock 114.907558228s] Trained 128 records in 0.090801074 seconds. Throughput is 1409.6749 records/second. Loss is 2.2087145. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7103155911446063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 23936/60000][Iteration 1125][Wall Clock 114.996354001s] Trained 128 records in 0.088795773 seconds. Throughput is 1441.51 records/second. Loss is 2.2011888. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7080979284369113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 24064/60000][Iteration 1126][Wall Clock 115.083210243s] Trained 128 records in 0.086856242 seconds. Throughput is 1473.6996 records/second. Loss is 2.2052038. Sequentialb692dd65's hyper parameters: Current learning rate is 4.7058823529411766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 24192/60000][Iteration 1127][Wall Clock 115.170164007s] Trained 128 records in 0.086953764 seconds. Throughput is 1472.0466 records/second. Loss is 2.190676. Sequentialb692dd65's hyper parameters: Current learning rate is 4.703668861712135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:18 INFO  DistriOptimizer$:408 - [Epoch 3 24320/60000][Iteration 1128][Wall Clock 115.263118343s] Trained 128 records in 0.092954336 seconds. Throughput is 1377.0201 records/second. Loss is 2.198479. Sequentialb692dd65's hyper parameters: Current learning rate is 4.701457451810062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 24448/60000][Iteration 1129][Wall Clock 115.360442604s] Trained 128 records in 0.097324261 seconds. Throughput is 1315.191 records/second. Loss is 2.1945763. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6992481203007516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 24576/60000][Iteration 1130][Wall Clock 115.445748951s] Trained 128 records in 0.085306347 seconds. Throughput is 1500.4745 records/second. Loss is 2.2030704. Sequentialb692dd65's hyper parameters: Current learning rate is 4.697040864255519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 24704/60000][Iteration 1131][Wall Clock 115.532789583s] Trained 128 records in 0.087040632 seconds. Throughput is 1470.5775 records/second. Loss is 2.2088172. Sequentialb692dd65's hyper parameters: Current learning rate is 4.694835680751174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 24832/60000][Iteration 1132][Wall Clock 115.624816793s] Trained 128 records in 0.09202721 seconds. Throughput is 1390.893 records/second. Loss is 2.2131243. Sequentialb692dd65's hyper parameters: Current learning rate is 4.692632566870014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 24960/60000][Iteration 1133][Wall Clock 115.71787456s] Trained 128 records in 0.093057767 seconds. Throughput is 1375.4897 records/second. Loss is 2.1919687. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6904315196998124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25088/60000][Iteration 1134][Wall Clock 115.808436145s] Trained 128 records in 0.090561585 seconds. Throughput is 1413.4028 records/second. Loss is 2.2234273. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6882325363338024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25216/60000][Iteration 1135][Wall Clock 115.89871692s] Trained 128 records in 0.090280775 seconds. Throughput is 1417.7991 records/second. Loss is 2.2087889. Sequentialb692dd65's hyper parameters: Current learning rate is 4.686035613870665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25344/60000][Iteration 1136][Wall Clock 115.988986766s] Trained 128 records in 0.090269846 seconds. Throughput is 1417.9707 records/second. Loss is 2.2128015. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6838407494145204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25472/60000][Iteration 1137][Wall Clock 116.07644097s] Trained 128 records in 0.087454204 seconds. Throughput is 1463.6232 records/second. Loss is 2.1989617. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6816479400749064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25600/60000][Iteration 1138][Wall Clock 116.166002413s] Trained 128 records in 0.089561443 seconds. Throughput is 1429.1865 records/second. Loss is 2.2019694. Sequentialb692dd65's hyper parameters: Current learning rate is 4.679457182966776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25728/60000][Iteration 1139][Wall Clock 116.252935572s] Trained 128 records in 0.086933159 seconds. Throughput is 1472.3956 records/second. Loss is 2.1953619. Sequentialb692dd65's hyper parameters: Current learning rate is 4.677268475210477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:19 INFO  DistriOptimizer$:408 - [Epoch 3 25856/60000][Iteration 1140][Wall Clock 116.339489764s] Trained 128 records in 0.086554192 seconds. Throughput is 1478.8423 records/second. Loss is 2.2073913. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6750818139317435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 25984/60000][Iteration 1141][Wall Clock 116.427694878s] Trained 128 records in 0.088205114 seconds. Throughput is 1451.163 records/second. Loss is 2.2037761. Sequentialb692dd65's hyper parameters: Current learning rate is 4.672897196261682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26112/60000][Iteration 1142][Wall Clock 116.512753834s] Trained 128 records in 0.085058956 seconds. Throughput is 1504.8386 records/second. Loss is 2.190656. Sequentialb692dd65's hyper parameters: Current learning rate is 4.670714619336759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26240/60000][Iteration 1143][Wall Clock 116.604497705s] Trained 128 records in 0.091743871 seconds. Throughput is 1395.1886 records/second. Loss is 2.1931286. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6685340802987853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26368/60000][Iteration 1144][Wall Clock 116.694460591s] Trained 128 records in 0.089962886 seconds. Throughput is 1422.809 records/second. Loss is 2.1950717. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6663555762949143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26496/60000][Iteration 1145][Wall Clock 116.778948481s] Trained 128 records in 0.08448789 seconds. Throughput is 1515.01 records/second. Loss is 2.1914284. Sequentialb692dd65's hyper parameters: Current learning rate is 4.664179104477612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26624/60000][Iteration 1146][Wall Clock 116.861953171s] Trained 128 records in 0.08300469 seconds. Throughput is 1542.0815 records/second. Loss is 2.1905615. Sequentialb692dd65's hyper parameters: Current learning rate is 4.662004662004662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26752/60000][Iteration 1147][Wall Clock 116.950043983s] Trained 128 records in 0.088090812 seconds. Throughput is 1453.0459 records/second. Loss is 2.2030263. Sequentialb692dd65's hyper parameters: Current learning rate is 4.659832246039143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 26880/60000][Iteration 1148][Wall Clock 117.036233706s] Trained 128 records in 0.086189723 seconds. Throughput is 1485.0958 records/second. Loss is 2.2132652. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6576618537494174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 27008/60000][Iteration 1149][Wall Clock 117.126407141s] Trained 128 records in 0.090173435 seconds. Throughput is 1419.4867 records/second. Loss is 2.205271. Sequentialb692dd65's hyper parameters: Current learning rate is 4.655493482309125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 27136/60000][Iteration 1150][Wall Clock 117.21409968s] Trained 128 records in 0.087692539 seconds. Throughput is 1459.6453 records/second. Loss is 2.1918662. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6533271288971617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:20 INFO  DistriOptimizer$:408 - [Epoch 3 27264/60000][Iteration 1151][Wall Clock 117.301355691s] Trained 128 records in 0.087256011 seconds. Throughput is 1466.9476 records/second. Loss is 2.1855166. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6511627906976736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 27392/60000][Iteration 1152][Wall Clock 117.389953292s] Trained 128 records in 0.088597601 seconds. Throughput is 1444.7344 records/second. Loss is 2.2036245. Sequentialb692dd65's hyper parameters: Current learning rate is 4.649000464900047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 27520/60000][Iteration 1153][Wall Clock 117.485828075s] Trained 128 records in 0.095874783 seconds. Throughput is 1335.0747 records/second. Loss is 2.215286. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6468401486988845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 27648/60000][Iteration 1154][Wall Clock 117.578146867s] Trained 128 records in 0.092318792 seconds. Throughput is 1386.4999 records/second. Loss is 2.1985288. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6446818392940084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 27776/60000][Iteration 1155][Wall Clock 117.664336319s] Trained 128 records in 0.086189452 seconds. Throughput is 1485.1006 records/second. Loss is 2.1963596. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6425255338904364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 27904/60000][Iteration 1156][Wall Clock 117.751797629s] Trained 128 records in 0.08746131 seconds. Throughput is 1463.5043 records/second. Loss is 2.1955435. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6403712296983754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28032/60000][Iteration 1157][Wall Clock 117.843567712s] Trained 128 records in 0.091770083 seconds. Throughput is 1394.79 records/second. Loss is 2.184816. Sequentialb692dd65's hyper parameters: Current learning rate is 4.63821892393321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28160/60000][Iteration 1158][Wall Clock 117.930043278s] Trained 128 records in 0.086475566 seconds. Throughput is 1480.1869 records/second. Loss is 2.209805. Sequentialb692dd65's hyper parameters: Current learning rate is 4.636068613815484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28288/60000][Iteration 1159][Wall Clock 118.017007478s] Trained 128 records in 0.0869642 seconds. Throughput is 1471.8701 records/second. Loss is 2.2063222. Sequentialb692dd65's hyper parameters: Current learning rate is 4.633920296570899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28416/60000][Iteration 1160][Wall Clock 118.105110045s] Trained 128 records in 0.088102567 seconds. Throughput is 1452.8522 records/second. Loss is 2.208211. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6317739694302923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28544/60000][Iteration 1161][Wall Clock 118.190110463s] Trained 128 records in 0.085000418 seconds. Throughput is 1505.875 records/second. Loss is 2.1913807. Sequentialb692dd65's hyper parameters: Current learning rate is 4.629629629629629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:21 INFO  DistriOptimizer$:408 - [Epoch 3 28672/60000][Iteration 1162][Wall Clock 118.277677312s] Trained 128 records in 0.087566849 seconds. Throughput is 1461.7404 records/second. Loss is 2.1951883. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6274872744099955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 28800/60000][Iteration 1163][Wall Clock 118.365547547s] Trained 128 records in 0.087870235 seconds. Throughput is 1456.6935 records/second. Loss is 2.2173688. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6253469010175765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 28928/60000][Iteration 1164][Wall Clock 118.452189193s] Trained 128 records in 0.086641646 seconds. Throughput is 1477.3496 records/second. Loss is 2.2075052. Sequentialb692dd65's hyper parameters: Current learning rate is 4.623208506703652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29056/60000][Iteration 1165][Wall Clock 118.540595867s] Trained 128 records in 0.088406674 seconds. Throughput is 1447.8545 records/second. Loss is 2.1889327. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6210720887245846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29184/60000][Iteration 1166][Wall Clock 118.627421507s] Trained 128 records in 0.08682564 seconds. Throughput is 1474.2189 records/second. Loss is 2.1831677. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6189376443418013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29312/60000][Iteration 1167][Wall Clock 118.716783656s] Trained 128 records in 0.089362149 seconds. Throughput is 1432.3738 records/second. Loss is 2.1873362. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6168051708217917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29440/60000][Iteration 1168][Wall Clock 118.80458598s] Trained 128 records in 0.087802324 seconds. Throughput is 1457.8202 records/second. Loss is 2.2154112. Sequentialb692dd65's hyper parameters: Current learning rate is 4.614674665436087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29568/60000][Iteration 1169][Wall Clock 118.88996544s] Trained 128 records in 0.08537946 seconds. Throughput is 1499.1896 records/second. Loss is 2.1712391. Sequentialb692dd65's hyper parameters: Current learning rate is 4.6125461254612545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29696/60000][Iteration 1170][Wall Clock 118.974102249s] Trained 128 records in 0.084136809 seconds. Throughput is 1521.3318 records/second. Loss is 2.2023554. Sequentialb692dd65's hyper parameters: Current learning rate is 4.610419548178884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29824/60000][Iteration 1171][Wall Clock 119.057826348s] Trained 128 records in 0.083724099 seconds. Throughput is 1528.831 records/second. Loss is 2.2108922. Sequentialb692dd65's hyper parameters: Current learning rate is 4.608294930875576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 29952/60000][Iteration 1172][Wall Clock 119.148677863s] Trained 128 records in 0.090851515 seconds. Throughput is 1408.8923 records/second. Loss is 2.199717. Sequentialb692dd65's hyper parameters: Current learning rate is 4.606172270842929E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 30080/60000][Iteration 1173][Wall Clock 119.232995177s] Trained 128 records in 0.084317314 seconds. Throughput is 1518.075 records/second. Loss is 2.2127392. Sequentialb692dd65's hyper parameters: Current learning rate is 4.604051565377533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:22 INFO  DistriOptimizer$:408 - [Epoch 3 30208/60000][Iteration 1174][Wall Clock 119.323576382s] Trained 128 records in 0.090581205 seconds. Throughput is 1413.0967 records/second. Loss is 2.1931207. Sequentialb692dd65's hyper parameters: Current learning rate is 4.601932811780948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30336/60000][Iteration 1175][Wall Clock 119.409840886s] Trained 128 records in 0.086264504 seconds. Throughput is 1483.8085 records/second. Loss is 2.1941764. Sequentialb692dd65's hyper parameters: Current learning rate is 4.599816007359706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30464/60000][Iteration 1176][Wall Clock 119.496531928s] Trained 128 records in 0.086691042 seconds. Throughput is 1476.5078 records/second. Loss is 2.1924503. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5977011494252877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30592/60000][Iteration 1177][Wall Clock 119.585636472s] Trained 128 records in 0.089104544 seconds. Throughput is 1436.5149 records/second. Loss is 2.1971023. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5955882352941176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30720/60000][Iteration 1178][Wall Clock 119.675286444s] Trained 128 records in 0.089649972 seconds. Throughput is 1427.775 records/second. Loss is 2.1785495. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5934772622875517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30848/60000][Iteration 1179][Wall Clock 119.763212801s] Trained 128 records in 0.087926357 seconds. Throughput is 1455.7637 records/second. Loss is 2.1978776. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5913682277318646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 30976/60000][Iteration 1180][Wall Clock 119.855225099s] Trained 128 records in 0.092012298 seconds. Throughput is 1391.1183 records/second. Loss is 2.2068937. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5892611289582373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 31104/60000][Iteration 1181][Wall Clock 119.944388587s] Trained 128 records in 0.089163488 seconds. Throughput is 1435.5652 records/second. Loss is 2.1986675. Sequentialb692dd65's hyper parameters: Current learning rate is 4.587155963302753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 31232/60000][Iteration 1182][Wall Clock 120.03266765s] Trained 128 records in 0.088279063 seconds. Throughput is 1449.9475 records/second. Loss is 2.2106438. Sequentialb692dd65's hyper parameters: Current learning rate is 4.585052728106373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 31360/60000][Iteration 1183][Wall Clock 120.121048386s] Trained 128 records in 0.088380736 seconds. Throughput is 1448.2793 records/second. Loss is 2.198654. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5829514207149406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 31488/60000][Iteration 1184][Wall Clock 120.222275049s] Trained 128 records in 0.101226663 seconds. Throughput is 1264.489 records/second. Loss is 2.2157774. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5808520384791576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:23 INFO  DistriOptimizer$:408 - [Epoch 3 31616/60000][Iteration 1185][Wall Clock 120.307839744s] Trained 128 records in 0.085564695 seconds. Throughput is 1495.9441 records/second. Loss is 2.1798506. Sequentialb692dd65's hyper parameters: Current learning rate is 4.578754578754579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 31744/60000][Iteration 1186][Wall Clock 120.397780212s] Trained 128 records in 0.089940468 seconds. Throughput is 1423.1636 records/second. Loss is 2.184944. Sequentialb692dd65's hyper parameters: Current learning rate is 4.576659038901602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 31872/60000][Iteration 1187][Wall Clock 120.488680878s] Trained 128 records in 0.090900666 seconds. Throughput is 1408.1305 records/second. Loss is 2.1893897. Sequentialb692dd65's hyper parameters: Current learning rate is 4.574565416285453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32000/60000][Iteration 1188][Wall Clock 120.580117623s] Trained 128 records in 0.091436745 seconds. Throughput is 1399.8749 records/second. Loss is 2.1816723. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5724737082761767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32128/60000][Iteration 1189][Wall Clock 120.669521545s] Trained 128 records in 0.089403922 seconds. Throughput is 1431.7046 records/second. Loss is 2.189082. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5703839122486294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32256/60000][Iteration 1190][Wall Clock 120.758293207s] Trained 128 records in 0.088771662 seconds. Throughput is 1441.9016 records/second. Loss is 2.203653. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5682960255824577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32384/60000][Iteration 1191][Wall Clock 120.845914101s] Trained 128 records in 0.087620894 seconds. Throughput is 1460.8389 records/second. Loss is 2.2078626. Sequentialb692dd65's hyper parameters: Current learning rate is 4.566210045662101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32512/60000][Iteration 1192][Wall Clock 120.934101888s] Trained 128 records in 0.088187787 seconds. Throughput is 1451.4482 records/second. Loss is 2.2125528. Sequentialb692dd65's hyper parameters: Current learning rate is 4.564125969876769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32640/60000][Iteration 1193][Wall Clock 121.021687907s] Trained 128 records in 0.087586019 seconds. Throughput is 1461.4205 records/second. Loss is 2.1901243. Sequentialb692dd65's hyper parameters: Current learning rate is 4.562043795620438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32768/60000][Iteration 1194][Wall Clock 121.108112297s] Trained 128 records in 0.08642439 seconds. Throughput is 1481.0635 records/second. Loss is 2.1819859. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5599635202918376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 32896/60000][Iteration 1195][Wall Clock 121.203107452s] Trained 128 records in 0.094995155 seconds. Throughput is 1347.4371 records/second. Loss is 2.1888433. Sequentialb692dd65's hyper parameters: Current learning rate is 4.55788514129444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:24 INFO  DistriOptimizer$:408 - [Epoch 3 33024/60000][Iteration 1196][Wall Clock 121.286742407s] Trained 128 records in 0.083634955 seconds. Throughput is 1530.4606 records/second. Loss is 2.207148. Sequentialb692dd65's hyper parameters: Current learning rate is 4.555808656036446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33152/60000][Iteration 1197][Wall Clock 121.397769069s] Trained 128 records in 0.111026662 seconds. Throughput is 1152.8762 records/second. Loss is 2.1919425. Sequentialb692dd65's hyper parameters: Current learning rate is 4.553734061930784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33280/60000][Iteration 1198][Wall Clock 121.488446903s] Trained 128 records in 0.090677834 seconds. Throughput is 1411.5908 records/second. Loss is 2.1814766. Sequentialb692dd65's hyper parameters: Current learning rate is 4.551661356395084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33408/60000][Iteration 1199][Wall Clock 121.578437865s] Trained 128 records in 0.089990962 seconds. Throughput is 1422.3651 records/second. Loss is 2.1795. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5495905368516835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33536/60000][Iteration 1200][Wall Clock 121.670404912s] Trained 128 records in 0.091967047 seconds. Throughput is 1391.8029 records/second. Loss is 2.2048523. Sequentialb692dd65's hyper parameters: Current learning rate is 4.547521600727604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33664/60000][Iteration 1201][Wall Clock 121.76463999s] Trained 128 records in 0.094235078 seconds. Throughput is 1358.3053 records/second. Loss is 2.1867874. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5454545454545455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33792/60000][Iteration 1202][Wall Clock 121.853404248s] Trained 128 records in 0.088764258 seconds. Throughput is 1442.0219 records/second. Loss is 2.1886556. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5433893684688776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 33920/60000][Iteration 1203][Wall Clock 121.944045334s] Trained 128 records in 0.090641086 seconds. Throughput is 1412.1631 records/second. Loss is 2.195789. Sequentialb692dd65's hyper parameters: Current learning rate is 4.541326067211626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 34048/60000][Iteration 1204][Wall Clock 122.030175001s] Trained 128 records in 0.086129667 seconds. Throughput is 1486.1313 records/second. Loss is 2.2022333. Sequentialb692dd65's hyper parameters: Current learning rate is 4.539264639128461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 34176/60000][Iteration 1205][Wall Clock 122.124185304s] Trained 128 records in 0.094010303 seconds. Throughput is 1361.553 records/second. Loss is 2.2012548. Sequentialb692dd65's hyper parameters: Current learning rate is 4.537205081669692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 34304/60000][Iteration 1206][Wall Clock 122.204656858s] Trained 128 records in 0.080471554 seconds. Throughput is 1590.6243 records/second. Loss is 2.1952097. Sequentialb692dd65's hyper parameters: Current learning rate is 4.535147392290249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:25 INFO  DistriOptimizer$:408 - [Epoch 3 34432/60000][Iteration 1207][Wall Clock 122.290835442s] Trained 128 records in 0.086178584 seconds. Throughput is 1485.2877 records/second. Loss is 2.1991663. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5330915684496827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 34560/60000][Iteration 1208][Wall Clock 122.377765449s] Trained 128 records in 0.086930007 seconds. Throughput is 1472.449 records/second. Loss is 2.20769. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5310376076121433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 34688/60000][Iteration 1209][Wall Clock 122.469228296s] Trained 128 records in 0.091462847 seconds. Throughput is 1399.4753 records/second. Loss is 2.1926777. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5289855072463763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 34816/60000][Iteration 1210][Wall Clock 122.560763139s] Trained 128 records in 0.091534843 seconds. Throughput is 1398.3745 records/second. Loss is 2.1976578. Sequentialb692dd65's hyper parameters: Current learning rate is 4.526935264825713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 34944/60000][Iteration 1211][Wall Clock 122.646048198s] Trained 128 records in 0.085285059 seconds. Throughput is 1500.849 records/second. Loss is 2.1910803. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5248868778280545E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35072/60000][Iteration 1212][Wall Clock 122.73654658s] Trained 128 records in 0.090498382 seconds. Throughput is 1414.3899 records/second. Loss is 2.1863594. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5228403437358656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35200/60000][Iteration 1213][Wall Clock 122.822573297s] Trained 128 records in 0.086026717 seconds. Throughput is 1487.9098 records/second. Loss is 2.1884315. Sequentialb692dd65's hyper parameters: Current learning rate is 4.520795660036167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35328/60000][Iteration 1214][Wall Clock 122.909128501s] Trained 128 records in 0.086555204 seconds. Throughput is 1478.825 records/second. Loss is 2.1935833. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5187528242205153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35456/60000][Iteration 1215][Wall Clock 122.998486117s] Trained 128 records in 0.089357616 seconds. Throughput is 1432.4465 records/second. Loss is 2.1889365. Sequentialb692dd65's hyper parameters: Current learning rate is 4.516711833785005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35584/60000][Iteration 1216][Wall Clock 123.087983286s] Trained 128 records in 0.089497169 seconds. Throughput is 1430.2128 records/second. Loss is 2.2058158. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5146726862302486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35712/60000][Iteration 1217][Wall Clock 123.175178994s] Trained 128 records in 0.087195708 seconds. Throughput is 1467.9622 records/second. Loss is 2.1952808. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5126353790613715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:26 INFO  DistriOptimizer$:408 - [Epoch 3 35840/60000][Iteration 1218][Wall Clock 123.266193423s] Trained 128 records in 0.091014429 seconds. Throughput is 1406.3704 records/second. Loss is 2.194643. Sequentialb692dd65's hyper parameters: Current learning rate is 4.510599909788002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 35968/60000][Iteration 1219][Wall Clock 123.357770305s] Trained 128 records in 0.091576882 seconds. Throughput is 1397.7327 records/second. Loss is 2.2045336. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5085662759242564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36096/60000][Iteration 1220][Wall Clock 123.450626809s] Trained 128 records in 0.092856504 seconds. Throughput is 1378.4711 records/second. Loss is 2.1860902. Sequentialb692dd65's hyper parameters: Current learning rate is 4.506534474988733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36224/60000][Iteration 1221][Wall Clock 123.536413712s] Trained 128 records in 0.085786903 seconds. Throughput is 1492.0693 records/second. Loss is 2.1956606. Sequentialb692dd65's hyper parameters: Current learning rate is 4.504504504504505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36352/60000][Iteration 1222][Wall Clock 123.624572048s] Trained 128 records in 0.088158336 seconds. Throughput is 1451.933 records/second. Loss is 2.1817343. Sequentialb692dd65's hyper parameters: Current learning rate is 4.5024763619990995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36480/60000][Iteration 1223][Wall Clock 123.712694938s] Trained 128 records in 0.08812289 seconds. Throughput is 1452.5171 records/second. Loss is 2.1789076. Sequentialb692dd65's hyper parameters: Current learning rate is 4.500450045004501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36608/60000][Iteration 1224][Wall Clock 123.801601851s] Trained 128 records in 0.088906913 seconds. Throughput is 1439.708 records/second. Loss is 2.2044573. Sequentialb692dd65's hyper parameters: Current learning rate is 4.49842555105713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36736/60000][Iteration 1225][Wall Clock 123.890667508s] Trained 128 records in 0.089065657 seconds. Throughput is 1437.1421 records/second. Loss is 2.192523. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4964028776978414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36864/60000][Iteration 1226][Wall Clock 123.976506214s] Trained 128 records in 0.085838706 seconds. Throughput is 1491.1688 records/second. Loss is 2.1879795. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4943820224719103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 36992/60000][Iteration 1227][Wall Clock 124.06297837s] Trained 128 records in 0.086472156 seconds. Throughput is 1480.2454 records/second. Loss is 2.17793. Sequentialb692dd65's hyper parameters: Current learning rate is 4.492362982929021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 37120/60000][Iteration 1228][Wall Clock 124.150041588s] Trained 128 records in 0.087063218 seconds. Throughput is 1470.196 records/second. Loss is 2.203061. Sequentialb692dd65's hyper parameters: Current learning rate is 4.490345756623259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:27 INFO  DistriOptimizer$:408 - [Epoch 3 37248/60000][Iteration 1229][Wall Clock 124.234141541s] Trained 128 records in 0.084099953 seconds. Throughput is 1521.9984 records/second. Loss is 2.1653478. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4883303411131066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 37376/60000][Iteration 1230][Wall Clock 124.325054999s] Trained 128 records in 0.090913458 seconds. Throughput is 1407.9324 records/second. Loss is 2.2037983. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4863167339614175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 37504/60000][Iteration 1231][Wall Clock 124.41974773s] Trained 128 records in 0.094692731 seconds. Throughput is 1351.7405 records/second. Loss is 2.1835272. Sequentialb692dd65's hyper parameters: Current learning rate is 4.484304932735426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 37632/60000][Iteration 1232][Wall Clock 124.49840834s] Trained 128 records in 0.07866061 seconds. Throughput is 1627.244 records/second. Loss is 2.1789584. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4822949350067237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 37760/60000][Iteration 1233][Wall Clock 124.591406821s] Trained 128 records in 0.092998481 seconds. Throughput is 1376.3666 records/second. Loss is 2.1897006. Sequentialb692dd65's hyper parameters: Current learning rate is 4.480286738351254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 37888/60000][Iteration 1234][Wall Clock 124.681498663s] Trained 128 records in 0.090091842 seconds. Throughput is 1420.7725 records/second. Loss is 2.1930757. Sequentialb692dd65's hyper parameters: Current learning rate is 4.478280340349306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38016/60000][Iteration 1235][Wall Clock 124.768149279s] Trained 128 records in 0.086650616 seconds. Throughput is 1477.1967 records/second. Loss is 2.1972861. Sequentialb692dd65's hyper parameters: Current learning rate is 4.476275738585497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38144/60000][Iteration 1236][Wall Clock 124.858043973s] Trained 128 records in 0.089894694 seconds. Throughput is 1423.8882 records/second. Loss is 2.18566. Sequentialb692dd65's hyper parameters: Current learning rate is 4.474272930648769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38272/60000][Iteration 1237][Wall Clock 124.945261758s] Trained 128 records in 0.087217785 seconds. Throughput is 1467.5906 records/second. Loss is 2.2016249. Sequentialb692dd65's hyper parameters: Current learning rate is 4.47227191413238E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38400/60000][Iteration 1238][Wall Clock 125.032959415s] Trained 128 records in 0.087697657 seconds. Throughput is 1459.5602 records/second. Loss is 2.1828327. Sequentialb692dd65's hyper parameters: Current learning rate is 4.470272686633885E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38528/60000][Iteration 1239][Wall Clock 125.120683569s] Trained 128 records in 0.087724154 seconds. Throughput is 1459.1191 records/second. Loss is 2.199284. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4682752457551384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:28 INFO  DistriOptimizer$:408 - [Epoch 3 38656/60000][Iteration 1240][Wall Clock 125.209660763s] Trained 128 records in 0.088977194 seconds. Throughput is 1438.5708 records/second. Loss is 2.1933455. Sequentialb692dd65's hyper parameters: Current learning rate is 4.466279589102278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 38784/60000][Iteration 1241][Wall Clock 125.304579077s] Trained 128 records in 0.094918314 seconds. Throughput is 1348.528 records/second. Loss is 2.188319. Sequentialb692dd65's hyper parameters: Current learning rate is 4.464285714285714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 38912/60000][Iteration 1242][Wall Clock 125.394903276s] Trained 128 records in 0.090324199 seconds. Throughput is 1417.1174 records/second. Loss is 2.1921232. Sequentialb692dd65's hyper parameters: Current learning rate is 4.462293618920125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39040/60000][Iteration 1243][Wall Clock 125.483032838s] Trained 128 records in 0.088129562 seconds. Throughput is 1452.407 records/second. Loss is 2.2103179. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4603033006244426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39168/60000][Iteration 1244][Wall Clock 125.573700609s] Trained 128 records in 0.090667771 seconds. Throughput is 1411.7476 records/second. Loss is 2.1913195. Sequentialb692dd65's hyper parameters: Current learning rate is 4.458314757021845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39296/60000][Iteration 1245][Wall Clock 125.669729055s] Trained 128 records in 0.096028446 seconds. Throughput is 1332.9384 records/second. Loss is 2.17816. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4563279857397507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39424/60000][Iteration 1246][Wall Clock 125.754362711s] Trained 128 records in 0.084633656 seconds. Throughput is 1512.4008 records/second. Loss is 2.2063088. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4543429844097997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39552/60000][Iteration 1247][Wall Clock 125.843265224s] Trained 128 records in 0.088902513 seconds. Throughput is 1439.7794 records/second. Loss is 2.176703. Sequentialb692dd65's hyper parameters: Current learning rate is 4.452359750667854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39680/60000][Iteration 1248][Wall Clock 125.92785184s] Trained 128 records in 0.084586616 seconds. Throughput is 1513.2418 records/second. Loss is 2.1786478. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4503782821539835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39808/60000][Iteration 1249][Wall Clock 126.019928897s] Trained 128 records in 0.092077057 seconds. Throughput is 1390.14 records/second. Loss is 2.2026272. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4483985765124553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 39936/60000][Iteration 1250][Wall Clock 126.107067349s] Trained 128 records in 0.087138452 seconds. Throughput is 1468.9268 records/second. Loss is 2.1883307. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4464206313917296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 40064/60000][Iteration 1251][Wall Clock 126.196369092s] Trained 128 records in 0.089301743 seconds. Throughput is 1433.3427 records/second. Loss is 2.190595. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4444444444444447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:29 INFO  DistriOptimizer$:408 - [Epoch 3 40192/60000][Iteration 1252][Wall Clock 126.280476055s] Trained 128 records in 0.084106963 seconds. Throughput is 1521.8717 records/second. Loss is 2.194905. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4424700133274093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40320/60000][Iteration 1253][Wall Clock 126.367945139s] Trained 128 records in 0.087469084 seconds. Throughput is 1463.3741 records/second. Loss is 2.1855977. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4404973357015993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40448/60000][Iteration 1254][Wall Clock 126.453079087s] Trained 128 records in 0.085133948 seconds. Throughput is 1503.5131 records/second. Loss is 2.1856754. Sequentialb692dd65's hyper parameters: Current learning rate is 4.438526409232135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40576/60000][Iteration 1255][Wall Clock 126.541597525s] Trained 128 records in 0.088518438 seconds. Throughput is 1446.0264 records/second. Loss is 2.1802707. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4365572315882877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40704/60000][Iteration 1256][Wall Clock 126.631576806s] Trained 128 records in 0.089979281 seconds. Throughput is 1422.5497 records/second. Loss is 2.2077694. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4345898004434595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40832/60000][Iteration 1257][Wall Clock 126.726330793s] Trained 128 records in 0.094753987 seconds. Throughput is 1350.8666 records/second. Loss is 2.1925619. Sequentialb692dd65's hyper parameters: Current learning rate is 4.432624113475177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 40960/60000][Iteration 1258][Wall Clock 126.81961479s] Trained 128 records in 0.093283997 seconds. Throughput is 1372.1539 records/second. Loss is 2.1940646. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4306601683650863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 41088/60000][Iteration 1259][Wall Clock 126.910154791s] Trained 128 records in 0.090540001 seconds. Throughput is 1413.7397 records/second. Loss is 2.1786833. Sequentialb692dd65's hyper parameters: Current learning rate is 4.428697962798937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 41216/60000][Iteration 1260][Wall Clock 126.998437157s] Trained 128 records in 0.088282366 seconds. Throughput is 1449.8931 records/second. Loss is 2.197355. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4267374944665776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 41344/60000][Iteration 1261][Wall Clock 127.085776781s] Trained 128 records in 0.087339624 seconds. Throughput is 1465.5433 records/second. Loss is 2.1935847. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4247787610619474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 41472/60000][Iteration 1262][Wall Clock 127.175796173s] Trained 128 records in 0.090019392 seconds. Throughput is 1421.9159 records/second. Loss is 2.1920235. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4228217602830603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:30 INFO  DistriOptimizer$:408 - [Epoch 3 41600/60000][Iteration 1263][Wall Clock 127.265533526s] Trained 128 records in 0.089737353 seconds. Throughput is 1426.3848 records/second. Loss is 2.1803596. Sequentialb692dd65's hyper parameters: Current learning rate is 4.4208664898320074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 41728/60000][Iteration 1264][Wall Clock 127.355839652s] Trained 128 records in 0.090306126 seconds. Throughput is 1417.4011 records/second. Loss is 2.1940439. Sequentialb692dd65's hyper parameters: Current learning rate is 4.418912947414936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 41856/60000][Iteration 1265][Wall Clock 127.442267577s] Trained 128 records in 0.086427925 seconds. Throughput is 1481.0028 records/second. Loss is 2.181311. Sequentialb692dd65's hyper parameters: Current learning rate is 4.416961130742049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 41984/60000][Iteration 1266][Wall Clock 127.532029298s] Trained 128 records in 0.089761721 seconds. Throughput is 1425.9977 records/second. Loss is 2.199332. Sequentialb692dd65's hyper parameters: Current learning rate is 4.415011037527594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42112/60000][Iteration 1267][Wall Clock 127.624290665s] Trained 128 records in 0.092261367 seconds. Throughput is 1387.3629 records/second. Loss is 2.1915972. Sequentialb692dd65's hyper parameters: Current learning rate is 4.41306266548985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42240/60000][Iteration 1268][Wall Clock 127.717067334s] Trained 128 records in 0.092776669 seconds. Throughput is 1379.6572 records/second. Loss is 2.1934536. Sequentialb692dd65's hyper parameters: Current learning rate is 4.411116012351124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42368/60000][Iteration 1269][Wall Clock 127.807264782s] Trained 128 records in 0.090197448 seconds. Throughput is 1419.1089 records/second. Loss is 2.1899307. Sequentialb692dd65's hyper parameters: Current learning rate is 4.409171075837743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42496/60000][Iteration 1270][Wall Clock 127.908548229s] Trained 128 records in 0.101283447 seconds. Throughput is 1263.78 records/second. Loss is 2.1739993. Sequentialb692dd65's hyper parameters: Current learning rate is 4.407227853680035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42624/60000][Iteration 1271][Wall Clock 127.99425719s] Trained 128 records in 0.085708961 seconds. Throughput is 1493.4261 records/second. Loss is 2.1925576. Sequentialb692dd65's hyper parameters: Current learning rate is 4.405286343612335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42752/60000][Iteration 1272][Wall Clock 128.083377499s] Trained 128 records in 0.089120309 seconds. Throughput is 1436.2607 records/second. Loss is 2.1924694. Sequentialb692dd65's hyper parameters: Current learning rate is 4.403346543372964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 42880/60000][Iteration 1273][Wall Clock 128.167709344s] Trained 128 records in 0.084331845 seconds. Throughput is 1517.8134 records/second. Loss is 2.193269. Sequentialb692dd65's hyper parameters: Current learning rate is 4.401408450704225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:31 INFO  DistriOptimizer$:408 - [Epoch 3 43008/60000][Iteration 1274][Wall Clock 128.25847658s] Trained 128 records in 0.090767236 seconds. Throughput is 1410.2006 records/second. Loss is 2.1860552. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3994720633523974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43136/60000][Iteration 1275][Wall Clock 128.350020683s] Trained 128 records in 0.091544103 seconds. Throughput is 1398.2332 records/second. Loss is 2.1970065. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3975373790677223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43264/60000][Iteration 1276][Wall Clock 128.442981135s] Trained 128 records in 0.092960452 seconds. Throughput is 1376.9296 records/second. Loss is 2.1872666. Sequentialb692dd65's hyper parameters: Current learning rate is 4.395604395604395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43392/60000][Iteration 1277][Wall Clock 128.528286621s] Trained 128 records in 0.085305486 seconds. Throughput is 1500.4896 records/second. Loss is 2.1862402. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3936731107205627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43520/60000][Iteration 1278][Wall Clock 128.615423015s] Trained 128 records in 0.087136394 seconds. Throughput is 1468.9614 records/second. Loss is 2.1858501. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3917435221783044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43648/60000][Iteration 1279][Wall Clock 128.705089181s] Trained 128 records in 0.089666166 seconds. Throughput is 1427.5173 records/second. Loss is 2.2101395. Sequentialb692dd65's hyper parameters: Current learning rate is 4.389815627743635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43776/60000][Iteration 1280][Wall Clock 128.794608951s] Trained 128 records in 0.08951977 seconds. Throughput is 1429.8518 records/second. Loss is 2.208201. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3878894251864854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 43904/60000][Iteration 1281][Wall Clock 128.881165717s] Trained 128 records in 0.086556766 seconds. Throughput is 1478.7983 records/second. Loss is 2.193711. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3859649122807013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 44032/60000][Iteration 1282][Wall Clock 128.977706714s] Trained 128 records in 0.096540997 seconds. Throughput is 1325.8616 records/second. Loss is 2.2002482. Sequentialb692dd65's hyper parameters: Current learning rate is 4.384042086804034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 44160/60000][Iteration 1283][Wall Clock 129.068315535s] Trained 128 records in 0.090608821 seconds. Throughput is 1412.666 records/second. Loss is 2.1845455. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3821209465381246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 44288/60000][Iteration 1284][Wall Clock 129.153380976s] Trained 128 records in 0.085065441 seconds. Throughput is 1504.7239 records/second. Loss is 2.1743782. Sequentialb692dd65's hyper parameters: Current learning rate is 4.380201489268507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:32 INFO  DistriOptimizer$:408 - [Epoch 3 44416/60000][Iteration 1285][Wall Clock 129.242693696s] Trained 128 records in 0.08931272 seconds. Throughput is 1433.1665 records/second. Loss is 2.1877356. Sequentialb692dd65's hyper parameters: Current learning rate is 4.378283712784589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 44544/60000][Iteration 1286][Wall Clock 129.329880151s] Trained 128 records in 0.087186455 seconds. Throughput is 1468.1179 records/second. Loss is 2.196091. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3763676148796495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 44672/60000][Iteration 1287][Wall Clock 129.418488201s] Trained 128 records in 0.08860805 seconds. Throughput is 1444.5641 records/second. Loss is 2.205464. Sequentialb692dd65's hyper parameters: Current learning rate is 4.374453193350831E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 44800/60000][Iteration 1288][Wall Clock 129.50610948s] Trained 128 records in 0.087621279 seconds. Throughput is 1460.8324 records/second. Loss is 2.1913164. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3725404459991256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 44928/60000][Iteration 1289][Wall Clock 129.594417209s] Trained 128 records in 0.088307729 seconds. Throughput is 1449.4767 records/second. Loss is 2.1784093. Sequentialb692dd65's hyper parameters: Current learning rate is 4.37062937062937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45056/60000][Iteration 1290][Wall Clock 129.686401937s] Trained 128 records in 0.091984728 seconds. Throughput is 1391.5354 records/second. Loss is 2.186525. Sequentialb692dd65's hyper parameters: Current learning rate is 4.368719965050241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45184/60000][Iteration 1291][Wall Clock 129.775689966s] Trained 128 records in 0.089288029 seconds. Throughput is 1433.5629 records/second. Loss is 2.190954. Sequentialb692dd65's hyper parameters: Current learning rate is 4.366812227074236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45312/60000][Iteration 1292][Wall Clock 129.863958664s] Trained 128 records in 0.088268698 seconds. Throughput is 1450.1177 records/second. Loss is 2.200793. Sequentialb692dd65's hyper parameters: Current learning rate is 4.364906154517678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45440/60000][Iteration 1293][Wall Clock 129.950945616s] Trained 128 records in 0.086986952 seconds. Throughput is 1471.4851 records/second. Loss is 2.187387. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3630017452006987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45568/60000][Iteration 1294][Wall Clock 130.037763936s] Trained 128 records in 0.08681832 seconds. Throughput is 1474.3431 records/second. Loss is 2.1935332. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3610989969472303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45696/60000][Iteration 1295][Wall Clock 130.130728976s] Trained 128 records in 0.09296504 seconds. Throughput is 1376.8617 records/second. Loss is 2.187294. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3591979075850045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:33 INFO  DistriOptimizer$:408 - [Epoch 3 45824/60000][Iteration 1296][Wall Clock 130.217252245s] Trained 128 records in 0.086523269 seconds. Throughput is 1479.3707 records/second. Loss is 2.1961572. Sequentialb692dd65's hyper parameters: Current learning rate is 4.357298474945534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 45952/60000][Iteration 1297][Wall Clock 130.309036057s] Trained 128 records in 0.091783812 seconds. Throughput is 1394.5814 records/second. Loss is 2.1879082. Sequentialb692dd65's hyper parameters: Current learning rate is 4.355400696864111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46080/60000][Iteration 1298][Wall Clock 130.392924762s] Trained 128 records in 0.083888705 seconds. Throughput is 1525.8312 records/second. Loss is 2.1798112. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3535045711798006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46208/60000][Iteration 1299][Wall Clock 130.481277587s] Trained 128 records in 0.088352825 seconds. Throughput is 1448.7369 records/second. Loss is 2.1925633. Sequentialb692dd65's hyper parameters: Current learning rate is 4.351610095735422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46336/60000][Iteration 1300][Wall Clock 130.574613517s] Trained 128 records in 0.09333593 seconds. Throughput is 1371.3905 records/second. Loss is 2.1863618. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3497172683775554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46464/60000][Iteration 1301][Wall Clock 130.667734176s] Trained 128 records in 0.093120659 seconds. Throughput is 1374.5608 records/second. Loss is 2.1774373. Sequentialb692dd65's hyper parameters: Current learning rate is 4.347826086956522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46592/60000][Iteration 1302][Wall Clock 130.756875159s] Trained 128 records in 0.089140983 seconds. Throughput is 1435.9276 records/second. Loss is 2.1914716. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3459365493263795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46720/60000][Iteration 1303][Wall Clock 130.847115785s] Trained 128 records in 0.090240626 seconds. Throughput is 1418.4298 records/second. Loss is 2.1720824. Sequentialb692dd65's hyper parameters: Current learning rate is 4.344048653344917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46848/60000][Iteration 1304][Wall Clock 130.934147736s] Trained 128 records in 0.087031951 seconds. Throughput is 1470.7242 records/second. Loss is 2.1947603. Sequentialb692dd65's hyper parameters: Current learning rate is 4.342162396873643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 46976/60000][Iteration 1305][Wall Clock 131.021001574s] Trained 128 records in 0.086853838 seconds. Throughput is 1473.7402 records/second. Loss is 2.1900444. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3402777777777775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 47104/60000][Iteration 1306][Wall Clock 131.110380585s] Trained 128 records in 0.089379011 seconds. Throughput is 1432.1035 records/second. Loss is 2.202001. Sequentialb692dd65's hyper parameters: Current learning rate is 4.338394793926248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:34 INFO  DistriOptimizer$:408 - [Epoch 3 47232/60000][Iteration 1307][Wall Clock 131.199200366s] Trained 128 records in 0.088819781 seconds. Throughput is 1441.1205 records/second. Loss is 2.1728897. Sequentialb692dd65's hyper parameters: Current learning rate is 4.336513443191674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 47360/60000][Iteration 1308][Wall Clock 131.298595831s] Trained 128 records in 0.099395465 seconds. Throughput is 1287.7852 records/second. Loss is 2.199316. Sequentialb692dd65's hyper parameters: Current learning rate is 4.334633723450369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 47488/60000][Iteration 1309][Wall Clock 131.389423655s] Trained 128 records in 0.090827824 seconds. Throughput is 1409.2598 records/second. Loss is 2.208707. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3327556325823227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 47616/60000][Iteration 1310][Wall Clock 131.475163016s] Trained 128 records in 0.085739361 seconds. Throughput is 1492.8966 records/second. Loss is 2.1903417. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3308791684711995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 47744/60000][Iteration 1311][Wall Clock 131.56354287s] Trained 128 records in 0.088379854 seconds. Throughput is 1448.294 records/second. Loss is 2.1695786. Sequentialb692dd65's hyper parameters: Current learning rate is 4.329004329004329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 47872/60000][Iteration 1312][Wall Clock 131.653725743s] Trained 128 records in 0.090182873 seconds. Throughput is 1419.3383 records/second. Loss is 2.1981416. Sequentialb692dd65's hyper parameters: Current learning rate is 4.327131112072696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48000/60000][Iteration 1313][Wall Clock 131.745258604s] Trained 128 records in 0.091532861 seconds. Throughput is 1398.4048 records/second. Loss is 2.1832714. Sequentialb692dd65's hyper parameters: Current learning rate is 4.325259515570934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48128/60000][Iteration 1314][Wall Clock 131.834664801s] Trained 128 records in 0.089406197 seconds. Throughput is 1431.6681 records/second. Loss is 2.1947548. Sequentialb692dd65's hyper parameters: Current learning rate is 4.32338953739732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48256/60000][Iteration 1315][Wall Clock 131.918655054s] Trained 128 records in 0.083990253 seconds. Throughput is 1523.9863 records/second. Loss is 2.2012525. Sequentialb692dd65's hyper parameters: Current learning rate is 4.32152117545376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48384/60000][Iteration 1316][Wall Clock 132.006312792s] Trained 128 records in 0.087657738 seconds. Throughput is 1460.2249 records/second. Loss is 2.166545. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3196544276457883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48512/60000][Iteration 1317][Wall Clock 132.092937092s] Trained 128 records in 0.0866243 seconds. Throughput is 1477.6454 records/second. Loss is 2.173992. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3177892918825565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:35 INFO  DistriOptimizer$:408 - [Epoch 3 48640/60000][Iteration 1318][Wall Clock 132.178472482s] Trained 128 records in 0.08553539 seconds. Throughput is 1496.4565 records/second. Loss is 2.1790874. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3159257660768235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 48768/60000][Iteration 1319][Wall Clock 132.264890279s] Trained 128 records in 0.086417797 seconds. Throughput is 1481.1764 records/second. Loss is 2.1815856. Sequentialb692dd65's hyper parameters: Current learning rate is 4.314063848144953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 48896/60000][Iteration 1320][Wall Clock 132.354966448s] Trained 128 records in 0.090076169 seconds. Throughput is 1421.0195 records/second. Loss is 2.1749265. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3122035360068997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49024/60000][Iteration 1321][Wall Clock 132.455159844s] Trained 128 records in 0.100193396 seconds. Throughput is 1277.5293 records/second. Loss is 2.1738076. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3103448275862063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49152/60000][Iteration 1322][Wall Clock 132.544007131s] Trained 128 records in 0.088847287 seconds. Throughput is 1440.6743 records/second. Loss is 2.1719246. Sequentialb692dd65's hyper parameters: Current learning rate is 4.308487720809996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49280/60000][Iteration 1323][Wall Clock 132.630539167s] Trained 128 records in 0.086532036 seconds. Throughput is 1479.221 records/second. Loss is 2.1808121. Sequentialb692dd65's hyper parameters: Current learning rate is 4.306632213608958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49408/60000][Iteration 1324][Wall Clock 132.717718184s] Trained 128 records in 0.087179017 seconds. Throughput is 1468.2432 records/second. Loss is 2.1725965. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3047783039173483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49536/60000][Iteration 1325][Wall Clock 132.806605763s] Trained 128 records in 0.088887579 seconds. Throughput is 1440.0212 records/second. Loss is 2.161354. Sequentialb692dd65's hyper parameters: Current learning rate is 4.302925989672978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49664/60000][Iteration 1326][Wall Clock 132.896452823s] Trained 128 records in 0.08984706 seconds. Throughput is 1424.6432 records/second. Loss is 2.1834912. Sequentialb692dd65's hyper parameters: Current learning rate is 4.3010752688172043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49792/60000][Iteration 1327][Wall Clock 132.982843556s] Trained 128 records in 0.086390733 seconds. Throughput is 1481.6404 records/second. Loss is 2.1737096. Sequentialb692dd65's hyper parameters: Current learning rate is 4.299226139294927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 49920/60000][Iteration 1328][Wall Clock 133.071148129s] Trained 128 records in 0.088304573 seconds. Throughput is 1449.5286 records/second. Loss is 2.1860418. Sequentialb692dd65's hyper parameters: Current learning rate is 4.297378599054577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:36 INFO  DistriOptimizer$:408 - [Epoch 3 50048/60000][Iteration 1329][Wall Clock 133.169518796s] Trained 128 records in 0.098370667 seconds. Throughput is 1301.2009 records/second. Loss is 2.1878345. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2955326460481093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50176/60000][Iteration 1330][Wall Clock 133.262651293s] Trained 128 records in 0.093132497 seconds. Throughput is 1374.386 records/second. Loss is 2.1764617. Sequentialb692dd65's hyper parameters: Current learning rate is 4.293688278231001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50304/60000][Iteration 1331][Wall Clock 133.35585393s] Trained 128 records in 0.093202637 seconds. Throughput is 1373.3517 records/second. Loss is 2.1998186. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2918454935622315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50432/60000][Iteration 1332][Wall Clock 133.443259677s] Trained 128 records in 0.087405747 seconds. Throughput is 1464.4346 records/second. Loss is 2.1869109. Sequentialb692dd65's hyper parameters: Current learning rate is 4.29000429000429E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50560/60000][Iteration 1333][Wall Clock 133.534320627s] Trained 128 records in 0.09106095 seconds. Throughput is 1405.6519 records/second. Loss is 2.1816192. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2881646655231566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50688/60000][Iteration 1334][Wall Clock 133.636977564s] Trained 128 records in 0.102656937 seconds. Throughput is 1246.8713 records/second. Loss is 2.1707177. Sequentialb692dd65's hyper parameters: Current learning rate is 4.286326618088298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50816/60000][Iteration 1335][Wall Clock 133.727025211s] Trained 128 records in 0.090047647 seconds. Throughput is 1421.4696 records/second. Loss is 2.1989918. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2844901456726646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 50944/60000][Iteration 1336][Wall Clock 133.845995454s] Trained 128 records in 0.118970243 seconds. Throughput is 1075.8993 records/second. Loss is 2.1682673. Sequentialb692dd65's hyper parameters: Current learning rate is 4.282655246252677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 51072/60000][Iteration 1337][Wall Clock 133.962541241s] Trained 128 records in 0.116545787 seconds. Throughput is 1098.2808 records/second. Loss is 2.1775522. Sequentialb692dd65's hyper parameters: Current learning rate is 4.280821917808219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 51200/60000][Iteration 1338][Wall Clock 134.074039215s] Trained 128 records in 0.111497974 seconds. Throughput is 1148.0029 records/second. Loss is 2.1609166. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2789901583226365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 51328/60000][Iteration 1339][Wall Clock 134.159651692s] Trained 128 records in 0.085612477 seconds. Throughput is 1495.1093 records/second. Loss is 2.175067. Sequentialb692dd65's hyper parameters: Current learning rate is 4.27715996578272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:37 INFO  DistriOptimizer$:408 - [Epoch 3 51456/60000][Iteration 1340][Wall Clock 134.247240427s] Trained 128 records in 0.087588735 seconds. Throughput is 1461.3751 records/second. Loss is 2.162302. Sequentialb692dd65's hyper parameters: Current learning rate is 4.275331338178709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 51584/60000][Iteration 1341][Wall Clock 134.335534354s] Trained 128 records in 0.088293927 seconds. Throughput is 1449.7034 records/second. Loss is 2.184364. Sequentialb692dd65's hyper parameters: Current learning rate is 4.273504273504274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 51712/60000][Iteration 1342][Wall Clock 134.426362884s] Trained 128 records in 0.09082853 seconds. Throughput is 1409.2488 records/second. Loss is 2.1978865. Sequentialb692dd65's hyper parameters: Current learning rate is 4.271678769756514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 51840/60000][Iteration 1343][Wall Clock 134.517564741s] Trained 128 records in 0.091201857 seconds. Throughput is 1403.4802 records/second. Loss is 2.1693692. Sequentialb692dd65's hyper parameters: Current learning rate is 4.269854824935952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 51968/60000][Iteration 1344][Wall Clock 134.612495689s] Trained 128 records in 0.094930948 seconds. Throughput is 1348.3485 records/second. Loss is 2.192478. Sequentialb692dd65's hyper parameters: Current learning rate is 4.268032437046522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52096/60000][Iteration 1345][Wall Clock 134.704162746s] Trained 128 records in 0.091667057 seconds. Throughput is 1396.3577 records/second. Loss is 2.187283. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2662116040955626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52224/60000][Iteration 1346][Wall Clock 134.811464584s] Trained 128 records in 0.107301838 seconds. Throughput is 1192.8966 records/second. Loss is 2.1851914. Sequentialb692dd65's hyper parameters: Current learning rate is 4.264392324093817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52352/60000][Iteration 1347][Wall Clock 134.897044441s] Trained 128 records in 0.085579857 seconds. Throughput is 1495.6791 records/second. Loss is 2.183097. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2625745950554135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52480/60000][Iteration 1348][Wall Clock 134.987856831s] Trained 128 records in 0.09081239 seconds. Throughput is 1409.4993 records/second. Loss is 2.193891. Sequentialb692dd65's hyper parameters: Current learning rate is 4.26075841499787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52608/60000][Iteration 1349][Wall Clock 135.076323346s] Trained 128 records in 0.088466515 seconds. Throughput is 1446.8751 records/second. Loss is 2.1760054. Sequentialb692dd65's hyper parameters: Current learning rate is 4.258943781942079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:38 INFO  DistriOptimizer$:408 - [Epoch 3 52736/60000][Iteration 1350][Wall Clock 135.164343105s] Trained 128 records in 0.088019759 seconds. Throughput is 1454.219 records/second. Loss is 2.1961668. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2571306939123026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 52864/60000][Iteration 1351][Wall Clock 135.252572286s] Trained 128 records in 0.088229181 seconds. Throughput is 1450.7672 records/second. Loss is 2.1737344. Sequentialb692dd65's hyper parameters: Current learning rate is 4.25531914893617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 52992/60000][Iteration 1352][Wall Clock 135.341060081s] Trained 128 records in 0.088487795 seconds. Throughput is 1446.5271 records/second. Loss is 2.1684797. Sequentialb692dd65's hyper parameters: Current learning rate is 4.253509145044662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53120/60000][Iteration 1353][Wall Clock 135.429178401s] Trained 128 records in 0.08811832 seconds. Throughput is 1452.5923 records/second. Loss is 2.185469. Sequentialb692dd65's hyper parameters: Current learning rate is 4.251700680272108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53248/60000][Iteration 1354][Wall Clock 135.517532291s] Trained 128 records in 0.08835389 seconds. Throughput is 1448.7195 records/second. Loss is 2.1814198. Sequentialb692dd65's hyper parameters: Current learning rate is 4.249893752656184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53376/60000][Iteration 1355][Wall Clock 135.605349801s] Trained 128 records in 0.08781751 seconds. Throughput is 1457.568 records/second. Loss is 2.1888077. Sequentialb692dd65's hyper parameters: Current learning rate is 4.248088360237893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53504/60000][Iteration 1356][Wall Clock 135.692561651s] Trained 128 records in 0.08721185 seconds. Throughput is 1467.6906 records/second. Loss is 2.1720147. Sequentialb692dd65's hyper parameters: Current learning rate is 4.246284501061571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53632/60000][Iteration 1357][Wall Clock 135.78135312s] Trained 128 records in 0.088791469 seconds. Throughput is 1441.58 records/second. Loss is 2.1966136. Sequentialb692dd65's hyper parameters: Current learning rate is 4.244482173174873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53760/60000][Iteration 1358][Wall Clock 135.871858032s] Trained 128 records in 0.090504912 seconds. Throughput is 1414.2878 records/second. Loss is 2.1693041. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2426813746287653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 53888/60000][Iteration 1359][Wall Clock 135.960896809s] Trained 128 records in 0.089038777 seconds. Throughput is 1437.5759 records/second. Loss is 2.1921003. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2408821034775233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 54016/60000][Iteration 1360][Wall Clock 136.064470413s] Trained 128 records in 0.103573604 seconds. Throughput is 1235.836 records/second. Loss is 2.17144. Sequentialb692dd65's hyper parameters: Current learning rate is 4.23908435777872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:39 INFO  DistriOptimizer$:408 - [Epoch 3 54144/60000][Iteration 1361][Wall Clock 136.15172114s] Trained 128 records in 0.087250727 seconds. Throughput is 1467.0365 records/second. Loss is 2.1581256. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2372881355932197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54272/60000][Iteration 1362][Wall Clock 136.242307706s] Trained 128 records in 0.090586566 seconds. Throughput is 1413.0131 records/second. Loss is 2.1939478. Sequentialb692dd65's hyper parameters: Current learning rate is 4.235493434985176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54400/60000][Iteration 1363][Wall Clock 136.336225254s] Trained 128 records in 0.093917548 seconds. Throughput is 1362.8976 records/second. Loss is 2.185336. Sequentialb692dd65's hyper parameters: Current learning rate is 4.233700254022015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54528/60000][Iteration 1364][Wall Clock 136.448741389s] Trained 128 records in 0.112516135 seconds. Throughput is 1137.6146 records/second. Loss is 2.1754198. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2319085907744394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54656/60000][Iteration 1365][Wall Clock 136.537893783s] Trained 128 records in 0.089152394 seconds. Throughput is 1435.7438 records/second. Loss is 2.1755178. Sequentialb692dd65's hyper parameters: Current learning rate is 4.230118443316413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54784/60000][Iteration 1366][Wall Clock 136.627991228s] Trained 128 records in 0.090097445 seconds. Throughput is 1420.6841 records/second. Loss is 2.1839235. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2283298097251583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 54912/60000][Iteration 1367][Wall Clock 136.723732823s] Trained 128 records in 0.095741595 seconds. Throughput is 1336.932 records/second. Loss is 2.1571321. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2265426880811494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 55040/60000][Iteration 1368][Wall Clock 136.818446199s] Trained 128 records in 0.094713376 seconds. Throughput is 1351.4459 records/second. Loss is 2.1914825. Sequentialb692dd65's hyper parameters: Current learning rate is 4.224757076468103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 55168/60000][Iteration 1369][Wall Clock 136.913848903s] Trained 128 records in 0.095402704 seconds. Throughput is 1341.681 records/second. Loss is 2.190228. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2229729729729727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 55296/60000][Iteration 1370][Wall Clock 137.004304333s] Trained 128 records in 0.09045543 seconds. Throughput is 1415.0615 records/second. Loss is 2.1831079. Sequentialb692dd65's hyper parameters: Current learning rate is 4.221190375685944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 55424/60000][Iteration 1371][Wall Clock 137.096976873s] Trained 128 records in 0.09267254 seconds. Throughput is 1381.2074 records/second. Loss is 2.2000859. Sequentialb692dd65's hyper parameters: Current learning rate is 4.219409282700422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:40 INFO  DistriOptimizer$:408 - [Epoch 3 55552/60000][Iteration 1372][Wall Clock 137.182091698s] Trained 128 records in 0.085114825 seconds. Throughput is 1503.8508 records/second. Loss is 2.1820238. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2176296921130323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 55680/60000][Iteration 1373][Wall Clock 137.268900861s] Trained 128 records in 0.086809163 seconds. Throughput is 1474.4987 records/second. Loss is 2.1674805. Sequentialb692dd65's hyper parameters: Current learning rate is 4.215851602023609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 55808/60000][Iteration 1374][Wall Clock 137.358394199s] Trained 128 records in 0.089493338 seconds. Throughput is 1430.2742 records/second. Loss is 2.1734686. Sequentialb692dd65's hyper parameters: Current learning rate is 4.214075010535187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 55936/60000][Iteration 1375][Wall Clock 137.446034939s] Trained 128 records in 0.08764074 seconds. Throughput is 1460.5079 records/second. Loss is 2.1818228. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2122999157540015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56064/60000][Iteration 1376][Wall Clock 137.542557628s] Trained 128 records in 0.096522689 seconds. Throughput is 1326.113 records/second. Loss is 2.1623447. Sequentialb692dd65's hyper parameters: Current learning rate is 4.210526315789474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56192/60000][Iteration 1377][Wall Clock 137.634902415s] Trained 128 records in 0.092344787 seconds. Throughput is 1386.1096 records/second. Loss is 2.160089. Sequentialb692dd65's hyper parameters: Current learning rate is 4.208754208754208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56320/60000][Iteration 1378][Wall Clock 137.744727557s] Trained 128 records in 0.109825142 seconds. Throughput is 1165.489 records/second. Loss is 2.202948. Sequentialb692dd65's hyper parameters: Current learning rate is 4.206983592763989E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56448/60000][Iteration 1379][Wall Clock 137.829838464s] Trained 128 records in 0.085110907 seconds. Throughput is 1503.92 records/second. Loss is 2.197635. Sequentialb692dd65's hyper parameters: Current learning rate is 4.2052144659377626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56576/60000][Iteration 1380][Wall Clock 137.91469847s] Trained 128 records in 0.084860006 seconds. Throughput is 1508.3667 records/second. Loss is 2.1827352. Sequentialb692dd65's hyper parameters: Current learning rate is 4.203446826397646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56704/60000][Iteration 1381][Wall Clock 138.000120067s] Trained 128 records in 0.085421597 seconds. Throughput is 1498.4501 records/second. Loss is 2.1776211. Sequentialb692dd65's hyper parameters: Current learning rate is 4.201680672268908E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56832/60000][Iteration 1382][Wall Clock 138.0864956s] Trained 128 records in 0.086375533 seconds. Throughput is 1481.9011 records/second. Loss is 2.1606503. Sequentialb692dd65's hyper parameters: Current learning rate is 4.199916001679966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:41 INFO  DistriOptimizer$:408 - [Epoch 3 56960/60000][Iteration 1383][Wall Clock 138.174478814s] Trained 128 records in 0.087983214 seconds. Throughput is 1454.823 records/second. Loss is 2.192427. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1981528127623844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57088/60000][Iteration 1384][Wall Clock 138.260353982s] Trained 128 records in 0.085875168 seconds. Throughput is 1490.5356 records/second. Loss is 2.1722157. Sequentialb692dd65's hyper parameters: Current learning rate is 4.19639110365086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57216/60000][Iteration 1385][Wall Clock 138.348111914s] Trained 128 records in 0.087757932 seconds. Throughput is 1458.5576 records/second. Loss is 2.1824112. Sequentialb692dd65's hyper parameters: Current learning rate is 4.194630872483221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57344/60000][Iteration 1386][Wall Clock 138.434175105s] Trained 128 records in 0.086063191 seconds. Throughput is 1487.2793 records/second. Loss is 2.1768796. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1928721174004196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57472/60000][Iteration 1387][Wall Clock 138.535759248s] Trained 128 records in 0.101584143 seconds. Throughput is 1260.0392 records/second. Loss is 2.1637726. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1911148365465214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57600/60000][Iteration 1388][Wall Clock 138.618032301s] Trained 128 records in 0.082273053 seconds. Throughput is 1555.7949 records/second. Loss is 2.1937058. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1893590280687055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57728/60000][Iteration 1389][Wall Clock 138.708004987s] Trained 128 records in 0.089972686 seconds. Throughput is 1422.654 records/second. Loss is 2.1887648. Sequentialb692dd65's hyper parameters: Current learning rate is 4.187604690117253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57856/60000][Iteration 1390][Wall Clock 138.795520614s] Trained 128 records in 0.087515627 seconds. Throughput is 1462.5958 records/second. Loss is 2.1770446. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1858518208455416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 57984/60000][Iteration 1391][Wall Clock 138.880795507s] Trained 128 records in 0.085274893 seconds. Throughput is 1501.0281 records/second. Loss is 2.1923726. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1841004184100416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 58112/60000][Iteration 1392][Wall Clock 138.967392579s] Trained 128 records in 0.086597072 seconds. Throughput is 1478.1101 records/second. Loss is 2.1681137. Sequentialb692dd65's hyper parameters: Current learning rate is 4.182350480970305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 58240/60000][Iteration 1393][Wall Clock 139.057859802s] Trained 128 records in 0.090467223 seconds. Throughput is 1414.8771 records/second. Loss is 2.1796153. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1806020066889626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:42 INFO  DistriOptimizer$:408 - [Epoch 3 58368/60000][Iteration 1394][Wall Clock 139.148484413s] Trained 128 records in 0.090624611 seconds. Throughput is 1412.4199 records/second. Loss is 2.173793. Sequentialb692dd65's hyper parameters: Current learning rate is 4.178854993731718E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 58496/60000][Iteration 1395][Wall Clock 139.241282173s] Trained 128 records in 0.09279776 seconds. Throughput is 1379.3436 records/second. Loss is 2.1738086. Sequentialb692dd65's hyper parameters: Current learning rate is 4.177109440267335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 58624/60000][Iteration 1396][Wall Clock 139.326977909s] Trained 128 records in 0.085695736 seconds. Throughput is 1493.6566 records/second. Loss is 2.1856186. Sequentialb692dd65's hyper parameters: Current learning rate is 4.175365344467641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 58752/60000][Iteration 1397][Wall Clock 139.410472528s] Trained 128 records in 0.083494619 seconds. Throughput is 1533.033 records/second. Loss is 2.1737947. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1736227045075126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 58880/60000][Iteration 1398][Wall Clock 139.498062975s] Trained 128 records in 0.087590447 seconds. Throughput is 1461.3466 records/second. Loss is 2.184825. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1718815185648727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59008/60000][Iteration 1399][Wall Clock 139.587636945s] Trained 128 records in 0.08957397 seconds. Throughput is 1428.9866 records/second. Loss is 2.1763127. Sequentialb692dd65's hyper parameters: Current learning rate is 4.170141784820684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59136/60000][Iteration 1400][Wall Clock 139.676494433s] Trained 128 records in 0.088857488 seconds. Throughput is 1440.5089 records/second. Loss is 2.180937. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1684035014589413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59264/60000][Iteration 1401][Wall Clock 139.765238183s] Trained 128 records in 0.08874375 seconds. Throughput is 1442.3551 records/second. Loss is 2.1868215. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1666666666666664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59392/60000][Iteration 1402][Wall Clock 139.851147438s] Trained 128 records in 0.085909255 seconds. Throughput is 1489.9442 records/second. Loss is 2.1844656. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1649312786339027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59520/60000][Iteration 1403][Wall Clock 139.937914863s] Trained 128 records in 0.086767425 seconds. Throughput is 1475.208 records/second. Loss is 2.186124. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1631973355537054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59648/60000][Iteration 1404][Wall Clock 140.025732917s] Trained 128 records in 0.087818054 seconds. Throughput is 1457.559 records/second. Loss is 2.1844008. Sequentialb692dd65's hyper parameters: Current learning rate is 4.161464835622139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59776/60000][Iteration 1405][Wall Clock 140.112820959s] Trained 128 records in 0.087088042 seconds. Throughput is 1469.777 records/second. Loss is 2.1732447. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1597337770382697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:43 INFO  DistriOptimizer$:408 - [Epoch 3 59904/60000][Iteration 1406][Wall Clock 140.199108598s] Trained 128 records in 0.086287639 seconds. Throughput is 1483.4106 records/second. Loss is 2.180048. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1580041580041577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:44 INFO  DistriOptimizer$:408 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.287491922s] Trained 128 records in 0.088383324 seconds. Throughput is 1448.2369 records/second. Loss is 2.1746063. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1562759767248546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:44 INFO  DistriOptimizer$:452 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.287491922s] Epoch finished. Wall clock time is 141456.202506 ms
2019-10-15 07:48:44 INFO  DistriOptimizer$:111 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.287491922s] Validate model...
2019-10-15 07:48:45 INFO  DistriOptimizer$:178 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.287491922s] validate model throughput is 10492.934 records/second
2019-10-15 07:48:45 INFO  DistriOptimizer$:181 - [Epoch 3 60032/60000][Iteration 1407][Wall Clock 140.287491922s] Top1Accuracy is Accuracy(correct: 4325, count: 10000, accuracy: 0.4325)
2019-10-15 07:48:45 INFO  DistriOptimizer$:221 - [Wall Clock 141.456202506s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:48:45 INFO  DistriOptimizer$:226 - [Wall Clock 141.456202506s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 128/60000][Iteration 1408][Wall Clock 141.542906357s] Trained 128 records in 0.086703851 seconds. Throughput is 1476.2897 records/second. Loss is 2.1823347. Sequentialb692dd65's hyper parameters: Current learning rate is 4.154549231408392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 256/60000][Iteration 1409][Wall Clock 141.618898394s] Trained 128 records in 0.075992037 seconds. Throughput is 1684.387 records/second. Loss is 2.1906347. Sequentialb692dd65's hyper parameters: Current learning rate is 4.152823920265781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 384/60000][Iteration 1410][Wall Clock 141.695073993s] Trained 128 records in 0.076175599 seconds. Throughput is 1680.3281 records/second. Loss is 2.1750069. Sequentialb692dd65's hyper parameters: Current learning rate is 4.151100041511001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 512/60000][Iteration 1411][Wall Clock 141.774894518s] Trained 128 records in 0.079820525 seconds. Throughput is 1603.5975 records/second. Loss is 2.1937106. Sequentialb692dd65's hyper parameters: Current learning rate is 4.149377593360996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 640/60000][Iteration 1412][Wall Clock 141.868318118s] Trained 128 records in 0.0934236 seconds. Throughput is 1370.1035 records/second. Loss is 2.1729228. Sequentialb692dd65's hyper parameters: Current learning rate is 4.14765657403567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 768/60000][Iteration 1413][Wall Clock 141.974806389s] Trained 128 records in 0.106488271 seconds. Throughput is 1202.0103 records/second. Loss is 2.1774025. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1459369817578774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 896/60000][Iteration 1414][Wall Clock 142.051418749s] Trained 128 records in 0.07661236 seconds. Throughput is 1670.7487 records/second. Loss is 2.1980107. Sequentialb692dd65's hyper parameters: Current learning rate is 4.144218814753419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 1024/60000][Iteration 1415][Wall Clock 142.135873556s] Trained 128 records in 0.084454807 seconds. Throughput is 1515.6035 records/second. Loss is 2.1689646. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1425020712510365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 1152/60000][Iteration 1416][Wall Clock 142.220952428s] Trained 128 records in 0.085078872 seconds. Throughput is 1504.4863 records/second. Loss is 2.1732938. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1407867494824016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:45 INFO  DistriOptimizer$:408 - [Epoch 4 1280/60000][Iteration 1417][Wall Clock 142.309354346s] Trained 128 records in 0.088401918 seconds. Throughput is 1447.9324 records/second. Loss is 2.1776927. Sequentialb692dd65's hyper parameters: Current learning rate is 4.139072847682119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 1408/60000][Iteration 1418][Wall Clock 142.396719613s] Trained 128 records in 0.087365267 seconds. Throughput is 1465.113 records/second. Loss is 2.1934. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1373603640877123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 1536/60000][Iteration 1419][Wall Clock 142.483163375s] Trained 128 records in 0.086443762 seconds. Throughput is 1480.7316 records/second. Loss is 2.1742563. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1356492969396195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 1664/60000][Iteration 1420][Wall Clock 142.576368908s] Trained 128 records in 0.093205533 seconds. Throughput is 1373.309 records/second. Loss is 2.1779199. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1339396444811904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 1792/60000][Iteration 1421][Wall Clock 142.660862927s] Trained 128 records in 0.084494019 seconds. Throughput is 1514.9001 records/second. Loss is 2.1645055. Sequentialb692dd65's hyper parameters: Current learning rate is 4.132231404958678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 1920/60000][Iteration 1422][Wall Clock 142.748722668s] Trained 128 records in 0.087859741 seconds. Throughput is 1456.8674 records/second. Loss is 2.1739402. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1305245766212306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2048/60000][Iteration 1423][Wall Clock 142.835420984s] Trained 128 records in 0.086698316 seconds. Throughput is 1476.3839 records/second. Loss is 2.1892047. Sequentialb692dd65's hyper parameters: Current learning rate is 4.128819157720892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2176/60000][Iteration 1424][Wall Clock 142.924558921s] Trained 128 records in 0.089137937 seconds. Throughput is 1435.9767 records/second. Loss is 2.186211. Sequentialb692dd65's hyper parameters: Current learning rate is 4.127115146512588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2304/60000][Iteration 1425][Wall Clock 143.01075533s] Trained 128 records in 0.086196409 seconds. Throughput is 1484.9807 records/second. Loss is 2.1783004. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1254125412541255E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2432/60000][Iteration 1426][Wall Clock 143.101715938s] Trained 128 records in 0.090960608 seconds. Throughput is 1407.2025 records/second. Loss is 2.1615765. Sequentialb692dd65's hyper parameters: Current learning rate is 4.123711340206186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2560/60000][Iteration 1427][Wall Clock 143.188740363s] Trained 128 records in 0.087024425 seconds. Throughput is 1470.8514 records/second. Loss is 2.178113. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1220115416323167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:46 INFO  DistriOptimizer$:408 - [Epoch 4 2688/60000][Iteration 1428][Wall Clock 143.276403331s] Trained 128 records in 0.087662968 seconds. Throughput is 1460.1377 records/second. Loss is 2.1558924. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1203131437989287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 2816/60000][Iteration 1429][Wall Clock 143.361796948s] Trained 128 records in 0.085393617 seconds. Throughput is 1498.9412 records/second. Loss is 2.1631176. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1186161449752884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 2944/60000][Iteration 1430][Wall Clock 143.449544354s] Trained 128 records in 0.087747406 seconds. Throughput is 1458.7327 records/second. Loss is 2.1734505. Sequentialb692dd65's hyper parameters: Current learning rate is 4.116920543433511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3072/60000][Iteration 1431][Wall Clock 143.537104749s] Trained 128 records in 0.087560395 seconds. Throughput is 1461.8481 records/second. Loss is 2.1625628. Sequentialb692dd65's hyper parameters: Current learning rate is 4.11522633744856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3200/60000][Iteration 1432][Wall Clock 143.622802258s] Trained 128 records in 0.085697509 seconds. Throughput is 1493.6257 records/second. Loss is 2.1883423. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1135335252982314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3328/60000][Iteration 1433][Wall Clock 143.709175854s] Trained 128 records in 0.086373596 seconds. Throughput is 1481.9343 records/second. Loss is 2.1586745. Sequentialb692dd65's hyper parameters: Current learning rate is 4.111842105263158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3456/60000][Iteration 1434][Wall Clock 143.797823993s] Trained 128 records in 0.088648139 seconds. Throughput is 1443.9108 records/second. Loss is 2.1873977. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1101520756267986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3584/60000][Iteration 1435][Wall Clock 143.884420435s] Trained 128 records in 0.086596442 seconds. Throughput is 1478.1207 records/second. Loss is 2.1880555. Sequentialb692dd65's hyper parameters: Current learning rate is 4.108463434675431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3712/60000][Iteration 1436][Wall Clock 143.97089172s] Trained 128 records in 0.086471285 seconds. Throughput is 1480.2603 records/second. Loss is 2.1836512. Sequentialb692dd65's hyper parameters: Current learning rate is 4.106776180698152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3840/60000][Iteration 1437][Wall Clock 144.065832452s] Trained 128 records in 0.094940732 seconds. Throughput is 1348.2096 records/second. Loss is 2.170736. Sequentialb692dd65's hyper parameters: Current learning rate is 4.105090311986864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 3968/60000][Iteration 1438][Wall Clock 144.146827069s] Trained 128 records in 0.080994617 seconds. Throughput is 1580.352 records/second. Loss is 2.1549354. Sequentialb692dd65's hyper parameters: Current learning rate is 4.1034058268362735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 4096/60000][Iteration 1439][Wall Clock 144.228867219s] Trained 128 records in 0.08204015 seconds. Throughput is 1560.2117 records/second. Loss is 2.158807. Sequentialb692dd65's hyper parameters: Current learning rate is 4.101722723543889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:47 INFO  DistriOptimizer$:408 - [Epoch 4 4224/60000][Iteration 1440][Wall Clock 144.315320917s] Trained 128 records in 0.086453698 seconds. Throughput is 1480.5613 records/second. Loss is 2.1717815. Sequentialb692dd65's hyper parameters: Current learning rate is 4.100041000410004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4352/60000][Iteration 1441][Wall Clock 144.404294439s] Trained 128 records in 0.088973522 seconds. Throughput is 1438.6302 records/second. Loss is 2.1884878. Sequentialb692dd65's hyper parameters: Current learning rate is 4.098360655737705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4480/60000][Iteration 1442][Wall Clock 144.490369306s] Trained 128 records in 0.086074867 seconds. Throughput is 1487.0775 records/second. Loss is 2.1673882. Sequentialb692dd65's hyper parameters: Current learning rate is 4.096681687832856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4608/60000][Iteration 1443][Wall Clock 144.580387661s] Trained 128 records in 0.090018355 seconds. Throughput is 1421.9323 records/second. Loss is 2.1821837. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0950040950040947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4736/60000][Iteration 1444][Wall Clock 144.668458254s] Trained 128 records in 0.088070593 seconds. Throughput is 1453.3795 records/second. Loss is 2.1784906. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0933278755628325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4864/60000][Iteration 1445][Wall Clock 144.754187607s] Trained 128 records in 0.085729353 seconds. Throughput is 1493.0709 records/second. Loss is 2.157546. Sequentialb692dd65's hyper parameters: Current learning rate is 4.091653027823241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 4992/60000][Iteration 1446][Wall Clock 144.847292219s] Trained 128 records in 0.093104612 seconds. Throughput is 1374.7977 records/second. Loss is 2.1850152. Sequentialb692dd65's hyper parameters: Current learning rate is 4.089979550102249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 5120/60000][Iteration 1447][Wall Clock 144.93193667s] Trained 128 records in 0.084644451 seconds. Throughput is 1512.2078 records/second. Loss is 2.1548226. Sequentialb692dd65's hyper parameters: Current learning rate is 4.088307440719543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 5248/60000][Iteration 1448][Wall Clock 145.019321882s] Trained 128 records in 0.087385212 seconds. Throughput is 1464.7787 records/second. Loss is 2.176416. Sequentialb692dd65's hyper parameters: Current learning rate is 4.086636697997548E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 5376/60000][Iteration 1449][Wall Clock 145.105635209s] Trained 128 records in 0.086313327 seconds. Throughput is 1482.9691 records/second. Loss is 2.1683288. Sequentialb692dd65's hyper parameters: Current learning rate is 4.084967320261438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 5504/60000][Iteration 1450][Wall Clock 145.193398548s] Trained 128 records in 0.087763339 seconds. Throughput is 1458.4678 records/second. Loss is 2.1863577. Sequentialb692dd65's hyper parameters: Current learning rate is 4.083299305839118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:48 INFO  DistriOptimizer$:408 - [Epoch 4 5632/60000][Iteration 1451][Wall Clock 145.284493825s] Trained 128 records in 0.091095277 seconds. Throughput is 1405.1223 records/second. Loss is 2.1868668. Sequentialb692dd65's hyper parameters: Current learning rate is 4.081632653061224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 5760/60000][Iteration 1452][Wall Clock 145.376284184s] Trained 128 records in 0.091790359 seconds. Throughput is 1394.482 records/second. Loss is 2.157265. Sequentialb692dd65's hyper parameters: Current learning rate is 4.079967360261118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 5888/60000][Iteration 1453][Wall Clock 145.465135508s] Trained 128 records in 0.088851324 seconds. Throughput is 1440.6088 records/second. Loss is 2.1802454. Sequentialb692dd65's hyper parameters: Current learning rate is 4.078303425774878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6016/60000][Iteration 1454][Wall Clock 145.557709155s] Trained 128 records in 0.092573647 seconds. Throughput is 1382.6829 records/second. Loss is 2.1697652. Sequentialb692dd65's hyper parameters: Current learning rate is 4.076640847941296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6144/60000][Iteration 1455][Wall Clock 145.650435417s] Trained 128 records in 0.092726262 seconds. Throughput is 1380.4072 records/second. Loss is 2.166955. Sequentialb692dd65's hyper parameters: Current learning rate is 4.074979625101875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6272/60000][Iteration 1456][Wall Clock 145.74227484s] Trained 128 records in 0.091839423 seconds. Throughput is 1393.7369 records/second. Loss is 2.157474. Sequentialb692dd65's hyper parameters: Current learning rate is 4.073319755600815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6400/60000][Iteration 1457][Wall Clock 145.832053517s] Trained 128 records in 0.089778677 seconds. Throughput is 1425.7283 records/second. Loss is 2.1594987. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0716612377850165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6528/60000][Iteration 1458][Wall Clock 145.91947605s] Trained 128 records in 0.087422533 seconds. Throughput is 1464.1534 records/second. Loss is 2.1785648. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0700040700040704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6656/60000][Iteration 1459][Wall Clock 146.006370968s] Trained 128 records in 0.086894918 seconds. Throughput is 1473.0436 records/second. Loss is 2.180208. Sequentialb692dd65's hyper parameters: Current learning rate is 4.068348250610252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6784/60000][Iteration 1460][Wall Clock 146.096610983s] Trained 128 records in 0.090240015 seconds. Throughput is 1418.4395 records/second. Loss is 2.1537063. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0666937779585197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 6912/60000][Iteration 1461][Wall Clock 146.18339086s] Trained 128 records in 0.086779877 seconds. Throughput is 1474.9963 records/second. Loss is 2.1736333. Sequentialb692dd65's hyper parameters: Current learning rate is 4.065040650406504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:49 INFO  DistriOptimizer$:408 - [Epoch 4 7040/60000][Iteration 1462][Wall Clock 146.273953177s] Trained 128 records in 0.090562317 seconds. Throughput is 1413.3915 records/second. Loss is 2.1594288. Sequentialb692dd65's hyper parameters: Current learning rate is 4.063388866314506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7168/60000][Iteration 1463][Wall Clock 146.370013496s] Trained 128 records in 0.096060319 seconds. Throughput is 1332.4961 records/second. Loss is 2.1771517. Sequentialb692dd65's hyper parameters: Current learning rate is 4.061738424045492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7296/60000][Iteration 1464][Wall Clock 146.454741071s] Trained 128 records in 0.084727575 seconds. Throughput is 1510.7241 records/second. Loss is 2.1657934. Sequentialb692dd65's hyper parameters: Current learning rate is 4.060089321965083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7424/60000][Iteration 1465][Wall Clock 146.540581649s] Trained 128 records in 0.085840578 seconds. Throughput is 1491.1364 records/second. Loss is 2.1586292. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0584415584415587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7552/60000][Iteration 1466][Wall Clock 146.627232591s] Trained 128 records in 0.086650942 seconds. Throughput is 1477.191 records/second. Loss is 2.1736012. Sequentialb692dd65's hyper parameters: Current learning rate is 4.056795131845842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7680/60000][Iteration 1467][Wall Clock 146.720381977s] Trained 128 records in 0.093149386 seconds. Throughput is 1374.1368 records/second. Loss is 2.1633685. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0551500405515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7808/60000][Iteration 1468][Wall Clock 146.807025512s] Trained 128 records in 0.086643535 seconds. Throughput is 1477.3174 records/second. Loss is 2.179275. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0535062829347385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 7936/60000][Iteration 1469][Wall Clock 146.897756057s] Trained 128 records in 0.090730545 seconds. Throughput is 1410.7708 records/second. Loss is 2.1964219. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0518638573743926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 8064/60000][Iteration 1470][Wall Clock 146.988340513s] Trained 128 records in 0.090584456 seconds. Throughput is 1413.0459 records/second. Loss is 2.1659327. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0502227622519235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 8192/60000][Iteration 1471][Wall Clock 147.082871656s] Trained 128 records in 0.094531143 seconds. Throughput is 1354.0511 records/second. Loss is 2.1736684. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0485829959514174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 8320/60000][Iteration 1472][Wall Clock 147.165409999s] Trained 128 records in 0.082538343 seconds. Throughput is 1550.7944 records/second. Loss is 2.168235. Sequentialb692dd65's hyper parameters: Current learning rate is 4.046944556859571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:50 INFO  DistriOptimizer$:408 - [Epoch 4 8448/60000][Iteration 1473][Wall Clock 147.250100205s] Trained 128 records in 0.084690206 seconds. Throughput is 1511.3909 records/second. Loss is 2.1673877. Sequentialb692dd65's hyper parameters: Current learning rate is 4.045307443365696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 8576/60000][Iteration 1474][Wall Clock 147.338352765s] Trained 128 records in 0.08825256 seconds. Throughput is 1450.3828 records/second. Loss is 2.1629956. Sequentialb692dd65's hyper parameters: Current learning rate is 4.043671653861707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 8704/60000][Iteration 1475][Wall Clock 147.426793377s] Trained 128 records in 0.088440612 seconds. Throughput is 1447.299 records/second. Loss is 2.167523. Sequentialb692dd65's hyper parameters: Current learning rate is 4.042037186742118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 8832/60000][Iteration 1476][Wall Clock 147.513746702s] Trained 128 records in 0.086953325 seconds. Throughput is 1472.0541 records/second. Loss is 2.1695263. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0404040404040404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 8960/60000][Iteration 1477][Wall Clock 147.600234156s] Trained 128 records in 0.086487454 seconds. Throughput is 1479.9834 records/second. Loss is 2.146887. Sequentialb692dd65's hyper parameters: Current learning rate is 4.038772213247173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9088/60000][Iteration 1478][Wall Clock 147.687067921s] Trained 128 records in 0.086833765 seconds. Throughput is 1474.0809 records/second. Loss is 2.1806293. Sequentialb692dd65's hyper parameters: Current learning rate is 4.037141703673799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9216/60000][Iteration 1479][Wall Clock 147.775320605s] Trained 128 records in 0.088252684 seconds. Throughput is 1450.3807 records/second. Loss is 2.1670566. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0355125100887816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9344/60000][Iteration 1480][Wall Clock 147.862042201s] Trained 128 records in 0.086721596 seconds. Throughput is 1475.9875 records/second. Loss is 2.1672988. Sequentialb692dd65's hyper parameters: Current learning rate is 4.033884630899556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9472/60000][Iteration 1481][Wall Clock 147.947344575s] Trained 128 records in 0.085302374 seconds. Throughput is 1500.5444 records/second. Loss is 2.1592145. Sequentialb692dd65's hyper parameters: Current learning rate is 4.032258064516129E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9600/60000][Iteration 1482][Wall Clock 148.033844892s] Trained 128 records in 0.086500317 seconds. Throughput is 1479.7633 records/second. Loss is 2.1748729. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0306328093510683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9728/60000][Iteration 1483][Wall Clock 148.120746198s] Trained 128 records in 0.086901306 seconds. Throughput is 1472.9353 records/second. Loss is 2.1587882. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0290088638195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9856/60000][Iteration 1484][Wall Clock 148.208127597s] Trained 128 records in 0.087381399 seconds. Throughput is 1464.8427 records/second. Loss is 2.1620905. Sequentialb692dd65's hyper parameters: Current learning rate is 4.027386226339106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:51 INFO  DistriOptimizer$:408 - [Epoch 4 9984/60000][Iteration 1485][Wall Clock 148.29495215s] Trained 128 records in 0.086824553 seconds. Throughput is 1474.2374 records/second. Loss is 2.1881924. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0257648953301127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10112/60000][Iteration 1486][Wall Clock 148.383730918s] Trained 128 records in 0.088778768 seconds. Throughput is 1441.7861 records/second. Loss is 2.1823702. Sequentialb692dd65's hyper parameters: Current learning rate is 4.024144869215291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10240/60000][Iteration 1487][Wall Clock 148.470529328s] Trained 128 records in 0.08679841 seconds. Throughput is 1474.6814 records/second. Loss is 2.177237. Sequentialb692dd65's hyper parameters: Current learning rate is 4.022526146419952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10368/60000][Iteration 1488][Wall Clock 148.558572846s] Trained 128 records in 0.088043518 seconds. Throughput is 1453.8265 records/second. Loss is 2.1508474. Sequentialb692dd65's hyper parameters: Current learning rate is 4.020908725371934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10496/60000][Iteration 1489][Wall Clock 148.657948443s] Trained 128 records in 0.099375597 seconds. Throughput is 1288.0426 records/second. Loss is 2.1587203. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0192926045016077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10624/60000][Iteration 1490][Wall Clock 148.748638942s] Trained 128 records in 0.090690499 seconds. Throughput is 1411.3937 records/second. Loss is 2.1723611. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0176777822418646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10752/60000][Iteration 1491][Wall Clock 148.829904715s] Trained 128 records in 0.081265773 seconds. Throughput is 1575.0789 records/second. Loss is 2.1671283. Sequentialb692dd65's hyper parameters: Current learning rate is 4.016064257028112E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 10880/60000][Iteration 1492][Wall Clock 148.911281084s] Trained 128 records in 0.081376369 seconds. Throughput is 1572.9382 records/second. Loss is 2.1853871. Sequentialb692dd65's hyper parameters: Current learning rate is 4.014452027298274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 11008/60000][Iteration 1493][Wall Clock 148.998120614s] Trained 128 records in 0.08683953 seconds. Throughput is 1473.9832 records/second. Loss is 2.161821. Sequentialb692dd65's hyper parameters: Current learning rate is 4.012841091492777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 11136/60000][Iteration 1494][Wall Clock 149.091272926s] Trained 128 records in 0.093152312 seconds. Throughput is 1374.0936 records/second. Loss is 2.144976. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0112314480545525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 11264/60000][Iteration 1495][Wall Clock 149.180586806s] Trained 128 records in 0.08931388 seconds. Throughput is 1433.148 records/second. Loss is 2.1790664. Sequentialb692dd65's hyper parameters: Current learning rate is 4.00962309542903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:52 INFO  DistriOptimizer$:408 - [Epoch 4 11392/60000][Iteration 1496][Wall Clock 149.26715302s] Trained 128 records in 0.086566214 seconds. Throughput is 1478.6368 records/second. Loss is 2.1806905. Sequentialb692dd65's hyper parameters: Current learning rate is 4.008016032064128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 11520/60000][Iteration 1497][Wall Clock 149.35825592s] Trained 128 records in 0.0911029 seconds. Throughput is 1405.0046 records/second. Loss is 2.1847062. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0064102564102563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 11648/60000][Iteration 1498][Wall Clock 149.441912461s] Trained 128 records in 0.083656541 seconds. Throughput is 1530.0657 records/second. Loss is 2.1689677. Sequentialb692dd65's hyper parameters: Current learning rate is 4.004805766920305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 11776/60000][Iteration 1499][Wall Clock 149.527535747s] Trained 128 records in 0.085623286 seconds. Throughput is 1494.9204 records/second. Loss is 2.1636333. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0032025620496394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 11904/60000][Iteration 1500][Wall Clock 149.617199837s] Trained 128 records in 0.08966409 seconds. Throughput is 1427.5504 records/second. Loss is 2.1832871. Sequentialb692dd65's hyper parameters: Current learning rate is 4.001600640256102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12032/60000][Iteration 1501][Wall Clock 149.704504483s] Trained 128 records in 0.087304646 seconds. Throughput is 1466.1305 records/second. Loss is 2.178712. Sequentialb692dd65's hyper parameters: Current learning rate is 4.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12160/60000][Iteration 1502][Wall Clock 149.791188125s] Trained 128 records in 0.086683642 seconds. Throughput is 1476.6339 records/second. Loss is 2.1815689. Sequentialb692dd65's hyper parameters: Current learning rate is 3.998400639744102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12288/60000][Iteration 1503][Wall Clock 149.876662971s] Trained 128 records in 0.085474846 seconds. Throughput is 1497.5166 records/second. Loss is 2.1779718. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9968025579536375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12416/60000][Iteration 1504][Wall Clock 149.963963883s] Trained 128 records in 0.087300912 seconds. Throughput is 1466.1931 records/second. Loss is 2.1656144. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9952057530962844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12544/60000][Iteration 1505][Wall Clock 150.051183195s] Trained 128 records in 0.087219312 seconds. Throughput is 1467.5648 records/second. Loss is 2.1619887. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9936102236421724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12672/60000][Iteration 1506][Wall Clock 150.141688561s] Trained 128 records in 0.090505366 seconds. Throughput is 1414.2808 records/second. Loss is 2.1574826. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9920159680638726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:53 INFO  DistriOptimizer$:408 - [Epoch 4 12800/60000][Iteration 1507][Wall Clock 150.228864264s] Trained 128 records in 0.087175703 seconds. Throughput is 1468.299 records/second. Loss is 2.1740098. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9904229848363923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 12928/60000][Iteration 1508][Wall Clock 150.318639443s] Trained 128 records in 0.089775179 seconds. Throughput is 1425.7838 records/second. Loss is 2.1546535. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9888312724371757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13056/60000][Iteration 1509][Wall Clock 150.407191568s] Trained 128 records in 0.088552125 seconds. Throughput is 1445.4763 records/second. Loss is 2.1554708. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9872408293460925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13184/60000][Iteration 1510][Wall Clock 150.494372566s] Trained 128 records in 0.087180998 seconds. Throughput is 1468.21 records/second. Loss is 2.1748717. Sequentialb692dd65's hyper parameters: Current learning rate is 3.985651654045436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13312/60000][Iteration 1511][Wall Clock 150.587912707s] Trained 128 records in 0.093540141 seconds. Throughput is 1368.3965 records/second. Loss is 2.172666. Sequentialb692dd65's hyper parameters: Current learning rate is 3.984063745019921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13440/60000][Iteration 1512][Wall Clock 150.67524016s] Trained 128 records in 0.087327453 seconds. Throughput is 1465.7476 records/second. Loss is 2.164434. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9824771007566706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13568/60000][Iteration 1513][Wall Clock 150.764905929s] Trained 128 records in 0.089665769 seconds. Throughput is 1427.5236 records/second. Loss is 2.1847568. Sequentialb692dd65's hyper parameters: Current learning rate is 3.980891719745223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13696/60000][Iteration 1514][Wall Clock 150.853761061s] Trained 128 records in 0.088855132 seconds. Throughput is 1440.5471 records/second. Loss is 2.1673331. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9793076004775174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13824/60000][Iteration 1515][Wall Clock 150.954930119s] Trained 128 records in 0.101169058 seconds. Throughput is 1265.209 records/second. Loss is 2.1699636. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9777247414478914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 13952/60000][Iteration 1516][Wall Clock 151.038313875s] Trained 128 records in 0.083383756 seconds. Throughput is 1535.0712 records/second. Loss is 2.1683772. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9761431411530816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 14080/60000][Iteration 1517][Wall Clock 151.125205909s] Trained 128 records in 0.086892034 seconds. Throughput is 1473.0925 records/second. Loss is 2.1445572. Sequentialb692dd65's hyper parameters: Current learning rate is 3.97456279809221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:54 INFO  DistriOptimizer$:408 - [Epoch 4 14208/60000][Iteration 1518][Wall Clock 151.210355789s] Trained 128 records in 0.08514988 seconds. Throughput is 1503.2318 records/second. Loss is 2.1525488. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9729837107667853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14336/60000][Iteration 1519][Wall Clock 151.29691149s] Trained 128 records in 0.086555701 seconds. Throughput is 1478.8164 records/second. Loss is 2.1852033. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9714058776806993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14464/60000][Iteration 1520][Wall Clock 151.382747719s] Trained 128 records in 0.085836229 seconds. Throughput is 1491.2118 records/second. Loss is 2.1573846. Sequentialb692dd65's hyper parameters: Current learning rate is 3.969829297340214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14592/60000][Iteration 1521][Wall Clock 151.471899189s] Trained 128 records in 0.08915147 seconds. Throughput is 1435.7587 records/second. Loss is 2.1643093. Sequentialb692dd65's hyper parameters: Current learning rate is 3.968253968253968E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14720/60000][Iteration 1522][Wall Clock 151.559993044s] Trained 128 records in 0.088093855 seconds. Throughput is 1452.9958 records/second. Loss is 2.1639242. Sequentialb692dd65's hyper parameters: Current learning rate is 3.966679888932963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14848/60000][Iteration 1523][Wall Clock 151.654940005s] Trained 128 records in 0.094946961 seconds. Throughput is 1348.1211 records/second. Loss is 2.1586425. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9651070578905625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 14976/60000][Iteration 1524][Wall Clock 151.739813572s] Trained 128 records in 0.084873567 seconds. Throughput is 1508.1256 records/second. Loss is 2.1629064. Sequentialb692dd65's hyper parameters: Current learning rate is 3.963535473642489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15104/60000][Iteration 1525][Wall Clock 151.824583077s] Trained 128 records in 0.084769505 seconds. Throughput is 1509.977 records/second. Loss is 2.1636891. Sequentialb692dd65's hyper parameters: Current learning rate is 3.961965134706815E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15232/60000][Iteration 1526][Wall Clock 151.91157547s] Trained 128 records in 0.086992393 seconds. Throughput is 1471.3931 records/second. Loss is 2.1877658. Sequentialb692dd65's hyper parameters: Current learning rate is 3.96039603960396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15360/60000][Iteration 1527][Wall Clock 151.999296761s] Trained 128 records in 0.087721291 seconds. Throughput is 1459.1669 records/second. Loss is 2.1679938. Sequentialb692dd65's hyper parameters: Current learning rate is 3.958828186856691E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15488/60000][Iteration 1528][Wall Clock 152.084937673s] Trained 128 records in 0.085640912 seconds. Throughput is 1494.6127 records/second. Loss is 2.1743934. Sequentialb692dd65's hyper parameters: Current learning rate is 3.957261574990107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15616/60000][Iteration 1529][Wall Clock 152.171668377s] Trained 128 records in 0.086730704 seconds. Throughput is 1475.8326 records/second. Loss is 2.1637344. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9556962025316455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:55 INFO  DistriOptimizer$:408 - [Epoch 4 15744/60000][Iteration 1530][Wall Clock 152.256558636s] Trained 128 records in 0.084890259 seconds. Throughput is 1507.829 records/second. Loss is 2.1682308. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9541320680110717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 15872/60000][Iteration 1531][Wall Clock 152.342023395s] Trained 128 records in 0.085464759 seconds. Throughput is 1497.6934 records/second. Loss is 2.1561286. Sequentialb692dd65's hyper parameters: Current learning rate is 3.952569169960474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16000/60000][Iteration 1532][Wall Clock 152.431405494s] Trained 128 records in 0.089382099 seconds. Throughput is 1432.0541 records/second. Loss is 2.1608942. Sequentialb692dd65's hyper parameters: Current learning rate is 3.951007506914263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16128/60000][Iteration 1533][Wall Clock 152.521296784s] Trained 128 records in 0.08989129 seconds. Throughput is 1423.9421 records/second. Loss is 2.1705177. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9494470774091627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16256/60000][Iteration 1534][Wall Clock 152.612230026s] Trained 128 records in 0.090933242 seconds. Throughput is 1407.6261 records/second. Loss is 2.1635365. Sequentialb692dd65's hyper parameters: Current learning rate is 3.947887879984208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16384/60000][Iteration 1535][Wall Clock 152.704524699s] Trained 128 records in 0.092294673 seconds. Throughput is 1386.8623 records/second. Loss is 2.1797454. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9463299131807424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16512/60000][Iteration 1536][Wall Clock 152.792490056s] Trained 128 records in 0.087965357 seconds. Throughput is 1455.1183 records/second. Loss is 2.1878514. Sequentialb692dd65's hyper parameters: Current learning rate is 3.944773175542406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16640/60000][Iteration 1537][Wall Clock 152.880186226s] Trained 128 records in 0.08769617 seconds. Throughput is 1459.5848 records/second. Loss is 2.1693518. Sequentialb692dd65's hyper parameters: Current learning rate is 3.943217665615142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16768/60000][Iteration 1538][Wall Clock 152.966470401s] Trained 128 records in 0.086284175 seconds. Throughput is 1483.4702 records/second. Loss is 2.1661274. Sequentialb692dd65's hyper parameters: Current learning rate is 3.941663381947182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 16896/60000][Iteration 1539][Wall Clock 153.054212353s] Trained 128 records in 0.087741952 seconds. Throughput is 1458.8234 records/second. Loss is 2.134038. Sequentialb692dd65's hyper parameters: Current learning rate is 3.940110323089046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 17024/60000][Iteration 1540][Wall Clock 153.152596233s] Trained 128 records in 0.09838388 seconds. Throughput is 1301.0261 records/second. Loss is 2.1637347. Sequentialb692dd65's hyper parameters: Current learning rate is 3.938558487593541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:56 INFO  DistriOptimizer$:408 - [Epoch 4 17152/60000][Iteration 1541][Wall Clock 153.239316671s] Trained 128 records in 0.086720438 seconds. Throughput is 1476.0073 records/second. Loss is 2.1577065. Sequentialb692dd65's hyper parameters: Current learning rate is 3.937007874015748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17280/60000][Iteration 1542][Wall Clock 153.328132461s] Trained 128 records in 0.08881579 seconds. Throughput is 1441.1852 records/second. Loss is 2.168581. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9354584809130267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17408/60000][Iteration 1543][Wall Clock 153.414450937s] Trained 128 records in 0.086318476 seconds. Throughput is 1482.8806 records/second. Loss is 2.1773062. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9339103068450045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17536/60000][Iteration 1544][Wall Clock 153.504412657s] Trained 128 records in 0.08996172 seconds. Throughput is 1422.8274 records/second. Loss is 2.1860027. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9323633503735744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17664/60000][Iteration 1545][Wall Clock 153.589287274s] Trained 128 records in 0.084874617 seconds. Throughput is 1508.1069 records/second. Loss is 2.15961. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9308176100628933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17792/60000][Iteration 1546][Wall Clock 153.677952205s] Trained 128 records in 0.088664931 seconds. Throughput is 1443.6372 records/second. Loss is 2.1770806. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9292730844793717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 17920/60000][Iteration 1547][Wall Clock 153.766185129s] Trained 128 records in 0.088232924 seconds. Throughput is 1450.7056 records/second. Loss is 2.1914983. Sequentialb692dd65's hyper parameters: Current learning rate is 3.927729772191673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 18048/60000][Iteration 1548][Wall Clock 153.874484495s] Trained 128 records in 0.108299366 seconds. Throughput is 1181.909 records/second. Loss is 2.1665053. Sequentialb692dd65's hyper parameters: Current learning rate is 3.926187671770711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 18176/60000][Iteration 1549][Wall Clock 153.961103203s] Trained 128 records in 0.086618708 seconds. Throughput is 1477.7408 records/second. Loss is 2.1552508. Sequentialb692dd65's hyper parameters: Current learning rate is 3.924646781789639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 18304/60000][Iteration 1550][Wall Clock 154.043489676s] Trained 128 records in 0.082386473 seconds. Throughput is 1553.6532 records/second. Loss is 2.149659. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9231071008238524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 18432/60000][Iteration 1551][Wall Clock 154.131904819s] Trained 128 records in 0.088415143 seconds. Throughput is 1447.7157 records/second. Loss is 2.1623807. Sequentialb692dd65's hyper parameters: Current learning rate is 3.921568627450981E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:57 INFO  DistriOptimizer$:408 - [Epoch 4 18560/60000][Iteration 1552][Wall Clock 154.221130966s] Trained 128 records in 0.089226147 seconds. Throughput is 1434.557 records/second. Loss is 2.1644473. Sequentialb692dd65's hyper parameters: Current learning rate is 3.920031360250882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 18688/60000][Iteration 1553][Wall Clock 154.307280222s] Trained 128 records in 0.086149256 seconds. Throughput is 1485.7935 records/second. Loss is 2.1739442. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9184952978056425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 18816/60000][Iteration 1554][Wall Clock 154.394169668s] Trained 128 records in 0.086889446 seconds. Throughput is 1473.1364 records/second. Loss is 2.153037. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9169604386995695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 18944/60000][Iteration 1555][Wall Clock 154.506701621s] Trained 128 records in 0.112531953 seconds. Throughput is 1137.4547 records/second. Loss is 2.1701005. Sequentialb692dd65's hyper parameters: Current learning rate is 3.915426781519185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19072/60000][Iteration 1556][Wall Clock 154.591731242s] Trained 128 records in 0.085029621 seconds. Throughput is 1505.3577 records/second. Loss is 2.154511. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9138943248532296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19200/60000][Iteration 1557][Wall Clock 154.67798605s] Trained 128 records in 0.086254808 seconds. Throughput is 1483.9753 records/second. Loss is 2.1789575. Sequentialb692dd65's hyper parameters: Current learning rate is 3.912363067292645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19328/60000][Iteration 1558][Wall Clock 154.765715816s] Trained 128 records in 0.087729766 seconds. Throughput is 1459.0259 records/second. Loss is 2.175262. Sequentialb692dd65's hyper parameters: Current learning rate is 3.910833007430583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19456/60000][Iteration 1559][Wall Clock 154.852147076s] Trained 128 records in 0.08643126 seconds. Throughput is 1480.9457 records/second. Loss is 2.1554348. Sequentialb692dd65's hyper parameters: Current learning rate is 3.909304143862393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19584/60000][Iteration 1560][Wall Clock 154.938323576s] Trained 128 records in 0.0861765 seconds. Throughput is 1485.3237 records/second. Loss is 2.191127. Sequentialb692dd65's hyper parameters: Current learning rate is 3.907776475185619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19712/60000][Iteration 1561][Wall Clock 155.024760229s] Trained 128 records in 0.086436653 seconds. Throughput is 1480.8533 records/second. Loss is 2.1655273. Sequentialb692dd65's hyper parameters: Current learning rate is 3.90625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19840/60000][Iteration 1562][Wall Clock 155.111538112s] Trained 128 records in 0.086777883 seconds. Throughput is 1475.0303 records/second. Loss is 2.1666157. Sequentialb692dd65's hyper parameters: Current learning rate is 3.904724716907458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:58 INFO  DistriOptimizer$:408 - [Epoch 4 19968/60000][Iteration 1563][Wall Clock 155.200185285s] Trained 128 records in 0.088647173 seconds. Throughput is 1443.9265 records/second. Loss is 2.1630054. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9032006245120994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20096/60000][Iteration 1564][Wall Clock 155.28809418s] Trained 128 records in 0.087908895 seconds. Throughput is 1456.0529 records/second. Loss is 2.1774054. Sequentialb692dd65's hyper parameters: Current learning rate is 3.9016777214202113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20224/60000][Iteration 1565][Wall Clock 155.373817003s] Trained 128 records in 0.085722823 seconds. Throughput is 1493.1846 records/second. Loss is 2.1540642. Sequentialb692dd65's hyper parameters: Current learning rate is 3.90015600624025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20352/60000][Iteration 1566][Wall Clock 155.474233851s] Trained 128 records in 0.100416848 seconds. Throughput is 1274.6865 records/second. Loss is 2.141476. Sequentialb692dd65's hyper parameters: Current learning rate is 3.898635477582846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20480/60000][Iteration 1567][Wall Clock 155.561780419s] Trained 128 records in 0.087546568 seconds. Throughput is 1462.0791 records/second. Loss is 2.1702933. Sequentialb692dd65's hyper parameters: Current learning rate is 3.897116134060795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20608/60000][Iteration 1568][Wall Clock 155.652041746s] Trained 128 records in 0.090261327 seconds. Throughput is 1418.1046 records/second. Loss is 2.1563256. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8955979742890534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20736/60000][Iteration 1569][Wall Clock 155.741839436s] Trained 128 records in 0.08979769 seconds. Throughput is 1425.4264 records/second. Loss is 2.161577. Sequentialb692dd65's hyper parameters: Current learning rate is 3.894080996884735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20864/60000][Iteration 1570][Wall Clock 155.830657195s] Trained 128 records in 0.088817759 seconds. Throughput is 1441.1532 records/second. Loss is 2.1569011. Sequentialb692dd65's hyper parameters: Current learning rate is 3.892565200467108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 20992/60000][Iteration 1571][Wall Clock 155.919542665s] Trained 128 records in 0.08888547 seconds. Throughput is 1440.0554 records/second. Loss is 2.168827. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8910505836575873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 21120/60000][Iteration 1572][Wall Clock 156.006648385s] Trained 128 records in 0.08710572 seconds. Throughput is 1469.4786 records/second. Loss is 2.1809716. Sequentialb692dd65's hyper parameters: Current learning rate is 3.889537145079736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 21248/60000][Iteration 1573][Wall Clock 156.093122075s] Trained 128 records in 0.08647369 seconds. Throughput is 1480.219 records/second. Loss is 2.1621706. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8880248833592535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:48:59 INFO  DistriOptimizer$:408 - [Epoch 4 21376/60000][Iteration 1574][Wall Clock 156.188814193s] Trained 128 records in 0.095692118 seconds. Throughput is 1337.6232 records/second. Loss is 2.1520607. Sequentialb692dd65's hyper parameters: Current learning rate is 3.88651379712398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 21504/60000][Iteration 1575][Wall Clock 156.278169399s] Trained 128 records in 0.089355206 seconds. Throughput is 1432.4851 records/second. Loss is 2.162322. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8850038850038855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 21632/60000][Iteration 1576][Wall Clock 156.367103526s] Trained 128 records in 0.088934127 seconds. Throughput is 1439.2676 records/second. Loss is 2.1487205. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8834951456310677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 21760/60000][Iteration 1577][Wall Clock 156.456847038s] Trained 128 records in 0.089743512 seconds. Throughput is 1426.287 records/second. Loss is 2.1740494. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8819875776397513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 21888/60000][Iteration 1578][Wall Clock 156.545741672s] Trained 128 records in 0.088894634 seconds. Throughput is 1439.9069 records/second. Loss is 2.132341. Sequentialb692dd65's hyper parameters: Current learning rate is 3.880481179666279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22016/60000][Iteration 1579][Wall Clock 156.632335879s] Trained 128 records in 0.086594207 seconds. Throughput is 1478.1589 records/second. Loss is 2.1627476. Sequentialb692dd65's hyper parameters: Current learning rate is 3.878975950349107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22144/60000][Iteration 1580][Wall Clock 156.721194101s] Trained 128 records in 0.088858222 seconds. Throughput is 1440.497 records/second. Loss is 2.171053. Sequentialb692dd65's hyper parameters: Current learning rate is 3.87747188832881E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22272/60000][Iteration 1581][Wall Clock 156.811081462s] Trained 128 records in 0.089887361 seconds. Throughput is 1424.0045 records/second. Loss is 2.1583998. Sequentialb692dd65's hyper parameters: Current learning rate is 3.875968992248062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22400/60000][Iteration 1582][Wall Clock 156.898566464s] Trained 128 records in 0.087485002 seconds. Throughput is 1463.1079 records/second. Loss is 2.1523664. Sequentialb692dd65's hyper parameters: Current learning rate is 3.874467260751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22528/60000][Iteration 1583][Wall Clock 157.001507211s] Trained 128 records in 0.102940747 seconds. Throughput is 1243.4337 records/second. Loss is 2.1484187. Sequentialb692dd65's hyper parameters: Current learning rate is 3.872966692486445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22656/60000][Iteration 1584][Wall Clock 157.089940756s] Trained 128 records in 0.088433545 seconds. Throughput is 1447.4147 records/second. Loss is 2.157913. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8714672861014324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:00 INFO  DistriOptimizer$:408 - [Epoch 4 22784/60000][Iteration 1585][Wall Clock 157.175530745s] Trained 128 records in 0.085589989 seconds. Throughput is 1495.502 records/second. Loss is 2.1504562. Sequentialb692dd65's hyper parameters: Current learning rate is 3.869969040247678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 22912/60000][Iteration 1586][Wall Clock 157.266294959s] Trained 128 records in 0.090764214 seconds. Throughput is 1410.2474 records/second. Loss is 2.1761749. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8684719535783365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23040/60000][Iteration 1587][Wall Clock 157.353316386s] Trained 128 records in 0.087021427 seconds. Throughput is 1470.9021 records/second. Loss is 2.1556349. Sequentialb692dd65's hyper parameters: Current learning rate is 3.866976024748646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23168/60000][Iteration 1588][Wall Clock 157.441441592s] Trained 128 records in 0.088125206 seconds. Throughput is 1452.4789 records/second. Loss is 2.1753693. Sequentialb692dd65's hyper parameters: Current learning rate is 3.865481252415926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23296/60000][Iteration 1589][Wall Clock 157.531261337s] Trained 128 records in 0.089819745 seconds. Throughput is 1425.0764 records/second. Loss is 2.151707. Sequentialb692dd65's hyper parameters: Current learning rate is 3.863987635239567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23424/60000][Iteration 1590][Wall Clock 157.621907666s] Trained 128 records in 0.090646329 seconds. Throughput is 1412.0815 records/second. Loss is 2.139507. Sequentialb692dd65's hyper parameters: Current learning rate is 3.862495171881035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23552/60000][Iteration 1591][Wall Clock 157.723685514s] Trained 128 records in 0.101777848 seconds. Throughput is 1257.641 records/second. Loss is 2.1698935. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8610038610038615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23680/60000][Iteration 1592][Wall Clock 157.809565108s] Trained 128 records in 0.085879594 seconds. Throughput is 1490.4589 records/second. Loss is 2.150817. Sequentialb692dd65's hyper parameters: Current learning rate is 3.859513701273639E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23808/60000][Iteration 1593][Wall Clock 157.896690361s] Trained 128 records in 0.087125253 seconds. Throughput is 1469.1492 records/second. Loss is 2.1432123. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8580246913580245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 23936/60000][Iteration 1594][Wall Clock 157.983976815s] Trained 128 records in 0.087286454 seconds. Throughput is 1466.4359 records/second. Loss is 2.1340349. Sequentialb692dd65's hyper parameters: Current learning rate is 3.856536829926726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 24064/60000][Iteration 1595][Wall Clock 158.071377693s] Trained 128 records in 0.087400878 seconds. Throughput is 1464.5162 records/second. Loss is 2.1676311. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8550501156515033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 24192/60000][Iteration 1596][Wall Clock 158.159289403s] Trained 128 records in 0.08791171 seconds. Throughput is 1456.0062 records/second. Loss is 2.1678383. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8535645472061663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:01 INFO  DistriOptimizer$:408 - [Epoch 4 24320/60000][Iteration 1597][Wall Clock 158.245347339s] Trained 128 records in 0.086057936 seconds. Throughput is 1487.37 records/second. Loss is 2.156915. Sequentialb692dd65's hyper parameters: Current learning rate is 3.852080123266564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 24448/60000][Iteration 1598][Wall Clock 158.33279444s] Trained 128 records in 0.087447101 seconds. Throughput is 1463.7421 records/second. Loss is 2.1714773. Sequentialb692dd65's hyper parameters: Current learning rate is 3.850596842510589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 24576/60000][Iteration 1599][Wall Clock 158.423813206s] Trained 128 records in 0.091018766 seconds. Throughput is 1406.3033 records/second. Loss is 2.1451385. Sequentialb692dd65's hyper parameters: Current learning rate is 3.849114703618168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 24704/60000][Iteration 1600][Wall Clock 158.509309851s] Trained 128 records in 0.085496645 seconds. Throughput is 1497.1349 records/second. Loss is 2.163158. Sequentialb692dd65's hyper parameters: Current learning rate is 3.847633705271258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 24832/60000][Iteration 1601][Wall Clock 158.590185338s] Trained 128 records in 0.080875487 seconds. Throughput is 1582.6798 records/second. Loss is 2.1596098. Sequentialb692dd65's hyper parameters: Current learning rate is 3.846153846153846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 24960/60000][Iteration 1602][Wall Clock 158.677287099s] Trained 128 records in 0.087101761 seconds. Throughput is 1469.5455 records/second. Loss is 2.157228. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8446751249519417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25088/60000][Iteration 1603][Wall Clock 158.764890319s] Trained 128 records in 0.08760322 seconds. Throughput is 1461.1335 records/second. Loss is 2.1682596. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8431975403535736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25216/60000][Iteration 1604][Wall Clock 158.857006548s] Trained 128 records in 0.092116229 seconds. Throughput is 1389.5488 records/second. Loss is 2.1729941. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8417210910487906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25344/60000][Iteration 1605][Wall Clock 158.944214401s] Trained 128 records in 0.087207853 seconds. Throughput is 1467.7577 records/second. Loss is 2.1708977. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8402457757296467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25472/60000][Iteration 1606][Wall Clock 159.034430603s] Trained 128 records in 0.090216202 seconds. Throughput is 1418.8138 records/second. Loss is 2.1372995. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8387715930902113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25600/60000][Iteration 1607][Wall Clock 159.12729898s] Trained 128 records in 0.092868377 seconds. Throughput is 1378.2948 records/second. Loss is 2.1593754. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8372985418265546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:02 INFO  DistriOptimizer$:408 - [Epoch 4 25728/60000][Iteration 1608][Wall Clock 159.218357533s] Trained 128 records in 0.091058553 seconds. Throughput is 1405.689 records/second. Loss is 2.161933. Sequentialb692dd65's hyper parameters: Current learning rate is 3.835826620636747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 25856/60000][Iteration 1609][Wall Clock 159.307702083s] Trained 128 records in 0.08934455 seconds. Throughput is 1432.6559 records/second. Loss is 2.1595914. Sequentialb692dd65's hyper parameters: Current learning rate is 3.834355828220859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 25984/60000][Iteration 1610][Wall Clock 159.394413219s] Trained 128 records in 0.086711136 seconds. Throughput is 1476.1656 records/second. Loss is 2.1789625. Sequentialb692dd65's hyper parameters: Current learning rate is 3.832886163280951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26112/60000][Iteration 1611][Wall Clock 159.479301631s] Trained 128 records in 0.084888412 seconds. Throughput is 1507.8618 records/second. Loss is 2.161707. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8314176245210724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26240/60000][Iteration 1612][Wall Clock 159.565302035s] Trained 128 records in 0.086000404 seconds. Throughput is 1488.3651 records/second. Loss is 2.166738. Sequentialb692dd65's hyper parameters: Current learning rate is 3.829950210647262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26368/60000][Iteration 1613][Wall Clock 159.656007859s] Trained 128 records in 0.090705824 seconds. Throughput is 1411.1552 records/second. Loss is 2.1537411. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8284839203675346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26496/60000][Iteration 1614][Wall Clock 159.742199189s] Trained 128 records in 0.08619133 seconds. Throughput is 1485.0682 records/second. Loss is 2.1429942. Sequentialb692dd65's hyper parameters: Current learning rate is 3.827018752391887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26624/60000][Iteration 1615][Wall Clock 159.827063561s] Trained 128 records in 0.084864372 seconds. Throughput is 1508.2891 records/second. Loss is 2.155374. Sequentialb692dd65's hyper parameters: Current learning rate is 3.825554705432288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26752/60000][Iteration 1616][Wall Clock 159.913794925s] Trained 128 records in 0.086731364 seconds. Throughput is 1475.8213 records/second. Loss is 2.1508284. Sequentialb692dd65's hyper parameters: Current learning rate is 3.824091778202677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 26880/60000][Iteration 1617][Wall Clock 160.01007473s] Trained 128 records in 0.096279805 seconds. Throughput is 1329.4584 records/second. Loss is 2.1534882. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8226299694189603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 27008/60000][Iteration 1618][Wall Clock 160.097744577s] Trained 128 records in 0.087669847 seconds. Throughput is 1460.0231 records/second. Loss is 2.1436822. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8211692777990065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:03 INFO  DistriOptimizer$:408 - [Epoch 4 27136/60000][Iteration 1619][Wall Clock 160.175170096s] Trained 128 records in 0.077425519 seconds. Throughput is 1653.2018 records/second. Loss is 2.14237. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8197097020626426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27264/60000][Iteration 1620][Wall Clock 160.260110824s] Trained 128 records in 0.084940728 seconds. Throughput is 1506.9331 records/second. Loss is 2.1644099. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8182512409316535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27392/60000][Iteration 1621][Wall Clock 160.345567222s] Trained 128 records in 0.085456398 seconds. Throughput is 1497.8398 records/second. Loss is 2.155555. Sequentialb692dd65's hyper parameters: Current learning rate is 3.816793893129771E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27520/60000][Iteration 1622][Wall Clock 160.430520563s] Trained 128 records in 0.084953341 seconds. Throughput is 1506.7095 records/second. Loss is 2.1636472. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8153376573826786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27648/60000][Iteration 1623][Wall Clock 160.518762658s] Trained 128 records in 0.088242095 seconds. Throughput is 1450.5548 records/second. Loss is 2.1424696. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8138825324180017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27776/60000][Iteration 1624][Wall Clock 160.602363793s] Trained 128 records in 0.083601135 seconds. Throughput is 1531.0797 records/second. Loss is 2.1579673. Sequentialb692dd65's hyper parameters: Current learning rate is 3.812428516965307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 27904/60000][Iteration 1625][Wall Clock 160.699839304s] Trained 128 records in 0.097475511 seconds. Throughput is 1313.1503 records/second. Loss is 2.1507943. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8109756097560977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28032/60000][Iteration 1626][Wall Clock 160.782495656s] Trained 128 records in 0.082656352 seconds. Throughput is 1548.5803 records/second. Loss is 2.1306307. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8095238095238096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28160/60000][Iteration 1627][Wall Clock 160.868907958s] Trained 128 records in 0.086412302 seconds. Throughput is 1481.2705 records/second. Loss is 2.1667843. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8080731150038076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28288/60000][Iteration 1628][Wall Clock 160.954672174s] Trained 128 records in 0.085764216 seconds. Throughput is 1492.464 records/second. Loss is 2.150783. Sequentialb692dd65's hyper parameters: Current learning rate is 3.8066235249333843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28416/60000][Iteration 1629][Wall Clock 161.042537094s] Trained 128 records in 0.08786492 seconds. Throughput is 1456.7816 records/second. Loss is 2.167965. Sequentialb692dd65's hyper parameters: Current learning rate is 3.80517503805175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28544/60000][Iteration 1630][Wall Clock 161.130499245s] Trained 128 records in 0.087962151 seconds. Throughput is 1455.1714 records/second. Loss is 2.1638527. Sequentialb692dd65's hyper parameters: Current learning rate is 3.803727653100038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:04 INFO  DistriOptimizer$:408 - [Epoch 4 28672/60000][Iteration 1631][Wall Clock 161.219246784s] Trained 128 records in 0.088747539 seconds. Throughput is 1442.2936 records/second. Loss is 2.1667817. Sequentialb692dd65's hyper parameters: Current learning rate is 3.802281368821293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 28800/60000][Iteration 1632][Wall Clock 161.312579682s] Trained 128 records in 0.093332898 seconds. Throughput is 1371.4349 records/second. Loss is 2.1563082. Sequentialb692dd65's hyper parameters: Current learning rate is 3.800836183960471E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 28928/60000][Iteration 1633][Wall Clock 161.40231443s] Trained 128 records in 0.089734748 seconds. Throughput is 1426.4263 records/second. Loss is 2.160068. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7993920972644377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29056/60000][Iteration 1634][Wall Clock 161.491640249s] Trained 128 records in 0.089325819 seconds. Throughput is 1432.9564 records/second. Loss is 2.1319041. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7979491074819596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29184/60000][Iteration 1635][Wall Clock 161.581441439s] Trained 128 records in 0.08980119 seconds. Throughput is 1425.3708 records/second. Loss is 2.158148. Sequentialb692dd65's hyper parameters: Current learning rate is 3.796507213363705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29312/60000][Iteration 1636][Wall Clock 161.672366543s] Trained 128 records in 0.090925104 seconds. Throughput is 1407.7521 records/second. Loss is 2.1643085. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7950664136622396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29440/60000][Iteration 1637][Wall Clock 161.759357704s] Trained 128 records in 0.086991161 seconds. Throughput is 1471.4138 records/second. Loss is 2.1646817. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7936267071320183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29568/60000][Iteration 1638][Wall Clock 161.845933654s] Trained 128 records in 0.08657595 seconds. Throughput is 1478.4707 records/second. Loss is 2.1617527. Sequentialb692dd65's hyper parameters: Current learning rate is 3.792188092529389E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29696/60000][Iteration 1639][Wall Clock 161.938189131s] Trained 128 records in 0.092255477 seconds. Throughput is 1387.4514 records/second. Loss is 2.1537273. Sequentialb692dd65's hyper parameters: Current learning rate is 3.790750568612585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29824/60000][Iteration 1640][Wall Clock 162.025342525s] Trained 128 records in 0.087153394 seconds. Throughput is 1468.6748 records/second. Loss is 2.1505287. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7893141341417203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 29952/60000][Iteration 1641][Wall Clock 162.11620229s] Trained 128 records in 0.090859765 seconds. Throughput is 1408.7644 records/second. Loss is 2.1682255. Sequentialb692dd65's hyper parameters: Current learning rate is 3.787878787878788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:05 INFO  DistriOptimizer$:408 - [Epoch 4 30080/60000][Iteration 1642][Wall Clock 162.204449185s] Trained 128 records in 0.088246895 seconds. Throughput is 1450.476 records/second. Loss is 2.1460645. Sequentialb692dd65's hyper parameters: Current learning rate is 3.786444528587656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30208/60000][Iteration 1643][Wall Clock 162.299590758s] Trained 128 records in 0.095141573 seconds. Throughput is 1345.3635 records/second. Loss is 2.1627889. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7850113550340646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30336/60000][Iteration 1644][Wall Clock 162.392756832s] Trained 128 records in 0.093166074 seconds. Throughput is 1373.8906 records/second. Loss is 2.1750243. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7835792659856227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30464/60000][Iteration 1645][Wall Clock 162.478578032s] Trained 128 records in 0.0858212 seconds. Throughput is 1491.473 records/second. Loss is 2.1564856. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7821482602118004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30592/60000][Iteration 1646][Wall Clock 162.561184629s] Trained 128 records in 0.082606597 seconds. Throughput is 1549.5131 records/second. Loss is 2.140529. Sequentialb692dd65's hyper parameters: Current learning rate is 3.780718336483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30720/60000][Iteration 1647][Wall Clock 162.647029345s] Trained 128 records in 0.085844716 seconds. Throughput is 1491.0643 records/second. Loss is 2.1634398. Sequentialb692dd65's hyper parameters: Current learning rate is 3.779289493575208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30848/60000][Iteration 1648][Wall Clock 162.761778552s] Trained 128 records in 0.114749207 seconds. Throughput is 1115.4761 records/second. Loss is 2.1597264. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7778617302606723E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 30976/60000][Iteration 1649][Wall Clock 162.846888817s] Trained 128 records in 0.085110265 seconds. Throughput is 1503.9314 records/second. Loss is 2.1430664. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7764350453172205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 31104/60000][Iteration 1650][Wall Clock 162.932688174s] Trained 128 records in 0.085799357 seconds. Throughput is 1491.8527 records/second. Loss is 2.1724458. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7750094375235937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 31232/60000][Iteration 1651][Wall Clock 163.02614608s] Trained 128 records in 0.093457906 seconds. Throughput is 1369.6006 records/second. Loss is 2.176533. Sequentialb692dd65's hyper parameters: Current learning rate is 3.773584905660377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 31360/60000][Iteration 1652][Wall Clock 163.112069219s] Trained 128 records in 0.085923139 seconds. Throughput is 1489.7036 records/second. Loss is 2.1630576. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7721614485099967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:06 INFO  DistriOptimizer$:408 - [Epoch 4 31488/60000][Iteration 1653][Wall Clock 163.197553615s] Trained 128 records in 0.085484396 seconds. Throughput is 1497.3494 records/second. Loss is 2.149855. Sequentialb692dd65's hyper parameters: Current learning rate is 3.770739064856712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 31616/60000][Iteration 1654][Wall Clock 163.289662239s] Trained 128 records in 0.092108624 seconds. Throughput is 1389.6636 records/second. Loss is 2.1503317. Sequentialb692dd65's hyper parameters: Current learning rate is 3.769317753486619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 31744/60000][Iteration 1655][Wall Clock 163.376392551s] Trained 128 records in 0.086730312 seconds. Throughput is 1475.8394 records/second. Loss is 2.1478233. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7678975131876413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 31872/60000][Iteration 1656][Wall Clock 163.467435125s] Trained 128 records in 0.091042574 seconds. Throughput is 1405.9357 records/second. Loss is 2.1427789. Sequentialb692dd65's hyper parameters: Current learning rate is 3.766478342749529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32000/60000][Iteration 1657][Wall Clock 163.554512351s] Trained 128 records in 0.087077226 seconds. Throughput is 1469.9596 records/second. Loss is 2.1636922. Sequentialb692dd65's hyper parameters: Current learning rate is 3.765060240963855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32128/60000][Iteration 1658][Wall Clock 163.641662025s] Trained 128 records in 0.087149674 seconds. Throughput is 1468.7375 records/second. Loss is 2.1591406. Sequentialb692dd65's hyper parameters: Current learning rate is 3.763643206624012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32256/60000][Iteration 1659][Wall Clock 163.732746059s] Trained 128 records in 0.091084034 seconds. Throughput is 1405.2957 records/second. Loss is 2.1777449. Sequentialb692dd65's hyper parameters: Current learning rate is 3.762227238525206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32384/60000][Iteration 1660][Wall Clock 163.819771976s] Trained 128 records in 0.087025917 seconds. Throughput is 1470.8262 records/second. Loss is 2.1588924. Sequentialb692dd65's hyper parameters: Current learning rate is 3.760812335464461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32512/60000][Iteration 1661][Wall Clock 163.908981327s] Trained 128 records in 0.089209351 seconds. Throughput is 1434.8273 records/second. Loss is 2.1416562. Sequentialb692dd65's hyper parameters: Current learning rate is 3.759398496240601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32640/60000][Iteration 1662][Wall Clock 163.996513179s] Trained 128 records in 0.087531852 seconds. Throughput is 1462.3248 records/second. Loss is 2.1409526. Sequentialb692dd65's hyper parameters: Current learning rate is 3.757985719654265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32768/60000][Iteration 1663][Wall Clock 164.087195863s] Trained 128 records in 0.090682684 seconds. Throughput is 1411.5154 records/second. Loss is 2.1541076. Sequentialb692dd65's hyper parameters: Current learning rate is 3.756574004507889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:07 INFO  DistriOptimizer$:408 - [Epoch 4 32896/60000][Iteration 1664][Wall Clock 164.174787942s] Trained 128 records in 0.087592079 seconds. Throughput is 1461.3193 records/second. Loss is 2.1665196. Sequentialb692dd65's hyper parameters: Current learning rate is 3.755163349605708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33024/60000][Iteration 1665][Wall Clock 164.261898312s] Trained 128 records in 0.08711037 seconds. Throughput is 1469.4003 records/second. Loss is 2.1467547. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7537537537537537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33152/60000][Iteration 1666][Wall Clock 164.350550419s] Trained 128 records in 0.088652107 seconds. Throughput is 1443.8462 records/second. Loss is 2.1352823. Sequentialb692dd65's hyper parameters: Current learning rate is 3.75234521575985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33280/60000][Iteration 1667][Wall Clock 164.439464454s] Trained 128 records in 0.088914035 seconds. Throughput is 1439.5928 records/second. Loss is 2.1424592. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7509377344336085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33408/60000][Iteration 1668][Wall Clock 164.534209569s] Trained 128 records in 0.094745115 seconds. Throughput is 1350.9932 records/second. Loss is 2.1496363. Sequentialb692dd65's hyper parameters: Current learning rate is 3.749531308586427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33536/60000][Iteration 1669][Wall Clock 164.623667424s] Trained 128 records in 0.089457855 seconds. Throughput is 1430.8414 records/second. Loss is 2.1440814. Sequentialb692dd65's hyper parameters: Current learning rate is 3.748125937031484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33664/60000][Iteration 1670][Wall Clock 164.705348059s] Trained 128 records in 0.081680635 seconds. Throughput is 1567.079 records/second. Loss is 2.1337006. Sequentialb692dd65's hyper parameters: Current learning rate is 3.746721618583739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33792/60000][Iteration 1671][Wall Clock 164.790403163s] Trained 128 records in 0.085055104 seconds. Throughput is 1504.9067 records/second. Loss is 2.1680956. Sequentialb692dd65's hyper parameters: Current learning rate is 3.745318352059925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 33920/60000][Iteration 1672][Wall Clock 164.878693259s] Trained 128 records in 0.088290096 seconds. Throughput is 1449.7662 records/second. Loss is 2.172838. Sequentialb692dd65's hyper parameters: Current learning rate is 3.743916136278547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 34048/60000][Iteration 1673][Wall Clock 164.966208095s] Trained 128 records in 0.087514836 seconds. Throughput is 1462.6093 records/second. Loss is 2.1667933. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7425149700598805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 34176/60000][Iteration 1674][Wall Clock 165.056543672s] Trained 128 records in 0.090335577 seconds. Throughput is 1416.939 records/second. Loss is 2.1662366. Sequentialb692dd65's hyper parameters: Current learning rate is 3.741114852225963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:08 INFO  DistriOptimizer$:408 - [Epoch 4 34304/60000][Iteration 1675][Wall Clock 165.142522244s] Trained 128 records in 0.085978572 seconds. Throughput is 1488.7429 records/second. Loss is 2.138433. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7397157816005983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 34432/60000][Iteration 1676][Wall Clock 165.254444557s] Trained 128 records in 0.111922313 seconds. Throughput is 1143.6504 records/second. Loss is 2.132738. Sequentialb692dd65's hyper parameters: Current learning rate is 3.738317757009346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 34560/60000][Iteration 1677][Wall Clock 165.334727699s] Trained 128 records in 0.080283142 seconds. Throughput is 1594.3572 records/second. Loss is 2.1447163. Sequentialb692dd65's hyper parameters: Current learning rate is 3.736920777279522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 34688/60000][Iteration 1678][Wall Clock 165.421308987s] Trained 128 records in 0.086581288 seconds. Throughput is 1478.3794 records/second. Loss is 2.1562698. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7355248412401944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 34816/60000][Iteration 1679][Wall Clock 165.51071256s] Trained 128 records in 0.089403573 seconds. Throughput is 1431.7102 records/second. Loss is 2.1443694. Sequentialb692dd65's hyper parameters: Current learning rate is 3.734129947722181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 34944/60000][Iteration 1680][Wall Clock 165.598868535s] Trained 128 records in 0.088155975 seconds. Throughput is 1451.9719 records/second. Loss is 2.1563606. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7327360955580435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35072/60000][Iteration 1681][Wall Clock 165.684829657s] Trained 128 records in 0.085961122 seconds. Throughput is 1489.0453 records/second. Loss is 2.1548607. Sequentialb692dd65's hyper parameters: Current learning rate is 3.73134328358209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35200/60000][Iteration 1682][Wall Clock 165.774965555s] Trained 128 records in 0.090135898 seconds. Throughput is 1420.078 records/second. Loss is 2.1442308. Sequentialb692dd65's hyper parameters: Current learning rate is 3.729951510630362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35328/60000][Iteration 1683][Wall Clock 165.861723837s] Trained 128 records in 0.086758282 seconds. Throughput is 1475.3635 records/second. Loss is 2.147498. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7285607755406416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35456/60000][Iteration 1684][Wall Clock 165.950434265s] Trained 128 records in 0.088710428 seconds. Throughput is 1442.8969 records/second. Loss is 2.1589212. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7271710771524417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35584/60000][Iteration 1685][Wall Clock 166.039256757s] Trained 128 records in 0.088822492 seconds. Throughput is 1441.0764 records/second. Loss is 2.1392937. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7257824143070045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:09 INFO  DistriOptimizer$:408 - [Epoch 4 35712/60000][Iteration 1686][Wall Clock 166.128214365s] Trained 128 records in 0.088957608 seconds. Throughput is 1438.8876 records/second. Loss is 2.135767. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7243947858472997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 35840/60000][Iteration 1687][Wall Clock 166.21448616s] Trained 128 records in 0.086271795 seconds. Throughput is 1483.6831 records/second. Loss is 2.1605358. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7230081906180194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 35968/60000][Iteration 1688][Wall Clock 166.302012237s] Trained 128 records in 0.087526077 seconds. Throughput is 1462.4214 records/second. Loss is 2.1555934. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7216226274655747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36096/60000][Iteration 1689][Wall Clock 166.392585817s] Trained 128 records in 0.09057358 seconds. Throughput is 1413.2157 records/second. Loss is 2.1301782. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7202380952380956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36224/60000][Iteration 1690][Wall Clock 166.480533522s] Trained 128 records in 0.087947705 seconds. Throughput is 1455.4104 records/second. Loss is 2.1378753. Sequentialb692dd65's hyper parameters: Current learning rate is 3.718854592785422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36352/60000][Iteration 1691][Wall Clock 166.572109671s] Trained 128 records in 0.091576149 seconds. Throughput is 1397.7438 records/second. Loss is 2.1471918. Sequentialb692dd65's hyper parameters: Current learning rate is 3.717472118959108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36480/60000][Iteration 1692][Wall Clock 166.660481718s] Trained 128 records in 0.088372047 seconds. Throughput is 1448.4219 records/second. Loss is 2.166433. Sequentialb692dd65's hyper parameters: Current learning rate is 3.716090672612412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36608/60000][Iteration 1693][Wall Clock 166.758841924s] Trained 128 records in 0.098360206 seconds. Throughput is 1301.3394 records/second. Loss is 2.1387079. Sequentialb692dd65's hyper parameters: Current learning rate is 3.714710252600297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36736/60000][Iteration 1694][Wall Clock 166.843179399s] Trained 128 records in 0.084337475 seconds. Throughput is 1517.712 records/second. Loss is 2.1535914. Sequentialb692dd65's hyper parameters: Current learning rate is 3.713330857779428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36864/60000][Iteration 1695][Wall Clock 166.928209381s] Trained 128 records in 0.085029982 seconds. Throughput is 1505.3513 records/second. Loss is 2.1441147. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7119524870081667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 36992/60000][Iteration 1696][Wall Clock 167.01768978s] Trained 128 records in 0.089480399 seconds. Throughput is 1430.4808 records/second. Loss is 2.1469996. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7105751391465676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 37120/60000][Iteration 1697][Wall Clock 167.10663134s] Trained 128 records in 0.08894156 seconds. Throughput is 1439.1472 records/second. Loss is 2.1715863. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7091988130563805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:10 INFO  DistriOptimizer$:408 - [Epoch 4 37248/60000][Iteration 1698][Wall Clock 167.194207009s] Trained 128 records in 0.087575669 seconds. Throughput is 1461.5933 records/second. Loss is 2.157116. Sequentialb692dd65's hyper parameters: Current learning rate is 3.707823507601038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 37376/60000][Iteration 1699][Wall Clock 167.28197721s] Trained 128 records in 0.087770201 seconds. Throughput is 1458.3538 records/second. Loss is 2.1721334. Sequentialb692dd65's hyper parameters: Current learning rate is 3.706449221645664E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 37504/60000][Iteration 1700][Wall Clock 167.368809226s] Trained 128 records in 0.086832016 seconds. Throughput is 1474.1106 records/second. Loss is 2.1526978. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7050759540570587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 37632/60000][Iteration 1701][Wall Clock 167.457057054s] Trained 128 records in 0.088247828 seconds. Throughput is 1450.4606 records/second. Loss is 2.136683. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7037037037037035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 37760/60000][Iteration 1702][Wall Clock 167.552457498s] Trained 128 records in 0.095400444 seconds. Throughput is 1341.7128 records/second. Loss is 2.1531549. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7023324694557573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 37888/60000][Iteration 1703][Wall Clock 167.636616475s] Trained 128 records in 0.084158977 seconds. Throughput is 1520.931 records/second. Loss is 2.163372. Sequentialb692dd65's hyper parameters: Current learning rate is 3.7009622501850485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38016/60000][Iteration 1704][Wall Clock 167.719381069s] Trained 128 records in 0.082764594 seconds. Throughput is 1546.555 records/second. Loss is 2.1585166. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6995930447650754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38144/60000][Iteration 1705][Wall Clock 167.808857426s] Trained 128 records in 0.089476357 seconds. Throughput is 1430.5455 records/second. Loss is 2.1410735. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6982248520710064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38272/60000][Iteration 1706][Wall Clock 167.899358936s] Trained 128 records in 0.09050151 seconds. Throughput is 1414.3411 records/second. Loss is 2.1514428. Sequentialb692dd65's hyper parameters: Current learning rate is 3.696857670979667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38400/60000][Iteration 1707][Wall Clock 167.984735041s] Trained 128 records in 0.085376105 seconds. Throughput is 1499.2485 records/second. Loss is 2.151814. Sequentialb692dd65's hyper parameters: Current learning rate is 3.695491500369549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38528/60000][Iteration 1708][Wall Clock 168.072220885s] Trained 128 records in 0.087485844 seconds. Throughput is 1463.0939 records/second. Loss is 2.1470704. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6941263391207984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:11 INFO  DistriOptimizer$:408 - [Epoch 4 38656/60000][Iteration 1709][Wall Clock 168.158449724s] Trained 128 records in 0.086228839 seconds. Throughput is 1484.4221 records/second. Loss is 2.1660774. Sequentialb692dd65's hyper parameters: Current learning rate is 3.692762186115214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 38784/60000][Iteration 1710][Wall Clock 168.245511086s] Trained 128 records in 0.087061362 seconds. Throughput is 1470.2274 records/second. Loss is 2.1355336. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6913990402362494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 38912/60000][Iteration 1711][Wall Clock 168.332043958s] Trained 128 records in 0.086532872 seconds. Throughput is 1479.2067 records/second. Loss is 2.1364486. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6900369003690036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39040/60000][Iteration 1712][Wall Clock 168.420014497s] Trained 128 records in 0.087970539 seconds. Throughput is 1455.0326 records/second. Loss is 2.1394718. Sequentialb692dd65's hyper parameters: Current learning rate is 3.688675765400221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39168/60000][Iteration 1713][Wall Clock 168.506600822s] Trained 128 records in 0.086586325 seconds. Throughput is 1478.2935 records/second. Loss is 2.1453125. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6873156342182896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39296/60000][Iteration 1714][Wall Clock 168.595352293s] Trained 128 records in 0.088751471 seconds. Throughput is 1442.2296 records/second. Loss is 2.1419227. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6859565057132326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39424/60000][Iteration 1715][Wall Clock 168.677652697s] Trained 128 records in 0.082300404 seconds. Throughput is 1555.278 records/second. Loss is 2.1352732. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6845983787767134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39552/60000][Iteration 1716][Wall Clock 168.765777029s] Trained 128 records in 0.088124332 seconds. Throughput is 1452.4933 records/second. Loss is 2.1499486. Sequentialb692dd65's hyper parameters: Current learning rate is 3.683241252302026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39680/60000][Iteration 1717][Wall Clock 168.850708555s] Trained 128 records in 0.084931526 seconds. Throughput is 1507.0964 records/second. Loss is 2.1562543. Sequentialb692dd65's hyper parameters: Current learning rate is 3.681885125184094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39808/60000][Iteration 1718][Wall Clock 168.940430349s] Trained 128 records in 0.089721794 seconds. Throughput is 1426.6322 records/second. Loss is 2.145274. Sequentialb692dd65's hyper parameters: Current learning rate is 3.68052999631947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 39936/60000][Iteration 1719][Wall Clock 169.030107046s] Trained 128 records in 0.089676697 seconds. Throughput is 1427.3496 records/second. Loss is 2.1481464. Sequentialb692dd65's hyper parameters: Current learning rate is 3.679175864606328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:12 INFO  DistriOptimizer$:408 - [Epoch 4 40064/60000][Iteration 1720][Wall Clock 169.117892581s] Trained 128 records in 0.087785535 seconds. Throughput is 1458.099 records/second. Loss is 2.1616712. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6778227289444644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40192/60000][Iteration 1721][Wall Clock 169.203930318s] Trained 128 records in 0.086037737 seconds. Throughput is 1487.7192 records/second. Loss is 2.1100664. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6764705882352946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40320/60000][Iteration 1722][Wall Clock 169.289917209s] Trained 128 records in 0.085986891 seconds. Throughput is 1488.599 records/second. Loss is 2.1389425. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6751194413818446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40448/60000][Iteration 1723][Wall Clock 169.376470627s] Trained 128 records in 0.086553418 seconds. Throughput is 1478.8556 records/second. Loss is 2.1297972. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6737692872887586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40576/60000][Iteration 1724][Wall Clock 169.462547574s] Trained 128 records in 0.086076947 seconds. Throughput is 1487.0416 records/second. Loss is 2.1470728. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6724201248622846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40704/60000][Iteration 1725][Wall Clock 169.547464093s] Trained 128 records in 0.084916519 seconds. Throughput is 1507.3628 records/second. Loss is 2.1451654. Sequentialb692dd65's hyper parameters: Current learning rate is 3.671071953010279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40832/60000][Iteration 1726][Wall Clock 169.633834697s] Trained 128 records in 0.086370604 seconds. Throughput is 1481.9857 records/second. Loss is 2.1556723. Sequentialb692dd65's hyper parameters: Current learning rate is 3.669724770642202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 40960/60000][Iteration 1727][Wall Clock 169.719016393s] Trained 128 records in 0.085181696 seconds. Throughput is 1502.6702 records/second. Loss is 2.1502452. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6683785766691124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 41088/60000][Iteration 1728][Wall Clock 169.807304188s] Trained 128 records in 0.088287795 seconds. Throughput is 1449.8041 records/second. Loss is 2.1585944. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6670333700036665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 41216/60000][Iteration 1729][Wall Clock 169.891197418s] Trained 128 records in 0.08389323 seconds. Throughput is 1525.7488 records/second. Loss is 2.1658623. Sequentialb692dd65's hyper parameters: Current learning rate is 3.665689149560118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 41344/60000][Iteration 1730][Wall Clock 169.980550422s] Trained 128 records in 0.089353004 seconds. Throughput is 1432.5204 records/second. Loss is 2.1371605. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6643459142543056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 41472/60000][Iteration 1731][Wall Clock 170.069488142s] Trained 128 records in 0.08893772 seconds. Throughput is 1439.2094 records/second. Loss is 2.146253. Sequentialb692dd65's hyper parameters: Current learning rate is 3.663003663003663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:13 INFO  DistriOptimizer$:408 - [Epoch 4 41600/60000][Iteration 1732][Wall Clock 170.156473117s] Trained 128 records in 0.086984975 seconds. Throughput is 1471.5184 records/second. Loss is 2.1399581. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6616623947272064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 41728/60000][Iteration 1733][Wall Clock 170.243203932s] Trained 128 records in 0.086730815 seconds. Throughput is 1475.8307 records/second. Loss is 2.1279306. Sequentialb692dd65's hyper parameters: Current learning rate is 3.660322108345534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 41856/60000][Iteration 1734][Wall Clock 170.332613668s] Trained 128 records in 0.089409736 seconds. Throughput is 1431.6113 records/second. Loss is 2.1531928. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6589828027808267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 41984/60000][Iteration 1735][Wall Clock 170.420110349s] Trained 128 records in 0.087496681 seconds. Throughput is 1462.9126 records/second. Loss is 2.135123. Sequentialb692dd65's hyper parameters: Current learning rate is 3.65764447695684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42112/60000][Iteration 1736][Wall Clock 170.509850752s] Trained 128 records in 0.089740403 seconds. Throughput is 1426.3363 records/second. Loss is 2.131856. Sequentialb692dd65's hyper parameters: Current learning rate is 3.656307129798903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42240/60000][Iteration 1737][Wall Clock 170.600357554s] Trained 128 records in 0.090506802 seconds. Throughput is 1414.2584 records/second. Loss is 2.1568694. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6549707602339185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42368/60000][Iteration 1738][Wall Clock 170.688726118s] Trained 128 records in 0.088368564 seconds. Throughput is 1448.4789 records/second. Loss is 2.153872. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6536353671903543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42496/60000][Iteration 1739][Wall Clock 170.773034395s] Trained 128 records in 0.084308277 seconds. Throughput is 1518.2377 records/second. Loss is 2.1673572. Sequentialb692dd65's hyper parameters: Current learning rate is 3.652300949598247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42624/60000][Iteration 1740][Wall Clock 170.861173168s] Trained 128 records in 0.088138773 seconds. Throughput is 1452.2552 records/second. Loss is 2.1398482. Sequentialb692dd65's hyper parameters: Current learning rate is 3.650967506389193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42752/60000][Iteration 1741][Wall Clock 170.94820209s] Trained 128 records in 0.087028922 seconds. Throughput is 1470.7754 records/second. Loss is 2.108944. Sequentialb692dd65's hyper parameters: Current learning rate is 3.64963503649635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 42880/60000][Iteration 1742][Wall Clock 171.035733792s] Trained 128 records in 0.087531702 seconds. Throughput is 1462.3274 records/second. Loss is 2.1290953. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6483035388544326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:14 INFO  DistriOptimizer$:408 - [Epoch 4 43008/60000][Iteration 1743][Wall Clock 171.125253191s] Trained 128 records in 0.089519399 seconds. Throughput is 1429.8577 records/second. Loss is 2.1381612. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6469730123997083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43136/60000][Iteration 1744][Wall Clock 171.212294106s] Trained 128 records in 0.087040915 seconds. Throughput is 1470.5728 records/second. Loss is 2.1690857. Sequentialb692dd65's hyper parameters: Current learning rate is 3.645643456069996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43264/60000][Iteration 1745][Wall Clock 171.297743969s] Trained 128 records in 0.085449863 seconds. Throughput is 1497.9545 records/second. Loss is 2.1407306. Sequentialb692dd65's hyper parameters: Current learning rate is 3.644314868804665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43392/60000][Iteration 1746][Wall Clock 171.386252178s] Trained 128 records in 0.088508209 seconds. Throughput is 1446.1935 records/second. Loss is 2.1391203. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6429872495446266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43520/60000][Iteration 1747][Wall Clock 171.47480999s] Trained 128 records in 0.088557812 seconds. Throughput is 1445.3835 records/second. Loss is 2.1390765. Sequentialb692dd65's hyper parameters: Current learning rate is 3.641660597232338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43648/60000][Iteration 1748][Wall Clock 171.563042939s] Trained 128 records in 0.088232949 seconds. Throughput is 1450.7052 records/second. Loss is 2.1408002. Sequentialb692dd65's hyper parameters: Current learning rate is 3.640334910811795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43776/60000][Iteration 1749][Wall Clock 171.651243946s] Trained 128 records in 0.088201007 seconds. Throughput is 1451.2306 records/second. Loss is 2.1538455. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6390101892285295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 43904/60000][Iteration 1750][Wall Clock 171.74163749s] Trained 128 records in 0.090393544 seconds. Throughput is 1416.0304 records/second. Loss is 2.1527326. Sequentialb692dd65's hyper parameters: Current learning rate is 3.637686431429611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 44032/60000][Iteration 1751][Wall Clock 171.830815987s] Trained 128 records in 0.089178497 seconds. Throughput is 1435.3236 records/second. Loss is 2.1351032. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6363636363636367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 44160/60000][Iteration 1752][Wall Clock 171.919279341s] Trained 128 records in 0.088463354 seconds. Throughput is 1446.9269 records/second. Loss is 2.1252882. Sequentialb692dd65's hyper parameters: Current learning rate is 3.635041802980734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 44288/60000][Iteration 1753][Wall Clock 172.01397614s] Trained 128 records in 0.094696799 seconds. Throughput is 1351.6825 records/second. Loss is 2.146842. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6337209302325586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:15 INFO  DistriOptimizer$:408 - [Epoch 4 44416/60000][Iteration 1754][Wall Clock 172.098072293s] Trained 128 records in 0.084096153 seconds. Throughput is 1522.0671 records/second. Loss is 2.1404345. Sequentialb692dd65's hyper parameters: Current learning rate is 3.632401017072285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 44544/60000][Iteration 1755][Wall Clock 172.185739409s] Trained 128 records in 0.087667116 seconds. Throughput is 1460.0686 records/second. Loss is 2.1233168. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6310820624546115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 44672/60000][Iteration 1756][Wall Clock 172.272523624s] Trained 128 records in 0.086784215 seconds. Throughput is 1474.9226 records/second. Loss is 2.1610568. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6297640653357535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 44800/60000][Iteration 1757][Wall Clock 172.362309563s] Trained 128 records in 0.089785939 seconds. Throughput is 1425.6129 records/second. Loss is 2.1387029. Sequentialb692dd65's hyper parameters: Current learning rate is 3.62844702467344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 44928/60000][Iteration 1758][Wall Clock 172.449476816s] Trained 128 records in 0.087167253 seconds. Throughput is 1468.4413 records/second. Loss is 2.1435041. Sequentialb692dd65's hyper parameters: Current learning rate is 3.627130939426913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45056/60000][Iteration 1759][Wall Clock 172.539413994s] Trained 128 records in 0.089937178 seconds. Throughput is 1423.2156 records/second. Loss is 2.1267686. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6258158085569254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45184/60000][Iteration 1760][Wall Clock 172.626838885s] Trained 128 records in 0.087424891 seconds. Throughput is 1464.1139 records/second. Loss is 2.1620984. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6245016310257333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45312/60000][Iteration 1761][Wall Clock 172.714289187s] Trained 128 records in 0.087450302 seconds. Throughput is 1463.6885 records/second. Loss is 2.1535208. Sequentialb692dd65's hyper parameters: Current learning rate is 3.623188405797102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45440/60000][Iteration 1762][Wall Clock 172.800440075s] Trained 128 records in 0.086150888 seconds. Throughput is 1485.7654 records/second. Loss is 2.1214468. Sequentialb692dd65's hyper parameters: Current learning rate is 3.621876131836291E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45568/60000][Iteration 1763][Wall Clock 172.887545229s] Trained 128 records in 0.087105154 seconds. Throughput is 1469.4883 records/second. Loss is 2.1558254. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6205648081100655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45696/60000][Iteration 1764][Wall Clock 172.975562187s] Trained 128 records in 0.088016958 seconds. Throughput is 1454.2653 records/second. Loss is 2.155547. Sequentialb692dd65's hyper parameters: Current learning rate is 3.619254433586681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45824/60000][Iteration 1765][Wall Clock 173.061422203s] Trained 128 records in 0.085860016 seconds. Throughput is 1490.7987 records/second. Loss is 2.1405053. Sequentialb692dd65's hyper parameters: Current learning rate is 3.61794500723589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:16 INFO  DistriOptimizer$:408 - [Epoch 4 45952/60000][Iteration 1766][Wall Clock 173.148379759s] Trained 128 records in 0.086957556 seconds. Throughput is 1471.9824 records/second. Loss is 2.1626508. Sequentialb692dd65's hyper parameters: Current learning rate is 3.616636528028933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46080/60000][Iteration 1767][Wall Clock 173.236737937s] Trained 128 records in 0.088358178 seconds. Throughput is 1448.6492 records/second. Loss is 2.146825. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6153289949385393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46208/60000][Iteration 1768][Wall Clock 173.323628105s] Trained 128 records in 0.086890168 seconds. Throughput is 1473.1241 records/second. Loss is 2.1317565. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6140224069389226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46336/60000][Iteration 1769][Wall Clock 173.406710444s] Trained 128 records in 0.083082339 seconds. Throughput is 1540.6403 records/second. Loss is 2.1190615. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6127167630057807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46464/60000][Iteration 1770][Wall Clock 173.49117051s] Trained 128 records in 0.084460066 seconds. Throughput is 1515.5092 records/second. Loss is 2.1373107. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6114120621162876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46592/60000][Iteration 1771][Wall Clock 173.576781547s] Trained 128 records in 0.085611037 seconds. Throughput is 1495.1343 records/second. Loss is 2.1358824. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6101083032490973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46720/60000][Iteration 1772][Wall Clock 173.662926065s] Trained 128 records in 0.086144518 seconds. Throughput is 1485.8752 records/second. Loss is 2.1244369. Sequentialb692dd65's hyper parameters: Current learning rate is 3.608805485384338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46848/60000][Iteration 1773][Wall Clock 173.749867073s] Trained 128 records in 0.086941008 seconds. Throughput is 1472.2626 records/second. Loss is 2.1603773. Sequentialb692dd65's hyper parameters: Current learning rate is 3.6075036075036075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 46976/60000][Iteration 1774][Wall Clock 173.838885573s] Trained 128 records in 0.0890185 seconds. Throughput is 1437.9033 records/second. Loss is 2.1331747. Sequentialb692dd65's hyper parameters: Current learning rate is 3.606202668589975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 47104/60000][Iteration 1775][Wall Clock 173.927454974s] Trained 128 records in 0.088569401 seconds. Throughput is 1445.1943 records/second. Loss is 2.1271892. Sequentialb692dd65's hyper parameters: Current learning rate is 3.604902667627974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 47232/60000][Iteration 1776][Wall Clock 174.014007571s] Trained 128 records in 0.086552597 seconds. Throughput is 1478.8695 records/second. Loss is 2.124486. Sequentialb692dd65's hyper parameters: Current learning rate is 3.603603603603603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:17 INFO  DistriOptimizer$:408 - [Epoch 4 47360/60000][Iteration 1777][Wall Clock 174.098399124s] Trained 128 records in 0.084391553 seconds. Throughput is 1516.7394 records/second. Loss is 2.130995. Sequentialb692dd65's hyper parameters: Current learning rate is 3.602305475504323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 47488/60000][Iteration 1778][Wall Clock 174.18510199s] Trained 128 records in 0.086702866 seconds. Throughput is 1476.3064 records/second. Loss is 2.1261723. Sequentialb692dd65's hyper parameters: Current learning rate is 3.601008282319049E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 47616/60000][Iteration 1779][Wall Clock 174.285667469s] Trained 128 records in 0.100565479 seconds. Throughput is 1272.8026 records/second. Loss is 2.1454508. Sequentialb692dd65's hyper parameters: Current learning rate is 3.599712023038157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 47744/60000][Iteration 1780][Wall Clock 174.367166014s] Trained 128 records in 0.081498545 seconds. Throughput is 1570.5801 records/second. Loss is 2.1487603. Sequentialb692dd65's hyper parameters: Current learning rate is 3.598416696653473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 47872/60000][Iteration 1781][Wall Clock 174.454893047s] Trained 128 records in 0.087727033 seconds. Throughput is 1459.0714 records/second. Loss is 2.1523867. Sequentialb692dd65's hyper parameters: Current learning rate is 3.597122302158273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48000/60000][Iteration 1782][Wall Clock 174.545310802s] Trained 128 records in 0.090417755 seconds. Throughput is 1415.6511 records/second. Loss is 2.1358912. Sequentialb692dd65's hyper parameters: Current learning rate is 3.595828838547285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48128/60000][Iteration 1783][Wall Clock 174.634181203s] Trained 128 records in 0.088870401 seconds. Throughput is 1440.2996 records/second. Loss is 2.1465619. Sequentialb692dd65's hyper parameters: Current learning rate is 3.594536304816679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48256/60000][Iteration 1784][Wall Clock 174.722794913s] Trained 128 records in 0.08861371 seconds. Throughput is 1444.4717 records/second. Loss is 2.1253676. Sequentialb692dd65's hyper parameters: Current learning rate is 3.593244699964067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48384/60000][Iteration 1785][Wall Clock 174.814326022s] Trained 128 records in 0.091531109 seconds. Throughput is 1398.4318 records/second. Loss is 2.1615725. Sequentialb692dd65's hyper parameters: Current learning rate is 3.591954022988506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48512/60000][Iteration 1786][Wall Clock 174.905821212s] Trained 128 records in 0.09149519 seconds. Throughput is 1398.9806 records/second. Loss is 2.1222067. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5906642728904844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48640/60000][Iteration 1787][Wall Clock 175.000755802s] Trained 128 records in 0.09493459 seconds. Throughput is 1348.2968 records/second. Loss is 2.1542633. Sequentialb692dd65's hyper parameters: Current learning rate is 3.589375448671931E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:18 INFO  DistriOptimizer$:408 - [Epoch 4 48768/60000][Iteration 1788][Wall Clock 175.09410271s] Trained 128 records in 0.093346908 seconds. Throughput is 1371.2291 records/second. Loss is 2.1222932. Sequentialb692dd65's hyper parameters: Current learning rate is 3.588087549336204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 48896/60000][Iteration 1789][Wall Clock 175.186643411s] Trained 128 records in 0.092540701 seconds. Throughput is 1383.1752 records/second. Loss is 2.1371748. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5868005738880915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49024/60000][Iteration 1790][Wall Clock 175.274121349s] Trained 128 records in 0.087477938 seconds. Throughput is 1463.2261 records/second. Loss is 2.1734715. Sequentialb692dd65's hyper parameters: Current learning rate is 3.585514521333811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49152/60000][Iteration 1791][Wall Clock 175.3647395s] Trained 128 records in 0.090618151 seconds. Throughput is 1412.5206 records/second. Loss is 2.1396222. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5842293906810036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49280/60000][Iteration 1792][Wall Clock 175.472577849s] Trained 128 records in 0.107838349 seconds. Throughput is 1186.9618 records/second. Loss is 2.1269934. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5829451809387314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49408/60000][Iteration 1793][Wall Clock 175.581167208s] Trained 128 records in 0.108589359 seconds. Throughput is 1178.7527 records/second. Loss is 2.1185906. Sequentialb692dd65's hyper parameters: Current learning rate is 3.581661891117479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49536/60000][Iteration 1794][Wall Clock 175.670044095s] Trained 128 records in 0.088876887 seconds. Throughput is 1440.1945 records/second. Loss is 2.1489027. Sequentialb692dd65's hyper parameters: Current learning rate is 3.580379520229144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49664/60000][Iteration 1795][Wall Clock 175.750489411s] Trained 128 records in 0.080445316 seconds. Throughput is 1591.143 records/second. Loss is 2.1503654. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5790980672870435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49792/60000][Iteration 1796][Wall Clock 175.836119917s] Trained 128 records in 0.085630506 seconds. Throughput is 1494.7944 records/second. Loss is 2.1401596. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5778175313059033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 49920/60000][Iteration 1797][Wall Clock 175.921256167s] Trained 128 records in 0.08513625 seconds. Throughput is 1503.4724 records/second. Loss is 2.1533184. Sequentialb692dd65's hyper parameters: Current learning rate is 3.57653791130186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 50048/60000][Iteration 1798][Wall Clock 176.005274612s] Trained 128 records in 0.084018445 seconds. Throughput is 1523.475 records/second. Loss is 2.1432486. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5752592062924567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:19 INFO  DistriOptimizer$:408 - [Epoch 4 50176/60000][Iteration 1799][Wall Clock 176.089117779s] Trained 128 records in 0.083843167 seconds. Throughput is 1526.6599 records/second. Loss is 2.1591396. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5739814152966406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50304/60000][Iteration 1800][Wall Clock 176.174404198s] Trained 128 records in 0.085286419 seconds. Throughput is 1500.8252 records/second. Loss is 2.1397808. Sequentialb692dd65's hyper parameters: Current learning rate is 3.572704537334763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50432/60000][Iteration 1801][Wall Clock 176.257778845s] Trained 128 records in 0.083374647 seconds. Throughput is 1535.2389 records/second. Loss is 2.1280177. Sequentialb692dd65's hyper parameters: Current learning rate is 3.571428571428572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50560/60000][Iteration 1802][Wall Clock 176.343728239s] Trained 128 records in 0.085949394 seconds. Throughput is 1489.2485 records/second. Loss is 2.132036. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5701535166012135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50688/60000][Iteration 1803][Wall Clock 176.430959783s] Trained 128 records in 0.087231544 seconds. Throughput is 1467.359 records/second. Loss is 2.134145. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5688793718772306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50816/60000][Iteration 1804][Wall Clock 176.517990142s] Trained 128 records in 0.087030359 seconds. Throughput is 1470.7511 records/second. Loss is 2.1472468. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5676061362825543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 50944/60000][Iteration 1805][Wall Clock 176.614663991s] Trained 128 records in 0.096673849 seconds. Throughput is 1324.0396 records/second. Loss is 2.1341066. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5663338088445074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51072/60000][Iteration 1806][Wall Clock 176.69867717s] Trained 128 records in 0.084013179 seconds. Throughput is 1523.5704 records/second. Loss is 2.1238916. Sequentialb692dd65's hyper parameters: Current learning rate is 3.565062388591801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51200/60000][Iteration 1807][Wall Clock 176.781573928s] Trained 128 records in 0.082896758 seconds. Throughput is 1544.0892 records/second. Loss is 2.1306462. Sequentialb692dd65's hyper parameters: Current learning rate is 3.563791874554526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51328/60000][Iteration 1808][Wall Clock 176.869542453s] Trained 128 records in 0.087968525 seconds. Throughput is 1455.0658 records/second. Loss is 2.130046. Sequentialb692dd65's hyper parameters: Current learning rate is 3.562522265764161E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51456/60000][Iteration 1809][Wall Clock 176.955931617s] Trained 128 records in 0.086389164 seconds. Throughput is 1481.6674 records/second. Loss is 2.1558578. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5612535612535614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51584/60000][Iteration 1810][Wall Clock 177.041057159s] Trained 128 records in 0.085125542 seconds. Throughput is 1503.6615 records/second. Loss is 2.1377785. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5599857600569594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:20 INFO  DistriOptimizer$:408 - [Epoch 4 51712/60000][Iteration 1811][Wall Clock 177.12851092s] Trained 128 records in 0.087453761 seconds. Throughput is 1463.6306 records/second. Loss is 2.117227. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5587188612099647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 51840/60000][Iteration 1812][Wall Clock 177.215743642s] Trained 128 records in 0.087232722 seconds. Throughput is 1467.3392 records/second. Loss is 2.1397314. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5574528637495557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 51968/60000][Iteration 1813][Wall Clock 177.302573964s] Trained 128 records in 0.086830322 seconds. Throughput is 1474.1394 records/second. Loss is 2.1562233. Sequentialb692dd65's hyper parameters: Current learning rate is 3.556187766714082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52096/60000][Iteration 1814][Wall Clock 177.389147062s] Trained 128 records in 0.086573098 seconds. Throughput is 1478.5193 records/second. Loss is 2.1256905. Sequentialb692dd65's hyper parameters: Current learning rate is 3.554923569143264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52224/60000][Iteration 1815][Wall Clock 177.474626767s] Trained 128 records in 0.085479705 seconds. Throughput is 1497.4314 records/second. Loss is 2.1486752. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5536602700781805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52352/60000][Iteration 1816][Wall Clock 177.558435978s] Trained 128 records in 0.083809211 seconds. Throughput is 1527.2784 records/second. Loss is 2.148867. Sequentialb692dd65's hyper parameters: Current learning rate is 3.552397868561279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52480/60000][Iteration 1817][Wall Clock 177.644989214s] Trained 128 records in 0.086553236 seconds. Throughput is 1478.8586 records/second. Loss is 2.1222677. Sequentialb692dd65's hyper parameters: Current learning rate is 3.551136363636364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52608/60000][Iteration 1818][Wall Clock 177.735421046s] Trained 128 records in 0.090431832 seconds. Throughput is 1415.4308 records/second. Loss is 2.1125011. Sequentialb692dd65's hyper parameters: Current learning rate is 3.549875754348598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52736/60000][Iteration 1819][Wall Clock 177.815946442s] Trained 128 records in 0.080525396 seconds. Throughput is 1589.5605 records/second. Loss is 2.1323645. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5486160397445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52864/60000][Iteration 1820][Wall Clock 177.903921363s] Trained 128 records in 0.087974921 seconds. Throughput is 1454.9601 records/second. Loss is 2.133941. Sequentialb692dd65's hyper parameters: Current learning rate is 3.547357218871941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 52992/60000][Iteration 1821][Wall Clock 177.990641419s] Trained 128 records in 0.086720056 seconds. Throughput is 1476.0138 records/second. Loss is 2.1301825. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5460992907801415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:21 INFO  DistriOptimizer$:408 - [Epoch 4 53120/60000][Iteration 1822][Wall Clock 178.078340971s] Trained 128 records in 0.087699552 seconds. Throughput is 1459.5284 records/second. Loss is 2.156836. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5448422545196744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53248/60000][Iteration 1823][Wall Clock 178.163669261s] Trained 128 records in 0.08532829 seconds. Throughput is 1500.0887 records/second. Loss is 2.15342. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5435861091424523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53376/60000][Iteration 1824][Wall Clock 178.250011909s] Trained 128 records in 0.086342648 seconds. Throughput is 1482.4656 records/second. Loss is 2.129503. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5423308537017357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53504/60000][Iteration 1825][Wall Clock 178.335710966s] Trained 128 records in 0.085699057 seconds. Throughput is 1493.5986 records/second. Loss is 2.1429656. Sequentialb692dd65's hyper parameters: Current learning rate is 3.541076487252125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53632/60000][Iteration 1826][Wall Clock 178.42418002s] Trained 128 records in 0.088469054 seconds. Throughput is 1446.8336 records/second. Loss is 2.150155. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5398230088495576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53760/60000][Iteration 1827][Wall Clock 178.511016468s] Trained 128 records in 0.086836448 seconds. Throughput is 1474.0354 records/second. Loss is 2.1452312. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5385704175513094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 53888/60000][Iteration 1828][Wall Clock 178.60024273s] Trained 128 records in 0.089226262 seconds. Throughput is 1434.5553 records/second. Loss is 2.1212652. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5373187124159886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 54016/60000][Iteration 1829][Wall Clock 178.685779977s] Trained 128 records in 0.085537247 seconds. Throughput is 1496.4241 records/second. Loss is 2.136698. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5360678925035356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 54144/60000][Iteration 1830][Wall Clock 178.774275014s] Trained 128 records in 0.088495037 seconds. Throughput is 1446.4088 records/second. Loss is 2.1174517. Sequentialb692dd65's hyper parameters: Current learning rate is 3.534817956875221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 54272/60000][Iteration 1831][Wall Clock 178.872382891s] Trained 128 records in 0.098107877 seconds. Throughput is 1304.6863 records/second. Loss is 2.1406806. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5335689045936394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 54400/60000][Iteration 1832][Wall Clock 178.961486098s] Trained 128 records in 0.089103207 seconds. Throughput is 1436.5364 records/second. Loss is 2.1409695. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5323207347227127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:22 INFO  DistriOptimizer$:408 - [Epoch 4 54528/60000][Iteration 1833][Wall Clock 179.052481357s] Trained 128 records in 0.090995259 seconds. Throughput is 1406.6666 records/second. Loss is 2.1444585. Sequentialb692dd65's hyper parameters: Current learning rate is 3.531073446327684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 54656/60000][Iteration 1834][Wall Clock 179.138200151s] Trained 128 records in 0.085718794 seconds. Throughput is 1493.2548 records/second. Loss is 2.1387415. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5298270384751147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 54784/60000][Iteration 1835][Wall Clock 179.22368319s] Trained 128 records in 0.085483039 seconds. Throughput is 1497.373 records/second. Loss is 2.1454947. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5285815102328866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 54912/60000][Iteration 1836][Wall Clock 179.314091384s] Trained 128 records in 0.090408194 seconds. Throughput is 1415.8009 records/second. Loss is 2.1331468. Sequentialb692dd65's hyper parameters: Current learning rate is 3.527336860670194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55040/60000][Iteration 1837][Wall Clock 179.398906816s] Trained 128 records in 0.084815432 seconds. Throughput is 1509.1593 records/second. Loss is 2.1266024. Sequentialb692dd65's hyper parameters: Current learning rate is 3.526093088857546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55168/60000][Iteration 1838][Wall Clock 179.486562714s] Trained 128 records in 0.087655898 seconds. Throughput is 1460.2555 records/second. Loss is 2.1228693. Sequentialb692dd65's hyper parameters: Current learning rate is 3.524850193866761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55296/60000][Iteration 1839][Wall Clock 179.571813502s] Trained 128 records in 0.085250788 seconds. Throughput is 1501.4524 records/second. Loss is 2.1227922. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5236081747709656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55424/60000][Iteration 1840][Wall Clock 179.658134641s] Trained 128 records in 0.086321139 seconds. Throughput is 1482.835 records/second. Loss is 2.1508355. Sequentialb692dd65's hyper parameters: Current learning rate is 3.522367030644593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55552/60000][Iteration 1841][Wall Clock 179.744957955s] Trained 128 records in 0.086823314 seconds. Throughput is 1474.2584 records/second. Loss is 2.1596158. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5211267605633805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55680/60000][Iteration 1842][Wall Clock 179.830806711s] Trained 128 records in 0.085848756 seconds. Throughput is 1490.9943 records/second. Loss is 2.1266844. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5198873636043646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55808/60000][Iteration 1843][Wall Clock 179.92722592s] Trained 128 records in 0.096419209 seconds. Throughput is 1327.5364 records/second. Loss is 2.125639. Sequentialb692dd65's hyper parameters: Current learning rate is 3.518648838845883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 55936/60000][Iteration 1844][Wall Clock 180.016193979s] Trained 128 records in 0.088968059 seconds. Throughput is 1438.7185 records/second. Loss is 2.1289265. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5174111853675694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:23 INFO  DistriOptimizer$:408 - [Epoch 4 56064/60000][Iteration 1845][Wall Clock 180.10105521s] Trained 128 records in 0.084861231 seconds. Throughput is 1508.3448 records/second. Loss is 2.1410992. Sequentialb692dd65's hyper parameters: Current learning rate is 3.516174402250351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56192/60000][Iteration 1846][Wall Clock 180.186893774s] Trained 128 records in 0.085838564 seconds. Throughput is 1491.1713 records/second. Loss is 2.1526659. Sequentialb692dd65's hyper parameters: Current learning rate is 3.51493848857645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56320/60000][Iteration 1847][Wall Clock 180.278096101s] Trained 128 records in 0.091202327 seconds. Throughput is 1403.473 records/second. Loss is 2.151703. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5137034434293746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56448/60000][Iteration 1848][Wall Clock 180.363366216s] Trained 128 records in 0.085270115 seconds. Throughput is 1501.112 records/second. Loss is 2.1475544. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5124692658939234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56576/60000][Iteration 1849][Wall Clock 180.451412269s] Trained 128 records in 0.088046053 seconds. Throughput is 1453.7847 records/second. Loss is 2.1563303. Sequentialb692dd65's hyper parameters: Current learning rate is 3.51123595505618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56704/60000][Iteration 1850][Wall Clock 180.539758471s] Trained 128 records in 0.088346202 seconds. Throughput is 1448.8455 records/second. Loss is 2.118284. Sequentialb692dd65's hyper parameters: Current learning rate is 3.51000351000351E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56832/60000][Iteration 1851][Wall Clock 180.627407512s] Trained 128 records in 0.087649041 seconds. Throughput is 1460.3696 records/second. Loss is 2.1609867. Sequentialb692dd65's hyper parameters: Current learning rate is 3.508771929824561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 56960/60000][Iteration 1852][Wall Clock 180.712792087s] Trained 128 records in 0.085384575 seconds. Throughput is 1499.0997 records/second. Loss is 2.123131. Sequentialb692dd65's hyper parameters: Current learning rate is 3.50754121360926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 57088/60000][Iteration 1853][Wall Clock 180.805261681s] Trained 128 records in 0.092469594 seconds. Throughput is 1384.2388 records/second. Loss is 2.1364224. Sequentialb692dd65's hyper parameters: Current learning rate is 3.506311360448808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 57216/60000][Iteration 1854][Wall Clock 180.893619878s] Trained 128 records in 0.088358197 seconds. Throughput is 1448.6489 records/second. Loss is 2.1337006. Sequentialb692dd65's hyper parameters: Current learning rate is 3.505082369435682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 57344/60000][Iteration 1855][Wall Clock 180.989792402s] Trained 128 records in 0.096172524 seconds. Throughput is 1330.9414 records/second. Loss is 2.1220481. Sequentialb692dd65's hyper parameters: Current learning rate is 3.50385423966363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:24 INFO  DistriOptimizer$:408 - [Epoch 4 57472/60000][Iteration 1856][Wall Clock 181.093160489s] Trained 128 records in 0.103368087 seconds. Throughput is 1238.2932 records/second. Loss is 2.129765. Sequentialb692dd65's hyper parameters: Current learning rate is 3.502626970227671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 57600/60000][Iteration 1857][Wall Clock 181.20973281s] Trained 128 records in 0.116572321 seconds. Throughput is 1098.0308 records/second. Loss is 2.1418812. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5014005602240897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 57728/60000][Iteration 1858][Wall Clock 181.301619095s] Trained 128 records in 0.091886285 seconds. Throughput is 1393.0262 records/second. Loss is 2.1420617. Sequentialb692dd65's hyper parameters: Current learning rate is 3.5001750087504374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 57856/60000][Iteration 1859][Wall Clock 181.386870403s] Trained 128 records in 0.085251308 seconds. Throughput is 1501.4432 records/second. Loss is 2.1359458. Sequentialb692dd65's hyper parameters: Current learning rate is 3.498950314905528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 57984/60000][Iteration 1860][Wall Clock 181.47228072s] Trained 128 records in 0.085410317 seconds. Throughput is 1498.648 records/second. Loss is 2.1325557. Sequentialb692dd65's hyper parameters: Current learning rate is 3.497726477789437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58112/60000][Iteration 1861][Wall Clock 181.561793683s] Trained 128 records in 0.089512963 seconds. Throughput is 1429.9604 records/second. Loss is 2.146148. Sequentialb692dd65's hyper parameters: Current learning rate is 3.496503496503496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58240/60000][Iteration 1862][Wall Clock 181.647759892s] Trained 128 records in 0.085966209 seconds. Throughput is 1488.9572 records/second. Loss is 2.1351256. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4952813701502974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58368/60000][Iteration 1863][Wall Clock 181.742996336s] Trained 128 records in 0.095236444 seconds. Throughput is 1344.0233 records/second. Loss is 2.1590772. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4940600978336826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58496/60000][Iteration 1864][Wall Clock 181.831074467s] Trained 128 records in 0.088078131 seconds. Throughput is 1453.2551 records/second. Loss is 2.1529524. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4928396786587494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58624/60000][Iteration 1865][Wall Clock 181.921910613s] Trained 128 records in 0.090836146 seconds. Throughput is 1409.1307 records/second. Loss is 2.1478424. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4916201117318437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:25 INFO  DistriOptimizer$:408 - [Epoch 4 58752/60000][Iteration 1866][Wall Clock 182.032507548s] Trained 128 records in 0.110596935 seconds. Throughput is 1157.3558 records/second. Loss is 2.1225832. Sequentialb692dd65's hyper parameters: Current learning rate is 3.490401396160558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 58880/60000][Iteration 1867][Wall Clock 182.123434383s] Trained 128 records in 0.090926835 seconds. Throughput is 1407.7252 records/second. Loss is 2.1302564. Sequentialb692dd65's hyper parameters: Current learning rate is 3.489183531053733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59008/60000][Iteration 1868][Wall Clock 182.210359488s] Trained 128 records in 0.086925105 seconds. Throughput is 1472.532 records/second. Loss is 2.115121. Sequentialb692dd65's hyper parameters: Current learning rate is 3.487966515521451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59136/60000][Iteration 1869][Wall Clock 182.31173975s] Trained 128 records in 0.101380262 seconds. Throughput is 1262.5732 records/second. Loss is 2.1335132. Sequentialb692dd65's hyper parameters: Current learning rate is 3.486750348675035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59264/60000][Iteration 1870][Wall Clock 182.406247091s] Trained 128 records in 0.094507341 seconds. Throughput is 1354.3921 records/second. Loss is 2.1591454. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4855350296270483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59392/60000][Iteration 1871][Wall Clock 182.500162439s] Trained 128 records in 0.093915348 seconds. Throughput is 1362.9294 records/second. Loss is 2.1552062. Sequentialb692dd65's hyper parameters: Current learning rate is 3.484320557491289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59520/60000][Iteration 1872][Wall Clock 182.587384378s] Trained 128 records in 0.087221939 seconds. Throughput is 1467.5208 records/second. Loss is 2.1313741. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4831069313827936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59648/60000][Iteration 1873][Wall Clock 182.675718834s] Trained 128 records in 0.088334456 seconds. Throughput is 1449.0382 records/second. Loss is 2.1407073. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4818941504178273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59776/60000][Iteration 1874][Wall Clock 182.765947846s] Trained 128 records in 0.090229012 seconds. Throughput is 1418.6124 records/second. Loss is 2.140864. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4806822137138876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 59904/60000][Iteration 1875][Wall Clock 182.857274574s] Trained 128 records in 0.091326728 seconds. Throughput is 1401.5612 records/second. Loss is 2.1296299. Sequentialb692dd65's hyper parameters: Current learning rate is 3.479471120389701E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:408 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 182.946411146s] Trained 128 records in 0.089136572 seconds. Throughput is 1435.9987 records/second. Loss is 2.1547995. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4782608695652176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:26 INFO  DistriOptimizer$:452 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 182.946411146s] Epoch finished. Wall clock time is 184224.319891 ms
2019-10-15 07:49:26 INFO  DistriOptimizer$:111 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 182.946411146s] Validate model...
2019-10-15 07:49:27 INFO  DistriOptimizer$:178 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 182.946411146s] validate model throughput is 12088.121 records/second
2019-10-15 07:49:27 INFO  DistriOptimizer$:181 - [Epoch 4 60032/60000][Iteration 1876][Wall Clock 182.946411146s] Top1Accuracy is Accuracy(correct: 4835, count: 10000, accuracy: 0.4835)
2019-10-15 07:49:27 INFO  DistriOptimizer$:221 - [Wall Clock 184.224319891s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:49:27 INFO  DistriOptimizer$:226 - [Wall Clock 184.224319891s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:49:27 INFO  DistriOptimizer$:408 - [Epoch 5 128/60000][Iteration 1877][Wall Clock 184.322384515s] Trained 128 records in 0.098064624 seconds. Throughput is 1305.2617 records/second. Loss is 2.1277876. Sequentialb692dd65's hyper parameters: Current learning rate is 3.477051460361613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:27 INFO  DistriOptimizer$:408 - [Epoch 5 256/60000][Iteration 1878][Wall Clock 184.413003961s] Trained 128 records in 0.090619446 seconds. Throughput is 1412.5004 records/second. Loss is 2.1412725. Sequentialb692dd65's hyper parameters: Current learning rate is 3.475842891901286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 384/60000][Iteration 1879][Wall Clock 184.502419245s] Trained 128 records in 0.089415284 seconds. Throughput is 1431.5226 records/second. Loss is 2.1502728. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4746351633078526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 512/60000][Iteration 1880][Wall Clock 184.592334487s] Trained 128 records in 0.089915242 seconds. Throughput is 1423.563 records/second. Loss is 2.1377385. Sequentialb692dd65's hyper parameters: Current learning rate is 3.473428273706148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 640/60000][Iteration 1881][Wall Clock 184.688937239s] Trained 128 records in 0.096602752 seconds. Throughput is 1325.014 records/second. Loss is 2.118817. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4722222222222224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 768/60000][Iteration 1882][Wall Clock 184.783547815s] Trained 128 records in 0.094610576 seconds. Throughput is 1352.9142 records/second. Loss is 2.1253684. Sequentialb692dd65's hyper parameters: Current learning rate is 3.471017007983339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 896/60000][Iteration 1883][Wall Clock 184.86723126s] Trained 128 records in 0.083683445 seconds. Throughput is 1529.5737 records/second. Loss is 2.1598976. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4698126301179735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1024/60000][Iteration 1884][Wall Clock 184.953111648s] Trained 128 records in 0.085880388 seconds. Throughput is 1490.445 records/second. Loss is 2.1150393. Sequentialb692dd65's hyper parameters: Current learning rate is 3.46860908775581E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1152/60000][Iteration 1885][Wall Clock 185.041310106s] Trained 128 records in 0.088198458 seconds. Throughput is 1451.2725 records/second. Loss is 2.1418467. Sequentialb692dd65's hyper parameters: Current learning rate is 3.467406380027739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1280/60000][Iteration 1886][Wall Clock 185.125708036s] Trained 128 records in 0.08439793 seconds. Throughput is 1516.6249 records/second. Loss is 2.154427. Sequentialb692dd65's hyper parameters: Current learning rate is 3.466204506065858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1408/60000][Iteration 1887][Wall Clock 185.213439432s] Trained 128 records in 0.087731396 seconds. Throughput is 1458.9988 records/second. Loss is 2.1152766. Sequentialb692dd65's hyper parameters: Current learning rate is 3.465003465003465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1536/60000][Iteration 1888][Wall Clock 185.301753593s] Trained 128 records in 0.088314161 seconds. Throughput is 1449.3712 records/second. Loss is 2.1228924. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4638032559750607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:28 INFO  DistriOptimizer$:408 - [Epoch 5 1664/60000][Iteration 1889][Wall Clock 185.390745363s] Trained 128 records in 0.08899177 seconds. Throughput is 1438.3353 records/second. Loss is 2.1366231. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4626038781163435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 1792/60000][Iteration 1890][Wall Clock 185.477885944s] Trained 128 records in 0.087140581 seconds. Throughput is 1468.8907 records/second. Loss is 2.1336868. Sequentialb692dd65's hyper parameters: Current learning rate is 3.461405330564209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 1920/60000][Iteration 1891][Wall Clock 185.56486651s] Trained 128 records in 0.086980566 seconds. Throughput is 1471.5931 records/second. Loss is 2.14178. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4602076124567473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2048/60000][Iteration 1892][Wall Clock 185.670356109s] Trained 128 records in 0.105489599 seconds. Throughput is 1213.3898 records/second. Loss is 2.1438203. Sequentialb692dd65's hyper parameters: Current learning rate is 3.459010722933241E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2176/60000][Iteration 1893][Wall Clock 185.758436673s] Trained 128 records in 0.088080564 seconds. Throughput is 1453.2151 records/second. Loss is 2.1330054. Sequentialb692dd65's hyper parameters: Current learning rate is 3.457814661134163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2304/60000][Iteration 1894][Wall Clock 185.847532464s] Trained 128 records in 0.089095791 seconds. Throughput is 1436.6559 records/second. Loss is 2.1462815. Sequentialb692dd65's hyper parameters: Current learning rate is 3.456619426201176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2432/60000][Iteration 1895][Wall Clock 185.934775715s] Trained 128 records in 0.087243251 seconds. Throughput is 1467.1622 records/second. Loss is 2.1582139. Sequentialb692dd65's hyper parameters: Current learning rate is 3.455425017277125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2560/60000][Iteration 1896][Wall Clock 186.021720424s] Trained 128 records in 0.086944709 seconds. Throughput is 1472.2001 records/second. Loss is 2.1569977. Sequentialb692dd65's hyper parameters: Current learning rate is 3.454231433506045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2688/60000][Iteration 1897][Wall Clock 186.110553984s] Trained 128 records in 0.08883356 seconds. Throughput is 1440.8969 records/second. Loss is 2.134728. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4530386740331496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2816/60000][Iteration 1898][Wall Clock 186.196213894s] Trained 128 records in 0.08565991 seconds. Throughput is 1494.2812 records/second. Loss is 2.1339028. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4518467380048324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 2944/60000][Iteration 1899][Wall Clock 186.283420903s] Trained 128 records in 0.087207009 seconds. Throughput is 1467.7719 records/second. Loss is 2.1439145. Sequentialb692dd65's hyper parameters: Current learning rate is 3.450655624568668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 3072/60000][Iteration 1900][Wall Clock 186.373970328s] Trained 128 records in 0.090549425 seconds. Throughput is 1413.5927 records/second. Loss is 2.1550708. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4494653328734045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:29 INFO  DistriOptimizer$:408 - [Epoch 5 3200/60000][Iteration 1901][Wall Clock 186.457208522s] Trained 128 records in 0.083238194 seconds. Throughput is 1537.7556 records/second. Loss is 2.112467. Sequentialb692dd65's hyper parameters: Current learning rate is 3.448275862068965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3328/60000][Iteration 1902][Wall Clock 186.544051382s] Trained 128 records in 0.08684286 seconds. Throughput is 1473.9266 records/second. Loss is 2.1293364. Sequentialb692dd65's hyper parameters: Current learning rate is 3.447087211306446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3456/60000][Iteration 1903][Wall Clock 186.628921107s] Trained 128 records in 0.084869725 seconds. Throughput is 1508.1938 records/second. Loss is 2.1260622. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4458993797381116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3584/60000][Iteration 1904][Wall Clock 186.715620209s] Trained 128 records in 0.086699102 seconds. Throughput is 1476.3706 records/second. Loss is 2.112755. Sequentialb692dd65's hyper parameters: Current learning rate is 3.444712366517396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3712/60000][Iteration 1905][Wall Clock 186.801802684s] Trained 128 records in 0.086182475 seconds. Throughput is 1485.2207 records/second. Loss is 2.1296673. Sequentialb692dd65's hyper parameters: Current learning rate is 3.443526170798898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3840/60000][Iteration 1906][Wall Clock 186.888454507s] Trained 128 records in 0.086651823 seconds. Throughput is 1477.176 records/second. Loss is 2.128059. Sequentialb692dd65's hyper parameters: Current learning rate is 3.442340791738382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 3968/60000][Iteration 1907][Wall Clock 186.986417656s] Trained 128 records in 0.097963149 seconds. Throughput is 1306.6138 records/second. Loss is 2.1530337. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4411562284927734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 4096/60000][Iteration 1908][Wall Clock 187.071276341s] Trained 128 records in 0.084858685 seconds. Throughput is 1508.3901 records/second. Loss is 2.1416337. Sequentialb692dd65's hyper parameters: Current learning rate is 3.439972480220158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 4224/60000][Iteration 1909][Wall Clock 187.15265346s] Trained 128 records in 0.081377119 seconds. Throughput is 1572.9237 records/second. Loss is 2.1369202. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4387895460797794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 4352/60000][Iteration 1910][Wall Clock 187.242959618s] Trained 128 records in 0.090306158 seconds. Throughput is 1417.4006 records/second. Loss is 2.136958. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4376074252320387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 4480/60000][Iteration 1911][Wall Clock 187.332607859s] Trained 128 records in 0.089648241 seconds. Throughput is 1427.8027 records/second. Loss is 2.1254978. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4364261168384877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:30 INFO  DistriOptimizer$:408 - [Epoch 5 4608/60000][Iteration 1912][Wall Clock 187.419538475s] Trained 128 records in 0.086930616 seconds. Throughput is 1472.4386 records/second. Loss is 2.1402133. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4352456200618345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 4736/60000][Iteration 1913][Wall Clock 187.506458177s] Trained 128 records in 0.086919702 seconds. Throughput is 1472.6235 records/second. Loss is 2.1443584. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4340659340659343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 4864/60000][Iteration 1914][Wall Clock 187.593423538s] Trained 128 records in 0.086965361 seconds. Throughput is 1471.8505 records/second. Loss is 2.1436107. Sequentialb692dd65's hyper parameters: Current learning rate is 3.432887058015791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 4992/60000][Iteration 1915][Wall Clock 187.681765335s] Trained 128 records in 0.088341797 seconds. Throughput is 1448.9178 records/second. Loss is 2.1396227. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4317089910775565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5120/60000][Iteration 1916][Wall Clock 187.767949547s] Trained 128 records in 0.086184212 seconds. Throughput is 1485.1908 records/second. Loss is 2.1161635. Sequentialb692dd65's hyper parameters: Current learning rate is 3.430531732418525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5248/60000][Iteration 1917][Wall Clock 187.865693104s] Trained 128 records in 0.097743557 seconds. Throughput is 1309.5492 records/second. Loss is 2.1320043. Sequentialb692dd65's hyper parameters: Current learning rate is 3.429355281207133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5376/60000][Iteration 1918][Wall Clock 187.954057137s] Trained 128 records in 0.088364033 seconds. Throughput is 1448.5531 records/second. Loss is 2.151809. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4281796366129587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5504/60000][Iteration 1919][Wall Clock 188.040731232s] Trained 128 records in 0.086674095 seconds. Throughput is 1476.7965 records/second. Loss is 2.1292386. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4270047978067166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5632/60000][Iteration 1920][Wall Clock 188.12845252s] Trained 128 records in 0.087721288 seconds. Throughput is 1459.1669 records/second. Loss is 2.1408584. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4258307639602604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5760/60000][Iteration 1921][Wall Clock 188.214656812s] Trained 128 records in 0.086204292 seconds. Throughput is 1484.8448 records/second. Loss is 2.1465342. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4246575342465754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 5888/60000][Iteration 1922][Wall Clock 188.299964506s] Trained 128 records in 0.085307694 seconds. Throughput is 1500.4508 records/second. Loss is 2.1025448. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4234851078397807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:31 INFO  DistriOptimizer$:408 - [Epoch 5 6016/60000][Iteration 1923][Wall Clock 188.386559627s] Trained 128 records in 0.086595121 seconds. Throughput is 1478.1434 records/second. Loss is 2.1431088. Sequentialb692dd65's hyper parameters: Current learning rate is 3.422313483915127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6144/60000][Iteration 1924][Wall Clock 188.473800715s] Trained 128 records in 0.087241088 seconds. Throughput is 1467.1985 records/second. Loss is 2.1384363. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4211426616489907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6272/60000][Iteration 1925][Wall Clock 188.561988679s] Trained 128 records in 0.088187964 seconds. Throughput is 1451.4453 records/second. Loss is 2.1185832. Sequentialb692dd65's hyper parameters: Current learning rate is 3.419972640218878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6400/60000][Iteration 1926][Wall Clock 188.649157939s] Trained 128 records in 0.08716926 seconds. Throughput is 1468.4076 records/second. Loss is 2.1337512. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4188034188034193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6528/60000][Iteration 1927][Wall Clock 188.737844963s] Trained 128 records in 0.088687024 seconds. Throughput is 1443.2776 records/second. Loss is 2.1180258. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4176349965823647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6656/60000][Iteration 1928][Wall Clock 188.825923208s] Trained 128 records in 0.088078245 seconds. Throughput is 1453.2533 records/second. Loss is 2.1438231. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4164673727365904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6784/60000][Iteration 1929][Wall Clock 188.914883527s] Trained 128 records in 0.088960319 seconds. Throughput is 1438.8438 records/second. Loss is 2.110252. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4153005464480874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 6912/60000][Iteration 1930][Wall Clock 189.000934664s] Trained 128 records in 0.086051137 seconds. Throughput is 1487.4877 records/second. Loss is 2.1396747. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4141345168999654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 7040/60000][Iteration 1931][Wall Clock 189.088578006s] Trained 128 records in 0.087643342 seconds. Throughput is 1460.4646 records/second. Loss is 2.1140478. Sequentialb692dd65's hyper parameters: Current learning rate is 3.412969283276451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 7168/60000][Iteration 1932][Wall Clock 189.177087982s] Trained 128 records in 0.088509976 seconds. Throughput is 1446.1647 records/second. Loss is 2.1505022. Sequentialb692dd65's hyper parameters: Current learning rate is 3.41180484476288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 7296/60000][Iteration 1933][Wall Clock 189.270066031s] Trained 128 records in 0.092978049 seconds. Throughput is 1376.6691 records/second. Loss is 2.137727. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4106412005457026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 7424/60000][Iteration 1934][Wall Clock 189.357193728s] Trained 128 records in 0.087127697 seconds. Throughput is 1469.108 records/second. Loss is 2.1223025. Sequentialb692dd65's hyper parameters: Current learning rate is 3.409478349812479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:32 INFO  DistriOptimizer$:408 - [Epoch 5 7552/60000][Iteration 1935][Wall Clock 189.439401848s] Trained 128 records in 0.08220812 seconds. Throughput is 1557.0238 records/second. Loss is 2.1135716. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4083162917518747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 7680/60000][Iteration 1936][Wall Clock 189.521770109s] Trained 128 records in 0.082368261 seconds. Throughput is 1553.9966 records/second. Loss is 2.1332967. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4071550255536625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 7808/60000][Iteration 1937][Wall Clock 189.609475738s] Trained 128 records in 0.087705629 seconds. Throughput is 1459.4275 records/second. Loss is 2.1400025. Sequentialb692dd65's hyper parameters: Current learning rate is 3.405994550408719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 7936/60000][Iteration 1938][Wall Clock 189.695752706s] Trained 128 records in 0.086276968 seconds. Throughput is 1483.594 records/second. Loss is 2.130865. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4048348655090226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8064/60000][Iteration 1939][Wall Clock 189.782994175s] Trained 128 records in 0.087241469 seconds. Throughput is 1467.1921 records/second. Loss is 2.1409237. Sequentialb692dd65's hyper parameters: Current learning rate is 3.403675970047652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8192/60000][Iteration 1940][Wall Clock 189.870255313s] Trained 128 records in 0.087261138 seconds. Throughput is 1466.8615 records/second. Loss is 2.121495. Sequentialb692dd65's hyper parameters: Current learning rate is 3.402517863218782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8320/60000][Iteration 1941][Wall Clock 189.957279877s] Trained 128 records in 0.087024564 seconds. Throughput is 1470.8491 records/second. Loss is 2.1377003. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4013605442176874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8448/60000][Iteration 1942][Wall Clock 190.044439557s] Trained 128 records in 0.08715968 seconds. Throughput is 1468.569 records/second. Loss is 2.1569738. Sequentialb692dd65's hyper parameters: Current learning rate is 3.4002040122407346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8576/60000][Iteration 1943][Wall Clock 190.148642467s] Trained 128 records in 0.10420291 seconds. Throughput is 1228.3726 records/second. Loss is 2.1506855. Sequentialb692dd65's hyper parameters: Current learning rate is 3.399048266485384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8704/60000][Iteration 1944][Wall Clock 190.228234705s] Trained 128 records in 0.079592238 seconds. Throughput is 1608.197 records/second. Loss is 2.1452172. Sequentialb692dd65's hyper parameters: Current learning rate is 3.397893306150187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8832/60000][Iteration 1945][Wall Clock 190.313041713s] Trained 128 records in 0.084807008 seconds. Throughput is 1509.3092 records/second. Loss is 2.1044853. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3967391304347825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:33 INFO  DistriOptimizer$:408 - [Epoch 5 8960/60000][Iteration 1946][Wall Clock 190.398657118s] Trained 128 records in 0.085615405 seconds. Throughput is 1495.0581 records/second. Loss is 2.1282268. Sequentialb692dd65's hyper parameters: Current learning rate is 3.395585738539898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9088/60000][Iteration 1947][Wall Clock 190.483388047s] Trained 128 records in 0.084730929 seconds. Throughput is 1510.6644 records/second. Loss is 2.1510835. Sequentialb692dd65's hyper parameters: Current learning rate is 3.394433129667346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9216/60000][Iteration 1948][Wall Clock 190.566967009s] Trained 128 records in 0.083578962 seconds. Throughput is 1531.486 records/second. Loss is 2.139528. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3932813030200206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9344/60000][Iteration 1949][Wall Clock 190.652152927s] Trained 128 records in 0.085185918 seconds. Throughput is 1502.5958 records/second. Loss is 2.1447988. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3921302578019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9472/60000][Iteration 1950][Wall Clock 190.738973751s] Trained 128 records in 0.086820824 seconds. Throughput is 1474.3007 records/second. Loss is 2.1299734. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3909799932180403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9600/60000][Iteration 1951][Wall Clock 190.82577451s] Trained 128 records in 0.086800759 seconds. Throughput is 1474.6415 records/second. Loss is 2.137057. Sequentialb692dd65's hyper parameters: Current learning rate is 3.389830508474576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9728/60000][Iteration 1952][Wall Clock 190.910270918s] Trained 128 records in 0.084496408 seconds. Throughput is 1514.8573 records/second. Loss is 2.0936012. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3886818027787193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9856/60000][Iteration 1953][Wall Clock 190.995244615s] Trained 128 records in 0.084973697 seconds. Throughput is 1506.3484 records/second. Loss is 2.1102593. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3875338753387534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 9984/60000][Iteration 1954][Wall Clock 191.082126478s] Trained 128 records in 0.086881863 seconds. Throughput is 1473.2649 records/second. Loss is 2.1239128. Sequentialb692dd65's hyper parameters: Current learning rate is 3.386386725364036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 10112/60000][Iteration 1955][Wall Clock 191.168880504s] Trained 128 records in 0.086754026 seconds. Throughput is 1475.4359 records/second. Loss is 2.1397624. Sequentialb692dd65's hyper parameters: Current learning rate is 3.385240352064997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 10240/60000][Iteration 1956][Wall Clock 191.253161798s] Trained 128 records in 0.084281294 seconds. Throughput is 1518.7236 records/second. Loss is 2.1067553. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3840947546531303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 10368/60000][Iteration 1957][Wall Clock 191.338039252s] Trained 128 records in 0.084877454 seconds. Throughput is 1508.0565 records/second. Loss is 2.1298206. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3829499323410016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:34 INFO  DistriOptimizer$:408 - [Epoch 5 10496/60000][Iteration 1958][Wall Clock 191.423406927s] Trained 128 records in 0.085367675 seconds. Throughput is 1499.3966 records/second. Loss is 2.1239297. Sequentialb692dd65's hyper parameters: Current learning rate is 3.381805884342239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 10624/60000][Iteration 1959][Wall Clock 191.509264236s] Trained 128 records in 0.085857309 seconds. Throughput is 1490.8457 records/second. Loss is 2.1138444. Sequentialb692dd65's hyper parameters: Current learning rate is 3.380662609871535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 10752/60000][Iteration 1960][Wall Clock 191.609179581s] Trained 128 records in 0.099915345 seconds. Throughput is 1281.0845 records/second. Loss is 2.1216366. Sequentialb692dd65's hyper parameters: Current learning rate is 3.379520108144643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 10880/60000][Iteration 1961][Wall Clock 191.68967387s] Trained 128 records in 0.080494289 seconds. Throughput is 1590.1748 records/second. Loss is 2.134326. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3783783783783786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11008/60000][Iteration 1962][Wall Clock 191.771099389s] Trained 128 records in 0.081425519 seconds. Throughput is 1571.9888 records/second. Loss is 2.101801. Sequentialb692dd65's hyper parameters: Current learning rate is 3.377237419790611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11136/60000][Iteration 1963][Wall Clock 191.858857956s] Trained 128 records in 0.087758567 seconds. Throughput is 1458.5471 records/second. Loss is 2.1229637. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3760972316002703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11264/60000][Iteration 1964][Wall Clock 191.946860864s] Trained 128 records in 0.088002908 seconds. Throughput is 1454.4974 records/second. Loss is 2.1342704. Sequentialb692dd65's hyper parameters: Current learning rate is 3.374957813027337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11392/60000][Iteration 1965][Wall Clock 192.034907618s] Trained 128 records in 0.088046754 seconds. Throughput is 1453.7731 records/second. Loss is 2.1256275. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3738191632928474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11520/60000][Iteration 1966][Wall Clock 192.12469668s] Trained 128 records in 0.089789062 seconds. Throughput is 1425.5634 records/second. Loss is 2.131641. Sequentialb692dd65's hyper parameters: Current learning rate is 3.372681281618887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11648/60000][Iteration 1967][Wall Clock 192.214972152s] Trained 128 records in 0.090275472 seconds. Throughput is 1417.8823 records/second. Loss is 2.1339781. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3715441672285906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11776/60000][Iteration 1968][Wall Clock 192.31417773s] Trained 128 records in 0.099205578 seconds. Throughput is 1290.25 records/second. Loss is 2.1339831. Sequentialb692dd65's hyper parameters: Current learning rate is 3.370407819346141E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:35 INFO  DistriOptimizer$:408 - [Epoch 5 11904/60000][Iteration 1969][Wall Clock 192.399566817s] Trained 128 records in 0.085389087 seconds. Throughput is 1499.0206 records/second. Loss is 2.1369555. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3692722371967657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12032/60000][Iteration 1970][Wall Clock 192.484068772s] Trained 128 records in 0.084501955 seconds. Throughput is 1514.7579 records/second. Loss is 2.1305413. Sequentialb692dd65's hyper parameters: Current learning rate is 3.368137420006736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12160/60000][Iteration 1971][Wall Clock 192.568772235s] Trained 128 records in 0.084703463 seconds. Throughput is 1511.1543 records/second. Loss is 2.1242807. Sequentialb692dd65's hyper parameters: Current learning rate is 3.367003367003367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12288/60000][Iteration 1972][Wall Clock 192.653457557s] Trained 128 records in 0.084685322 seconds. Throughput is 1511.4779 records/second. Loss is 2.1068661. Sequentialb692dd65's hyper parameters: Current learning rate is 3.365870077415012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12416/60000][Iteration 1973][Wall Clock 192.740654448s] Trained 128 records in 0.087196891 seconds. Throughput is 1467.9421 records/second. Loss is 2.1435988. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3647375504710633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12544/60000][Iteration 1974][Wall Clock 192.828854468s] Trained 128 records in 0.08820002 seconds. Throughput is 1451.2468 records/second. Loss is 2.1247506. Sequentialb692dd65's hyper parameters: Current learning rate is 3.363605785401951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12672/60000][Iteration 1975][Wall Clock 192.912769775s] Trained 128 records in 0.083915307 seconds. Throughput is 1525.3474 records/second. Loss is 2.1268377. Sequentialb692dd65's hyper parameters: Current learning rate is 3.362474781439139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12800/60000][Iteration 1976][Wall Clock 192.998705574s] Trained 128 records in 0.085935799 seconds. Throughput is 1489.484 records/second. Loss is 2.1145332. Sequentialb692dd65's hyper parameters: Current learning rate is 3.361344537815126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 12928/60000][Iteration 1977][Wall Clock 193.085980091s] Trained 128 records in 0.087274517 seconds. Throughput is 1466.6366 records/second. Loss is 2.109119. Sequentialb692dd65's hyper parameters: Current learning rate is 3.360215053763441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 13056/60000][Iteration 1978][Wall Clock 193.172333928s] Trained 128 records in 0.086353837 seconds. Throughput is 1482.2734 records/second. Loss is 2.1238832. Sequentialb692dd65's hyper parameters: Current learning rate is 3.359086328518643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 13184/60000][Iteration 1979][Wall Clock 193.258447333s] Trained 128 records in 0.086113405 seconds. Throughput is 1486.412 records/second. Loss is 2.1128774. Sequentialb692dd65's hyper parameters: Current learning rate is 3.35795836131632E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:36 INFO  DistriOptimizer$:408 - [Epoch 5 13312/60000][Iteration 1980][Wall Clock 193.349005168s] Trained 128 records in 0.090557835 seconds. Throughput is 1413.4613 records/second. Loss is 2.1162205. Sequentialb692dd65's hyper parameters: Current learning rate is 3.356831151393085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 13440/60000][Iteration 1981][Wall Clock 193.433688828s] Trained 128 records in 0.08468366 seconds. Throughput is 1511.5077 records/second. Loss is 2.1080055. Sequentialb692dd65's hyper parameters: Current learning rate is 3.355704697986577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 13568/60000][Iteration 1982][Wall Clock 193.518224207s] Trained 128 records in 0.084535379 seconds. Throughput is 1514.1589 records/second. Loss is 2.129647. Sequentialb692dd65's hyper parameters: Current learning rate is 3.354579000335458E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 13696/60000][Iteration 1983][Wall Clock 193.607727179s] Trained 128 records in 0.089502972 seconds. Throughput is 1430.12 records/second. Loss is 2.1214356. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3534540576794097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 13824/60000][Iteration 1984][Wall Clock 193.694845209s] Trained 128 records in 0.08711803 seconds. Throughput is 1469.2711 records/second. Loss is 2.1377387. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3523298692591353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 13952/60000][Iteration 1985][Wall Clock 193.782743961s] Trained 128 records in 0.087898752 seconds. Throughput is 1456.2208 records/second. Loss is 2.1431315. Sequentialb692dd65's hyper parameters: Current learning rate is 3.351206434316354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14080/60000][Iteration 1986][Wall Clock 193.87916555s] Trained 128 records in 0.096421589 seconds. Throughput is 1327.5035 records/second. Loss is 2.128766. Sequentialb692dd65's hyper parameters: Current learning rate is 3.350083752093802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14208/60000][Iteration 1987][Wall Clock 193.966667676s] Trained 128 records in 0.087502126 seconds. Throughput is 1462.8215 records/second. Loss is 2.1407993. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3489618218352315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14336/60000][Iteration 1988][Wall Clock 194.052859361s] Trained 128 records in 0.086191685 seconds. Throughput is 1485.062 records/second. Loss is 2.1265564. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3478406427854036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14464/60000][Iteration 1989][Wall Clock 194.137689808s] Trained 128 records in 0.084830447 seconds. Throughput is 1508.8922 records/second. Loss is 2.1369343. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3467202141900936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14592/60000][Iteration 1990][Wall Clock 194.226821577s] Trained 128 records in 0.089131769 seconds. Throughput is 1436.076 records/second. Loss is 2.133897. Sequentialb692dd65's hyper parameters: Current learning rate is 3.345600535296086E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14720/60000][Iteration 1991][Wall Clock 194.314398557s] Trained 128 records in 0.08757698 seconds. Throughput is 1461.5713 records/second. Loss is 2.1366487. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3444816053511704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:37 INFO  DistriOptimizer$:408 - [Epoch 5 14848/60000][Iteration 1992][Wall Clock 194.401201987s] Trained 128 records in 0.08680343 seconds. Throughput is 1474.5961 records/second. Loss is 2.113551. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3433634236041456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 14976/60000][Iteration 1993][Wall Clock 194.486610072s] Trained 128 records in 0.085408085 seconds. Throughput is 1498.6871 records/second. Loss is 2.1230268. Sequentialb692dd65's hyper parameters: Current learning rate is 3.342245989304813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15104/60000][Iteration 1994][Wall Clock 194.576029564s] Trained 128 records in 0.089419492 seconds. Throughput is 1431.4552 records/second. Loss is 2.1297328. Sequentialb692dd65's hyper parameters: Current learning rate is 3.341129301703976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15232/60000][Iteration 1995][Wall Clock 194.661375323s] Trained 128 records in 0.085345759 seconds. Throughput is 1499.7816 records/second. Loss is 2.1414819. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3400133600534405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15360/60000][Iteration 1996][Wall Clock 194.746215005s] Trained 128 records in 0.084839682 seconds. Throughput is 1508.728 records/second. Loss is 2.1222763. Sequentialb692dd65's hyper parameters: Current learning rate is 3.33889816360601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15488/60000][Iteration 1997][Wall Clock 194.832191351s] Trained 128 records in 0.085976346 seconds. Throughput is 1488.7815 records/second. Loss is 2.1140997. Sequentialb692dd65's hyper parameters: Current learning rate is 3.337783711615487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15616/60000][Iteration 1998][Wall Clock 194.920096881s] Trained 128 records in 0.08790553 seconds. Throughput is 1456.1085 records/second. Loss is 2.1094055. Sequentialb692dd65's hyper parameters: Current learning rate is 3.33667000333667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15744/60000][Iteration 1999][Wall Clock 195.005691666s] Trained 128 records in 0.085594785 seconds. Throughput is 1495.4182 records/second. Loss is 2.102617. Sequentialb692dd65's hyper parameters: Current learning rate is 3.33555703802535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 15872/60000][Iteration 2000][Wall Clock 195.091219514s] Trained 128 records in 0.085527848 seconds. Throughput is 1496.5886 records/second. Loss is 2.126882. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3344448149383126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 16000/60000][Iteration 2001][Wall Clock 195.176927581s] Trained 128 records in 0.085708067 seconds. Throughput is 1493.4417 records/second. Loss is 2.1008155. Sequentialb692dd65's hyper parameters: Current learning rate is 3.333333333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 16128/60000][Iteration 2002][Wall Clock 195.262194133s] Trained 128 records in 0.085266552 seconds. Throughput is 1501.1748 records/second. Loss is 2.127608. Sequentialb692dd65's hyper parameters: Current learning rate is 3.332222592469177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:38 INFO  DistriOptimizer$:408 - [Epoch 5 16256/60000][Iteration 2003][Wall Clock 195.347589562s] Trained 128 records in 0.085395429 seconds. Throughput is 1498.9093 records/second. Loss is 2.125584. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3311125916055963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 16384/60000][Iteration 2004][Wall Clock 195.43772343s] Trained 128 records in 0.090133868 seconds. Throughput is 1420.1099 records/second. Loss is 2.1333694. Sequentialb692dd65's hyper parameters: Current learning rate is 3.33000333000333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 16512/60000][Iteration 2005][Wall Clock 195.525230316s] Trained 128 records in 0.087506886 seconds. Throughput is 1462.7421 records/second. Loss is 2.1263735. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3288948069241014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 16640/60000][Iteration 2006][Wall Clock 195.612220785s] Trained 128 records in 0.086990469 seconds. Throughput is 1471.4255 records/second. Loss is 2.1359925. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3277870216306157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 16768/60000][Iteration 2007][Wall Clock 195.696447131s] Trained 128 records in 0.084226346 seconds. Throughput is 1519.7145 records/second. Loss is 2.1114051. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3266799733865603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 16896/60000][Iteration 2008][Wall Clock 195.782671687s] Trained 128 records in 0.086224556 seconds. Throughput is 1484.4958 records/second. Loss is 2.1387618. Sequentialb692dd65's hyper parameters: Current learning rate is 3.325573661456601E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17024/60000][Iteration 2009][Wall Clock 195.86827164s] Trained 128 records in 0.085599953 seconds. Throughput is 1495.328 records/second. Loss is 2.127025. Sequentialb692dd65's hyper parameters: Current learning rate is 3.324468085106383E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17152/60000][Iteration 2010][Wall Clock 195.958300214s] Trained 128 records in 0.090028574 seconds. Throughput is 1421.7708 records/second. Loss is 2.1295846. Sequentialb692dd65's hyper parameters: Current learning rate is 3.323363243602526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17280/60000][Iteration 2011][Wall Clock 196.052966489s] Trained 128 records in 0.094666275 seconds. Throughput is 1352.1183 records/second. Loss is 2.1062021. Sequentialb692dd65's hyper parameters: Current learning rate is 3.322259136212624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17408/60000][Iteration 2012][Wall Clock 196.136615603s] Trained 128 records in 0.083649114 seconds. Throughput is 1530.2015 records/second. Loss is 2.1115172. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3211557622052476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17536/60000][Iteration 2013][Wall Clock 196.222963972s] Trained 128 records in 0.086348369 seconds. Throughput is 1482.3673 records/second. Loss is 2.1124547. Sequentialb692dd65's hyper parameters: Current learning rate is 3.320053120849934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17664/60000][Iteration 2014][Wall Clock 196.306370668s] Trained 128 records in 0.083406696 seconds. Throughput is 1534.649 records/second. Loss is 2.1216195. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3189512114171923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:39 INFO  DistriOptimizer$:408 - [Epoch 5 17792/60000][Iteration 2015][Wall Clock 196.391274172s] Trained 128 records in 0.084903504 seconds. Throughput is 1507.5939 records/second. Loss is 2.1297305. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3178500331785003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 17920/60000][Iteration 2016][Wall Clock 196.477492041s] Trained 128 records in 0.086217869 seconds. Throughput is 1484.6111 records/second. Loss is 2.1406012. Sequentialb692dd65's hyper parameters: Current learning rate is 3.316749585406302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18048/60000][Iteration 2017][Wall Clock 196.564370266s] Trained 128 records in 0.086878225 seconds. Throughput is 1473.3265 records/second. Loss is 2.1283474. Sequentialb692dd65's hyper parameters: Current learning rate is 3.315649867374005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18176/60000][Iteration 2018][Wall Clock 196.648956218s] Trained 128 records in 0.084585952 seconds. Throughput is 1513.2537 records/second. Loss is 2.1159375. Sequentialb692dd65's hyper parameters: Current learning rate is 3.314550878355983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18304/60000][Iteration 2019][Wall Clock 196.738632265s] Trained 128 records in 0.089676047 seconds. Throughput is 1427.36 records/second. Loss is 2.1423378. Sequentialb692dd65's hyper parameters: Current learning rate is 3.313452617627568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18432/60000][Iteration 2020][Wall Clock 196.826946419s] Trained 128 records in 0.088314154 seconds. Throughput is 1449.3713 records/second. Loss is 2.1314964. Sequentialb692dd65's hyper parameters: Current learning rate is 3.312355084465055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18560/60000][Iteration 2021][Wall Clock 196.912449224s] Trained 128 records in 0.085502805 seconds. Throughput is 1497.027 records/second. Loss is 2.1484761. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3112582781456954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18688/60000][Iteration 2022][Wall Clock 196.999732169s] Trained 128 records in 0.087282945 seconds. Throughput is 1466.4949 records/second. Loss is 2.120099. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3101621979476995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18816/60000][Iteration 2023][Wall Clock 197.086925385s] Trained 128 records in 0.087193216 seconds. Throughput is 1468.0042 records/second. Loss is 2.0998614. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3090668431502316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 18944/60000][Iteration 2024][Wall Clock 197.173466248s] Trained 128 records in 0.086540863 seconds. Throughput is 1479.0701 records/second. Loss is 2.117116. Sequentialb692dd65's hyper parameters: Current learning rate is 3.30797221303341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 19072/60000][Iteration 2025][Wall Clock 197.259450645s] Trained 128 records in 0.085984397 seconds. Throughput is 1488.6422 records/second. Loss is 2.1287575. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3068783068783067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:40 INFO  DistriOptimizer$:408 - [Epoch 5 19200/60000][Iteration 2026][Wall Clock 197.348641092s] Trained 128 records in 0.089190447 seconds. Throughput is 1435.1313 records/second. Loss is 2.1048508. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3057851239669424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19328/60000][Iteration 2027][Wall Clock 197.43792057s] Trained 128 records in 0.089279478 seconds. Throughput is 1433.7001 records/second. Loss is 2.142271. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3046926635822867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19456/60000][Iteration 2028][Wall Clock 197.524501155s] Trained 128 records in 0.086580585 seconds. Throughput is 1478.3916 records/second. Loss is 2.1189024. Sequentialb692dd65's hyper parameters: Current learning rate is 3.303600925008259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19584/60000][Iteration 2029][Wall Clock 197.611460783s] Trained 128 records in 0.086959628 seconds. Throughput is 1471.9474 records/second. Loss is 2.1248124. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3025099075297226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19712/60000][Iteration 2030][Wall Clock 197.698038634s] Trained 128 records in 0.086577851 seconds. Throughput is 1478.4382 records/second. Loss is 2.1121094. Sequentialb692dd65's hyper parameters: Current learning rate is 3.301419610432486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19840/60000][Iteration 2031][Wall Clock 197.784409524s] Trained 128 records in 0.08637089 seconds. Throughput is 1481.9807 records/second. Loss is 2.1426418. Sequentialb692dd65's hyper parameters: Current learning rate is 3.3003300330033004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 19968/60000][Iteration 2032][Wall Clock 197.87537549s] Trained 128 records in 0.090965966 seconds. Throughput is 1407.1198 records/second. Loss is 2.1088054. Sequentialb692dd65's hyper parameters: Current learning rate is 3.299241174529858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 20096/60000][Iteration 2033][Wall Clock 197.968622723s] Trained 128 records in 0.093247233 seconds. Throughput is 1372.6948 records/second. Loss is 2.104712. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2981530343007914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 20224/60000][Iteration 2034][Wall Clock 198.055402678s] Trained 128 records in 0.086779955 seconds. Throughput is 1474.995 records/second. Loss is 2.107938. Sequentialb692dd65's hyper parameters: Current learning rate is 3.297065611605671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 20352/60000][Iteration 2035][Wall Clock 198.143461865s] Trained 128 records in 0.088059187 seconds. Throughput is 1453.5679 records/second. Loss is 2.1361365. Sequentialb692dd65's hyper parameters: Current learning rate is 3.295978905735003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 20480/60000][Iteration 2036][Wall Clock 198.231258716s] Trained 128 records in 0.087796851 seconds. Throughput is 1457.911 records/second. Loss is 2.1214893. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2948929159802305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:41 INFO  DistriOptimizer$:408 - [Epoch 5 20608/60000][Iteration 2037][Wall Clock 198.328856644s] Trained 128 records in 0.097597928 seconds. Throughput is 1311.5033 records/second. Loss is 2.109202. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2938076416337287E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 20736/60000][Iteration 2038][Wall Clock 198.406452564s] Trained 128 records in 0.07759592 seconds. Throughput is 1649.5713 records/second. Loss is 2.1325457. Sequentialb692dd65's hyper parameters: Current learning rate is 3.292723081988805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 20864/60000][Iteration 2039][Wall Clock 198.491248892s] Trained 128 records in 0.084796328 seconds. Throughput is 1509.4994 records/second. Loss is 2.1206746. Sequentialb692dd65's hyper parameters: Current learning rate is 3.291639236339697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 20992/60000][Iteration 2040][Wall Clock 198.568981513s] Trained 128 records in 0.077732621 seconds. Throughput is 1646.6703 records/second. Loss is 2.1141322. Sequentialb692dd65's hyper parameters: Current learning rate is 3.290556103981573E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21120/60000][Iteration 2041][Wall Clock 198.655237269s] Trained 128 records in 0.086255756 seconds. Throughput is 1483.9589 records/second. Loss is 2.071508. Sequentialb692dd65's hyper parameters: Current learning rate is 3.289473684210526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21248/60000][Iteration 2042][Wall Clock 198.746685756s] Trained 128 records in 0.091448487 seconds. Throughput is 1399.6951 records/second. Loss is 2.097935. Sequentialb692dd65's hyper parameters: Current learning rate is 3.288391976323578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21376/60000][Iteration 2043][Wall Clock 198.833516921s] Trained 128 records in 0.086831165 seconds. Throughput is 1474.1251 records/second. Loss is 2.100451. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2873109796186715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21504/60000][Iteration 2044][Wall Clock 198.921838819s] Trained 128 records in 0.088321898 seconds. Throughput is 1449.2443 records/second. Loss is 2.107682. Sequentialb692dd65's hyper parameters: Current learning rate is 3.286230693394676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21632/60000][Iteration 2045][Wall Clock 199.01068211s] Trained 128 records in 0.088843291 seconds. Throughput is 1440.739 records/second. Loss is 2.1308331. Sequentialb692dd65's hyper parameters: Current learning rate is 3.28515111695138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21760/60000][Iteration 2046][Wall Clock 199.099325253s] Trained 128 records in 0.088643143 seconds. Throughput is 1443.9922 records/second. Loss is 2.1021771. Sequentialb692dd65's hyper parameters: Current learning rate is 3.284072249589491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 21888/60000][Iteration 2047][Wall Clock 199.187575047s] Trained 128 records in 0.088249794 seconds. Throughput is 1450.4283 records/second. Loss is 2.1274586. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2829940906106366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 22016/60000][Iteration 2048][Wall Clock 199.274747594s] Trained 128 records in 0.087172547 seconds. Throughput is 1468.3522 records/second. Loss is 2.120264. Sequentialb692dd65's hyper parameters: Current learning rate is 3.281916639317361E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:42 INFO  DistriOptimizer$:408 - [Epoch 5 22144/60000][Iteration 2049][Wall Clock 199.361802706s] Trained 128 records in 0.087055112 seconds. Throughput is 1470.333 records/second. Loss is 2.1086545. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2808398950131233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22272/60000][Iteration 2050][Wall Clock 199.450406574s] Trained 128 records in 0.088603868 seconds. Throughput is 1444.6322 records/second. Loss is 2.1307454. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2797638570022957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22400/60000][Iteration 2051][Wall Clock 199.541238187s] Trained 128 records in 0.090831613 seconds. Throughput is 1409.2009 records/second. Loss is 2.0979426. Sequentialb692dd65's hyper parameters: Current learning rate is 3.278688524590164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22528/60000][Iteration 2052][Wall Clock 199.632430458s] Trained 128 records in 0.091192271 seconds. Throughput is 1403.6278 records/second. Loss is 2.144132. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2776138970829236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22656/60000][Iteration 2053][Wall Clock 199.721170414s] Trained 128 records in 0.088739956 seconds. Throughput is 1442.4167 records/second. Loss is 2.089531. Sequentialb692dd65's hyper parameters: Current learning rate is 3.27653997378768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22784/60000][Iteration 2054][Wall Clock 199.806417714s] Trained 128 records in 0.0852473 seconds. Throughput is 1501.5138 records/second. Loss is 2.0985043. Sequentialb692dd65's hyper parameters: Current learning rate is 3.275466754012447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 22912/60000][Iteration 2055][Wall Clock 199.893014776s] Trained 128 records in 0.086597062 seconds. Throughput is 1478.1102 records/second. Loss is 2.1380074. Sequentialb692dd65's hyper parameters: Current learning rate is 3.274394237066143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 23040/60000][Iteration 2056][Wall Clock 199.979817375s] Trained 128 records in 0.086802599 seconds. Throughput is 1474.6102 records/second. Loss is 2.1475549. Sequentialb692dd65's hyper parameters: Current learning rate is 3.273322422258592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 23168/60000][Iteration 2057][Wall Clock 200.063984764s] Trained 128 records in 0.084167389 seconds. Throughput is 1520.7789 records/second. Loss is 2.1236966. Sequentialb692dd65's hyper parameters: Current learning rate is 3.272251308900524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 23296/60000][Iteration 2058][Wall Clock 200.151457881s] Trained 128 records in 0.087473117 seconds. Throughput is 1463.3068 records/second. Loss is 2.126013. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2711808963035657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 23424/60000][Iteration 2059][Wall Clock 200.238068486s] Trained 128 records in 0.086610605 seconds. Throughput is 1477.879 records/second. Loss is 2.1172159. Sequentialb692dd65's hyper parameters: Current learning rate is 3.270111183780249E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:43 INFO  DistriOptimizer$:408 - [Epoch 5 23552/60000][Iteration 2060][Wall Clock 200.322643934s] Trained 128 records in 0.084575448 seconds. Throughput is 1513.4417 records/second. Loss is 2.1216166. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2690421706440013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 23680/60000][Iteration 2061][Wall Clock 200.408100707s] Trained 128 records in 0.085456773 seconds. Throughput is 1497.8333 records/second. Loss is 2.115207. Sequentialb692dd65's hyper parameters: Current learning rate is 3.26797385620915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 23808/60000][Iteration 2062][Wall Clock 200.501097337s] Trained 128 records in 0.09299663 seconds. Throughput is 1376.394 records/second. Loss is 2.1169956. Sequentialb692dd65's hyper parameters: Current learning rate is 3.266906239790918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 23936/60000][Iteration 2063][Wall Clock 200.586380169s] Trained 128 records in 0.085282832 seconds. Throughput is 1500.8882 records/second. Loss is 2.1212022. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2658393207054214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24064/60000][Iteration 2064][Wall Clock 200.671364164s] Trained 128 records in 0.084983995 seconds. Throughput is 1506.1659 records/second. Loss is 2.1092582. Sequentialb692dd65's hyper parameters: Current learning rate is 3.26477309826967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24192/60000][Iteration 2065][Wall Clock 200.749421389s] Trained 128 records in 0.078057225 seconds. Throughput is 1639.8226 records/second. Loss is 2.1128652. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2637075718015666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24320/60000][Iteration 2066][Wall Clock 200.836682826s] Trained 128 records in 0.087261437 seconds. Throughput is 1466.8564 records/second. Loss is 2.1210477. Sequentialb692dd65's hyper parameters: Current learning rate is 3.262642740619902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24448/60000][Iteration 2067][Wall Clock 200.922535328s] Trained 128 records in 0.085852502 seconds. Throughput is 1490.9292 records/second. Loss is 2.1378152. Sequentialb692dd65's hyper parameters: Current learning rate is 3.261578604044358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24576/60000][Iteration 2068][Wall Clock 201.004765088s] Trained 128 records in 0.08222976 seconds. Throughput is 1556.614 records/second. Loss is 2.104144. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2605151613955004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24704/60000][Iteration 2069][Wall Clock 201.089637511s] Trained 128 records in 0.084872423 seconds. Throughput is 1508.1459 records/second. Loss is 2.1106362. Sequentialb692dd65's hyper parameters: Current learning rate is 3.259452411994785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24832/60000][Iteration 2070][Wall Clock 201.180083476s] Trained 128 records in 0.090445965 seconds. Throughput is 1415.2096 records/second. Loss is 2.1059227. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2583903551645487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 24960/60000][Iteration 2071][Wall Clock 201.264481412s] Trained 128 records in 0.084397936 seconds. Throughput is 1516.6248 records/second. Loss is 2.1041336. Sequentialb692dd65's hyper parameters: Current learning rate is 3.257328990228013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:44 INFO  DistriOptimizer$:408 - [Epoch 5 25088/60000][Iteration 2072][Wall Clock 201.347828946s] Trained 128 records in 0.083347534 seconds. Throughput is 1535.7383 records/second. Loss is 2.120732. Sequentialb692dd65's hyper parameters: Current learning rate is 3.25626831650928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25216/60000][Iteration 2073][Wall Clock 201.435226569s] Trained 128 records in 0.087397623 seconds. Throughput is 1464.5708 records/second. Loss is 2.134859. Sequentialb692dd65's hyper parameters: Current learning rate is 3.255208333333333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25344/60000][Iteration 2074][Wall Clock 201.52386359s] Trained 128 records in 0.088637021 seconds. Throughput is 1444.0918 records/second. Loss is 2.1243098. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2541490400260335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25472/60000][Iteration 2075][Wall Clock 201.613134259s] Trained 128 records in 0.089270669 seconds. Throughput is 1433.8417 records/second. Loss is 2.1458442. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2530904359141186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25600/60000][Iteration 2076][Wall Clock 201.703933318s] Trained 128 records in 0.090799059 seconds. Throughput is 1409.7063 records/second. Loss is 2.1063817. Sequentialb692dd65's hyper parameters: Current learning rate is 3.252032520325203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25728/60000][Iteration 2077][Wall Clock 201.79069632s] Trained 128 records in 0.086763002 seconds. Throughput is 1475.2832 records/second. Loss is 2.1178331. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2509752925877764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25856/60000][Iteration 2078][Wall Clock 201.876531718s] Trained 128 records in 0.085835398 seconds. Throughput is 1491.2263 records/second. Loss is 2.11591. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2499187520311994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 25984/60000][Iteration 2079][Wall Clock 201.963755078s] Trained 128 records in 0.08722336 seconds. Throughput is 1467.4968 records/second. Loss is 2.1230812. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2488628979857054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 26112/60000][Iteration 2080][Wall Clock 202.050356141s] Trained 128 records in 0.086601063 seconds. Throughput is 1478.0419 records/second. Loss is 2.1018333. Sequentialb692dd65's hyper parameters: Current learning rate is 3.247807729782397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 26240/60000][Iteration 2081][Wall Clock 202.135586695s] Trained 128 records in 0.085230554 seconds. Throughput is 1501.8088 records/second. Loss is 2.1093128. Sequentialb692dd65's hyper parameters: Current learning rate is 3.246753246753247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 26368/60000][Iteration 2082][Wall Clock 202.221243092s] Trained 128 records in 0.085656397 seconds. Throughput is 1494.3425 records/second. Loss is 2.1103199. Sequentialb692dd65's hyper parameters: Current learning rate is 3.245699448231094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:45 INFO  DistriOptimizer$:408 - [Epoch 5 26496/60000][Iteration 2083][Wall Clock 202.309532644s] Trained 128 records in 0.088289552 seconds. Throughput is 1449.7751 records/second. Loss is 2.096699. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2446463335496434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 26624/60000][Iteration 2084][Wall Clock 202.396238383s] Trained 128 records in 0.086705739 seconds. Throughput is 1476.2576 records/second. Loss is 2.124937. Sequentialb692dd65's hyper parameters: Current learning rate is 3.243593902043464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 26752/60000][Iteration 2085][Wall Clock 202.484779598s] Trained 128 records in 0.088541215 seconds. Throughput is 1445.6544 records/second. Loss is 2.1232762. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2425421530479895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 26880/60000][Iteration 2086][Wall Clock 202.580260631s] Trained 128 records in 0.095481033 seconds. Throughput is 1340.5804 records/second. Loss is 2.135658. Sequentialb692dd65's hyper parameters: Current learning rate is 3.241491085899514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27008/60000][Iteration 2087][Wall Clock 202.666688406s] Trained 128 records in 0.086427775 seconds. Throughput is 1481.0054 records/second. Loss is 2.1223068. Sequentialb692dd65's hyper parameters: Current learning rate is 3.240440699935191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27136/60000][Iteration 2088][Wall Clock 202.773741359s] Trained 128 records in 0.107052953 seconds. Throughput is 1195.6699 records/second. Loss is 2.1132064. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2393909944930353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27264/60000][Iteration 2089][Wall Clock 202.859271077s] Trained 128 records in 0.085529718 seconds. Throughput is 1496.5559 records/second. Loss is 2.131457. Sequentialb692dd65's hyper parameters: Current learning rate is 3.238341968911917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27392/60000][Iteration 2090][Wall Clock 202.945417008s] Trained 128 records in 0.086145931 seconds. Throughput is 1485.8508 records/second. Loss is 2.1020317. Sequentialb692dd65's hyper parameters: Current learning rate is 3.237293622531564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27520/60000][Iteration 2091][Wall Clock 203.035555755s] Trained 128 records in 0.090138747 seconds. Throughput is 1420.0331 records/second. Loss is 2.1289158. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2362459546925567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27648/60000][Iteration 2092][Wall Clock 203.122480327s] Trained 128 records in 0.086924572 seconds. Throughput is 1472.541 records/second. Loss is 2.1149282. Sequentialb692dd65's hyper parameters: Current learning rate is 3.235198964736331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27776/60000][Iteration 2093][Wall Clock 203.212242665s] Trained 128 records in 0.089762338 seconds. Throughput is 1425.9878 records/second. Loss is 2.101904. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2341526520051744E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:46 INFO  DistriOptimizer$:408 - [Epoch 5 27904/60000][Iteration 2094][Wall Clock 203.296949721s] Trained 128 records in 0.084707056 seconds. Throughput is 1511.0901 records/second. Loss is 2.1319184. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2331070158422246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28032/60000][Iteration 2095][Wall Clock 203.384132202s] Trained 128 records in 0.087182481 seconds. Throughput is 1468.1848 records/second. Loss is 2.1223023. Sequentialb692dd65's hyper parameters: Current learning rate is 3.232062055591468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28160/60000][Iteration 2096][Wall Clock 203.481392265s] Trained 128 records in 0.097260063 seconds. Throughput is 1316.0592 records/second. Loss is 2.1275873. Sequentialb692dd65's hyper parameters: Current learning rate is 3.231017770597738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28288/60000][Iteration 2097][Wall Clock 203.568208605s] Trained 128 records in 0.08681634 seconds. Throughput is 1474.3768 records/second. Loss is 2.1240013. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2299741602067185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28416/60000][Iteration 2098][Wall Clock 203.654783081s] Trained 128 records in 0.086574476 seconds. Throughput is 1478.4958 records/second. Loss is 2.1160436. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2289312237649337E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28544/60000][Iteration 2099][Wall Clock 203.750101488s] Trained 128 records in 0.095318407 seconds. Throughput is 1342.8676 records/second. Loss is 2.1368773. Sequentialb692dd65's hyper parameters: Current learning rate is 3.227888960619755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28672/60000][Iteration 2100][Wall Clock 203.834322536s] Trained 128 records in 0.084221048 seconds. Throughput is 1519.81 records/second. Loss is 2.1252513. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2268473701193933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28800/60000][Iteration 2101][Wall Clock 203.921705854s] Trained 128 records in 0.087383318 seconds. Throughput is 1464.8105 records/second. Loss is 2.1336324. Sequentialb692dd65's hyper parameters: Current learning rate is 3.225806451612903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 28928/60000][Iteration 2102][Wall Clock 204.006133808s] Trained 128 records in 0.084427954 seconds. Throughput is 1516.0856 records/second. Loss is 2.1204984. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2247662044501777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 29056/60000][Iteration 2103][Wall Clock 204.092195738s] Trained 128 records in 0.08606193 seconds. Throughput is 1487.301 records/second. Loss is 2.0993657. Sequentialb692dd65's hyper parameters: Current learning rate is 3.223726627981947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 29184/60000][Iteration 2104][Wall Clock 204.17760665s] Trained 128 records in 0.085410912 seconds. Throughput is 1498.6375 records/second. Loss is 2.1474967. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2226877215597806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 29312/60000][Iteration 2105][Wall Clock 204.263471889s] Trained 128 records in 0.085865239 seconds. Throughput is 1490.708 records/second. Loss is 2.1154668. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2216494845360824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:47 INFO  DistriOptimizer$:408 - [Epoch 5 29440/60000][Iteration 2106][Wall Clock 204.349882525s] Trained 128 records in 0.086410636 seconds. Throughput is 1481.2992 records/second. Loss is 2.116312. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2206119162640903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 29568/60000][Iteration 2107][Wall Clock 204.435671001s] Trained 128 records in 0.085788476 seconds. Throughput is 1492.042 records/second. Loss is 2.1358857. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2195750160978755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 29696/60000][Iteration 2108][Wall Clock 204.525258799s] Trained 128 records in 0.089587798 seconds. Throughput is 1428.766 records/second. Loss is 2.1217206. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2185387833923396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 29824/60000][Iteration 2109][Wall Clock 204.620084356s] Trained 128 records in 0.094825557 seconds. Throughput is 1349.847 records/second. Loss is 2.101307. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2175032175032174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 29952/60000][Iteration 2110][Wall Clock 204.706730999s] Trained 128 records in 0.086646643 seconds. Throughput is 1477.2643 records/second. Loss is 2.1066983. Sequentialb692dd65's hyper parameters: Current learning rate is 3.21646831778707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30080/60000][Iteration 2111][Wall Clock 204.795541625s] Trained 128 records in 0.088810626 seconds. Throughput is 1441.269 records/second. Loss is 2.126173. Sequentialb692dd65's hyper parameters: Current learning rate is 3.215434083601286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30208/60000][Iteration 2112][Wall Clock 204.882020169s] Trained 128 records in 0.086478544 seconds. Throughput is 1480.1359 records/second. Loss is 2.1185215. Sequentialb692dd65's hyper parameters: Current learning rate is 3.214400514304082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30336/60000][Iteration 2113][Wall Clock 204.9821573s] Trained 128 records in 0.100137131 seconds. Throughput is 1278.2472 records/second. Loss is 2.1103597. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2133676092544985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30464/60000][Iteration 2114][Wall Clock 205.064821309s] Trained 128 records in 0.082664009 seconds. Throughput is 1548.4369 records/second. Loss is 2.0857952. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2123353678124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30592/60000][Iteration 2115][Wall Clock 205.156602075s] Trained 128 records in 0.091780766 seconds. Throughput is 1394.6277 records/second. Loss is 2.1269538. Sequentialb692dd65's hyper parameters: Current learning rate is 3.211303789338472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30720/60000][Iteration 2116][Wall Clock 205.242481367s] Trained 128 records in 0.085879292 seconds. Throughput is 1490.4641 records/second. Loss is 2.1081517. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2102728731942215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:48 INFO  DistriOptimizer$:408 - [Epoch 5 30848/60000][Iteration 2117][Wall Clock 205.330706721s] Trained 128 records in 0.088225354 seconds. Throughput is 1450.8301 records/second. Loss is 2.1369011. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2092426187419767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 30976/60000][Iteration 2118][Wall Clock 205.417603839s] Trained 128 records in 0.086897118 seconds. Throughput is 1473.0062 records/second. Loss is 2.096441. Sequentialb692dd65's hyper parameters: Current learning rate is 3.208213025344883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31104/60000][Iteration 2119][Wall Clock 205.503460944s] Trained 128 records in 0.085857105 seconds. Throughput is 1490.8492 records/second. Loss is 2.1279702. Sequentialb692dd65's hyper parameters: Current learning rate is 3.207184092366902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31232/60000][Iteration 2120][Wall Clock 205.590659029s] Trained 128 records in 0.087198085 seconds. Throughput is 1467.9221 records/second. Loss is 2.1097453. Sequentialb692dd65's hyper parameters: Current learning rate is 3.206155819172812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31360/60000][Iteration 2121][Wall Clock 205.685053878s] Trained 128 records in 0.094394849 seconds. Throughput is 1356.0062 records/second. Loss is 2.1224709. Sequentialb692dd65's hyper parameters: Current learning rate is 3.205128205128205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31488/60000][Iteration 2122][Wall Clock 205.769988126s] Trained 128 records in 0.084934248 seconds. Throughput is 1507.0481 records/second. Loss is 2.0866773. Sequentialb692dd65's hyper parameters: Current learning rate is 3.204101249599487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31616/60000][Iteration 2123][Wall Clock 205.859111182s] Trained 128 records in 0.089123056 seconds. Throughput is 1436.2164 records/second. Loss is 2.1027129. Sequentialb692dd65's hyper parameters: Current learning rate is 3.203074951953876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31744/60000][Iteration 2124][Wall Clock 205.949309676s] Trained 128 records in 0.090198494 seconds. Throughput is 1419.0924 records/second. Loss is 2.1106815. Sequentialb692dd65's hyper parameters: Current learning rate is 3.202049311559398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 31872/60000][Iteration 2125][Wall Clock 206.035383668s] Trained 128 records in 0.086073992 seconds. Throughput is 1487.0927 records/second. Loss is 2.1146638. Sequentialb692dd65's hyper parameters: Current learning rate is 3.201024327784891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 32000/60000][Iteration 2126][Wall Clock 206.122369133s] Trained 128 records in 0.086985465 seconds. Throughput is 1471.5103 records/second. Loss is 2.1039505. Sequentialb692dd65's hyper parameters: Current learning rate is 3.2E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 32128/60000][Iteration 2127][Wall Clock 206.206984986s] Trained 128 records in 0.084615853 seconds. Throughput is 1512.7189 records/second. Loss is 2.124249. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1989763275751764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:49 INFO  DistriOptimizer$:408 - [Epoch 5 32256/60000][Iteration 2128][Wall Clock 206.296312843s] Trained 128 records in 0.089327857 seconds. Throughput is 1432.9237 records/second. Loss is 2.1230814. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1979533098816753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 32384/60000][Iteration 2129][Wall Clock 206.386971017s] Trained 128 records in 0.090658174 seconds. Throughput is 1411.897 records/second. Loss is 2.1340504. Sequentialb692dd65's hyper parameters: Current learning rate is 3.19693094629156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 32512/60000][Iteration 2130][Wall Clock 206.476071117s] Trained 128 records in 0.0891001 seconds. Throughput is 1436.5865 records/second. Loss is 2.1071317. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1959092361776926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 32640/60000][Iteration 2131][Wall Clock 206.561907469s] Trained 128 records in 0.085836352 seconds. Throughput is 1491.2097 records/second. Loss is 2.097505. Sequentialb692dd65's hyper parameters: Current learning rate is 3.194888178913738E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 32768/60000][Iteration 2132][Wall Clock 206.653466241s] Trained 128 records in 0.091558772 seconds. Throughput is 1398.0092 records/second. Loss is 2.1197348. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1938677738741617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 32896/60000][Iteration 2133][Wall Clock 206.755106569s] Trained 128 records in 0.101640328 seconds. Throughput is 1259.3427 records/second. Loss is 2.111465. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1928480204342275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33024/60000][Iteration 2134][Wall Clock 206.84380104s] Trained 128 records in 0.088694471 seconds. Throughput is 1443.1565 records/second. Loss is 2.1151297. Sequentialb692dd65's hyper parameters: Current learning rate is 3.191828917969997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33152/60000][Iteration 2135][Wall Clock 206.931888027s] Trained 128 records in 0.088086987 seconds. Throughput is 1453.1091 records/second. Loss is 2.1257193. Sequentialb692dd65's hyper parameters: Current learning rate is 3.190810465858328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33280/60000][Iteration 2136][Wall Clock 207.019171407s] Trained 128 records in 0.08728338 seconds. Throughput is 1466.4877 records/second. Loss is 2.134783. Sequentialb692dd65's hyper parameters: Current learning rate is 3.189792663476874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33408/60000][Iteration 2137][Wall Clock 207.107331308s] Trained 128 records in 0.088159901 seconds. Throughput is 1451.9072 records/second. Loss is 2.1317647. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1887755102040814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33536/60000][Iteration 2138][Wall Clock 207.195798757s] Trained 128 records in 0.088467449 seconds. Throughput is 1446.8599 records/second. Loss is 2.135295. Sequentialb692dd65's hyper parameters: Current learning rate is 3.18775900541919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:50 INFO  DistriOptimizer$:408 - [Epoch 5 33664/60000][Iteration 2139][Wall Clock 207.289180743s] Trained 128 records in 0.093381986 seconds. Throughput is 1370.714 records/second. Loss is 2.1068528. Sequentialb692dd65's hyper parameters: Current learning rate is 3.186743148502231E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 33792/60000][Iteration 2140][Wall Clock 207.370621856s] Trained 128 records in 0.081441113 seconds. Throughput is 1571.6877 records/second. Loss is 2.1244264. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1857279388340236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 33920/60000][Iteration 2141][Wall Clock 207.454876285s] Trained 128 records in 0.084254429 seconds. Throughput is 1519.208 records/second. Loss is 2.1247737. Sequentialb692dd65's hyper parameters: Current learning rate is 3.184713375796178E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34048/60000][Iteration 2142][Wall Clock 207.541141101s] Trained 128 records in 0.086264816 seconds. Throughput is 1483.803 records/second. Loss is 2.1163068. Sequentialb692dd65's hyper parameters: Current learning rate is 3.183699458771092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34176/60000][Iteration 2143][Wall Clock 207.628790776s] Trained 128 records in 0.087649675 seconds. Throughput is 1460.3591 records/second. Loss is 2.128904. Sequentialb692dd65's hyper parameters: Current learning rate is 3.182686187141948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34304/60000][Iteration 2144][Wall Clock 207.713413518s] Trained 128 records in 0.084622742 seconds. Throughput is 1512.5958 records/second. Loss is 2.111459. Sequentialb692dd65's hyper parameters: Current learning rate is 3.181673560292714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34432/60000][Iteration 2145][Wall Clock 207.797941179s] Trained 128 records in 0.084527661 seconds. Throughput is 1514.2971 records/second. Loss is 2.1226861. Sequentialb692dd65's hyper parameters: Current learning rate is 3.180661577608142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34560/60000][Iteration 2146][Wall Clock 207.890804369s] Trained 128 records in 0.09286319 seconds. Throughput is 1378.3718 records/second. Loss is 2.1345348. Sequentialb692dd65's hyper parameters: Current learning rate is 3.179650238473768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34688/60000][Iteration 2147][Wall Clock 207.970800987s] Trained 128 records in 0.079996618 seconds. Throughput is 1600.0677 records/second. Loss is 2.1135268. Sequentialb692dd65's hyper parameters: Current learning rate is 3.178639542275906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34816/60000][Iteration 2148][Wall Clock 208.055539408s] Trained 128 records in 0.084738421 seconds. Throughput is 1510.5309 records/second. Loss is 2.1079688. Sequentialb692dd65's hyper parameters: Current learning rate is 3.177629488401652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 34944/60000][Iteration 2149][Wall Clock 208.142514383s] Trained 128 records in 0.086974975 seconds. Throughput is 1471.6876 records/second. Loss is 2.111771. Sequentialb692dd65's hyper parameters: Current learning rate is 3.176620076238882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 35072/60000][Iteration 2150][Wall Clock 208.231389119s] Trained 128 records in 0.088874736 seconds. Throughput is 1440.2294 records/second. Loss is 2.097822. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1756113051762465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:51 INFO  DistriOptimizer$:408 - [Epoch 5 35200/60000][Iteration 2151][Wall Clock 208.317145013s] Trained 128 records in 0.085755894 seconds. Throughput is 1492.6088 records/second. Loss is 2.1025076. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1746031746031746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35328/60000][Iteration 2152][Wall Clock 208.402614675s] Trained 128 records in 0.085469662 seconds. Throughput is 1497.6074 records/second. Loss is 2.094656. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1735956839098697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35456/60000][Iteration 2153][Wall Clock 208.488182739s] Trained 128 records in 0.085568064 seconds. Throughput is 1495.8853 records/second. Loss is 2.1175437. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1725888324873094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35584/60000][Iteration 2154][Wall Clock 208.573948007s] Trained 128 records in 0.085765268 seconds. Throughput is 1492.4457 records/second. Loss is 2.120175. Sequentialb692dd65's hyper parameters: Current learning rate is 3.171582619727244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35712/60000][Iteration 2155][Wall Clock 208.660105837s] Trained 128 records in 0.08615783 seconds. Throughput is 1485.6456 records/second. Loss is 2.1033285. Sequentialb692dd65's hyper parameters: Current learning rate is 3.170577045022194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35840/60000][Iteration 2156][Wall Clock 208.744551079s] Trained 128 records in 0.084445242 seconds. Throughput is 1515.7751 records/second. Loss is 2.119911. Sequentialb692dd65's hyper parameters: Current learning rate is 3.169572107765451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 35968/60000][Iteration 2157][Wall Clock 208.832729581s] Trained 128 records in 0.088178502 seconds. Throughput is 1451.601 records/second. Loss is 2.1112285. Sequentialb692dd65's hyper parameters: Current learning rate is 3.168567807351077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 36096/60000][Iteration 2158][Wall Clock 208.920102071s] Trained 128 records in 0.08737249 seconds. Throughput is 1464.9921 records/second. Loss is 2.1002781. Sequentialb692dd65's hyper parameters: Current learning rate is 3.167564143173899E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 36224/60000][Iteration 2159][Wall Clock 209.005804709s] Trained 128 records in 0.085702638 seconds. Throughput is 1493.5364 records/second. Loss is 2.117357. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1665611146295124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 36352/60000][Iteration 2160][Wall Clock 209.091689063s] Trained 128 records in 0.085884354 seconds. Throughput is 1490.3762 records/second. Loss is 2.1110675. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1655587211142766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 36480/60000][Iteration 2161][Wall Clock 209.180493904s] Trained 128 records in 0.088804841 seconds. Throughput is 1441.3629 records/second. Loss is 2.1075487. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1645569620253165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:52 INFO  DistriOptimizer$:408 - [Epoch 5 36608/60000][Iteration 2162][Wall Clock 209.26600751s] Trained 128 records in 0.085513606 seconds. Throughput is 1496.8378 records/second. Loss is 2.1012912. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1635558367605187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 36736/60000][Iteration 2163][Wall Clock 209.355114078s] Trained 128 records in 0.089106568 seconds. Throughput is 1436.4822 records/second. Loss is 2.1120849. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1625553447185326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 36864/60000][Iteration 2164][Wall Clock 209.456185485s] Trained 128 records in 0.101071407 seconds. Throughput is 1266.4313 records/second. Loss is 2.1239402. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1615554852987667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 36992/60000][Iteration 2165][Wall Clock 209.541744393s] Trained 128 records in 0.085558908 seconds. Throughput is 1496.0453 records/second. Loss is 2.1063733. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1605562579013904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37120/60000][Iteration 2166][Wall Clock 209.627339796s] Trained 128 records in 0.085595403 seconds. Throughput is 1495.4073 records/second. Loss is 2.1201637. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1595576619273305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37248/60000][Iteration 2167][Wall Clock 209.709231652s] Trained 128 records in 0.081891856 seconds. Throughput is 1563.037 records/second. Loss is 2.130788. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1585596967782694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37376/60000][Iteration 2168][Wall Clock 209.799182684s] Trained 128 records in 0.089951032 seconds. Throughput is 1422.9965 records/second. Loss is 2.0882418. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1575623618566466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37504/60000][Iteration 2169][Wall Clock 209.886049313s] Trained 128 records in 0.086866629 seconds. Throughput is 1473.5232 records/second. Loss is 2.112059. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1565656565656563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37632/60000][Iteration 2170][Wall Clock 209.970853624s] Trained 128 records in 0.084804311 seconds. Throughput is 1509.3572 records/second. Loss is 2.1078362. Sequentialb692dd65's hyper parameters: Current learning rate is 3.155569580309246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37760/60000][Iteration 2171][Wall Clock 210.0543235s] Trained 128 records in 0.083469876 seconds. Throughput is 1533.4874 records/second. Loss is 2.114602. Sequentialb692dd65's hyper parameters: Current learning rate is 3.154574132492114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 37888/60000][Iteration 2172][Wall Clock 210.145189873s] Trained 128 records in 0.090866373 seconds. Throughput is 1408.662 records/second. Loss is 2.1220992. Sequentialb692dd65's hyper parameters: Current learning rate is 3.15357931251971E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 38016/60000][Iteration 2173][Wall Clock 210.231345606s] Trained 128 records in 0.086155733 seconds. Throughput is 1485.6818 records/second. Loss is 2.1006234. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1525851197982345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:53 INFO  DistriOptimizer$:408 - [Epoch 5 38144/60000][Iteration 2174][Wall Clock 210.317232879s] Trained 128 records in 0.085887273 seconds. Throughput is 1490.3256 records/second. Loss is 2.1182334. Sequentialb692dd65's hyper parameters: Current learning rate is 3.151591553734636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38272/60000][Iteration 2175][Wall Clock 210.409947299s] Trained 128 records in 0.09271442 seconds. Throughput is 1380.5835 records/second. Loss is 2.08854. Sequentialb692dd65's hyper parameters: Current learning rate is 3.15059861373661E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38400/60000][Iteration 2176][Wall Clock 210.496862711s] Trained 128 records in 0.086915412 seconds. Throughput is 1472.6963 records/second. Loss is 2.1063595. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1496062992125983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38528/60000][Iteration 2177][Wall Clock 210.58457694s] Trained 128 records in 0.087714229 seconds. Throughput is 1459.2843 records/second. Loss is 2.0995545. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1486146095717883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38656/60000][Iteration 2178][Wall Clock 210.675174503s] Trained 128 records in 0.090597563 seconds. Throughput is 1412.8416 records/second. Loss is 2.1215045. Sequentialb692dd65's hyper parameters: Current learning rate is 3.147623544224111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38784/60000][Iteration 2179][Wall Clock 210.760457613s] Trained 128 records in 0.08528311 seconds. Throughput is 1500.8834 records/second. Loss is 2.114719. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1466331025802394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 38912/60000][Iteration 2180][Wall Clock 210.850911962s] Trained 128 records in 0.090454349 seconds. Throughput is 1415.0785 records/second. Loss is 2.0946043. Sequentialb692dd65's hyper parameters: Current learning rate is 3.145643284051589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 39040/60000][Iteration 2181][Wall Clock 210.939100703s] Trained 128 records in 0.088188741 seconds. Throughput is 1451.4325 records/second. Loss is 2.09798. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1446540880503143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 39168/60000][Iteration 2182][Wall Clock 211.026010984s] Trained 128 records in 0.086910281 seconds. Throughput is 1472.7832 records/second. Loss is 2.1279876. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1436655139893113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 39296/60000][Iteration 2183][Wall Clock 211.112268306s] Trained 128 records in 0.086257322 seconds. Throughput is 1483.932 records/second. Loss is 2.092759. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1426775612822125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 39424/60000][Iteration 2184][Wall Clock 211.198136136s] Trained 128 records in 0.08586783 seconds. Throughput is 1490.6631 records/second. Loss is 2.0621448. Sequentialb692dd65's hyper parameters: Current learning rate is 3.141690229343387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:54 INFO  DistriOptimizer$:408 - [Epoch 5 39552/60000][Iteration 2185][Wall Clock 211.285554673s] Trained 128 records in 0.087418537 seconds. Throughput is 1464.2203 records/second. Loss is 2.1089382. Sequentialb692dd65's hyper parameters: Current learning rate is 3.14070351758794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 39680/60000][Iteration 2186][Wall Clock 211.372515146s] Trained 128 records in 0.086960473 seconds. Throughput is 1471.9331 records/second. Loss is 2.1110766. Sequentialb692dd65's hyper parameters: Current learning rate is 3.139717425431711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 39808/60000][Iteration 2187][Wall Clock 211.457113017s] Trained 128 records in 0.084597871 seconds. Throughput is 1513.0404 records/second. Loss is 2.1083446. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1387319522912746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 39936/60000][Iteration 2188][Wall Clock 211.546935852s] Trained 128 records in 0.089822835 seconds. Throughput is 1425.0273 records/second. Loss is 2.1112595. Sequentialb692dd65's hyper parameters: Current learning rate is 3.137747097583935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40064/60000][Iteration 2189][Wall Clock 211.643828757s] Trained 128 records in 0.096892905 seconds. Throughput is 1321.0461 records/second. Loss is 2.1082006. Sequentialb692dd65's hyper parameters: Current learning rate is 3.136762860727729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40192/60000][Iteration 2190][Wall Clock 211.724369914s] Trained 128 records in 0.080541157 seconds. Throughput is 1589.2496 records/second. Loss is 2.0828342. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1357792411414236E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40320/60000][Iteration 2191][Wall Clock 211.801253155s] Trained 128 records in 0.076883241 seconds. Throughput is 1664.8622 records/second. Loss is 2.1243002. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1347962382445143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40448/60000][Iteration 2192][Wall Clock 211.887258944s] Trained 128 records in 0.086005789 seconds. Throughput is 1488.2719 records/second. Loss is 2.109745. Sequentialb692dd65's hyper parameters: Current learning rate is 3.133813851457224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40576/60000][Iteration 2193][Wall Clock 211.976857248s] Trained 128 records in 0.089598304 seconds. Throughput is 1428.5984 records/second. Loss is 2.112193. Sequentialb692dd65's hyper parameters: Current learning rate is 3.132832080200501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40704/60000][Iteration 2194][Wall Clock 212.064185836s] Trained 128 records in 0.087328588 seconds. Throughput is 1465.7285 records/second. Loss is 2.1114793. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1318509238960227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40832/60000][Iteration 2195][Wall Clock 212.15282473s] Trained 128 records in 0.088638894 seconds. Throughput is 1444.0613 records/second. Loss is 2.1200166. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1308703819661864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:55 INFO  DistriOptimizer$:408 - [Epoch 5 40960/60000][Iteration 2196][Wall Clock 212.23867426s] Trained 128 records in 0.08584953 seconds. Throughput is 1490.9807 records/second. Loss is 2.0882704. Sequentialb692dd65's hyper parameters: Current learning rate is 3.129890453834116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41088/60000][Iteration 2197][Wall Clock 212.333642264s] Trained 128 records in 0.094968004 seconds. Throughput is 1347.8224 records/second. Loss is 2.1080897. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1289111389236547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41216/60000][Iteration 2198][Wall Clock 212.41421143s] Trained 128 records in 0.080569166 seconds. Throughput is 1588.6971 records/second. Loss is 2.1107972. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1279324366593683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41344/60000][Iteration 2199][Wall Clock 212.503497022s] Trained 128 records in 0.089285592 seconds. Throughput is 1433.602 records/second. Loss is 2.0937629. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1269543464665416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41472/60000][Iteration 2200][Wall Clock 212.591280535s] Trained 128 records in 0.087783513 seconds. Throughput is 1458.1326 records/second. Loss is 2.1167326. Sequentialb692dd65's hyper parameters: Current learning rate is 3.125976867771179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41600/60000][Iteration 2201][Wall Clock 212.679370575s] Trained 128 records in 0.08809004 seconds. Throughput is 1453.0587 records/second. Loss is 2.1086395. Sequentialb692dd65's hyper parameters: Current learning rate is 3.125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41728/60000][Iteration 2202][Wall Clock 212.767227539s] Trained 128 records in 0.087856964 seconds. Throughput is 1456.9136 records/second. Loss is 2.1387753. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1240237425804435E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41856/60000][Iteration 2203][Wall Clock 212.855458486s] Trained 128 records in 0.088230947 seconds. Throughput is 1450.7382 records/second. Loss is 2.1273723. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1230480949406624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 41984/60000][Iteration 2204][Wall Clock 212.943455262s] Trained 128 records in 0.087996776 seconds. Throughput is 1454.5988 records/second. Loss is 2.0988853. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1220730565095225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 42112/60000][Iteration 2205][Wall Clock 213.0324871s] Trained 128 records in 0.089031838 seconds. Throughput is 1437.688 records/second. Loss is 2.0933158. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1210986267166043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 42240/60000][Iteration 2206][Wall Clock 213.119283177s] Trained 128 records in 0.086796077 seconds. Throughput is 1474.7211 records/second. Loss is 2.1287818. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1201248049921997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 42368/60000][Iteration 2207][Wall Clock 213.205016541s] Trained 128 records in 0.085733364 seconds. Throughput is 1493.0011 records/second. Loss is 2.104392. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1191515907673113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:56 INFO  DistriOptimizer$:408 - [Epoch 5 42496/60000][Iteration 2208][Wall Clock 213.294082866s] Trained 128 records in 0.089066325 seconds. Throughput is 1437.1312 records/second. Loss is 2.0926065. Sequentialb692dd65's hyper parameters: Current learning rate is 3.118178983473652E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 42624/60000][Iteration 2209][Wall Clock 213.381391216s] Trained 128 records in 0.08730835 seconds. Throughput is 1466.0682 records/second. Loss is 2.0864496. Sequentialb692dd65's hyper parameters: Current learning rate is 3.117206982543641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 42752/60000][Iteration 2210][Wall Clock 213.466424495s] Trained 128 records in 0.085033279 seconds. Throughput is 1505.293 records/second. Loss is 2.110804. Sequentialb692dd65's hyper parameters: Current learning rate is 3.116235587410408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 42880/60000][Iteration 2211][Wall Clock 213.557460264s] Trained 128 records in 0.091035769 seconds. Throughput is 1406.0408 records/second. Loss is 2.0974953. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1152647975077883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43008/60000][Iteration 2212][Wall Clock 213.644395877s] Trained 128 records in 0.086935613 seconds. Throughput is 1472.3541 records/second. Loss is 2.0889943. Sequentialb692dd65's hyper parameters: Current learning rate is 3.114294612270321E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43136/60000][Iteration 2213][Wall Clock 213.733469681s] Trained 128 records in 0.089073804 seconds. Throughput is 1437.0105 records/second. Loss is 2.1234019. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1133250311332503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43264/60000][Iteration 2214][Wall Clock 213.818034815s] Trained 128 records in 0.084565134 seconds. Throughput is 1513.6262 records/second. Loss is 2.1014192. Sequentialb692dd65's hyper parameters: Current learning rate is 3.112356053532524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43392/60000][Iteration 2215][Wall Clock 213.920071192s] Trained 128 records in 0.102036377 seconds. Throughput is 1254.4546 records/second. Loss is 2.095927. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1113876789047915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43520/60000][Iteration 2216][Wall Clock 213.998281993s] Trained 128 records in 0.078210801 seconds. Throughput is 1636.6025 records/second. Loss is 2.1048784. Sequentialb692dd65's hyper parameters: Current learning rate is 3.110419906687403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43648/60000][Iteration 2217][Wall Clock 214.081541012s] Trained 128 records in 0.083259019 seconds. Throughput is 1537.3711 records/second. Loss is 2.1227677. Sequentialb692dd65's hyper parameters: Current learning rate is 3.109452736318408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43776/60000][Iteration 2218][Wall Clock 214.169121703s] Trained 128 records in 0.087580691 seconds. Throughput is 1461.5094 records/second. Loss is 2.0810382. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1084861672365556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:57 INFO  DistriOptimizer$:408 - [Epoch 5 43904/60000][Iteration 2219][Wall Clock 214.259500807s] Trained 128 records in 0.090379104 seconds. Throughput is 1416.2566 records/second. Loss is 2.1091123. Sequentialb692dd65's hyper parameters: Current learning rate is 3.107520198881293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44032/60000][Iteration 2220][Wall Clock 214.347892178s] Trained 128 records in 0.088391371 seconds. Throughput is 1448.1051 records/second. Loss is 2.1130073. Sequentialb692dd65's hyper parameters: Current learning rate is 3.106554830692762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44160/60000][Iteration 2221][Wall Clock 214.432762352s] Trained 128 records in 0.084870174 seconds. Throughput is 1508.1859 records/second. Loss is 2.0953958. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1055900621118014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44288/60000][Iteration 2222][Wall Clock 214.518456098s] Trained 128 records in 0.085693746 seconds. Throughput is 1493.6913 records/second. Loss is 2.119117. Sequentialb692dd65's hyper parameters: Current learning rate is 3.104625892579944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44416/60000][Iteration 2223][Wall Clock 214.609898995s] Trained 128 records in 0.091442897 seconds. Throughput is 1399.7806 records/second. Loss is 2.0836608. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1036623215394165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44544/60000][Iteration 2224][Wall Clock 214.696566807s] Trained 128 records in 0.086667812 seconds. Throughput is 1476.9036 records/second. Loss is 2.1171298. Sequentialb692dd65's hyper parameters: Current learning rate is 3.102699348433137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44672/60000][Iteration 2225][Wall Clock 214.78289005s] Trained 128 records in 0.086323243 seconds. Throughput is 1482.7987 records/second. Loss is 2.0730515. Sequentialb692dd65's hyper parameters: Current learning rate is 3.1017369727047146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44800/60000][Iteration 2226][Wall Clock 214.871779226s] Trained 128 records in 0.088889176 seconds. Throughput is 1439.9954 records/second. Loss is 2.1207225. Sequentialb692dd65's hyper parameters: Current learning rate is 3.10077519379845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 44928/60000][Iteration 2227][Wall Clock 214.958714352s] Trained 128 records in 0.086935126 seconds. Throughput is 1472.3623 records/second. Loss is 2.122164. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0998140111593303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 45056/60000][Iteration 2228][Wall Clock 215.047124852s] Trained 128 records in 0.0884105 seconds. Throughput is 1447.7919 records/second. Loss is 2.099154. Sequentialb692dd65's hyper parameters: Current learning rate is 3.098853424233034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 45184/60000][Iteration 2229][Wall Clock 215.133220893s] Trained 128 records in 0.086096041 seconds. Throughput is 1486.7118 records/second. Loss is 2.1035714. Sequentialb692dd65's hyper parameters: Current learning rate is 3.097893432465923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:58 INFO  DistriOptimizer$:408 - [Epoch 5 45312/60000][Iteration 2230][Wall Clock 215.220984309s] Trained 128 records in 0.087763416 seconds. Throughput is 1458.4666 records/second. Loss is 2.0779524. Sequentialb692dd65's hyper parameters: Current learning rate is 3.096934035305048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 45440/60000][Iteration 2231][Wall Clock 215.308236645s] Trained 128 records in 0.087252336 seconds. Throughput is 1467.0095 records/second. Loss is 2.0909214. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0959752321981426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 45568/60000][Iteration 2232][Wall Clock 215.397855765s] Trained 128 records in 0.08961912 seconds. Throughput is 1428.2666 records/second. Loss is 2.1174026. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0950170225936243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 45696/60000][Iteration 2233][Wall Clock 215.487868492s] Trained 128 records in 0.090012727 seconds. Throughput is 1422.0211 records/second. Loss is 2.1078587. Sequentialb692dd65's hyper parameters: Current learning rate is 3.094059405940594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 45824/60000][Iteration 2234][Wall Clock 215.574085664s] Trained 128 records in 0.086217172 seconds. Throughput is 1484.623 records/second. Loss is 2.0754976. Sequentialb692dd65's hyper parameters: Current learning rate is 3.093102381688834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 45952/60000][Iteration 2235][Wall Clock 215.661344891s] Trained 128 records in 0.087259227 seconds. Throughput is 1466.8936 records/second. Loss is 2.0971384. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0921459492888067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46080/60000][Iteration 2236][Wall Clock 215.748187193s] Trained 128 records in 0.086842302 seconds. Throughput is 1473.9362 records/second. Loss is 2.0879712. Sequentialb692dd65's hyper parameters: Current learning rate is 3.091190108191654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46208/60000][Iteration 2237][Wall Clock 215.83546107s] Trained 128 records in 0.087273877 seconds. Throughput is 1466.6475 records/second. Loss is 2.1163418. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0902348578491963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46336/60000][Iteration 2238][Wall Clock 215.921429541s] Trained 128 records in 0.085968471 seconds. Throughput is 1488.918 records/second. Loss is 2.0896802. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0892801977139327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46464/60000][Iteration 2239][Wall Clock 216.007829205s] Trained 128 records in 0.086399664 seconds. Throughput is 1481.4872 records/second. Loss is 2.0888312. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0883261272390367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46592/60000][Iteration 2240][Wall Clock 216.104735535s] Trained 128 records in 0.09690633 seconds. Throughput is 1320.8632 records/second. Loss is 2.096651. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0873726458783575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46720/60000][Iteration 2241][Wall Clock 216.187271612s] Trained 128 records in 0.082536077 seconds. Throughput is 1550.8369 records/second. Loss is 2.0904522. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0864197530864197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:49:59 INFO  DistriOptimizer$:408 - [Epoch 5 46848/60000][Iteration 2242][Wall Clock 216.275009993s] Trained 128 records in 0.087738381 seconds. Throughput is 1458.8827 records/second. Loss is 2.1067004. Sequentialb692dd65's hyper parameters: Current learning rate is 3.08546744831842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 46976/60000][Iteration 2243][Wall Clock 216.357445846s] Trained 128 records in 0.082435853 seconds. Throughput is 1552.7224 records/second. Loss is 2.1425023. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0845157310302283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47104/60000][Iteration 2244][Wall Clock 216.442207914s] Trained 128 records in 0.084762068 seconds. Throughput is 1510.1095 records/second. Loss is 2.105933. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0835646006783845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47232/60000][Iteration 2245][Wall Clock 216.529559851s] Trained 128 records in 0.087351937 seconds. Throughput is 1465.3367 records/second. Loss is 2.1140246. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0826140567200987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47360/60000][Iteration 2246][Wall Clock 216.615921684s] Trained 128 records in 0.086361833 seconds. Throughput is 1482.1362 records/second. Loss is 2.0752122. Sequentialb692dd65's hyper parameters: Current learning rate is 3.081664098613251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47488/60000][Iteration 2247][Wall Clock 216.706906413s] Trained 128 records in 0.090984729 seconds. Throughput is 1406.8295 records/second. Loss is 2.0895455. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0807147258163895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47616/60000][Iteration 2248][Wall Clock 216.803838525s] Trained 128 records in 0.096932112 seconds. Throughput is 1320.5118 records/second. Loss is 2.1203773. Sequentialb692dd65's hyper parameters: Current learning rate is 3.079765937788728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47744/60000][Iteration 2249][Wall Clock 216.900263289s] Trained 128 records in 0.096424764 seconds. Throughput is 1327.4598 records/second. Loss is 2.1083806. Sequentialb692dd65's hyper parameters: Current learning rate is 3.078817733990148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 47872/60000][Iteration 2250][Wall Clock 216.987960385s] Trained 128 records in 0.087697096 seconds. Throughput is 1459.5695 records/second. Loss is 2.1223917. Sequentialb692dd65's hyper parameters: Current learning rate is 3.077870113881194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 48000/60000][Iteration 2251][Wall Clock 217.074817921s] Trained 128 records in 0.086857536 seconds. Throughput is 1473.6776 records/second. Loss is 2.0999758. Sequentialb692dd65's hyper parameters: Current learning rate is 3.076923076923077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 48128/60000][Iteration 2252][Wall Clock 217.16240212s] Trained 128 records in 0.087584199 seconds. Throughput is 1461.4508 records/second. Loss is 2.074662. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0759766225776686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:00 INFO  DistriOptimizer$:408 - [Epoch 5 48256/60000][Iteration 2253][Wall Clock 217.248372856s] Trained 128 records in 0.085970736 seconds. Throughput is 1488.8787 records/second. Loss is 2.0809891. Sequentialb692dd65's hyper parameters: Current learning rate is 3.075030750307503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 48384/60000][Iteration 2254][Wall Clock 217.333041903s] Trained 128 records in 0.084669047 seconds. Throughput is 1511.7686 records/second. Loss is 2.0821068. Sequentialb692dd65's hyper parameters: Current learning rate is 3.074085459575776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 48512/60000][Iteration 2255][Wall Clock 217.419733874s] Trained 128 records in 0.086691971 seconds. Throughput is 1476.4921 records/second. Loss is 2.0847056. Sequentialb692dd65's hyper parameters: Current learning rate is 3.073140749846343E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 48640/60000][Iteration 2256][Wall Clock 217.504812421s] Trained 128 records in 0.085078547 seconds. Throughput is 1504.4921 records/second. Loss is 2.1210124. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0721966205837174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 48768/60000][Iteration 2257][Wall Clock 217.591541927s] Trained 128 records in 0.086729506 seconds. Throughput is 1475.853 records/second. Loss is 2.0956824. Sequentialb692dd65's hyper parameters: Current learning rate is 3.071253071253071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 48896/60000][Iteration 2258][Wall Clock 217.678148121s] Trained 128 records in 0.086606194 seconds. Throughput is 1477.9542 records/second. Loss is 2.114109. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0703101013202335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49024/60000][Iteration 2259][Wall Clock 217.763266197s] Trained 128 records in 0.085118076 seconds. Throughput is 1503.7933 records/second. Loss is 2.0780587. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0693677102516884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49152/60000][Iteration 2260][Wall Clock 217.848846059s] Trained 128 records in 0.085579862 seconds. Throughput is 1495.679 records/second. Loss is 2.070556. Sequentialb692dd65's hyper parameters: Current learning rate is 3.068425897514575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49280/60000][Iteration 2261][Wall Clock 217.934014583s] Trained 128 records in 0.085168524 seconds. Throughput is 1502.9026 records/second. Loss is 2.081223. Sequentialb692dd65's hyper parameters: Current learning rate is 3.067484662576687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49408/60000][Iteration 2262][Wall Clock 218.019115304s] Trained 128 records in 0.085100721 seconds. Throughput is 1504.1001 records/second. Loss is 2.092213. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0665440049064706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49536/60000][Iteration 2263][Wall Clock 218.110816531s] Trained 128 records in 0.091701227 seconds. Throughput is 1395.8374 records/second. Loss is 2.1257958. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0656039239730225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:01 INFO  DistriOptimizer$:408 - [Epoch 5 49664/60000][Iteration 2264][Wall Clock 218.19741447s] Trained 128 records in 0.086597939 seconds. Throughput is 1478.0952 records/second. Loss is 2.0821648. Sequentialb692dd65's hyper parameters: Current learning rate is 3.064664419246093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 49792/60000][Iteration 2265][Wall Clock 218.281961059s] Trained 128 records in 0.084546589 seconds. Throughput is 1513.9583 records/second. Loss is 2.1034102. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0637254901960784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 49920/60000][Iteration 2266][Wall Clock 218.388457298s] Trained 128 records in 0.106496239 seconds. Throughput is 1201.9204 records/second. Loss is 2.1114626. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0627871362940275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50048/60000][Iteration 2267][Wall Clock 218.474063315s] Trained 128 records in 0.085606017 seconds. Throughput is 1495.222 records/second. Loss is 2.1083384. Sequentialb692dd65's hyper parameters: Current learning rate is 3.061849357011635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50176/60000][Iteration 2268][Wall Clock 218.558813911s] Trained 128 records in 0.084750596 seconds. Throughput is 1510.314 records/second. Loss is 2.110526. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0609121518212427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50304/60000][Iteration 2269][Wall Clock 218.641687784s] Trained 128 records in 0.082873873 seconds. Throughput is 1544.5157 records/second. Loss is 2.0878456. Sequentialb692dd65's hyper parameters: Current learning rate is 3.059975520195838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50432/60000][Iteration 2270][Wall Clock 218.731078519s] Trained 128 records in 0.089390735 seconds. Throughput is 1431.9158 records/second. Loss is 2.094035. Sequentialb692dd65's hyper parameters: Current learning rate is 3.059039461609055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50560/60000][Iteration 2271][Wall Clock 218.816921646s] Trained 128 records in 0.085843127 seconds. Throughput is 1491.092 records/second. Loss is 2.091444. Sequentialb692dd65's hyper parameters: Current learning rate is 3.058103975535168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50688/60000][Iteration 2272][Wall Clock 218.900677601s] Trained 128 records in 0.083755955 seconds. Throughput is 1528.2495 records/second. Loss is 2.1149616. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0571690614490985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50816/60000][Iteration 2273][Wall Clock 218.986004498s] Trained 128 records in 0.085326897 seconds. Throughput is 1500.1132 records/second. Loss is 2.0994. Sequentialb692dd65's hyper parameters: Current learning rate is 3.056234718826406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 50944/60000][Iteration 2274][Wall Clock 219.084171813s] Trained 128 records in 0.098167315 seconds. Throughput is 1303.8964 records/second. Loss is 2.123771. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0553009471432935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 51072/60000][Iteration 2275][Wall Clock 219.171379937s] Trained 128 records in 0.087208124 seconds. Throughput is 1467.7532 records/second. Loss is 2.0984862. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0543677458766036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:02 INFO  DistriOptimizer$:408 - [Epoch 5 51200/60000][Iteration 2276][Wall Clock 219.256270194s] Trained 128 records in 0.084890257 seconds. Throughput is 1507.8291 records/second. Loss is 2.08502. Sequentialb692dd65's hyper parameters: Current learning rate is 3.053435114503817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51328/60000][Iteration 2277][Wall Clock 219.344912266s] Trained 128 records in 0.088642072 seconds. Throughput is 1444.0095 records/second. Loss is 2.0718598. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0525030525030525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51456/60000][Iteration 2278][Wall Clock 219.431373418s] Trained 128 records in 0.086461152 seconds. Throughput is 1480.4337 records/second. Loss is 2.104727. Sequentialb692dd65's hyper parameters: Current learning rate is 3.051571559353067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51584/60000][Iteration 2279][Wall Clock 219.51856359s] Trained 128 records in 0.087190172 seconds. Throughput is 1468.0553 records/second. Loss is 2.1119986. Sequentialb692dd65's hyper parameters: Current learning rate is 3.050640634533252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51712/60000][Iteration 2280][Wall Clock 219.607473949s] Trained 128 records in 0.088910359 seconds. Throughput is 1439.6523 records/second. Loss is 2.0797687. Sequentialb692dd65's hyper parameters: Current learning rate is 3.049710277523635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51840/60000][Iteration 2281][Wall Clock 219.692608448s] Trained 128 records in 0.085134499 seconds. Throughput is 1503.5033 records/second. Loss is 2.1027784. Sequentialb692dd65's hyper parameters: Current learning rate is 3.048780487804878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 51968/60000][Iteration 2282][Wall Clock 219.777545353s] Trained 128 records in 0.084936905 seconds. Throughput is 1507.0011 records/second. Loss is 2.0885313. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0478512648582747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 52096/60000][Iteration 2283][Wall Clock 219.863298557s] Trained 128 records in 0.085753204 seconds. Throughput is 1492.6556 records/second. Loss is 2.0841963. Sequentialb692dd65's hyper parameters: Current learning rate is 3.046922608165753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 52224/60000][Iteration 2284][Wall Clock 219.948759024s] Trained 128 records in 0.085460467 seconds. Throughput is 1497.7686 records/second. Loss is 2.1183605. Sequentialb692dd65's hyper parameters: Current learning rate is 3.045994517209869E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 52352/60000][Iteration 2285][Wall Clock 220.034955589s] Trained 128 records in 0.086196565 seconds. Throughput is 1484.978 records/second. Loss is 2.1099231. Sequentialb692dd65's hyper parameters: Current learning rate is 3.045066991473812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 52480/60000][Iteration 2286][Wall Clock 220.119951526s] Trained 128 records in 0.084995937 seconds. Throughput is 1505.9542 records/second. Loss is 2.097523. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0441400304414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:03 INFO  DistriOptimizer$:408 - [Epoch 5 52608/60000][Iteration 2287][Wall Clock 220.206783232s] Trained 128 records in 0.086831706 seconds. Throughput is 1474.116 records/second. Loss is 2.084215. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0432136335970786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 52736/60000][Iteration 2288][Wall Clock 220.289133925s] Trained 128 records in 0.082350693 seconds. Throughput is 1554.3281 records/second. Loss is 2.1087878. Sequentialb692dd65's hyper parameters: Current learning rate is 3.04228780042592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 52864/60000][Iteration 2289][Wall Clock 220.402550595s] Trained 128 records in 0.11341667 seconds. Throughput is 1128.5819 records/second. Loss is 2.071683. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0413625304136254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 52992/60000][Iteration 2290][Wall Clock 220.521207782s] Trained 128 records in 0.118657187 seconds. Throughput is 1078.7379 records/second. Loss is 2.0956252. Sequentialb692dd65's hyper parameters: Current learning rate is 3.040437823046519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53120/60000][Iteration 2291][Wall Clock 220.617513961s] Trained 128 records in 0.096306179 seconds. Throughput is 1329.0944 records/second. Loss is 2.0856075. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0395136778115504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53248/60000][Iteration 2292][Wall Clock 220.703877064s] Trained 128 records in 0.086363103 seconds. Throughput is 1482.1145 records/second. Loss is 2.095654. Sequentialb692dd65's hyper parameters: Current learning rate is 3.038590094196293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53376/60000][Iteration 2293][Wall Clock 220.78750152s] Trained 128 records in 0.083624456 seconds. Throughput is 1530.6528 records/second. Loss is 2.1037455. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0376670716889426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53504/60000][Iteration 2294][Wall Clock 220.872281882s] Trained 128 records in 0.084780362 seconds. Throughput is 1509.7836 records/second. Loss is 2.0965588. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0367446097783173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53632/60000][Iteration 2295][Wall Clock 220.958935233s] Trained 128 records in 0.086653351 seconds. Throughput is 1477.15 records/second. Loss is 2.0933735. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0358227079538557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53760/60000][Iteration 2296][Wall Clock 221.045551672s] Trained 128 records in 0.086616439 seconds. Throughput is 1477.7794 records/second. Loss is 2.066992. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0349013657056146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 53888/60000][Iteration 2297][Wall Clock 221.131300062s] Trained 128 records in 0.08574839 seconds. Throughput is 1492.7394 records/second. Loss is 2.1013582. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0339805825242716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:04 INFO  DistriOptimizer$:408 - [Epoch 5 54016/60000][Iteration 2298][Wall Clock 221.222277296s] Trained 128 records in 0.090977234 seconds. Throughput is 1406.9453 records/second. Loss is 2.0785203. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0330603579011223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54144/60000][Iteration 2299][Wall Clock 221.3188177s] Trained 128 records in 0.096540404 seconds. Throughput is 1325.8698 records/second. Loss is 2.0946693. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0321406913280777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54272/60000][Iteration 2300][Wall Clock 221.413786831s] Trained 128 records in 0.094969131 seconds. Throughput is 1347.8064 records/second. Loss is 2.1002085. Sequentialb692dd65's hyper parameters: Current learning rate is 3.031221582297666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54400/60000][Iteration 2301][Wall Clock 221.499283963s] Trained 128 records in 0.085497132 seconds. Throughput is 1497.1262 records/second. Loss is 2.1164162. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0303030303030303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54528/60000][Iteration 2302][Wall Clock 221.585391129s] Trained 128 records in 0.086107166 seconds. Throughput is 1486.5198 records/second. Loss is 2.0902004. Sequentialb692dd65's hyper parameters: Current learning rate is 3.029385034837928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54656/60000][Iteration 2303][Wall Clock 221.674271199s] Trained 128 records in 0.08888007 seconds. Throughput is 1440.143 records/second. Loss is 2.087879. Sequentialb692dd65's hyper parameters: Current learning rate is 3.028467595396729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54784/60000][Iteration 2304][Wall Clock 221.758423051s] Trained 128 records in 0.084151852 seconds. Throughput is 1521.0598 records/second. Loss is 2.0873048. Sequentialb692dd65's hyper parameters: Current learning rate is 3.027550711474417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 54912/60000][Iteration 2305][Wall Clock 221.845601163s] Trained 128 records in 0.087178112 seconds. Throughput is 1468.2584 records/second. Loss is 2.0897262. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0266343825665856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 55040/60000][Iteration 2306][Wall Clock 221.931667519s] Trained 128 records in 0.086066356 seconds. Throughput is 1487.2245 records/second. Loss is 2.091978. Sequentialb692dd65's hyper parameters: Current learning rate is 3.02571860816944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 55168/60000][Iteration 2307][Wall Clock 222.016818541s] Trained 128 records in 0.085151022 seconds. Throughput is 1503.2115 records/second. Loss is 2.10837. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0248033877797946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 55296/60000][Iteration 2308][Wall Clock 222.100345272s] Trained 128 records in 0.083526731 seconds. Throughput is 1532.4436 records/second. Loss is 2.0963454. Sequentialb692dd65's hyper parameters: Current learning rate is 3.023888720895071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:05 INFO  DistriOptimizer$:408 - [Epoch 5 55424/60000][Iteration 2309][Wall Clock 222.183091638s] Trained 128 records in 0.082746366 seconds. Throughput is 1546.8958 records/second. Loss is 2.0742877. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0229746070133015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 55552/60000][Iteration 2310][Wall Clock 222.268627988s] Trained 128 records in 0.08553635 seconds. Throughput is 1496.4398 records/second. Loss is 2.1056228. Sequentialb692dd65's hyper parameters: Current learning rate is 3.022061045633122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 55680/60000][Iteration 2311][Wall Clock 222.354452528s] Trained 128 records in 0.08582454 seconds. Throughput is 1491.4149 records/second. Loss is 2.1076956. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0211480362537764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 55808/60000][Iteration 2312][Wall Clock 222.44318339s] Trained 128 records in 0.088730862 seconds. Throughput is 1442.5646 records/second. Loss is 2.1031315. Sequentialb692dd65's hyper parameters: Current learning rate is 3.020235578375113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 55936/60000][Iteration 2313][Wall Clock 222.528942708s] Trained 128 records in 0.085759318 seconds. Throughput is 1492.5492 records/second. Loss is 2.078594. Sequentialb692dd65's hyper parameters: Current learning rate is 3.019323671497585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56064/60000][Iteration 2314][Wall Clock 222.616047895s] Trained 128 records in 0.087105187 seconds. Throughput is 1469.4877 records/second. Loss is 2.0839038. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0184123151222455E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56192/60000][Iteration 2315][Wall Clock 222.70245257s] Trained 128 records in 0.086404675 seconds. Throughput is 1481.4014 records/second. Loss is 2.0874622. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0175015087507544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56320/60000][Iteration 2316][Wall Clock 222.795903317s] Trained 128 records in 0.093450747 seconds. Throughput is 1369.7054 records/second. Loss is 2.109396. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0165912518853697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56448/60000][Iteration 2317][Wall Clock 222.883519132s] Trained 128 records in 0.087615815 seconds. Throughput is 1460.9235 records/second. Loss is 2.110575. Sequentialb692dd65's hyper parameters: Current learning rate is 3.015681544028951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56576/60000][Iteration 2318][Wall Clock 222.965521554s] Trained 128 records in 0.082002422 seconds. Throughput is 1560.9294 records/second. Loss is 2.110143. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0147723846849563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56704/60000][Iteration 2319][Wall Clock 223.04642313s] Trained 128 records in 0.080901576 seconds. Throughput is 1582.1694 records/second. Loss is 2.0790908. Sequentialb692dd65's hyper parameters: Current learning rate is 3.013863773357444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56832/60000][Iteration 2320][Wall Clock 223.133131228s] Trained 128 records in 0.086708098 seconds. Throughput is 1476.2174 records/second. Loss is 2.10707. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0129557095510696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:06 INFO  DistriOptimizer$:408 - [Epoch 5 56960/60000][Iteration 2321][Wall Clock 223.220286604s] Trained 128 records in 0.087155376 seconds. Throughput is 1468.6415 records/second. Loss is 2.0905936. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0120481927710846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57088/60000][Iteration 2322][Wall Clock 223.307788454s] Trained 128 records in 0.08750185 seconds. Throughput is 1462.8262 records/second. Loss is 2.1065774. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0111412225233364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57216/60000][Iteration 2323][Wall Clock 223.392501923s] Trained 128 records in 0.084713469 seconds. Throughput is 1510.9758 records/second. Loss is 2.106393. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0102347983142685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57344/60000][Iteration 2324][Wall Clock 223.476817093s] Trained 128 records in 0.08431517 seconds. Throughput is 1518.1135 records/second. Loss is 2.1205297. Sequentialb692dd65's hyper parameters: Current learning rate is 3.009328919650918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57472/60000][Iteration 2325][Wall Clock 223.577975966s] Trained 128 records in 0.101158873 seconds. Throughput is 1265.3364 records/second. Loss is 2.097562. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0084235860409147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57600/60000][Iteration 2326][Wall Clock 223.666410146s] Trained 128 records in 0.08843418 seconds. Throughput is 1447.4042 records/second. Loss is 2.0908086. Sequentialb692dd65's hyper parameters: Current learning rate is 3.007518796992481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57728/60000][Iteration 2327][Wall Clock 223.751522142s] Trained 128 records in 0.085111996 seconds. Throughput is 1503.9008 records/second. Loss is 2.0944386. Sequentialb692dd65's hyper parameters: Current learning rate is 3.006614552014432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57856/60000][Iteration 2328][Wall Clock 223.846875285s] Trained 128 records in 0.095353143 seconds. Throughput is 1342.3784 records/second. Loss is 2.0865319. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0057108506161706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 57984/60000][Iteration 2329][Wall Clock 223.934309426s] Trained 128 records in 0.087434141 seconds. Throughput is 1463.959 records/second. Loss is 2.1155453. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0048076923076925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 58112/60000][Iteration 2330][Wall Clock 224.022297596s] Trained 128 records in 0.08798817 seconds. Throughput is 1454.7411 records/second. Loss is 2.088461. Sequentialb692dd65's hyper parameters: Current learning rate is 3.0039050765995795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 58240/60000][Iteration 2331][Wall Clock 224.111995048s] Trained 128 records in 0.089697452 seconds. Throughput is 1427.0194 records/second. Loss is 2.0543685. Sequentialb692dd65's hyper parameters: Current learning rate is 3.003003003003003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:07 INFO  DistriOptimizer$:408 - [Epoch 5 58368/60000][Iteration 2332][Wall Clock 224.200403114s] Trained 128 records in 0.088408066 seconds. Throughput is 1447.8317 records/second. Loss is 2.0736191. Sequentialb692dd65's hyper parameters: Current learning rate is 3.002101471029721E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 58496/60000][Iteration 2333][Wall Clock 224.288270036s] Trained 128 records in 0.087866922 seconds. Throughput is 1456.7484 records/second. Loss is 2.0856075. Sequentialb692dd65's hyper parameters: Current learning rate is 3.001200480192077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 58624/60000][Iteration 2334][Wall Clock 224.374482889s] Trained 128 records in 0.086212853 seconds. Throughput is 1484.6974 records/second. Loss is 2.0993485. Sequentialb692dd65's hyper parameters: Current learning rate is 3.000300030003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 58752/60000][Iteration 2335][Wall Clock 224.461753667s] Trained 128 records in 0.087270778 seconds. Throughput is 1466.6993 records/second. Loss is 2.0902207. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9994001199760045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 58880/60000][Iteration 2336][Wall Clock 224.550439347s] Trained 128 records in 0.08868568 seconds. Throughput is 1443.2996 records/second. Loss is 2.0911436. Sequentialb692dd65's hyper parameters: Current learning rate is 2.998500749625188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59008/60000][Iteration 2337][Wall Clock 224.637882247s] Trained 128 records in 0.0874429 seconds. Throughput is 1463.8124 records/second. Loss is 2.0765274. Sequentialb692dd65's hyper parameters: Current learning rate is 2.997601918465228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59136/60000][Iteration 2338][Wall Clock 224.724714628s] Trained 128 records in 0.086832381 seconds. Throughput is 1474.1045 records/second. Loss is 2.0940704. Sequentialb692dd65's hyper parameters: Current learning rate is 2.996703626011387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59264/60000][Iteration 2339][Wall Clock 224.816577136s] Trained 128 records in 0.091862508 seconds. Throughput is 1393.3867 records/second. Loss is 2.0858665. Sequentialb692dd65's hyper parameters: Current learning rate is 2.995805871779509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59392/60000][Iteration 2340][Wall Clock 224.902888791s] Trained 128 records in 0.086311655 seconds. Throughput is 1482.9979 records/second. Loss is 2.1001554. Sequentialb692dd65's hyper parameters: Current learning rate is 2.994908655286014E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59520/60000][Iteration 2341][Wall Clock 225.003893037s] Trained 128 records in 0.101004246 seconds. Throughput is 1267.2734 records/second. Loss is 2.1041062. Sequentialb692dd65's hyper parameters: Current learning rate is 2.994011976047904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59648/60000][Iteration 2342][Wall Clock 225.09392803s] Trained 128 records in 0.090034993 seconds. Throughput is 1421.6694 records/second. Loss is 2.0848322. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9931158335827593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:08 INFO  DistriOptimizer$:408 - [Epoch 5 59776/60000][Iteration 2343][Wall Clock 225.175703667s] Trained 128 records in 0.081775637 seconds. Throughput is 1565.2584 records/second. Loss is 2.0728533. Sequentialb692dd65's hyper parameters: Current learning rate is 2.992220227408737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:09 INFO  DistriOptimizer$:408 - [Epoch 5 59904/60000][Iteration 2344][Wall Clock 225.260919231s] Trained 128 records in 0.085215564 seconds. Throughput is 1502.0731 records/second. Loss is 2.0933785. Sequentialb692dd65's hyper parameters: Current learning rate is 2.991325157044571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:09 INFO  DistriOptimizer$:408 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 225.346893666s] Trained 128 records in 0.085974435 seconds. Throughput is 1488.8147 records/second. Loss is 2.0505686. Sequentialb692dd65's hyper parameters: Current learning rate is 2.99043062200957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:09 INFO  DistriOptimizer$:452 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 225.346893666s] Epoch finished. Wall clock time is 226497.98287 ms
2019-10-15 07:50:09 INFO  DistriOptimizer$:111 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 225.346893666s] Validate model...
2019-10-15 07:50:10 INFO  DistriOptimizer$:178 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 225.346893666s] validate model throughput is 10537.184 records/second
2019-10-15 07:50:10 INFO  DistriOptimizer$:181 - [Epoch 5 60032/60000][Iteration 2345][Wall Clock 225.346893666s] Top1Accuracy is Accuracy(correct: 5253, count: 10000, accuracy: 0.5253)
2019-10-15 07:50:10 INFO  DistriOptimizer$:221 - [Wall Clock 226.49798287s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:50:10 INFO  DistriOptimizer$:226 - [Wall Clock 226.49798287s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 128/60000][Iteration 2346][Wall Clock 226.596427937s] Trained 128 records in 0.098445067 seconds. Throughput is 1300.2175 records/second. Loss is 2.0826843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.989536621823617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 256/60000][Iteration 2347][Wall Clock 226.678205839s] Trained 128 records in 0.081777902 seconds. Throughput is 1565.2151 records/second. Loss is 2.1138897. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9886431560071725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 384/60000][Iteration 2348][Wall Clock 226.757827664s] Trained 128 records in 0.079621825 seconds. Throughput is 1607.5995 records/second. Loss is 2.110067. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9877502240812666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 512/60000][Iteration 2349][Wall Clock 226.848568069s] Trained 128 records in 0.090740405 seconds. Throughput is 1410.6174 records/second. Loss is 2.1081717. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9868578255675033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 640/60000][Iteration 2350][Wall Clock 226.931155672s] Trained 128 records in 0.082587603 seconds. Throughput is 1549.8695 records/second. Loss is 2.0908365. Sequentialb692dd65's hyper parameters: Current learning rate is 2.985965959988056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 768/60000][Iteration 2351][Wall Clock 227.014852769s] Trained 128 records in 0.083697097 seconds. Throughput is 1529.3242 records/second. Loss is 2.1151662. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9850746268656717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 896/60000][Iteration 2352][Wall Clock 227.102893003s] Trained 128 records in 0.088040234 seconds. Throughput is 1453.8807 records/second. Loss is 2.0825806. Sequentialb692dd65's hyper parameters: Current learning rate is 2.984183825723665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 1024/60000][Iteration 2353][Wall Clock 227.187762776s] Trained 128 records in 0.084869773 seconds. Throughput is 1508.193 records/second. Loss is 2.0999887. Sequentialb692dd65's hyper parameters: Current learning rate is 2.983293556085919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:10 INFO  DistriOptimizer$:408 - [Epoch 6 1152/60000][Iteration 2354][Wall Clock 227.273344942s] Trained 128 records in 0.085582166 seconds. Throughput is 1495.6387 records/second. Loss is 2.0885108. Sequentialb692dd65's hyper parameters: Current learning rate is 2.982403817476886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1280/60000][Iteration 2355][Wall Clock 227.364688451s] Trained 128 records in 0.091343509 seconds. Throughput is 1401.3037 records/second. Loss is 2.1022012. Sequentialb692dd65's hyper parameters: Current learning rate is 2.981514609421586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1408/60000][Iteration 2356][Wall Clock 227.45047115s] Trained 128 records in 0.085782699 seconds. Throughput is 1492.1423 records/second. Loss is 2.083558. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9806259314456036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1536/60000][Iteration 2357][Wall Clock 227.540102003s] Trained 128 records in 0.089630853 seconds. Throughput is 1428.0797 records/second. Loss is 2.089865. Sequentialb692dd65's hyper parameters: Current learning rate is 2.97973778307509E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1664/60000][Iteration 2358][Wall Clock 227.626101939s] Trained 128 records in 0.085999936 seconds. Throughput is 1488.3732 records/second. Loss is 2.0673852. Sequentialb692dd65's hyper parameters: Current learning rate is 2.978850163836759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1792/60000][Iteration 2359][Wall Clock 227.715631589s] Trained 128 records in 0.08952965 seconds. Throughput is 1429.694 records/second. Loss is 2.0943182. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9779630732578913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 1920/60000][Iteration 2360][Wall Clock 227.803011643s] Trained 128 records in 0.087380054 seconds. Throughput is 1464.8652 records/second. Loss is 2.0734317. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9770765108663293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 2048/60000][Iteration 2361][Wall Clock 227.889444051s] Trained 128 records in 0.086432408 seconds. Throughput is 1480.926 records/second. Loss is 2.12693. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9761904761904765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 2176/60000][Iteration 2362][Wall Clock 227.97960255s] Trained 128 records in 0.090158499 seconds. Throughput is 1419.7219 records/second. Loss is 2.1053119. Sequentialb692dd65's hyper parameters: Current learning rate is 2.975304968759298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 2304/60000][Iteration 2363][Wall Clock 228.068393905s] Trained 128 records in 0.088791355 seconds. Throughput is 1441.5818 records/second. Loss is 2.083481. Sequentialb692dd65's hyper parameters: Current learning rate is 2.97441998810232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 2432/60000][Iteration 2364][Wall Clock 228.159107857s] Trained 128 records in 0.090713952 seconds. Throughput is 1411.0288 records/second. Loss is 2.1131713. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9735355337496286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:11 INFO  DistriOptimizer$:408 - [Epoch 6 2560/60000][Iteration 2365][Wall Clock 228.262146429s] Trained 128 records in 0.103038572 seconds. Throughput is 1242.2533 records/second. Loss is 2.0792553. Sequentialb692dd65's hyper parameters: Current learning rate is 2.972651605231867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 2688/60000][Iteration 2366][Wall Clock 228.348640563s] Trained 128 records in 0.086494134 seconds. Throughput is 1479.8691 records/second. Loss is 2.1081045. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9717682020802375E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 2816/60000][Iteration 2367][Wall Clock 228.435539391s] Trained 128 records in 0.086898828 seconds. Throughput is 1472.9773 records/second. Loss is 2.0732002. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9708853238265005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 2944/60000][Iteration 2368][Wall Clock 228.523002629s] Trained 128 records in 0.087463238 seconds. Throughput is 1463.472 records/second. Loss is 2.086866. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9700029700029703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3072/60000][Iteration 2369][Wall Clock 228.611219816s] Trained 128 records in 0.088217187 seconds. Throughput is 1450.9645 records/second. Loss is 2.0725706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.969121140142518E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3200/60000][Iteration 2370][Wall Clock 228.696898249s] Trained 128 records in 0.085678433 seconds. Throughput is 1493.9581 records/second. Loss is 2.0932198. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9682398337785694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3328/60000][Iteration 2371][Wall Clock 228.784646091s] Trained 128 records in 0.087747842 seconds. Throughput is 1458.7253 records/second. Loss is 2.0781162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.967359050445104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3456/60000][Iteration 2372][Wall Clock 228.869048667s] Trained 128 records in 0.084402576 seconds. Throughput is 1516.5414 records/second. Loss is 2.0641003. Sequentialb692dd65's hyper parameters: Current learning rate is 2.966478789676654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3584/60000][Iteration 2373][Wall Clock 228.955395244s] Trained 128 records in 0.086346577 seconds. Throughput is 1482.3981 records/second. Loss is 2.071436. Sequentialb692dd65's hyper parameters: Current learning rate is 2.965599051008304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3712/60000][Iteration 2374][Wall Clock 229.041940993s] Trained 128 records in 0.086545749 seconds. Throughput is 1478.9866 records/second. Loss is 2.1059175. Sequentialb692dd65's hyper parameters: Current learning rate is 2.964719833975689E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3840/60000][Iteration 2375][Wall Clock 229.137084058s] Trained 128 records in 0.095143065 seconds. Throughput is 1345.3424 records/second. Loss is 2.059347. Sequentialb692dd65's hyper parameters: Current learning rate is 2.963841138114997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 3968/60000][Iteration 2376][Wall Clock 229.222163468s] Trained 128 records in 0.08507941 seconds. Throughput is 1504.4768 records/second. Loss is 2.075158. Sequentialb692dd65's hyper parameters: Current learning rate is 2.962962962962963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:12 INFO  DistriOptimizer$:408 - [Epoch 6 4096/60000][Iteration 2377][Wall Clock 229.309980739s] Trained 128 records in 0.087817271 seconds. Throughput is 1457.572 records/second. Loss is 2.1130924. Sequentialb692dd65's hyper parameters: Current learning rate is 2.962085308056872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4224/60000][Iteration 2378][Wall Clock 229.39806937s] Trained 128 records in 0.088088631 seconds. Throughput is 1453.0819 records/second. Loss is 2.087958. Sequentialb692dd65's hyper parameters: Current learning rate is 2.961208172934557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4352/60000][Iteration 2379][Wall Clock 229.485733114s] Trained 128 records in 0.087663744 seconds. Throughput is 1460.1246 records/second. Loss is 2.0927231. Sequentialb692dd65's hyper parameters: Current learning rate is 2.960331557134399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4480/60000][Iteration 2380][Wall Clock 229.571564492s] Trained 128 records in 0.085831378 seconds. Throughput is 1491.296 records/second. Loss is 2.0782943. Sequentialb692dd65's hyper parameters: Current learning rate is 2.959455460195324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4608/60000][Iteration 2381][Wall Clock 229.660841106s] Trained 128 records in 0.089276614 seconds. Throughput is 1433.7462 records/second. Loss is 2.08903. Sequentialb692dd65's hyper parameters: Current learning rate is 2.958579881656805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4736/60000][Iteration 2382][Wall Clock 229.752015423s] Trained 128 records in 0.091174317 seconds. Throughput is 1403.904 records/second. Loss is 2.098242. Sequentialb692dd65's hyper parameters: Current learning rate is 2.957704821058858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4864/60000][Iteration 2383][Wall Clock 229.838896484s] Trained 128 records in 0.086881061 seconds. Throughput is 1473.2784 records/second. Loss is 2.0900912. Sequentialb692dd65's hyper parameters: Current learning rate is 2.956830277942046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 4992/60000][Iteration 2384][Wall Clock 229.924494348s] Trained 128 records in 0.085597864 seconds. Throughput is 1495.3644 records/second. Loss is 2.109506. Sequentialb692dd65's hyper parameters: Current learning rate is 2.955956251847473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 5120/60000][Iteration 2385][Wall Clock 230.010536077s] Trained 128 records in 0.086041729 seconds. Throughput is 1487.6503 records/second. Loss is 2.1018796. Sequentialb692dd65's hyper parameters: Current learning rate is 2.955082742316785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 5248/60000][Iteration 2386][Wall Clock 230.09805083s] Trained 128 records in 0.087514753 seconds. Throughput is 1462.6106 records/second. Loss is 2.1032474. Sequentialb692dd65's hyper parameters: Current learning rate is 2.954209748892171E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 5376/60000][Iteration 2387][Wall Clock 230.186513514s] Trained 128 records in 0.088462684 seconds. Throughput is 1446.9379 records/second. Loss is 2.0967116. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9533372711163615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:13 INFO  DistriOptimizer$:408 - [Epoch 6 5504/60000][Iteration 2388][Wall Clock 230.275765965s] Trained 128 records in 0.089252451 seconds. Throughput is 1434.1343 records/second. Loss is 2.088267. Sequentialb692dd65's hyper parameters: Current learning rate is 2.952465308532625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 5632/60000][Iteration 2389][Wall Clock 230.365310594s] Trained 128 records in 0.089544629 seconds. Throughput is 1429.4547 records/second. Loss is 2.0824246. Sequentialb692dd65's hyper parameters: Current learning rate is 2.95159386068477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 5760/60000][Iteration 2390][Wall Clock 230.45673194s] Trained 128 records in 0.091421346 seconds. Throughput is 1400.1107 records/second. Loss is 2.0711594. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9507229271171436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 5888/60000][Iteration 2391][Wall Clock 230.548132026s] Trained 128 records in 0.091400086 seconds. Throughput is 1400.4363 records/second. Loss is 2.0940042. Sequentialb692dd65's hyper parameters: Current learning rate is 2.949852507374631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6016/60000][Iteration 2392][Wall Clock 230.63292141s] Trained 128 records in 0.084789384 seconds. Throughput is 1509.623 records/second. Loss is 2.0790539. Sequentialb692dd65's hyper parameters: Current learning rate is 2.948982601002654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6144/60000][Iteration 2393][Wall Clock 230.721104961s] Trained 128 records in 0.088183551 seconds. Throughput is 1451.5178 records/second. Loss is 2.0612514. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9481132075471697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6272/60000][Iteration 2394][Wall Clock 230.809267382s] Trained 128 records in 0.088162421 seconds. Throughput is 1451.8657 records/second. Loss is 2.101531. Sequentialb692dd65's hyper parameters: Current learning rate is 2.947244326554671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6400/60000][Iteration 2395][Wall Clock 230.8960791s] Trained 128 records in 0.086811718 seconds. Throughput is 1474.4553 records/second. Loss is 2.0914922. Sequentialb692dd65's hyper parameters: Current learning rate is 2.946375957572186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6528/60000][Iteration 2396][Wall Clock 230.985002275s] Trained 128 records in 0.088923175 seconds. Throughput is 1439.4447 records/second. Loss is 2.0745497. Sequentialb692dd65's hyper parameters: Current learning rate is 2.945508100147275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6656/60000][Iteration 2397][Wall Clock 231.069028669s] Trained 128 records in 0.084026394 seconds. Throughput is 1523.3308 records/second. Loss is 2.0776353. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9446407538280333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6784/60000][Iteration 2398][Wall Clock 231.155917702s] Trained 128 records in 0.086889033 seconds. Throughput is 1473.1433 records/second. Loss is 2.121073. Sequentialb692dd65's hyper parameters: Current learning rate is 2.943773918163085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:14 INFO  DistriOptimizer$:408 - [Epoch 6 6912/60000][Iteration 2399][Wall Clock 231.243321668s] Trained 128 records in 0.087403966 seconds. Throughput is 1464.4644 records/second. Loss is 2.0555654. Sequentialb692dd65's hyper parameters: Current learning rate is 2.942907592701589E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7040/60000][Iteration 2400][Wall Clock 231.34447932s] Trained 128 records in 0.101157652 seconds. Throughput is 1265.3517 records/second. Loss is 2.0982642. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9420417769932336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7168/60000][Iteration 2401][Wall Clock 231.429751222s] Trained 128 records in 0.085271902 seconds. Throughput is 1501.0806 records/second. Loss is 2.0808733. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9411764705882356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7296/60000][Iteration 2402][Wall Clock 231.517479233s] Trained 128 records in 0.087728011 seconds. Throughput is 1459.0552 records/second. Loss is 2.0892467. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9403116730373417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7424/60000][Iteration 2403][Wall Clock 231.603501825s] Trained 128 records in 0.086022592 seconds. Throughput is 1487.9812 records/second. Loss is 2.0674958. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9394473838918284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7552/60000][Iteration 2404][Wall Clock 231.690803814s] Trained 128 records in 0.087301989 seconds. Throughput is 1466.175 records/second. Loss is 2.0885684. Sequentialb692dd65's hyper parameters: Current learning rate is 2.938583602703497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7680/60000][Iteration 2405][Wall Clock 231.778749147s] Trained 128 records in 0.087945333 seconds. Throughput is 1455.4496 records/second. Loss is 2.093381. Sequentialb692dd65's hyper parameters: Current learning rate is 2.937720329024677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7808/60000][Iteration 2406][Wall Clock 231.866210074s] Trained 128 records in 0.087460927 seconds. Throughput is 1463.5106 records/second. Loss is 2.0973363. Sequentialb692dd65's hyper parameters: Current learning rate is 2.936857562408223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 7936/60000][Iteration 2407][Wall Clock 231.951611734s] Trained 128 records in 0.08540166 seconds. Throughput is 1498.7999 records/second. Loss is 2.1211092. Sequentialb692dd65's hyper parameters: Current learning rate is 2.935995302407516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 8064/60000][Iteration 2408][Wall Clock 232.04015006s] Trained 128 records in 0.088538326 seconds. Throughput is 1445.7017 records/second. Loss is 2.0855856. Sequentialb692dd65's hyper parameters: Current learning rate is 2.93513354857646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 8192/60000][Iteration 2409][Wall Clock 232.127826146s] Trained 128 records in 0.087676086 seconds. Throughput is 1459.9192 records/second. Loss is 2.0766003. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9342723004694836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 8320/60000][Iteration 2410][Wall Clock 232.221033692s] Trained 128 records in 0.093207546 seconds. Throughput is 1373.2794 records/second. Loss is 2.1012006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.933411557641537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:15 INFO  DistriOptimizer$:408 - [Epoch 6 8448/60000][Iteration 2411][Wall Clock 232.309036927s] Trained 128 records in 0.088003235 seconds. Throughput is 1454.4921 records/second. Loss is 2.0679119. Sequentialb692dd65's hyper parameters: Current learning rate is 2.932551319648094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 8576/60000][Iteration 2412][Wall Clock 232.398781686s] Trained 128 records in 0.089744759 seconds. Throughput is 1426.2671 records/second. Loss is 2.1084285. Sequentialb692dd65's hyper parameters: Current learning rate is 2.931691586045148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 8704/60000][Iteration 2413][Wall Clock 232.48334419s] Trained 128 records in 0.084562504 seconds. Throughput is 1513.6732 records/second. Loss is 2.081722. Sequentialb692dd65's hyper parameters: Current learning rate is 2.930832356389215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 8832/60000][Iteration 2414][Wall Clock 232.572523841s] Trained 128 records in 0.089179651 seconds. Throughput is 1435.305 records/second. Loss is 2.1022344. Sequentialb692dd65's hyper parameters: Current learning rate is 2.929973630237328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 8960/60000][Iteration 2415][Wall Clock 232.664460418s] Trained 128 records in 0.091936577 seconds. Throughput is 1392.2642 records/second. Loss is 2.1110334. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9291154071470416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9088/60000][Iteration 2416][Wall Clock 232.747979011s] Trained 128 records in 0.083518593 seconds. Throughput is 1532.5929 records/second. Loss is 2.0864604. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9282576866764275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9216/60000][Iteration 2417][Wall Clock 232.834811202s] Trained 128 records in 0.086832191 seconds. Throughput is 1474.1078 records/second. Loss is 2.0616577. Sequentialb692dd65's hyper parameters: Current learning rate is 2.927400468384075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9344/60000][Iteration 2418][Wall Clock 232.915911387s] Trained 128 records in 0.081100185 seconds. Throughput is 1578.2947 records/second. Loss is 2.0967364. Sequentialb692dd65's hyper parameters: Current learning rate is 2.92654375182909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9472/60000][Iteration 2419][Wall Clock 233.001589193s] Trained 128 records in 0.085677806 seconds. Throughput is 1493.9692 records/second. Loss is 2.0873973. Sequentialb692dd65's hyper parameters: Current learning rate is 2.925687536571094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9600/60000][Iteration 2420][Wall Clock 233.089201116s] Trained 128 records in 0.087611923 seconds. Throughput is 1460.9884 records/second. Loss is 2.0712113. Sequentialb692dd65's hyper parameters: Current learning rate is 2.924831822170225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9728/60000][Iteration 2421][Wall Clock 233.180738122s] Trained 128 records in 0.091537006 seconds. Throughput is 1398.3416 records/second. Loss is 2.07287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9239766081871346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:16 INFO  DistriOptimizer$:408 - [Epoch 6 9856/60000][Iteration 2422][Wall Clock 233.267854771s] Trained 128 records in 0.087116649 seconds. Throughput is 1469.2943 records/second. Loss is 2.0765338. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9231218941829873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 9984/60000][Iteration 2423][Wall Clock 233.356222742s] Trained 128 records in 0.088367971 seconds. Throughput is 1448.4886 records/second. Loss is 2.103142. Sequentialb692dd65's hyper parameters: Current learning rate is 2.922267679719462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10112/60000][Iteration 2424][Wall Clock 233.444090726s] Trained 128 records in 0.087867984 seconds. Throughput is 1456.7308 records/second. Loss is 2.1131058. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9214139643587495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10240/60000][Iteration 2425][Wall Clock 233.531767359s] Trained 128 records in 0.087676633 seconds. Throughput is 1459.9102 records/second. Loss is 2.0916493. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9205607476635517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10368/60000][Iteration 2426][Wall Clock 233.628315974s] Trained 128 records in 0.096548615 seconds. Throughput is 1325.757 records/second. Loss is 2.074942. Sequentialb692dd65's hyper parameters: Current learning rate is 2.91970802919708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10496/60000][Iteration 2427][Wall Clock 233.714781971s] Trained 128 records in 0.086465997 seconds. Throughput is 1480.3507 records/second. Loss is 2.1074803. Sequentialb692dd65's hyper parameters: Current learning rate is 2.918855808523059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10624/60000][Iteration 2428][Wall Clock 233.803379494s] Trained 128 records in 0.088597523 seconds. Throughput is 1444.7357 records/second. Loss is 2.0879695. Sequentialb692dd65's hyper parameters: Current learning rate is 2.918004085205719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10752/60000][Iteration 2429][Wall Clock 233.888799146s] Trained 128 records in 0.085419652 seconds. Throughput is 1498.4841 records/second. Loss is 2.0994987. Sequentialb692dd65's hyper parameters: Current learning rate is 2.917152858809802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 10880/60000][Iteration 2430][Wall Clock 233.972652314s] Trained 128 records in 0.083853168 seconds. Throughput is 1526.4778 records/second. Loss is 2.0939288. Sequentialb692dd65's hyper parameters: Current learning rate is 2.916302128900554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 11008/60000][Iteration 2431][Wall Clock 234.065053778s] Trained 128 records in 0.092401464 seconds. Throughput is 1385.2594 records/second. Loss is 2.0813174. Sequentialb692dd65's hyper parameters: Current learning rate is 2.915451895043732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 11136/60000][Iteration 2432][Wall Clock 234.15313331s] Trained 128 records in 0.088079532 seconds. Throughput is 1453.232 records/second. Loss is 2.1006415. Sequentialb692dd65's hyper parameters: Current learning rate is 2.914602156805596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:17 INFO  DistriOptimizer$:408 - [Epoch 6 11264/60000][Iteration 2433][Wall Clock 234.241051037s] Trained 128 records in 0.087917727 seconds. Throughput is 1455.9066 records/second. Loss is 2.0805142. Sequentialb692dd65's hyper parameters: Current learning rate is 2.913752913752914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 11392/60000][Iteration 2434][Wall Clock 234.328064353s] Trained 128 records in 0.087013316 seconds. Throughput is 1471.0392 records/second. Loss is 2.0798926. Sequentialb692dd65's hyper parameters: Current learning rate is 2.912904165452957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 11520/60000][Iteration 2435][Wall Clock 234.415070375s] Trained 128 records in 0.087006022 seconds. Throughput is 1471.1625 records/second. Loss is 2.0372896. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9120559114735004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 11648/60000][Iteration 2436][Wall Clock 234.503535661s] Trained 128 records in 0.088465286 seconds. Throughput is 1446.8951 records/second. Loss is 2.0801976. Sequentialb692dd65's hyper parameters: Current learning rate is 2.911208151382824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 11776/60000][Iteration 2437][Wall Clock 234.589777145s] Trained 128 records in 0.086241484 seconds. Throughput is 1484.2045 records/second. Loss is 2.0801036. Sequentialb692dd65's hyper parameters: Current learning rate is 2.910360884749709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 11904/60000][Iteration 2438][Wall Clock 234.676086603s] Trained 128 records in 0.086309458 seconds. Throughput is 1483.0356 records/second. Loss is 2.069729. Sequentialb692dd65's hyper parameters: Current learning rate is 2.909514111143439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12032/60000][Iteration 2439][Wall Clock 234.763666069s] Trained 128 records in 0.087579466 seconds. Throughput is 1461.5298 records/second. Loss is 2.10796. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9086678301337986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12160/60000][Iteration 2440][Wall Clock 234.848790678s] Trained 128 records in 0.085124609 seconds. Throughput is 1503.678 records/second. Loss is 2.0592506. Sequentialb692dd65's hyper parameters: Current learning rate is 2.907822041291073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12288/60000][Iteration 2441][Wall Clock 234.926644973s] Trained 128 records in 0.077854295 seconds. Throughput is 1644.0968 records/second. Loss is 2.0712962. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9069767441860465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12416/60000][Iteration 2442][Wall Clock 235.011041216s] Trained 128 records in 0.084396243 seconds. Throughput is 1516.6552 records/second. Loss is 2.0762136. Sequentialb692dd65's hyper parameters: Current learning rate is 2.906131938390003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12544/60000][Iteration 2443][Wall Clock 235.096147233s] Trained 128 records in 0.085106017 seconds. Throughput is 1504.0065 records/second. Loss is 2.0808887. Sequentialb692dd65's hyper parameters: Current learning rate is 2.905287623474724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12672/60000][Iteration 2444][Wall Clock 235.183896396s] Trained 128 records in 0.087749163 seconds. Throughput is 1458.7034 records/second. Loss is 2.0900187. Sequentialb692dd65's hyper parameters: Current learning rate is 2.904443799012489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:18 INFO  DistriOptimizer$:408 - [Epoch 6 12800/60000][Iteration 2445][Wall Clock 235.269538387s] Trained 128 records in 0.085641991 seconds. Throughput is 1494.594 records/second. Loss is 2.088167. Sequentialb692dd65's hyper parameters: Current learning rate is 2.9036004645760743E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 12928/60000][Iteration 2446][Wall Clock 235.356015025s] Trained 128 records in 0.086476638 seconds. Throughput is 1480.1686 records/second. Loss is 2.0974874. Sequentialb692dd65's hyper parameters: Current learning rate is 2.902757619738752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13056/60000][Iteration 2447][Wall Clock 235.442155546s] Trained 128 records in 0.086140521 seconds. Throughput is 1485.9441 records/second. Loss is 2.065663. Sequentialb692dd65's hyper parameters: Current learning rate is 2.901915264074289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13184/60000][Iteration 2448][Wall Clock 235.528682611s] Trained 128 records in 0.086527065 seconds. Throughput is 1479.3059 records/second. Loss is 2.0878518. Sequentialb692dd65's hyper parameters: Current learning rate is 2.901073397156948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13312/60000][Iteration 2449][Wall Clock 235.618936602s] Trained 128 records in 0.090253991 seconds. Throughput is 1418.2197 records/second. Loss is 2.1169908. Sequentialb692dd65's hyper parameters: Current learning rate is 2.900232018561485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13440/60000][Iteration 2450][Wall Clock 235.705939266s] Trained 128 records in 0.087002664 seconds. Throughput is 1471.2194 records/second. Loss is 2.0778954. Sequentialb692dd65's hyper parameters: Current learning rate is 2.899391127863149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13568/60000][Iteration 2451][Wall Clock 235.791946681s] Trained 128 records in 0.086007415 seconds. Throughput is 1488.2438 records/second. Loss is 2.0802891. Sequentialb692dd65's hyper parameters: Current learning rate is 2.898550724637681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13696/60000][Iteration 2452][Wall Clock 235.887970683s] Trained 128 records in 0.096024002 seconds. Throughput is 1333.0001 records/second. Loss is 2.092916. Sequentialb692dd65's hyper parameters: Current learning rate is 2.897710808461316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13824/60000][Iteration 2453][Wall Clock 235.973186421s] Trained 128 records in 0.085215738 seconds. Throughput is 1502.07 records/second. Loss is 2.0764115. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8968713789107763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 13952/60000][Iteration 2454][Wall Clock 236.05759714s] Trained 128 records in 0.084410719 seconds. Throughput is 1516.3951 records/second. Loss is 2.075932. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8960324355632787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 14080/60000][Iteration 2455][Wall Clock 236.145898908s] Trained 128 records in 0.088301768 seconds. Throughput is 1449.5746 records/second. Loss is 2.082879. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8951939779965256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:19 INFO  DistriOptimizer$:408 - [Epoch 6 14208/60000][Iteration 2456][Wall Clock 236.23073509s] Trained 128 records in 0.084836182 seconds. Throughput is 1508.7902 records/second. Loss is 2.055804. Sequentialb692dd65's hyper parameters: Current learning rate is 2.894356005788712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14336/60000][Iteration 2457][Wall Clock 236.316592569s] Trained 128 records in 0.085857479 seconds. Throughput is 1490.8428 records/second. Loss is 2.0891101. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8935185185185184E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14464/60000][Iteration 2458][Wall Clock 236.405674998s] Trained 128 records in 0.089082429 seconds. Throughput is 1436.8715 records/second. Loss is 2.0723372. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8926815157651146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14592/60000][Iteration 2459][Wall Clock 236.494779411s] Trained 128 records in 0.089104413 seconds. Throughput is 1436.517 records/second. Loss is 2.067411. Sequentialb692dd65's hyper parameters: Current learning rate is 2.891844997108155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14720/60000][Iteration 2460][Wall Clock 236.581163208s] Trained 128 records in 0.086383797 seconds. Throughput is 1481.7594 records/second. Loss is 2.0782576. Sequentialb692dd65's hyper parameters: Current learning rate is 2.891008962127783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14848/60000][Iteration 2461][Wall Clock 236.668657468s] Trained 128 records in 0.08749426 seconds. Throughput is 1462.9531 records/second. Loss is 2.0748584. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8901734104046245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 14976/60000][Iteration 2462][Wall Clock 236.756173376s] Trained 128 records in 0.087515908 seconds. Throughput is 1462.5913 records/second. Loss is 2.0660105. Sequentialb692dd65's hyper parameters: Current learning rate is 2.889338341519792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15104/60000][Iteration 2463][Wall Clock 236.842644014s] Trained 128 records in 0.086470638 seconds. Throughput is 1480.2712 records/second. Loss is 2.0914855. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8885037550548814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15232/60000][Iteration 2464][Wall Clock 236.929492257s] Trained 128 records in 0.086848243 seconds. Throughput is 1473.8352 records/second. Loss is 2.0828674. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8876696505919725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15360/60000][Iteration 2465][Wall Clock 237.022929405s] Trained 128 records in 0.093437148 seconds. Throughput is 1369.9048 records/second. Loss is 2.0768435. Sequentialb692dd65's hyper parameters: Current learning rate is 2.886836027713626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15488/60000][Iteration 2466][Wall Clock 237.119927304s] Trained 128 records in 0.096997899 seconds. Throughput is 1319.6162 records/second. Loss is 2.0930893. Sequentialb692dd65's hyper parameters: Current learning rate is 2.886002886002886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15616/60000][Iteration 2467][Wall Clock 237.205742391s] Trained 128 records in 0.085815087 seconds. Throughput is 1491.5792 records/second. Loss is 2.0617466. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8851702250432774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:20 INFO  DistriOptimizer$:408 - [Epoch 6 15744/60000][Iteration 2468][Wall Clock 237.292734635s] Trained 128 records in 0.086992244 seconds. Throughput is 1471.3956 records/second. Loss is 2.1201794. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8843380444188056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 15872/60000][Iteration 2469][Wall Clock 237.37816936s] Trained 128 records in 0.085434725 seconds. Throughput is 1498.2198 records/second. Loss is 2.080661. Sequentialb692dd65's hyper parameters: Current learning rate is 2.883506343713956E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16000/60000][Iteration 2470][Wall Clock 237.463391418s] Trained 128 records in 0.085222058 seconds. Throughput is 1501.9586 records/second. Loss is 2.0787892. Sequentialb692dd65's hyper parameters: Current learning rate is 2.882675122513693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16128/60000][Iteration 2471][Wall Clock 237.550963264s] Trained 128 records in 0.087571846 seconds. Throughput is 1461.657 records/second. Loss is 2.1064253. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8818443804034583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16256/60000][Iteration 2472][Wall Clock 237.6378877s] Trained 128 records in 0.086924436 seconds. Throughput is 1472.5433 records/second. Loss is 2.0839808. Sequentialb692dd65's hyper parameters: Current learning rate is 2.881014116969173E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16384/60000][Iteration 2473][Wall Clock 237.725999272s] Trained 128 records in 0.088111572 seconds. Throughput is 1452.7036 records/second. Loss is 2.0783772. Sequentialb692dd65's hyper parameters: Current learning rate is 2.880184331797235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16512/60000][Iteration 2474][Wall Clock 237.810444492s] Trained 128 records in 0.08444522 seconds. Throughput is 1515.7755 records/second. Loss is 2.086691. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8793550244745177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16640/60000][Iteration 2475][Wall Clock 237.896244766s] Trained 128 records in 0.085800274 seconds. Throughput is 1491.8367 records/second. Loss is 2.0654824. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8785261945883704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16768/60000][Iteration 2476][Wall Clock 237.981122224s] Trained 128 records in 0.084877458 seconds. Throughput is 1508.0564 records/second. Loss is 2.0604188. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8776978417266187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 16896/60000][Iteration 2477][Wall Clock 238.067196062s] Trained 128 records in 0.086073838 seconds. Throughput is 1487.0953 records/second. Loss is 2.0752006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8768699654775604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 17024/60000][Iteration 2478][Wall Clock 238.16029666s] Trained 128 records in 0.093100598 seconds. Throughput is 1374.8569 records/second. Loss is 2.0896118. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8760425654299687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:21 INFO  DistriOptimizer$:408 - [Epoch 6 17152/60000][Iteration 2479][Wall Clock 238.24477218s] Trained 128 records in 0.08447552 seconds. Throughput is 1515.2319 records/second. Loss is 2.0723898. Sequentialb692dd65's hyper parameters: Current learning rate is 2.875215641173088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17280/60000][Iteration 2480][Wall Clock 238.331607961s] Trained 128 records in 0.086835781 seconds. Throughput is 1474.0468 records/second. Loss is 2.0870914. Sequentialb692dd65's hyper parameters: Current learning rate is 2.874389192296637E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17408/60000][Iteration 2481][Wall Clock 238.416192596s] Trained 128 records in 0.084584635 seconds. Throughput is 1513.2771 records/second. Loss is 2.072131. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8735632183908046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17536/60000][Iteration 2482][Wall Clock 238.501389934s] Trained 128 records in 0.085197338 seconds. Throughput is 1502.3944 records/second. Loss is 2.0700119. Sequentialb692dd65's hyper parameters: Current learning rate is 2.872737719046251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17664/60000][Iteration 2483][Wall Clock 238.588034605s] Trained 128 records in 0.086644671 seconds. Throughput is 1477.298 records/second. Loss is 2.089191. Sequentialb692dd65's hyper parameters: Current learning rate is 2.871912693854107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17792/60000][Iteration 2484][Wall Clock 238.672514918s] Trained 128 records in 0.084480313 seconds. Throughput is 1515.1459 records/second. Loss is 2.1026769. Sequentialb692dd65's hyper parameters: Current learning rate is 2.871088142405972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 17920/60000][Iteration 2485][Wall Clock 238.756510751s] Trained 128 records in 0.083995833 seconds. Throughput is 1523.8851 records/second. Loss is 2.054644. Sequentialb692dd65's hyper parameters: Current learning rate is 2.870264064293915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18048/60000][Iteration 2486][Wall Clock 238.841338299s] Trained 128 records in 0.084827548 seconds. Throughput is 1508.9437 records/second. Loss is 2.0618637. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8694404591104734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18176/60000][Iteration 2487][Wall Clock 238.927569642s] Trained 128 records in 0.086231343 seconds. Throughput is 1484.379 records/second. Loss is 2.0734215. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8686173264486515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18304/60000][Iteration 2488][Wall Clock 239.014931703s] Trained 128 records in 0.087362061 seconds. Throughput is 1465.167 records/second. Loss is 2.063841. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8677946659019213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18432/60000][Iteration 2489][Wall Clock 239.101428949s] Trained 128 records in 0.086497246 seconds. Throughput is 1479.8159 records/second. Loss is 2.1217246. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8669724770642203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18560/60000][Iteration 2490][Wall Clock 239.200936938s] Trained 128 records in 0.099507989 seconds. Throughput is 1286.3289 records/second. Loss is 2.0907264. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8661507595299513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:22 INFO  DistriOptimizer$:408 - [Epoch 6 18688/60000][Iteration 2491][Wall Clock 239.281240263s] Trained 128 records in 0.080303325 seconds. Throughput is 1593.9564 records/second. Loss is 2.0912988. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8653295128939826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 18816/60000][Iteration 2492][Wall Clock 239.365209913s] Trained 128 records in 0.08396965 seconds. Throughput is 1524.3602 records/second. Loss is 2.0728366. Sequentialb692dd65's hyper parameters: Current learning rate is 2.864508736751647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 18944/60000][Iteration 2493][Wall Clock 239.452781324s] Trained 128 records in 0.087571411 seconds. Throughput is 1461.6642 records/second. Loss is 2.0841312. Sequentialb692dd65's hyper parameters: Current learning rate is 2.86368843069874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19072/60000][Iteration 2494][Wall Clock 239.539500784s] Trained 128 records in 0.08671946 seconds. Throughput is 1476.0239 records/second. Loss is 2.07447. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8628685943315205E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19200/60000][Iteration 2495][Wall Clock 239.624695826s] Trained 128 records in 0.085195042 seconds. Throughput is 1502.4348 records/second. Loss is 2.061567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8620492272467084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19328/60000][Iteration 2496][Wall Clock 239.712472915s] Trained 128 records in 0.087777089 seconds. Throughput is 1458.2394 records/second. Loss is 2.0692892. Sequentialb692dd65's hyper parameters: Current learning rate is 2.861230329041488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19456/60000][Iteration 2497][Wall Clock 239.798488765s] Trained 128 records in 0.08601585 seconds. Throughput is 1488.0978 records/second. Loss is 2.0832865. Sequentialb692dd65's hyper parameters: Current learning rate is 2.860411899313501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19584/60000][Iteration 2498][Wall Clock 239.886323386s] Trained 128 records in 0.087834621 seconds. Throughput is 1457.2842 records/second. Loss is 2.1013565. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8595939376608524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19712/60000][Iteration 2499][Wall Clock 239.976638411s] Trained 128 records in 0.090315025 seconds. Throughput is 1417.2615 records/second. Loss is 2.0938482. Sequentialb692dd65's hyper parameters: Current learning rate is 2.858776443682104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19840/60000][Iteration 2500][Wall Clock 240.063818157s] Trained 128 records in 0.087179746 seconds. Throughput is 1468.231 records/second. Loss is 2.0702145. Sequentialb692dd65's hyper parameters: Current learning rate is 2.857959416976279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 19968/60000][Iteration 2501][Wall Clock 240.150417963s] Trained 128 records in 0.086599806 seconds. Throughput is 1478.0634 records/second. Loss is 2.1017425. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8571428571428574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:23 INFO  DistriOptimizer$:408 - [Epoch 6 20096/60000][Iteration 2502][Wall Clock 240.23608831s] Trained 128 records in 0.085670347 seconds. Throughput is 1494.0992 records/second. Loss is 2.0978992. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8563267637817766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20224/60000][Iteration 2503][Wall Clock 240.321245643s] Trained 128 records in 0.085157333 seconds. Throughput is 1503.1001 records/second. Loss is 2.086112. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8555111364934324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20352/60000][Iteration 2504][Wall Clock 240.415378179s] Trained 128 records in 0.094132536 seconds. Throughput is 1359.7849 records/second. Loss is 2.08624. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8546959748786756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20480/60000][Iteration 2505][Wall Clock 240.493485616s] Trained 128 records in 0.078107437 seconds. Throughput is 1638.7683 records/second. Loss is 2.0460567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8538812785388126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20608/60000][Iteration 2506][Wall Clock 240.574182871s] Trained 128 records in 0.080697255 seconds. Throughput is 1586.1754 records/second. Loss is 2.0838208. Sequentialb692dd65's hyper parameters: Current learning rate is 2.853067047075606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20736/60000][Iteration 2507][Wall Clock 240.663238802s] Trained 128 records in 0.089055931 seconds. Throughput is 1437.299 records/second. Loss is 2.1098878. Sequentialb692dd65's hyper parameters: Current learning rate is 2.852253280091272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20864/60000][Iteration 2508][Wall Clock 240.751050673s] Trained 128 records in 0.087811871 seconds. Throughput is 1457.6616 records/second. Loss is 2.0760007. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8514399771884804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 20992/60000][Iteration 2509][Wall Clock 240.83873185s] Trained 128 records in 0.087681177 seconds. Throughput is 1459.8345 records/second. Loss is 2.0828876. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8506271379703536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 21120/60000][Iteration 2510][Wall Clock 240.925879353s] Trained 128 records in 0.087147503 seconds. Throughput is 1468.7742 records/second. Loss is 2.0982168. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8498147620404675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 21248/60000][Iteration 2511][Wall Clock 241.011880803s] Trained 128 records in 0.08600145 seconds. Throughput is 1488.347 records/second. Loss is 2.0976927. Sequentialb692dd65's hyper parameters: Current learning rate is 2.849002849002849E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 21376/60000][Iteration 2512][Wall Clock 241.098561959s] Trained 128 records in 0.086681156 seconds. Throughput is 1476.6761 records/second. Loss is 2.043674. Sequentialb692dd65's hyper parameters: Current learning rate is 2.848191398461977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 21504/60000][Iteration 2513][Wall Clock 241.186395863s] Trained 128 records in 0.087833904 seconds. Throughput is 1457.296 records/second. Loss is 2.0752318. Sequentialb692dd65's hyper parameters: Current learning rate is 2.847380410022779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:24 INFO  DistriOptimizer$:408 - [Epoch 6 21632/60000][Iteration 2514][Wall Clock 241.272576608s] Trained 128 records in 0.086180745 seconds. Throughput is 1485.2505 records/second. Loss is 2.0781357. Sequentialb692dd65's hyper parameters: Current learning rate is 2.846569883290635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 21760/60000][Iteration 2515][Wall Clock 241.369171015s] Trained 128 records in 0.096594407 seconds. Throughput is 1325.1284 records/second. Loss is 2.1017046. Sequentialb692dd65's hyper parameters: Current learning rate is 2.845759817871372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 21888/60000][Iteration 2516][Wall Clock 241.471184822s] Trained 128 records in 0.102013807 seconds. Throughput is 1254.7322 records/second. Loss is 2.0714834. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8449502133712657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22016/60000][Iteration 2517][Wall Clock 241.558672164s] Trained 128 records in 0.087487342 seconds. Throughput is 1463.0688 records/second. Loss is 2.0730052. Sequentialb692dd65's hyper parameters: Current learning rate is 2.844141069397042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22144/60000][Iteration 2518][Wall Clock 241.647425993s] Trained 128 records in 0.088753829 seconds. Throughput is 1442.1913 records/second. Loss is 2.0499115. Sequentialb692dd65's hyper parameters: Current learning rate is 2.843332385555872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22272/60000][Iteration 2519][Wall Clock 241.737028705s] Trained 128 records in 0.089602712 seconds. Throughput is 1428.5282 records/second. Loss is 2.0740173. Sequentialb692dd65's hyper parameters: Current learning rate is 2.842524161455372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22400/60000][Iteration 2520][Wall Clock 241.822588528s] Trained 128 records in 0.085559823 seconds. Throughput is 1496.0293 records/second. Loss is 2.092953. Sequentialb692dd65's hyper parameters: Current learning rate is 2.841716396703609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22528/60000][Iteration 2521][Wall Clock 241.909284426s] Trained 128 records in 0.086695898 seconds. Throughput is 1476.4252 records/second. Loss is 2.1149735. Sequentialb692dd65's hyper parameters: Current learning rate is 2.840909090909091E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22656/60000][Iteration 2522][Wall Clock 241.995471899s] Trained 128 records in 0.086187473 seconds. Throughput is 1485.1346 records/second. Loss is 2.0668163. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8401022436807724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22784/60000][Iteration 2523][Wall Clock 242.079427835s] Trained 128 records in 0.083955936 seconds. Throughput is 1524.6093 records/second. Loss is 2.1059723. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8392958546280523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 22912/60000][Iteration 2524][Wall Clock 242.168421635s] Trained 128 records in 0.0889938 seconds. Throughput is 1438.3024 records/second. Loss is 2.0891287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.838489923360772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:25 INFO  DistriOptimizer$:408 - [Epoch 6 23040/60000][Iteration 2525][Wall Clock 242.256273547s] Trained 128 records in 0.087851912 seconds. Throughput is 1456.9973 records/second. Loss is 2.063289. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8376844494892167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23168/60000][Iteration 2526][Wall Clock 242.342332313s] Trained 128 records in 0.086058766 seconds. Throughput is 1487.3557 records/second. Loss is 2.0712552. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8368794326241134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23296/60000][Iteration 2527][Wall Clock 242.430659109s] Trained 128 records in 0.088326796 seconds. Throughput is 1449.1638 records/second. Loss is 2.0523505. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8360748723766304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23424/60000][Iteration 2528][Wall Clock 242.518444836s] Trained 128 records in 0.087785727 seconds. Throughput is 1458.0958 records/second. Loss is 2.0923293. Sequentialb692dd65's hyper parameters: Current learning rate is 2.835270768358378E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23552/60000][Iteration 2529][Wall Clock 242.607752441s] Trained 128 records in 0.089307605 seconds. Throughput is 1433.2485 records/second. Loss is 2.0656216. Sequentialb692dd65's hyper parameters: Current learning rate is 2.834467120181406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23680/60000][Iteration 2530][Wall Clock 242.701046815s] Trained 128 records in 0.093294374 seconds. Throughput is 1372.0012 records/second. Loss is 2.0723326. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8336639274582036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23808/60000][Iteration 2531][Wall Clock 242.779944098s] Trained 128 records in 0.078897283 seconds. Throughput is 1622.3625 records/second. Loss is 2.0690808. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8328611898016995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 23936/60000][Iteration 2532][Wall Clock 242.864661728s] Trained 128 records in 0.08471763 seconds. Throughput is 1510.9015 records/second. Loss is 2.0837786. Sequentialb692dd65's hyper parameters: Current learning rate is 2.832058906825262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 24064/60000][Iteration 2533][Wall Clock 242.95468936s] Trained 128 records in 0.090027632 seconds. Throughput is 1421.7858 records/second. Loss is 2.0551443. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8312570781426955E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 24192/60000][Iteration 2534][Wall Clock 243.039765016s] Trained 128 records in 0.085075656 seconds. Throughput is 1504.5432 records/second. Loss is 2.1102815. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8304557033682426E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 24320/60000][Iteration 2535][Wall Clock 243.127924704s] Trained 128 records in 0.088159688 seconds. Throughput is 1451.9108 records/second. Loss is 2.0872862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8296547821165814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:26 INFO  DistriOptimizer$:408 - [Epoch 6 24448/60000][Iteration 2536][Wall Clock 243.215878128s] Trained 128 records in 0.087953424 seconds. Throughput is 1455.3157 records/second. Loss is 2.053691. Sequentialb692dd65's hyper parameters: Current learning rate is 2.828854314002829E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 24576/60000][Iteration 2537][Wall Clock 243.304218467s] Trained 128 records in 0.088340339 seconds. Throughput is 1448.9417 records/second. Loss is 2.0844193. Sequentialb692dd65's hyper parameters: Current learning rate is 2.828054298642534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 24704/60000][Iteration 2538][Wall Clock 243.39026629s] Trained 128 records in 0.086047823 seconds. Throughput is 1487.5449 records/second. Loss is 2.0744505. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8272547356516825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 24832/60000][Iteration 2539][Wall Clock 243.477369798s] Trained 128 records in 0.087103508 seconds. Throughput is 1469.516 records/second. Loss is 2.0591414. Sequentialb692dd65's hyper parameters: Current learning rate is 2.826455624646693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 24960/60000][Iteration 2540][Wall Clock 243.572691733s] Trained 128 records in 0.095321935 seconds. Throughput is 1342.8179 records/second. Loss is 2.070883. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8256569652444194E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25088/60000][Iteration 2541][Wall Clock 243.662731707s] Trained 128 records in 0.090039974 seconds. Throughput is 1421.5908 records/second. Loss is 2.0688431. Sequentialb692dd65's hyper parameters: Current learning rate is 2.824858757062147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25216/60000][Iteration 2542][Wall Clock 243.747201779s] Trained 128 records in 0.084470072 seconds. Throughput is 1515.3296 records/second. Loss is 2.0637767. Sequentialb692dd65's hyper parameters: Current learning rate is 2.824060999717594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25344/60000][Iteration 2543][Wall Clock 243.832932445s] Trained 128 records in 0.085730666 seconds. Throughput is 1493.048 records/second. Loss is 2.1057484. Sequentialb692dd65's hyper parameters: Current learning rate is 2.82326369282891E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25472/60000][Iteration 2544][Wall Clock 243.917859477s] Trained 128 records in 0.084927032 seconds. Throughput is 1507.1763 records/second. Loss is 2.0861802. Sequentialb692dd65's hyper parameters: Current learning rate is 2.822466836014677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25600/60000][Iteration 2545][Wall Clock 244.006829226s] Trained 128 records in 0.088969749 seconds. Throughput is 1438.6912 records/second. Loss is 2.0668168. Sequentialb692dd65's hyper parameters: Current learning rate is 2.821670428893905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25728/60000][Iteration 2546][Wall Clock 244.091958249s] Trained 128 records in 0.085129023 seconds. Throughput is 1503.6 records/second. Loss is 2.0557468. Sequentialb692dd65's hyper parameters: Current learning rate is 2.820874471086037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:27 INFO  DistriOptimizer$:408 - [Epoch 6 25856/60000][Iteration 2547][Wall Clock 244.176610405s] Trained 128 records in 0.084652156 seconds. Throughput is 1512.0702 records/second. Loss is 2.073746. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8200789622109416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 25984/60000][Iteration 2548][Wall Clock 244.261516494s] Trained 128 records in 0.084906089 seconds. Throughput is 1507.548 records/second. Loss is 2.0763729. Sequentialb692dd65's hyper parameters: Current learning rate is 2.81928390188892E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26112/60000][Iteration 2549][Wall Clock 244.349732073s] Trained 128 records in 0.088215579 seconds. Throughput is 1450.9908 records/second. Loss is 2.0587478. Sequentialb692dd65's hyper parameters: Current learning rate is 2.818489289740699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26240/60000][Iteration 2550][Wall Clock 244.433566708s] Trained 128 records in 0.083834635 seconds. Throughput is 1526.8153 records/second. Loss is 2.0926225. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8176951253874335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26368/60000][Iteration 2551][Wall Clock 244.524444211s] Trained 128 records in 0.090877503 seconds. Throughput is 1408.4894 records/second. Loss is 2.1092796. Sequentialb692dd65's hyper parameters: Current learning rate is 2.816901408450704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26496/60000][Iteration 2552][Wall Clock 244.615366819s] Trained 128 records in 0.090922608 seconds. Throughput is 1407.7906 records/second. Loss is 2.0971484. Sequentialb692dd65's hyper parameters: Current learning rate is 2.81610813855252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26624/60000][Iteration 2553][Wall Clock 244.704062758s] Trained 128 records in 0.088695939 seconds. Throughput is 1443.1327 records/second. Loss is 2.0706418. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8153153153153153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26752/60000][Iteration 2554][Wall Clock 244.793525894s] Trained 128 records in 0.089463136 seconds. Throughput is 1430.7568 records/second. Loss is 2.0553792. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8145229383619476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 26880/60000][Iteration 2555][Wall Clock 244.879321231s] Trained 128 records in 0.085795337 seconds. Throughput is 1491.9226 records/second. Loss is 2.0903947. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8137310073157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 27008/60000][Iteration 2556][Wall Clock 244.980274019s] Trained 128 records in 0.100952788 seconds. Throughput is 1267.9194 records/second. Loss is 2.102205. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8129395218002813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 27136/60000][Iteration 2557][Wall Clock 245.063119695s] Trained 128 records in 0.082845676 seconds. Throughput is 1545.0415 records/second. Loss is 2.0651712. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8121484814398203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 27264/60000][Iteration 2558][Wall Clock 245.140237094s] Trained 128 records in 0.077117399 seconds. Throughput is 1659.807 records/second. Loss is 2.081414. Sequentialb692dd65's hyper parameters: Current learning rate is 2.81135788585887E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:28 INFO  DistriOptimizer$:408 - [Epoch 6 27392/60000][Iteration 2559][Wall Clock 245.225024994s] Trained 128 records in 0.0847879 seconds. Throughput is 1509.6494 records/second. Loss is 2.0958624. Sequentialb692dd65's hyper parameters: Current learning rate is 2.810567734682406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 27520/60000][Iteration 2560][Wall Clock 245.311826288s] Trained 128 records in 0.086801294 seconds. Throughput is 1474.6324 records/second. Loss is 2.1008391. Sequentialb692dd65's hyper parameters: Current learning rate is 2.809778027535825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 27648/60000][Iteration 2561][Wall Clock 245.39692156s] Trained 128 records in 0.085095272 seconds. Throughput is 1504.1964 records/second. Loss is 2.0625792. Sequentialb692dd65's hyper parameters: Current learning rate is 2.808988764044944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 27776/60000][Iteration 2562][Wall Clock 245.483474965s] Trained 128 records in 0.086553405 seconds. Throughput is 1478.8558 records/second. Loss is 2.0542197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.808199943836001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 27904/60000][Iteration 2563][Wall Clock 245.5684517s] Trained 128 records in 0.084976735 seconds. Throughput is 1506.2947 records/second. Loss is 2.0881567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8074115665356543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28032/60000][Iteration 2564][Wall Clock 245.667428889s] Trained 128 records in 0.098977189 seconds. Throughput is 1293.2273 records/second. Loss is 2.0584838. Sequentialb692dd65's hyper parameters: Current learning rate is 2.806623631770979E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28160/60000][Iteration 2565][Wall Clock 245.759659025s] Trained 128 records in 0.092230136 seconds. Throughput is 1387.8328 records/second. Loss is 2.0762599. Sequentialb692dd65's hyper parameters: Current learning rate is 2.805836139169473E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28288/60000][Iteration 2566][Wall Clock 245.853576988s] Trained 128 records in 0.093917963 seconds. Throughput is 1362.8915 records/second. Loss is 2.0850816. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8050490883590464E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28416/60000][Iteration 2567][Wall Clock 245.939543981s] Trained 128 records in 0.085966993 seconds. Throughput is 1488.9436 records/second. Loss is 2.0618174. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8042624789680314E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28544/60000][Iteration 2568][Wall Clock 246.026940756s] Trained 128 records in 0.087396775 seconds. Throughput is 1464.5848 records/second. Loss is 2.0705643. Sequentialb692dd65's hyper parameters: Current learning rate is 2.803476310625175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28672/60000][Iteration 2569][Wall Clock 246.112589251s] Trained 128 records in 0.085648495 seconds. Throughput is 1494.4805 records/second. Loss is 2.0441933. Sequentialb692dd65's hyper parameters: Current learning rate is 2.802690582959641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:29 INFO  DistriOptimizer$:408 - [Epoch 6 28800/60000][Iteration 2570][Wall Clock 246.2258459s] Trained 128 records in 0.113256649 seconds. Throughput is 1130.1765 records/second. Loss is 2.0422978. Sequentialb692dd65's hyper parameters: Current learning rate is 2.801905295601009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 28928/60000][Iteration 2571][Wall Clock 246.311601461s] Trained 128 records in 0.085755561 seconds. Throughput is 1492.6145 records/second. Loss is 2.0894074. Sequentialb692dd65's hyper parameters: Current learning rate is 2.801120448179272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29056/60000][Iteration 2572][Wall Clock 246.400037198s] Trained 128 records in 0.088435737 seconds. Throughput is 1447.3787 records/second. Loss is 2.0609968. Sequentialb692dd65's hyper parameters: Current learning rate is 2.8003360403248387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29184/60000][Iteration 2573][Wall Clock 246.494413643s] Trained 128 records in 0.094376445 seconds. Throughput is 1356.2706 records/second. Loss is 2.07211. Sequentialb692dd65's hyper parameters: Current learning rate is 2.799552071668533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29312/60000][Iteration 2574][Wall Clock 246.577838279s] Trained 128 records in 0.083424636 seconds. Throughput is 1534.319 records/second. Loss is 2.0673633. Sequentialb692dd65's hyper parameters: Current learning rate is 2.79876854184159E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29440/60000][Iteration 2575][Wall Clock 246.67033364s] Trained 128 records in 0.092495361 seconds. Throughput is 1383.8531 records/second. Loss is 2.0868773. Sequentialb692dd65's hyper parameters: Current learning rate is 2.797985450475658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29568/60000][Iteration 2576][Wall Clock 246.757335948s] Trained 128 records in 0.087002308 seconds. Throughput is 1471.2253 records/second. Loss is 2.0564892. Sequentialb692dd65's hyper parameters: Current learning rate is 2.797202797202797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29696/60000][Iteration 2577][Wall Clock 246.844379583s] Trained 128 records in 0.087043635 seconds. Throughput is 1470.5269 records/second. Loss is 2.079443. Sequentialb692dd65's hyper parameters: Current learning rate is 2.796420581655481E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29824/60000][Iteration 2578][Wall Clock 246.935559023s] Trained 128 records in 0.09117944 seconds. Throughput is 1403.8253 records/second. Loss is 2.0798643. Sequentialb692dd65's hyper parameters: Current learning rate is 2.795638803466592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 29952/60000][Iteration 2579][Wall Clock 247.024513782s] Trained 128 records in 0.088954759 seconds. Throughput is 1438.9336 records/second. Loss is 2.0847435. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7948574622694243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 30080/60000][Iteration 2580][Wall Clock 247.112412848s] Trained 128 records in 0.087899066 seconds. Throughput is 1456.2157 records/second. Loss is 2.067893. Sequentialb692dd65's hyper parameters: Current learning rate is 2.794076557697681E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:30 INFO  DistriOptimizer$:408 - [Epoch 6 30208/60000][Iteration 2581][Wall Clock 247.200344969s] Trained 128 records in 0.087932121 seconds. Throughput is 1455.6683 records/second. Loss is 2.0577261. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7932960893854746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30336/60000][Iteration 2582][Wall Clock 247.301749161s] Trained 128 records in 0.101404192 seconds. Throughput is 1262.2753 records/second. Loss is 2.081756. Sequentialb692dd65's hyper parameters: Current learning rate is 2.792516056967328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30464/60000][Iteration 2583][Wall Clock 247.383855707s] Trained 128 records in 0.082106546 seconds. Throughput is 1558.95 records/second. Loss is 2.080162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7917364600781687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30592/60000][Iteration 2584][Wall Clock 247.498604769s] Trained 128 records in 0.114749062 seconds. Throughput is 1115.4775 records/second. Loss is 2.054275. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7909572983533354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30720/60000][Iteration 2585][Wall Clock 247.583448312s] Trained 128 records in 0.084843543 seconds. Throughput is 1508.6593 records/second. Loss is 2.0906408. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7901785714285713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30848/60000][Iteration 2586][Wall Clock 247.670876986s] Trained 128 records in 0.087428674 seconds. Throughput is 1464.0505 records/second. Loss is 2.062309. Sequentialb692dd65's hyper parameters: Current learning rate is 2.789400278940028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 30976/60000][Iteration 2587][Wall Clock 247.758047437s] Trained 128 records in 0.087170451 seconds. Throughput is 1468.3875 records/second. Loss is 2.0798771. Sequentialb692dd65's hyper parameters: Current learning rate is 2.788622420524261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 31104/60000][Iteration 2588][Wall Clock 247.843694839s] Trained 128 records in 0.085647402 seconds. Throughput is 1494.4995 records/second. Loss is 2.06684. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7878449958182325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 31232/60000][Iteration 2589][Wall Clock 247.927242062s] Trained 128 records in 0.083547223 seconds. Throughput is 1532.0677 records/second. Loss is 2.0904858. Sequentialb692dd65's hyper parameters: Current learning rate is 2.787068004459309E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 31360/60000][Iteration 2590][Wall Clock 248.016795981s] Trained 128 records in 0.089553919 seconds. Throughput is 1429.3065 records/second. Loss is 2.0706165. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7862914460852607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 31488/60000][Iteration 2591][Wall Clock 248.120419494s] Trained 128 records in 0.103623513 seconds. Throughput is 1235.241 records/second. Loss is 2.101303. Sequentialb692dd65's hyper parameters: Current learning rate is 2.785515320334262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:31 INFO  DistriOptimizer$:408 - [Epoch 6 31616/60000][Iteration 2592][Wall Clock 248.203581826s] Trained 128 records in 0.083162332 seconds. Throughput is 1539.1584 records/second. Loss is 2.0608783. Sequentialb692dd65's hyper parameters: Current learning rate is 2.78473962684489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 31744/60000][Iteration 2593][Wall Clock 248.296295041s] Trained 128 records in 0.092713215 seconds. Throughput is 1380.6014 records/second. Loss is 2.0748618. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7839643652561246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 31872/60000][Iteration 2594][Wall Clock 248.380353697s] Trained 128 records in 0.084058656 seconds. Throughput is 1522.7462 records/second. Loss is 2.0632422. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7831895352073476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32000/60000][Iteration 2595][Wall Clock 248.470838943s] Trained 128 records in 0.090485246 seconds. Throughput is 1414.5952 records/second. Loss is 2.0603566. Sequentialb692dd65's hyper parameters: Current learning rate is 2.782415136338342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32128/60000][Iteration 2596][Wall Clock 248.556442137s] Trained 128 records in 0.085603194 seconds. Throughput is 1495.2714 records/second. Loss is 2.0652065. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7816411682892903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32256/60000][Iteration 2597][Wall Clock 248.642955717s] Trained 128 records in 0.08651358 seconds. Throughput is 1479.5365 records/second. Loss is 2.0892107. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7808676307007786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32384/60000][Iteration 2598][Wall Clock 248.735694777s] Trained 128 records in 0.09273906 seconds. Throughput is 1380.2167 records/second. Loss is 2.0680766. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7800945232137893E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32512/60000][Iteration 2599][Wall Clock 248.844160492s] Trained 128 records in 0.108465715 seconds. Throughput is 1180.0964 records/second. Loss is 2.0825055. Sequentialb692dd65's hyper parameters: Current learning rate is 2.779321845469706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32640/60000][Iteration 2600][Wall Clock 248.958400703s] Trained 128 records in 0.114240211 seconds. Throughput is 1120.446 records/second. Loss is 2.0919936. Sequentialb692dd65's hyper parameters: Current learning rate is 2.778549597110308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32768/60000][Iteration 2601][Wall Clock 249.069160691s] Trained 128 records in 0.110759988 seconds. Throughput is 1155.652 records/second. Loss is 2.0568666. Sequentialb692dd65's hyper parameters: Current learning rate is 2.777777777777778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:32 INFO  DistriOptimizer$:408 - [Epoch 6 32896/60000][Iteration 2602][Wall Clock 249.178475187s] Trained 128 records in 0.109314496 seconds. Throughput is 1170.9335 records/second. Loss is 2.089391. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7770063871146905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33024/60000][Iteration 2603][Wall Clock 249.28970545s] Trained 128 records in 0.111230263 seconds. Throughput is 1150.766 records/second. Loss is 2.086204. Sequentialb692dd65's hyper parameters: Current learning rate is 2.77623542476402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33152/60000][Iteration 2604][Wall Clock 249.399345178s] Trained 128 records in 0.109639728 seconds. Throughput is 1167.4601 records/second. Loss is 2.076894. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7754648903691365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33280/60000][Iteration 2605][Wall Clock 249.491721372s] Trained 128 records in 0.092376194 seconds. Throughput is 1385.6384 records/second. Loss is 2.1011865. Sequentialb692dd65's hyper parameters: Current learning rate is 2.774694783573807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33408/60000][Iteration 2606][Wall Clock 249.580338173s] Trained 128 records in 0.088616801 seconds. Throughput is 1444.4213 records/second. Loss is 2.0581293. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7739251040221914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33536/60000][Iteration 2607][Wall Clock 249.668030962s] Trained 128 records in 0.087692789 seconds. Throughput is 1459.6411 records/second. Loss is 2.08506. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7731558513588466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33664/60000][Iteration 2608][Wall Clock 249.982224901s] Trained 128 records in 0.314193939 seconds. Throughput is 407.3917 records/second. Loss is 2.0827894. Sequentialb692dd65's hyper parameters: Current learning rate is 2.772387025228722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33792/60000][Iteration 2609][Wall Clock 250.065777351s] Trained 128 records in 0.08355245 seconds. Throughput is 1531.9718 records/second. Loss is 2.078054. Sequentialb692dd65's hyper parameters: Current learning rate is 2.771618625277162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:33 INFO  DistriOptimizer$:408 - [Epoch 6 33920/60000][Iteration 2610][Wall Clock 250.157343878s] Trained 128 records in 0.091566527 seconds. Throughput is 1397.8907 records/second. Loss is 2.0740964. Sequentialb692dd65's hyper parameters: Current learning rate is 2.770850651149903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34048/60000][Iteration 2611][Wall Clock 250.248233066s] Trained 128 records in 0.090889188 seconds. Throughput is 1408.3083 records/second. Loss is 2.0595124. Sequentialb692dd65's hyper parameters: Current learning rate is 2.770083102493075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34176/60000][Iteration 2612][Wall Clock 250.334137782s] Trained 128 records in 0.085904716 seconds. Throughput is 1490.023 records/second. Loss is 2.101511. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7693159789531985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34304/60000][Iteration 2613][Wall Clock 250.418334498s] Trained 128 records in 0.084196716 seconds. Throughput is 1520.2493 records/second. Loss is 2.054867. Sequentialb692dd65's hyper parameters: Current learning rate is 2.768549280177187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34432/60000][Iteration 2614][Wall Clock 250.50867367s] Trained 128 records in 0.090339172 seconds. Throughput is 1416.8827 records/second. Loss is 2.0274627. Sequentialb692dd65's hyper parameters: Current learning rate is 2.767783005812344E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34560/60000][Iteration 2615][Wall Clock 250.601414861s] Trained 128 records in 0.092741191 seconds. Throughput is 1380.1849 records/second. Loss is 2.0864. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7670171555063645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34688/60000][Iteration 2616][Wall Clock 250.701708248s] Trained 128 records in 0.100293387 seconds. Throughput is 1276.2556 records/second. Loss is 2.0402637. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7662517289073305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34816/60000][Iteration 2617][Wall Clock 250.788017281s] Trained 128 records in 0.086309033 seconds. Throughput is 1483.043 records/second. Loss is 2.09502. Sequentialb692dd65's hyper parameters: Current learning rate is 2.765486725663717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 34944/60000][Iteration 2618][Wall Clock 250.877041781s] Trained 128 records in 0.0890245 seconds. Throughput is 1437.8065 records/second. Loss is 2.0692484. Sequentialb692dd65's hyper parameters: Current learning rate is 2.764722145424385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 35072/60000][Iteration 2619][Wall Clock 250.965672459s] Trained 128 records in 0.088630678 seconds. Throughput is 1444.1952 records/second. Loss is 2.1041124. Sequentialb692dd65's hyper parameters: Current learning rate is 2.763957987838585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 35200/60000][Iteration 2620][Wall Clock 251.052045228s] Trained 128 records in 0.086372769 seconds. Throughput is 1481.9485 records/second. Loss is 2.0847228. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7631942525559546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:34 INFO  DistriOptimizer$:408 - [Epoch 6 35328/60000][Iteration 2621][Wall Clock 251.137377687s] Trained 128 records in 0.085332459 seconds. Throughput is 1500.0154 records/second. Loss is 2.0855627. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7624309392265195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 35456/60000][Iteration 2622][Wall Clock 251.225599071s] Trained 128 records in 0.088221384 seconds. Throughput is 1450.8954 records/second. Loss is 2.0834963. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7616680475006904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 35584/60000][Iteration 2623][Wall Clock 251.311977514s] Trained 128 records in 0.086378443 seconds. Throughput is 1481.8512 records/second. Loss is 2.0676136. Sequentialb692dd65's hyper parameters: Current learning rate is 2.760905577029266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 35712/60000][Iteration 2624][Wall Clock 251.397925262s] Trained 128 records in 0.085947748 seconds. Throughput is 1489.277 records/second. Loss is 2.0762687. Sequentialb692dd65's hyper parameters: Current learning rate is 2.760143527463428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 35840/60000][Iteration 2625][Wall Clock 251.488036227s] Trained 128 records in 0.090110965 seconds. Throughput is 1420.4708 records/second. Loss is 2.0849292. Sequentialb692dd65's hyper parameters: Current learning rate is 2.759381898454746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 35968/60000][Iteration 2626][Wall Clock 251.575941288s] Trained 128 records in 0.087905061 seconds. Throughput is 1456.1163 records/second. Loss is 2.048478. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7586206896551725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36096/60000][Iteration 2627][Wall Clock 251.662835114s] Trained 128 records in 0.086893826 seconds. Throughput is 1473.062 records/second. Loss is 2.0784118. Sequentialb692dd65's hyper parameters: Current learning rate is 2.757859900717044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36224/60000][Iteration 2628][Wall Clock 251.750533135s] Trained 128 records in 0.087698021 seconds. Throughput is 1459.5541 records/second. Loss is 2.084152. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7570995312930797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36352/60000][Iteration 2629][Wall Clock 251.839798984s] Trained 128 records in 0.089265849 seconds. Throughput is 1433.9191 records/second. Loss is 2.0665581. Sequentialb692dd65's hyper parameters: Current learning rate is 2.756339581036384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36480/60000][Iteration 2630][Wall Clock 251.929651765s] Trained 128 records in 0.089852781 seconds. Throughput is 1424.5525 records/second. Loss is 2.0633495. Sequentialb692dd65's hyper parameters: Current learning rate is 2.755580049600441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36608/60000][Iteration 2631][Wall Clock 252.016571381s] Trained 128 records in 0.086919616 seconds. Throughput is 1472.625 records/second. Loss is 2.093209. Sequentialb692dd65's hyper parameters: Current learning rate is 2.754820936639119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36736/60000][Iteration 2632][Wall Clock 252.103839003s] Trained 128 records in 0.087267622 seconds. Throughput is 1466.7524 records/second. Loss is 2.076354. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7540622418066645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:35 INFO  DistriOptimizer$:408 - [Epoch 6 36864/60000][Iteration 2633][Wall Clock 252.192283337s] Trained 128 records in 0.088444334 seconds. Throughput is 1447.2379 records/second. Loss is 2.0774658. Sequentialb692dd65's hyper parameters: Current learning rate is 2.753303964757709E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 36992/60000][Iteration 2634][Wall Clock 252.282332077s] Trained 128 records in 0.09004874 seconds. Throughput is 1421.4525 records/second. Loss is 2.0778065. Sequentialb692dd65's hyper parameters: Current learning rate is 2.752546105147261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37120/60000][Iteration 2635][Wall Clock 252.366165723s] Trained 128 records in 0.083833646 seconds. Throughput is 1526.8334 records/second. Loss is 2.059223. Sequentialb692dd65's hyper parameters: Current learning rate is 2.75178866263071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37248/60000][Iteration 2636][Wall Clock 252.453583086s] Trained 128 records in 0.087417363 seconds. Throughput is 1464.24 records/second. Loss is 2.0671837. Sequentialb692dd65's hyper parameters: Current learning rate is 2.751031636863824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37376/60000][Iteration 2637][Wall Clock 252.536944251s] Trained 128 records in 0.083361165 seconds. Throughput is 1535.4872 records/second. Loss is 2.0686917. Sequentialb692dd65's hyper parameters: Current learning rate is 2.75027502750275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37504/60000][Iteration 2638][Wall Clock 252.621523055s] Trained 128 records in 0.084578804 seconds. Throughput is 1513.3815 records/second. Loss is 2.0785072. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7495188342040145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37632/60000][Iteration 2639][Wall Clock 252.707524133s] Trained 128 records in 0.086001078 seconds. Throughput is 1488.3535 records/second. Loss is 2.0616674. Sequentialb692dd65's hyper parameters: Current learning rate is 2.748763056624519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37760/60000][Iteration 2640][Wall Clock 252.794814872s] Trained 128 records in 0.087290739 seconds. Throughput is 1466.364 records/second. Loss is 2.0666168. Sequentialb692dd65's hyper parameters: Current learning rate is 2.748007694421544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 37888/60000][Iteration 2641][Wall Clock 252.881421776s] Trained 128 records in 0.086606904 seconds. Throughput is 1477.9423 records/second. Loss is 2.06703. Sequentialb692dd65's hyper parameters: Current learning rate is 2.747252747252747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 38016/60000][Iteration 2642][Wall Clock 252.979264582s] Trained 128 records in 0.097842806 seconds. Throughput is 1308.2208 records/second. Loss is 2.060545. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7464982147761604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 38144/60000][Iteration 2643][Wall Clock 253.061676015s] Trained 128 records in 0.082411433 seconds. Throughput is 1553.1826 records/second. Loss is 2.0831966. Sequentialb692dd65's hyper parameters: Current learning rate is 2.745744096650192E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:36 INFO  DistriOptimizer$:408 - [Epoch 6 38272/60000][Iteration 2644][Wall Clock 253.146002629s] Trained 128 records in 0.084326614 seconds. Throughput is 1517.9075 records/second. Loss is 2.0379658. Sequentialb692dd65's hyper parameters: Current learning rate is 2.744990392533626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 38400/60000][Iteration 2645][Wall Clock 253.239524439s] Trained 128 records in 0.09352181 seconds. Throughput is 1368.6647 records/second. Loss is 2.068824. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7442371020856203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 38528/60000][Iteration 2646][Wall Clock 253.324291454s] Trained 128 records in 0.084767015 seconds. Throughput is 1510.0214 records/second. Loss is 2.0549045. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7434842249657066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 38656/60000][Iteration 2647][Wall Clock 253.414305903s] Trained 128 records in 0.090014449 seconds. Throughput is 1421.9939 records/second. Loss is 2.0806007. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7427317608337906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 38784/60000][Iteration 2648][Wall Clock 253.499816857s] Trained 128 records in 0.085510954 seconds. Throughput is 1496.8843 records/second. Loss is 2.0624602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7419797093501506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 38912/60000][Iteration 2649][Wall Clock 253.58818984s] Trained 128 records in 0.088372983 seconds. Throughput is 1448.4065 records/second. Loss is 2.0622592. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7412280701754384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39040/60000][Iteration 2650][Wall Clock 253.677051163s] Trained 128 records in 0.088861323 seconds. Throughput is 1440.4467 records/second. Loss is 2.0536861. Sequentialb692dd65's hyper parameters: Current learning rate is 2.740476842970677E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39168/60000][Iteration 2651][Wall Clock 253.765791734s] Trained 128 records in 0.088740571 seconds. Throughput is 1442.4067 records/second. Loss is 2.0887952. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7397260273972606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39296/60000][Iteration 2652][Wall Clock 253.854677087s] Trained 128 records in 0.088885353 seconds. Throughput is 1440.0573 records/second. Loss is 2.094616. Sequentialb692dd65's hyper parameters: Current learning rate is 2.738975623116954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39424/60000][Iteration 2653][Wall Clock 253.944613584s] Trained 128 records in 0.089936497 seconds. Throughput is 1423.2264 records/second. Loss is 2.075659. Sequentialb692dd65's hyper parameters: Current learning rate is 2.738225629791895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39552/60000][Iteration 2654][Wall Clock 254.033918505s] Trained 128 records in 0.089304921 seconds. Throughput is 1433.2916 records/second. Loss is 2.0631807. Sequentialb692dd65's hyper parameters: Current learning rate is 2.737476047084588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:37 INFO  DistriOptimizer$:408 - [Epoch 6 39680/60000][Iteration 2655][Wall Clock 254.119635362s] Trained 128 records in 0.085716857 seconds. Throughput is 1493.2885 records/second. Loss is 2.0551243. Sequentialb692dd65's hyper parameters: Current learning rate is 2.736726874657909E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 39808/60000][Iteration 2656][Wall Clock 254.208338831s] Trained 128 records in 0.088703469 seconds. Throughput is 1443.0101 records/second. Loss is 2.057013. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7359781121751026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 39936/60000][Iteration 2657][Wall Clock 254.29583645s] Trained 128 records in 0.087497619 seconds. Throughput is 1462.8969 records/second. Loss is 2.0972505. Sequentialb692dd65's hyper parameters: Current learning rate is 2.735229759299781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40064/60000][Iteration 2658][Wall Clock 254.383497583s] Trained 128 records in 0.087661133 seconds. Throughput is 1460.1682 records/second. Loss is 2.0498405. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7344818156959256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40192/60000][Iteration 2659][Wall Clock 254.472364847s] Trained 128 records in 0.088867264 seconds. Throughput is 1440.3505 records/second. Loss is 2.0623121. Sequentialb692dd65's hyper parameters: Current learning rate is 2.733734281027884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40320/60000][Iteration 2660][Wall Clock 254.567601401s] Trained 128 records in 0.095236554 seconds. Throughput is 1344.0217 records/second. Loss is 2.0375009. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7329871549603714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40448/60000][Iteration 2661][Wall Clock 254.662953917s] Trained 128 records in 0.095352516 seconds. Throughput is 1342.3872 records/second. Loss is 2.090245. Sequentialb692dd65's hyper parameters: Current learning rate is 2.73224043715847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40576/60000][Iteration 2662][Wall Clock 254.749067321s] Trained 128 records in 0.086113404 seconds. Throughput is 1486.4121 records/second. Loss is 2.0616994. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7314941272876266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40704/60000][Iteration 2663][Wall Clock 254.865472421s] Trained 128 records in 0.1164051 seconds. Throughput is 1099.6082 records/second. Loss is 2.063814. Sequentialb692dd65's hyper parameters: Current learning rate is 2.730748225013654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40832/60000][Iteration 2664][Wall Clock 254.954517513s] Trained 128 records in 0.089045092 seconds. Throughput is 1437.474 records/second. Loss is 2.0810013. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7300027300027296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 40960/60000][Iteration 2665][Wall Clock 255.062312097s] Trained 128 records in 0.107794584 seconds. Throughput is 1187.4437 records/second. Loss is 2.036801. Sequentialb692dd65's hyper parameters: Current learning rate is 2.729257641921397E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:38 INFO  DistriOptimizer$:408 - [Epoch 6 41088/60000][Iteration 2666][Wall Clock 255.165539976s] Trained 128 records in 0.103227879 seconds. Throughput is 1239.9751 records/second. Loss is 2.0460095. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7285129604365623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41216/60000][Iteration 2667][Wall Clock 255.271064296s] Trained 128 records in 0.10552432 seconds. Throughput is 1212.9906 records/second. Loss is 2.0618668. Sequentialb692dd65's hyper parameters: Current learning rate is 2.727768685215494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41344/60000][Iteration 2668][Wall Clock 255.386899905s] Trained 128 records in 0.115835609 seconds. Throughput is 1105.0143 records/second. Loss is 2.072173. Sequentialb692dd65's hyper parameters: Current learning rate is 2.727024815925825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41472/60000][Iteration 2669][Wall Clock 255.470968959s] Trained 128 records in 0.084069054 seconds. Throughput is 1522.558 records/second. Loss is 2.023324. Sequentialb692dd65's hyper parameters: Current learning rate is 2.726281352235551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41600/60000][Iteration 2670][Wall Clock 255.591114142s] Trained 128 records in 0.120145183 seconds. Throughput is 1065.3777 records/second. Loss is 2.0492904. Sequentialb692dd65's hyper parameters: Current learning rate is 2.725538293813028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41728/60000][Iteration 2671][Wall Clock 255.701429253s] Trained 128 records in 0.110315111 seconds. Throughput is 1160.3125 records/second. Loss is 2.0635438. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7247956403269756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41856/60000][Iteration 2672][Wall Clock 255.809450814s] Trained 128 records in 0.108021561 seconds. Throughput is 1184.9486 records/second. Loss is 2.0756998. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7240533914464724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 41984/60000][Iteration 2673][Wall Clock 255.92042317s] Trained 128 records in 0.110972356 seconds. Throughput is 1153.4404 records/second. Loss is 2.0720084. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7233115468409583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 42112/60000][Iteration 2674][Wall Clock 256.014026467s] Trained 128 records in 0.093603297 seconds. Throughput is 1367.4731 records/second. Loss is 2.0699818. Sequentialb692dd65's hyper parameters: Current learning rate is 2.722570106180234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:39 INFO  DistriOptimizer$:408 - [Epoch 6 42240/60000][Iteration 2675][Wall Clock 256.122203665s] Trained 128 records in 0.108177198 seconds. Throughput is 1183.2438 records/second. Loss is 2.0456803. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7218290691344586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 42368/60000][Iteration 2676][Wall Clock 256.215122807s] Trained 128 records in 0.092919142 seconds. Throughput is 1377.5417 records/second. Loss is 2.0638587. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7210884353741496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 42496/60000][Iteration 2677][Wall Clock 256.309359689s] Trained 128 records in 0.094236882 seconds. Throughput is 1358.2793 records/second. Loss is 2.081398. Sequentialb692dd65's hyper parameters: Current learning rate is 2.720348204570185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 42624/60000][Iteration 2678][Wall Clock 256.402619697s] Trained 128 records in 0.093260008 seconds. Throughput is 1372.5068 records/second. Loss is 2.0566227. Sequentialb692dd65's hyper parameters: Current learning rate is 2.719608376393799E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 42752/60000][Iteration 2679][Wall Clock 256.490428184s] Trained 128 records in 0.087808487 seconds. Throughput is 1457.7178 records/second. Loss is 2.0664122. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7188689505165854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 42880/60000][Iteration 2680][Wall Clock 256.589535832s] Trained 128 records in 0.099107648 seconds. Throughput is 1291.525 records/second. Loss is 2.088356. Sequentialb692dd65's hyper parameters: Current learning rate is 2.718129926610492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43008/60000][Iteration 2681][Wall Clock 256.676281467s] Trained 128 records in 0.086745635 seconds. Throughput is 1475.5786 records/second. Loss is 2.048673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.717391304347826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43136/60000][Iteration 2682][Wall Clock 256.766746177s] Trained 128 records in 0.09046471 seconds. Throughput is 1414.9164 records/second. Loss is 2.0629942. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7166530834012495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43264/60000][Iteration 2683][Wall Clock 256.851658943s] Trained 128 records in 0.084912766 seconds. Throughput is 1507.4293 records/second. Loss is 2.057506. Sequentialb692dd65's hyper parameters: Current learning rate is 2.715915263443781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43392/60000][Iteration 2684][Wall Clock 256.944762904s] Trained 128 records in 0.093103961 seconds. Throughput is 1374.8073 records/second. Loss is 2.0594919. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7151778441487917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43520/60000][Iteration 2685][Wall Clock 257.038805979s] Trained 128 records in 0.094043075 seconds. Throughput is 1361.0784 records/second. Loss is 2.0623622. Sequentialb692dd65's hyper parameters: Current learning rate is 2.714440825190011E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:40 INFO  DistriOptimizer$:408 - [Epoch 6 43648/60000][Iteration 2686][Wall Clock 257.147825194s] Trained 128 records in 0.109019215 seconds. Throughput is 1174.105 records/second. Loss is 2.060008. Sequentialb692dd65's hyper parameters: Current learning rate is 2.71370420624152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 43776/60000][Iteration 2687][Wall Clock 257.240964233s] Trained 128 records in 0.093139039 seconds. Throughput is 1374.2894 records/second. Loss is 2.043166. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7129679869777537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 43904/60000][Iteration 2688][Wall Clock 257.343239208s] Trained 128 records in 0.102274975 seconds. Throughput is 1251.5281 records/second. Loss is 2.0230548. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7122321670735016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44032/60000][Iteration 2689][Wall Clock 257.455533537s] Trained 128 records in 0.112294329 seconds. Throughput is 1139.8617 records/second. Loss is 2.0517697. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7114967462039046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44160/60000][Iteration 2690][Wall Clock 257.561596329s] Trained 128 records in 0.106062792 seconds. Throughput is 1206.8323 records/second. Loss is 2.0629423. Sequentialb692dd65's hyper parameters: Current learning rate is 2.710761724044457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44288/60000][Iteration 2691][Wall Clock 257.66965784s] Trained 128 records in 0.108061511 seconds. Throughput is 1184.5106 records/second. Loss is 2.0543854. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7100271002710027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44416/60000][Iteration 2692][Wall Clock 257.777487238s] Trained 128 records in 0.107829398 seconds. Throughput is 1187.0603 records/second. Loss is 2.074038. Sequentialb692dd65's hyper parameters: Current learning rate is 2.70929287455974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44544/60000][Iteration 2693][Wall Clock 257.884685264s] Trained 128 records in 0.107198026 seconds. Throughput is 1194.0519 records/second. Loss is 2.0651138. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7085590465872155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44672/60000][Iteration 2694][Wall Clock 258.00183505s] Trained 128 records in 0.117149786 seconds. Throughput is 1092.6183 records/second. Loss is 2.0645373. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7078256160303275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:41 INFO  DistriOptimizer$:408 - [Epoch 6 44800/60000][Iteration 2695][Wall Clock 258.106812959s] Trained 128 records in 0.104977909 seconds. Throughput is 1219.3042 records/second. Loss is 2.052476. Sequentialb692dd65's hyper parameters: Current learning rate is 2.707092582566324E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 44928/60000][Iteration 2696][Wall Clock 258.215628345s] Trained 128 records in 0.108815386 seconds. Throughput is 1176.3042 records/second. Loss is 2.0504837. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7063599458728013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45056/60000][Iteration 2697][Wall Clock 258.322937787s] Trained 128 records in 0.107309442 seconds. Throughput is 1192.8121 records/second. Loss is 2.017714. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7056277056277056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45184/60000][Iteration 2698][Wall Clock 258.434664481s] Trained 128 records in 0.111726694 seconds. Throughput is 1145.6528 records/second. Loss is 2.0423388. Sequentialb692dd65's hyper parameters: Current learning rate is 2.704895861509332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45312/60000][Iteration 2699][Wall Clock 258.543310175s] Trained 128 records in 0.108645694 seconds. Throughput is 1178.1415 records/second. Loss is 2.0606108. Sequentialb692dd65's hyper parameters: Current learning rate is 2.7041644131963225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45440/60000][Iteration 2700][Wall Clock 258.635790634s] Trained 128 records in 0.092480459 seconds. Throughput is 1384.0762 records/second. Loss is 2.0692513. Sequentialb692dd65's hyper parameters: Current learning rate is 2.703433360367667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45568/60000][Iteration 2701][Wall Clock 258.722247099s] Trained 128 records in 0.086456465 seconds. Throughput is 1480.5139 records/second. Loss is 2.0798185. Sequentialb692dd65's hyper parameters: Current learning rate is 2.702702702702703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45696/60000][Iteration 2702][Wall Clock 258.80803425s] Trained 128 records in 0.085787151 seconds. Throughput is 1492.065 records/second. Loss is 2.0837917. Sequentialb692dd65's hyper parameters: Current learning rate is 2.701972439881113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45824/60000][Iteration 2703][Wall Clock 258.89304722s] Trained 128 records in 0.08501297 seconds. Throughput is 1505.6526 records/second. Loss is 2.0976555. Sequentialb692dd65's hyper parameters: Current learning rate is 2.701242571582928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 45952/60000][Iteration 2704][Wall Clock 258.979899397s] Trained 128 records in 0.086852177 seconds. Throughput is 1473.7684 records/second. Loss is 2.0587494. Sequentialb692dd65's hyper parameters: Current learning rate is 2.700513097488523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 46080/60000][Iteration 2705][Wall Clock 259.0692593s] Trained 128 records in 0.089359903 seconds. Throughput is 1432.4098 records/second. Loss is 2.048558. Sequentialb692dd65's hyper parameters: Current learning rate is 2.699784017278618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:42 INFO  DistriOptimizer$:408 - [Epoch 6 46208/60000][Iteration 2706][Wall Clock 259.156356822s] Trained 128 records in 0.087097522 seconds. Throughput is 1469.617 records/second. Loss is 2.0737615. Sequentialb692dd65's hyper parameters: Current learning rate is 2.699055330634278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46336/60000][Iteration 2707][Wall Clock 259.24296613s] Trained 128 records in 0.086609308 seconds. Throughput is 1477.9011 records/second. Loss is 2.0657196. Sequentialb692dd65's hyper parameters: Current learning rate is 2.698327037236913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46464/60000][Iteration 2708][Wall Clock 259.324570982s] Trained 128 records in 0.081604852 seconds. Throughput is 1568.5342 records/second. Loss is 2.0602298. Sequentialb692dd65's hyper parameters: Current learning rate is 2.697599136768276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46592/60000][Iteration 2709][Wall Clock 259.413183813s] Trained 128 records in 0.088612831 seconds. Throughput is 1444.4861 records/second. Loss is 2.035064. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6968716289104636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46720/60000][Iteration 2710][Wall Clock 259.503124619s] Trained 128 records in 0.089940806 seconds. Throughput is 1423.1582 records/second. Loss is 2.0767767. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6961445133459155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46848/60000][Iteration 2711][Wall Clock 259.596775235s] Trained 128 records in 0.093650616 seconds. Throughput is 1366.7822 records/second. Loss is 2.0882936. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6954177897574127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 46976/60000][Iteration 2712][Wall Clock 259.677741484s] Trained 128 records in 0.080966249 seconds. Throughput is 1580.9056 records/second. Loss is 2.084538. Sequentialb692dd65's hyper parameters: Current learning rate is 2.694691457828079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 47104/60000][Iteration 2713][Wall Clock 259.766717613s] Trained 128 records in 0.088976129 seconds. Throughput is 1438.5881 records/second. Loss is 2.1013803. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6939655172413793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 47232/60000][Iteration 2714][Wall Clock 259.861737915s] Trained 128 records in 0.095020302 seconds. Throughput is 1347.0806 records/second. Loss is 2.030089. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6932399676811203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 47360/60000][Iteration 2715][Wall Clock 259.952156306s] Trained 128 records in 0.090418391 seconds. Throughput is 1415.6412 records/second. Loss is 2.0712287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6925148088314486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 47488/60000][Iteration 2716][Wall Clock 260.047907036s] Trained 128 records in 0.09575073 seconds. Throughput is 1336.8044 records/second. Loss is 2.0422645. Sequentialb692dd65's hyper parameters: Current learning rate is 2.691790040376851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:43 INFO  DistriOptimizer$:408 - [Epoch 6 47616/60000][Iteration 2717][Wall Clock 260.140564056s] Trained 128 records in 0.09265702 seconds. Throughput is 1381.4387 records/second. Loss is 2.0436237. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6910656620021526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 47744/60000][Iteration 2718][Wall Clock 260.225732405s] Trained 128 records in 0.085168349 seconds. Throughput is 1502.9058 records/second. Loss is 2.0516393. Sequentialb692dd65's hyper parameters: Current learning rate is 2.690341673392521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 47872/60000][Iteration 2719][Wall Clock 260.317363546s] Trained 128 records in 0.091631141 seconds. Throughput is 1396.9049 records/second. Loss is 2.0365932. Sequentialb692dd65's hyper parameters: Current learning rate is 2.689618074233459E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48000/60000][Iteration 2720][Wall Clock 260.405161489s] Trained 128 records in 0.087797943 seconds. Throughput is 1457.893 records/second. Loss is 2.0695233. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6888948642108095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48128/60000][Iteration 2721][Wall Clock 260.492224155s] Trained 128 records in 0.087062666 seconds. Throughput is 1470.2054 records/second. Loss is 2.0880845. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6881720430107527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48256/60000][Iteration 2722][Wall Clock 260.575631182s] Trained 128 records in 0.083407027 seconds. Throughput is 1534.6428 records/second. Loss is 2.0622246. Sequentialb692dd65's hyper parameters: Current learning rate is 2.687449610319806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48384/60000][Iteration 2723][Wall Clock 260.660358071s] Trained 128 records in 0.084726889 seconds. Throughput is 1510.7365 records/second. Loss is 2.0698113. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6867275658248256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48512/60000][Iteration 2724][Wall Clock 260.74487128s] Trained 128 records in 0.084513209 seconds. Throughput is 1514.5562 records/second. Loss is 2.0628314. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6860059092130003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48640/60000][Iteration 2725][Wall Clock 260.830870556s] Trained 128 records in 0.085999276 seconds. Throughput is 1488.3846 records/second. Loss is 2.059174. Sequentialb692dd65's hyper parameters: Current learning rate is 2.685284640171858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48768/60000][Iteration 2726][Wall Clock 260.915639302s] Trained 128 records in 0.084768746 seconds. Throughput is 1509.9906 records/second. Loss is 2.0470948. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6845637583892615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 48896/60000][Iteration 2727][Wall Clock 261.000072212s] Trained 128 records in 0.08443291 seconds. Throughput is 1515.9966 records/second. Loss is 2.084526. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6838432635534085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:44 INFO  DistriOptimizer$:408 - [Epoch 6 49024/60000][Iteration 2728][Wall Clock 261.085296414s] Trained 128 records in 0.085224202 seconds. Throughput is 1501.9208 records/second. Loss is 2.0465317. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6831231553528306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49152/60000][Iteration 2729][Wall Clock 261.170306947s] Trained 128 records in 0.085010533 seconds. Throughput is 1505.6957 records/second. Loss is 2.0575953. Sequentialb692dd65's hyper parameters: Current learning rate is 2.682403433476395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49280/60000][Iteration 2730][Wall Clock 261.260071651s] Trained 128 records in 0.089764704 seconds. Throughput is 1425.9502 records/second. Loss is 2.0357907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.681684097613301E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49408/60000][Iteration 2731][Wall Clock 261.343017384s] Trained 128 records in 0.082945733 seconds. Throughput is 1543.1776 records/second. Loss is 2.0444913. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6809651474530834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49536/60000][Iteration 2732][Wall Clock 261.442494353s] Trained 128 records in 0.099476969 seconds. Throughput is 1286.73 records/second. Loss is 2.0493762. Sequentialb692dd65's hyper parameters: Current learning rate is 2.680246582685607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49664/60000][Iteration 2733][Wall Clock 261.52878256s] Trained 128 records in 0.086288207 seconds. Throughput is 1483.4009 records/second. Loss is 2.061602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.679528403001072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49792/60000][Iteration 2734][Wall Clock 261.616800899s] Trained 128 records in 0.088018339 seconds. Throughput is 1454.2424 records/second. Loss is 2.045997. Sequentialb692dd65's hyper parameters: Current learning rate is 2.678810608090008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 49920/60000][Iteration 2735][Wall Clock 261.704336478s] Trained 128 records in 0.087535579 seconds. Throughput is 1462.2625 records/second. Loss is 2.035177. Sequentialb692dd65's hyper parameters: Current learning rate is 2.678093197643278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 50048/60000][Iteration 2736][Wall Clock 261.814055491s] Trained 128 records in 0.109719013 seconds. Throughput is 1166.6163 records/second. Loss is 2.0466228. Sequentialb692dd65's hyper parameters: Current learning rate is 2.677376171352075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 50176/60000][Iteration 2737][Wall Clock 261.916846986s] Trained 128 records in 0.102791495 seconds. Throughput is 1245.2393 records/second. Loss is 2.0488355. Sequentialb692dd65's hyper parameters: Current learning rate is 2.676659528907923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 50304/60000][Iteration 2738][Wall Clock 262.017064621s] Trained 128 records in 0.100217635 seconds. Throughput is 1277.2203 records/second. Loss is 2.0603235. Sequentialb692dd65's hyper parameters: Current learning rate is 2.675943270002676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:45 INFO  DistriOptimizer$:408 - [Epoch 6 50432/60000][Iteration 2739][Wall Clock 262.105152619s] Trained 128 records in 0.088087998 seconds. Throughput is 1453.0924 records/second. Loss is 2.0669215. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6752273943285177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 50560/60000][Iteration 2740][Wall Clock 262.225913492s] Trained 128 records in 0.120760873 seconds. Throughput is 1059.9459 records/second. Loss is 2.0448015. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6745119015779623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 50688/60000][Iteration 2741][Wall Clock 262.340104143s] Trained 128 records in 0.114190651 seconds. Throughput is 1120.9324 records/second. Loss is 2.041242. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6737967914438503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 50816/60000][Iteration 2742][Wall Clock 262.451391372s] Trained 128 records in 0.111287229 seconds. Throughput is 1150.1769 records/second. Loss is 2.0667906. Sequentialb692dd65's hyper parameters: Current learning rate is 2.673082063619353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 50944/60000][Iteration 2743][Wall Clock 262.572563765s] Trained 128 records in 0.121172393 seconds. Throughput is 1056.3462 records/second. Loss is 2.0611389. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6723677177979693E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51072/60000][Iteration 2744][Wall Clock 262.673082329s] Trained 128 records in 0.100518564 seconds. Throughput is 1273.3966 records/second. Loss is 2.0965276. Sequentialb692dd65's hyper parameters: Current learning rate is 2.671653753673524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51200/60000][Iteration 2745][Wall Clock 262.765083508s] Trained 128 records in 0.092001179 seconds. Throughput is 1391.2865 records/second. Loss is 2.0282679. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6709401709401707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51328/60000][Iteration 2746][Wall Clock 262.857281622s] Trained 128 records in 0.092198114 seconds. Throughput is 1388.3148 records/second. Loss is 2.069964. Sequentialb692dd65's hyper parameters: Current learning rate is 2.67022696929239E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51456/60000][Iteration 2747][Wall Clock 262.949139089s] Trained 128 records in 0.091857467 seconds. Throughput is 1393.4631 records/second. Loss is 2.0312421. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6695141484249865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51584/60000][Iteration 2748][Wall Clock 263.037818796s] Trained 128 records in 0.088679707 seconds. Throughput is 1443.3967 records/second. Loss is 2.0604482. Sequentialb692dd65's hyper parameters: Current learning rate is 2.668801708033093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:46 INFO  DistriOptimizer$:408 - [Epoch 6 51712/60000][Iteration 2749][Wall Clock 263.12670371s] Trained 128 records in 0.088884914 seconds. Throughput is 1440.0645 records/second. Loss is 2.0346055. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6680896478121667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 51840/60000][Iteration 2750][Wall Clock 263.230331117s] Trained 128 records in 0.103627407 seconds. Throughput is 1235.1945 records/second. Loss is 2.0473683. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6673779674579886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 51968/60000][Iteration 2751][Wall Clock 263.317029073s] Trained 128 records in 0.086697956 seconds. Throughput is 1476.39 records/second. Loss is 2.064534. Sequentialb692dd65's hyper parameters: Current learning rate is 2.666666666666667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52096/60000][Iteration 2752][Wall Clock 263.425348747s] Trained 128 records in 0.108319674 seconds. Throughput is 1181.6874 records/second. Loss is 2.0249393. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6659557451346307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52224/60000][Iteration 2753][Wall Clock 263.51355714s] Trained 128 records in 0.088208393 seconds. Throughput is 1451.1091 records/second. Loss is 2.0642223. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6652452025586353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52352/60000][Iteration 2754][Wall Clock 263.604179646s] Trained 128 records in 0.090622506 seconds. Throughput is 1412.4526 records/second. Loss is 2.0546536. Sequentialb692dd65's hyper parameters: Current learning rate is 2.664535038635758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52480/60000][Iteration 2755][Wall Clock 263.690234835s] Trained 128 records in 0.086055189 seconds. Throughput is 1487.4176 records/second. Loss is 2.06021. Sequentialb692dd65's hyper parameters: Current learning rate is 2.663825253063399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52608/60000][Iteration 2756][Wall Clock 263.774880365s] Trained 128 records in 0.08464553 seconds. Throughput is 1512.1885 records/second. Loss is 2.0451562. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6631158455392814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52736/60000][Iteration 2757][Wall Clock 263.859329412s] Trained 128 records in 0.084449047 seconds. Throughput is 1515.7069 records/second. Loss is 2.045145. Sequentialb692dd65's hyper parameters: Current learning rate is 2.662406815761448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52864/60000][Iteration 2758][Wall Clock 263.94551835s] Trained 128 records in 0.086188938 seconds. Throughput is 1485.1094 records/second. Loss is 2.0489542. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6616981634282674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 52992/60000][Iteration 2759][Wall Clock 264.031341068s] Trained 128 records in 0.085822718 seconds. Throughput is 1491.4467 records/second. Loss is 2.0396478. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6609898882384245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:47 INFO  DistriOptimizer$:408 - [Epoch 6 53120/60000][Iteration 2760][Wall Clock 264.114666103s] Trained 128 records in 0.083325035 seconds. Throughput is 1536.153 records/second. Loss is 2.0400221. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6602819898909286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53248/60000][Iteration 2761][Wall Clock 264.200089378s] Trained 128 records in 0.085423275 seconds. Throughput is 1498.4207 records/second. Loss is 2.050299. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6595744680851064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53376/60000][Iteration 2762][Wall Clock 264.293978147s] Trained 128 records in 0.093888769 seconds. Throughput is 1363.3154 records/second. Loss is 2.0653527. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6588673225206064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53504/60000][Iteration 2763][Wall Clock 264.385078016s] Trained 128 records in 0.091099869 seconds. Throughput is 1405.0515 records/second. Loss is 2.0899699. Sequentialb692dd65's hyper parameters: Current learning rate is 2.658160552897395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53632/60000][Iteration 2764][Wall Clock 264.473471862s] Trained 128 records in 0.088393846 seconds. Throughput is 1448.0646 records/second. Loss is 2.0527742. Sequentialb692dd65's hyper parameters: Current learning rate is 2.657454158915759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53760/60000][Iteration 2765][Wall Clock 264.563461148s] Trained 128 records in 0.089989286 seconds. Throughput is 1422.3915 records/second. Loss is 2.0568864. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6567481402763017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 53888/60000][Iteration 2766][Wall Clock 264.650769529s] Trained 128 records in 0.087308381 seconds. Throughput is 1466.0676 records/second. Loss is 2.0570838. Sequentialb692dd65's hyper parameters: Current learning rate is 2.656042496679947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 54016/60000][Iteration 2767][Wall Clock 264.740722594s] Trained 128 records in 0.089953065 seconds. Throughput is 1422.9644 records/second. Loss is 2.0557745. Sequentialb692dd65's hyper parameters: Current learning rate is 2.655337227827934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 54144/60000][Iteration 2768][Wall Clock 264.827202231s] Trained 128 records in 0.086479637 seconds. Throughput is 1480.1173 records/second. Loss is 2.0524724. Sequentialb692dd65's hyper parameters: Current learning rate is 2.654632333421821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 54272/60000][Iteration 2769][Wall Clock 264.916246669s] Trained 128 records in 0.089044438 seconds. Throughput is 1437.4845 records/second. Loss is 2.0590386. Sequentialb692dd65's hyper parameters: Current learning rate is 2.653927813163482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 54400/60000][Iteration 2770][Wall Clock 265.001340655s] Trained 128 records in 0.085093986 seconds. Throughput is 1504.2191 records/second. Loss is 2.0666366. Sequentialb692dd65's hyper parameters: Current learning rate is 2.653223666755107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:48 INFO  DistriOptimizer$:408 - [Epoch 6 54528/60000][Iteration 2771][Wall Clock 265.088502193s] Trained 128 records in 0.087161538 seconds. Throughput is 1468.5376 records/second. Loss is 2.032555. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6525198938992045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 54656/60000][Iteration 2772][Wall Clock 265.173888537s] Trained 128 records in 0.085386344 seconds. Throughput is 1499.0687 records/second. Loss is 2.0348687. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6518164942985947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 54784/60000][Iteration 2773][Wall Clock 265.259932461s] Trained 128 records in 0.086043924 seconds. Throughput is 1487.6123 records/second. Loss is 2.0523748. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6511134676564154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 54912/60000][Iteration 2774][Wall Clock 265.344791213s] Trained 128 records in 0.084858752 seconds. Throughput is 1508.3889 records/second. Loss is 2.0956628. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6504108136761196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55040/60000][Iteration 2775][Wall Clock 265.431042156s] Trained 128 records in 0.086250943 seconds. Throughput is 1484.0417 records/second. Loss is 2.048436. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6497085320614734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55168/60000][Iteration 2776][Wall Clock 265.518708152s] Trained 128 records in 0.087665996 seconds. Throughput is 1460.0872 records/second. Loss is 2.0559967. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6490066225165563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55296/60000][Iteration 2777][Wall Clock 265.605637976s] Trained 128 records in 0.086929824 seconds. Throughput is 1472.4521 records/second. Loss is 2.0401156. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6483050847457627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55424/60000][Iteration 2778][Wall Clock 265.689278134s] Trained 128 records in 0.083640158 seconds. Throughput is 1530.3654 records/second. Loss is 2.0406694. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6476039184537993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55552/60000][Iteration 2779][Wall Clock 265.774867816s] Trained 128 records in 0.085589682 seconds. Throughput is 1495.5073 records/second. Loss is 2.071448. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6469031233456857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55680/60000][Iteration 2780][Wall Clock 265.861433821s] Trained 128 records in 0.086566005 seconds. Throughput is 1478.6404 records/second. Loss is 2.0356421. Sequentialb692dd65's hyper parameters: Current learning rate is 2.646202699126753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55808/60000][Iteration 2781][Wall Clock 265.946581245s] Trained 128 records in 0.085147424 seconds. Throughput is 1503.275 records/second. Loss is 2.0659404. Sequentialb692dd65's hyper parameters: Current learning rate is 2.645502645502645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 55936/60000][Iteration 2782][Wall Clock 266.031268822s] Trained 128 records in 0.084687577 seconds. Throughput is 1511.4377 records/second. Loss is 2.043501. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6448029621793174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:49 INFO  DistriOptimizer$:408 - [Epoch 6 56064/60000][Iteration 2783][Wall Clock 266.11666691s] Trained 128 records in 0.085398088 seconds. Throughput is 1498.8627 records/second. Loss is 2.0660992. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6441036488630354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56192/60000][Iteration 2784][Wall Clock 266.202437551s] Trained 128 records in 0.085770641 seconds. Throughput is 1492.352 records/second. Loss is 2.0629096. Sequentialb692dd65's hyper parameters: Current learning rate is 2.643404705260376E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56320/60000][Iteration 2785][Wall Clock 266.290612268s] Trained 128 records in 0.088174717 seconds. Throughput is 1451.6633 records/second. Loss is 2.0278058. Sequentialb692dd65's hyper parameters: Current learning rate is 2.642706131078224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56448/60000][Iteration 2786][Wall Clock 266.376450803s] Trained 128 records in 0.085838535 seconds. Throughput is 1491.1718 records/second. Loss is 2.0538464. Sequentialb692dd65's hyper parameters: Current learning rate is 2.642007926023778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56576/60000][Iteration 2787][Wall Clock 266.477419668s] Trained 128 records in 0.100968865 seconds. Throughput is 1267.7175 records/second. Loss is 2.0605927. Sequentialb692dd65's hyper parameters: Current learning rate is 2.641310089804543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56704/60000][Iteration 2788][Wall Clock 266.562306055s] Trained 128 records in 0.084886387 seconds. Throughput is 1507.8978 records/second. Loss is 2.0546415. Sequentialb692dd65's hyper parameters: Current learning rate is 2.640612622128334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56832/60000][Iteration 2789][Wall Clock 266.655966368s] Trained 128 records in 0.093660313 seconds. Throughput is 1366.6407 records/second. Loss is 2.0708754. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6399155227032733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 56960/60000][Iteration 2790][Wall Clock 266.740471576s] Trained 128 records in 0.084505208 seconds. Throughput is 1514.6996 records/second. Loss is 2.0434234. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6392187912377933E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 57088/60000][Iteration 2791][Wall Clock 266.823822008s] Trained 128 records in 0.083350432 seconds. Throughput is 1535.6848 records/second. Loss is 2.0714362. Sequentialb692dd65's hyper parameters: Current learning rate is 2.638522427440633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 57216/60000][Iteration 2792][Wall Clock 266.907406523s] Trained 128 records in 0.083584515 seconds. Throughput is 1531.384 records/second. Loss is 2.036383. Sequentialb692dd65's hyper parameters: Current learning rate is 2.637826431020839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 57344/60000][Iteration 2793][Wall Clock 266.992185587s] Trained 128 records in 0.084779064 seconds. Throughput is 1509.8068 records/second. Loss is 2.0398455. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6371308016877635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:50 INFO  DistriOptimizer$:408 - [Epoch 6 57472/60000][Iteration 2794][Wall Clock 267.082650649s] Trained 128 records in 0.090465062 seconds. Throughput is 1414.9109 records/second. Loss is 2.0390759. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6364355391510674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 57600/60000][Iteration 2795][Wall Clock 267.16290899s] Trained 128 records in 0.080258341 seconds. Throughput is 1594.8499 records/second. Loss is 2.0758874. Sequentialb692dd65's hyper parameters: Current learning rate is 2.635740643120717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 57728/60000][Iteration 2796][Wall Clock 267.250313109s] Trained 128 records in 0.087404119 seconds. Throughput is 1464.4619 records/second. Loss is 2.0368133. Sequentialb692dd65's hyper parameters: Current learning rate is 2.635046113306983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 57856/60000][Iteration 2797][Wall Clock 267.339610685s] Trained 128 records in 0.089297576 seconds. Throughput is 1433.4095 records/second. Loss is 2.068413. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6343519494204424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 57984/60000][Iteration 2798][Wall Clock 267.425408297s] Trained 128 records in 0.085797612 seconds. Throughput is 1491.8829 records/second. Loss is 2.0729823. Sequentialb692dd65's hyper parameters: Current learning rate is 2.633658151171978E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58112/60000][Iteration 2799][Wall Clock 267.514305343s] Trained 128 records in 0.088897046 seconds. Throughput is 1439.8678 records/second. Loss is 2.0412266. Sequentialb692dd65's hyper parameters: Current learning rate is 2.632964718272775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58240/60000][Iteration 2800][Wall Clock 267.60995401s] Trained 128 records in 0.095648667 seconds. Throughput is 1338.2308 records/second. Loss is 2.0553694. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6322716504343247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58368/60000][Iteration 2801][Wall Clock 267.717747829s] Trained 128 records in 0.107793819 seconds. Throughput is 1187.4521 records/second. Loss is 2.0419984. Sequentialb692dd65's hyper parameters: Current learning rate is 2.631578947368421E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58496/60000][Iteration 2802][Wall Clock 267.811760892s] Trained 128 records in 0.094013063 seconds. Throughput is 1361.513 records/second. Loss is 2.0427902. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6308866087871614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58624/60000][Iteration 2803][Wall Clock 267.91092444s] Trained 128 records in 0.099163548 seconds. Throughput is 1290.7969 records/second. Loss is 2.043562. Sequentialb692dd65's hyper parameters: Current learning rate is 2.630194634402946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:51 INFO  DistriOptimizer$:408 - [Epoch 6 58752/60000][Iteration 2804][Wall Clock 268.020227767s] Trained 128 records in 0.109303327 seconds. Throughput is 1171.0531 records/second. Loss is 2.035238. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6295030239284776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 58880/60000][Iteration 2805][Wall Clock 268.132819977s] Trained 128 records in 0.11259221 seconds. Throughput is 1136.846 records/second. Loss is 2.0474584. Sequentialb692dd65's hyper parameters: Current learning rate is 2.628811777076761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59008/60000][Iteration 2806][Wall Clock 268.222858921s] Trained 128 records in 0.090038944 seconds. Throughput is 1421.6072 records/second. Loss is 2.0383213. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6281208935611036E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59136/60000][Iteration 2807][Wall Clock 268.310398487s] Trained 128 records in 0.087539566 seconds. Throughput is 1462.1959 records/second. Loss is 2.0552845. Sequentialb692dd65's hyper parameters: Current learning rate is 2.627430373095113E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59264/60000][Iteration 2808][Wall Clock 268.395373931s] Trained 128 records in 0.084975444 seconds. Throughput is 1506.3175 records/second. Loss is 2.0468657. Sequentialb692dd65's hyper parameters: Current learning rate is 2.626740215392698E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59392/60000][Iteration 2809][Wall Clock 268.480268247s] Trained 128 records in 0.084894316 seconds. Throughput is 1507.7571 records/second. Loss is 2.0260463. Sequentialb692dd65's hyper parameters: Current learning rate is 2.626050420168067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59520/60000][Iteration 2810][Wall Clock 268.569326601s] Trained 128 records in 0.089058354 seconds. Throughput is 1437.2599 records/second. Loss is 2.044319. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6253609871357313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59648/60000][Iteration 2811][Wall Clock 268.65672519s] Trained 128 records in 0.087398589 seconds. Throughput is 1464.5546 records/second. Loss is 2.0401533. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6246719160104987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59776/60000][Iteration 2812][Wall Clock 268.752148967s] Trained 128 records in 0.095423777 seconds. Throughput is 1341.3848 records/second. Loss is 2.0470185. Sequentialb692dd65's hyper parameters: Current learning rate is 2.623983206507478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 59904/60000][Iteration 2813][Wall Clock 268.835433621s] Trained 128 records in 0.083284654 seconds. Throughput is 1536.8978 records/second. Loss is 2.0275633. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6232948583420777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:408 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 268.921423256s] Trained 128 records in 0.085989635 seconds. Throughput is 1488.5515 records/second. Loss is 2.040331. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6226068712300026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:52 INFO  DistriOptimizer$:452 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 268.921423256s] Epoch finished. Wall clock time is 270185.793243 ms
2019-10-15 07:50:52 INFO  DistriOptimizer$:111 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 268.921423256s] Validate model...
2019-10-15 07:50:53 INFO  DistriOptimizer$:178 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 268.921423256s] validate model throughput is 12461.063 records/second
2019-10-15 07:50:53 INFO  DistriOptimizer$:181 - [Epoch 6 60032/60000][Iteration 2814][Wall Clock 268.921423256s] Top1Accuracy is Accuracy(correct: 5618, count: 10000, accuracy: 0.5618)
2019-10-15 07:50:53 INFO  DistriOptimizer$:221 - [Wall Clock 270.185793243s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:50:53 INFO  DistriOptimizer$:226 - [Wall Clock 270.185793243s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:50:53 INFO  DistriOptimizer$:408 - [Epoch 7 128/60000][Iteration 2815][Wall Clock 270.280508154s] Trained 128 records in 0.094714911 seconds. Throughput is 1351.424 records/second. Loss is 2.0479405. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6219192448872575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:53 INFO  DistriOptimizer$:408 - [Epoch 7 256/60000][Iteration 2816][Wall Clock 270.363096953s] Trained 128 records in 0.082588799 seconds. Throughput is 1549.8469 records/second. Loss is 2.0618198. Sequentialb692dd65's hyper parameters: Current learning rate is 2.621231979030144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:53 INFO  DistriOptimizer$:408 - [Epoch 7 384/60000][Iteration 2817][Wall Clock 270.443493395s] Trained 128 records in 0.080396442 seconds. Throughput is 1592.1102 records/second. Loss is 2.0728843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.620545073375262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 512/60000][Iteration 2818][Wall Clock 270.528657461s] Trained 128 records in 0.085164066 seconds. Throughput is 1502.9813 records/second. Loss is 2.0541863. Sequentialb692dd65's hyper parameters: Current learning rate is 2.619858527639507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 640/60000][Iteration 2819][Wall Clock 270.605087453s] Trained 128 records in 0.076429992 seconds. Throughput is 1674.7352 records/second. Loss is 2.0568943. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6191723415400735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 768/60000][Iteration 2820][Wall Clock 270.689658528s] Trained 128 records in 0.084571075 seconds. Throughput is 1513.5198 records/second. Loss is 2.0435479. Sequentialb692dd65's hyper parameters: Current learning rate is 2.618486514794449E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 896/60000][Iteration 2821][Wall Clock 270.774149931s] Trained 128 records in 0.084491403 seconds. Throughput is 1514.947 records/second. Loss is 2.0578423. Sequentialb692dd65's hyper parameters: Current learning rate is 2.617801047120419E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1024/60000][Iteration 2822][Wall Clock 270.860885988s] Trained 128 records in 0.086736057 seconds. Throughput is 1475.7415 records/second. Loss is 2.0496182. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6171159382360636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1152/60000][Iteration 2823][Wall Clock 270.946796247s] Trained 128 records in 0.085910259 seconds. Throughput is 1489.9268 records/second. Loss is 2.057816. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6164311878597594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1280/60000][Iteration 2824][Wall Clock 271.030752826s] Trained 128 records in 0.083956579 seconds. Throughput is 1524.5977 records/second. Loss is 2.0573647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6157467957101755E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1408/60000][Iteration 2825][Wall Clock 271.117627081s] Trained 128 records in 0.086874255 seconds. Throughput is 1473.3939 records/second. Loss is 2.0523295. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6150627615062765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1536/60000][Iteration 2826][Wall Clock 271.203479596s] Trained 128 records in 0.085852515 seconds. Throughput is 1490.9288 records/second. Loss is 2.0504441. Sequentialb692dd65's hyper parameters: Current learning rate is 2.61437908496732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1664/60000][Iteration 2827][Wall Clock 271.29034517s] Trained 128 records in 0.086865574 seconds. Throughput is 1473.5411 records/second. Loss is 2.047762. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6136957658128593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1792/60000][Iteration 2828][Wall Clock 271.376916711s] Trained 128 records in 0.086571541 seconds. Throughput is 1478.5459 records/second. Loss is 2.0154705. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6130128037627387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:54 INFO  DistriOptimizer$:408 - [Epoch 7 1920/60000][Iteration 2829][Wall Clock 271.462214288s] Trained 128 records in 0.085297577 seconds. Throughput is 1500.6288 records/second. Loss is 2.044881. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6123301985370953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2048/60000][Iteration 2830][Wall Clock 271.547437469s] Trained 128 records in 0.085223181 seconds. Throughput is 1501.9387 records/second. Loss is 2.0772266. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6116479498563595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2176/60000][Iteration 2831][Wall Clock 271.632844913s] Trained 128 records in 0.085407444 seconds. Throughput is 1498.6984 records/second. Loss is 2.0608816. Sequentialb692dd65's hyper parameters: Current learning rate is 2.610966057441253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2304/60000][Iteration 2832][Wall Clock 271.717143942s] Trained 128 records in 0.084299029 seconds. Throughput is 1518.4042 records/second. Loss is 2.0601993. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6102845210127906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2432/60000][Iteration 2833][Wall Clock 271.809321355s] Trained 128 records in 0.092177413 seconds. Throughput is 1388.6265 records/second. Loss is 2.037048. Sequentialb692dd65's hyper parameters: Current learning rate is 2.609603340292276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2560/60000][Iteration 2834][Wall Clock 271.892960422s] Trained 128 records in 0.083639067 seconds. Throughput is 1530.3853 records/second. Loss is 2.0679197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6089225150013044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2688/60000][Iteration 2835][Wall Clock 271.987603404s] Trained 128 records in 0.094642982 seconds. Throughput is 1352.451 records/second. Loss is 2.0502717. Sequentialb692dd65's hyper parameters: Current learning rate is 2.608242044861763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2816/60000][Iteration 2836][Wall Clock 272.069802572s] Trained 128 records in 0.082199168 seconds. Throughput is 1557.1934 records/second. Loss is 2.0609279. Sequentialb692dd65's hyper parameters: Current learning rate is 2.607561929595828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 2944/60000][Iteration 2837][Wall Clock 272.151779936s] Trained 128 records in 0.081977364 seconds. Throughput is 1561.4066 records/second. Loss is 2.0520227. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6068821689259646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 3072/60000][Iteration 2838][Wall Clock 272.232779837s] Trained 128 records in 0.080999901 seconds. Throughput is 1580.2488 records/second. Loss is 2.0179186. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6062027625749283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 3200/60000][Iteration 2839][Wall Clock 272.32043379s] Trained 128 records in 0.087653953 seconds. Throughput is 1460.2878 records/second. Loss is 2.059907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.605523710265763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 3328/60000][Iteration 2840][Wall Clock 272.406034518s] Trained 128 records in 0.085600728 seconds. Throughput is 1495.3145 records/second. Loss is 2.0596292. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6048450117218026E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:55 INFO  DistriOptimizer$:408 - [Epoch 7 3456/60000][Iteration 2841][Wall Clock 272.486039022s] Trained 128 records in 0.080004504 seconds. Throughput is 1599.9099 records/second. Loss is 2.0731661. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6041666666666666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 3584/60000][Iteration 2842][Wall Clock 272.571074449s] Trained 128 records in 0.085035427 seconds. Throughput is 1505.255 records/second. Loss is 2.0514567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.603488674824264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 3712/60000][Iteration 2843][Wall Clock 272.662968051s] Trained 128 records in 0.091893602 seconds. Throughput is 1392.9153 records/second. Loss is 2.0363002. Sequentialb692dd65's hyper parameters: Current learning rate is 2.602811035918792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 3840/60000][Iteration 2844][Wall Clock 272.75009018s] Trained 128 records in 0.087122129 seconds. Throughput is 1469.2019 records/second. Loss is 2.0265796. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6021337496747333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 3968/60000][Iteration 2845][Wall Clock 272.830987517s] Trained 128 records in 0.080897337 seconds. Throughput is 1582.2523 records/second. Loss is 2.067761. Sequentialb692dd65's hyper parameters: Current learning rate is 2.6014568158168577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4096/60000][Iteration 2846][Wall Clock 272.917887243s] Trained 128 records in 0.086899726 seconds. Throughput is 1472.962 records/second. Loss is 2.035306. Sequentialb692dd65's hyper parameters: Current learning rate is 2.600780234070221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4224/60000][Iteration 2847][Wall Clock 273.001944455s] Trained 128 records in 0.084057212 seconds. Throughput is 1522.7723 records/second. Loss is 2.0544. Sequentialb692dd65's hyper parameters: Current learning rate is 2.600104004160166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4352/60000][Iteration 2848][Wall Clock 273.085623009s] Trained 128 records in 0.083678554 seconds. Throughput is 1529.6632 records/second. Loss is 2.0399334. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5994281258123216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4480/60000][Iteration 2849][Wall Clock 273.169757557s] Trained 128 records in 0.084134548 seconds. Throughput is 1521.3727 records/second. Loss is 2.0339253. Sequentialb692dd65's hyper parameters: Current learning rate is 2.598752598752599E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4608/60000][Iteration 2850][Wall Clock 273.254542808s] Trained 128 records in 0.084785251 seconds. Throughput is 1509.6965 records/second. Loss is 2.0673728. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5980774227071964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4736/60000][Iteration 2851][Wall Clock 273.339463031s] Trained 128 records in 0.084920223 seconds. Throughput is 1507.2971 records/second. Loss is 2.0301356. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5974025974025974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:56 INFO  DistriOptimizer$:408 - [Epoch 7 4864/60000][Iteration 2852][Wall Clock 273.425152149s] Trained 128 records in 0.085689118 seconds. Throughput is 1493.7719 records/second. Loss is 2.0554402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5967281225655674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 4992/60000][Iteration 2853][Wall Clock 273.509714638s] Trained 128 records in 0.084562489 seconds. Throughput is 1513.6736 records/second. Loss is 2.0447073. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5960539979231567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5120/60000][Iteration 2854][Wall Clock 273.593284902s] Trained 128 records in 0.083570264 seconds. Throughput is 1531.6453 records/second. Loss is 2.0165057. Sequentialb692dd65's hyper parameters: Current learning rate is 2.595380223202699E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5248/60000][Iteration 2855][Wall Clock 273.678822231s] Trained 128 records in 0.085537329 seconds. Throughput is 1496.4227 records/second. Loss is 2.0393696. Sequentialb692dd65's hyper parameters: Current learning rate is 2.594706798131811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5376/60000][Iteration 2856][Wall Clock 273.764712892s] Trained 128 records in 0.085890661 seconds. Throughput is 1490.2668 records/second. Loss is 2.0412288. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5940337224383917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5504/60000][Iteration 2857][Wall Clock 273.85064035s] Trained 128 records in 0.085927458 seconds. Throughput is 1489.6287 records/second. Loss is 2.0186968. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5933609958506224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5632/60000][Iteration 2858][Wall Clock 273.934732715s] Trained 128 records in 0.084092365 seconds. Throughput is 1522.1359 records/second. Loss is 2.0244098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5926886180969663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5760/60000][Iteration 2859][Wall Clock 274.018701117s] Trained 128 records in 0.083968402 seconds. Throughput is 1524.3829 records/second. Loss is 2.0540483. Sequentialb692dd65's hyper parameters: Current learning rate is 2.592016588906169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 5888/60000][Iteration 2860][Wall Clock 274.11615101s] Trained 128 records in 0.097449893 seconds. Throughput is 1313.4956 records/second. Loss is 2.0372953. Sequentialb692dd65's hyper parameters: Current learning rate is 2.591344908007256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 6016/60000][Iteration 2861][Wall Clock 274.196801501s] Trained 128 records in 0.080650491 seconds. Throughput is 1587.0951 records/second. Loss is 2.0316832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5906735751295336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 6144/60000][Iteration 2862][Wall Clock 274.282192022s] Trained 128 records in 0.085390521 seconds. Throughput is 1498.9954 records/second. Loss is 2.0549843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.59000259000259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 6272/60000][Iteration 2863][Wall Clock 274.367488667s] Trained 128 records in 0.085296645 seconds. Throughput is 1500.6451 records/second. Loss is 2.0513396. Sequentialb692dd65's hyper parameters: Current learning rate is 2.589331952356292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:57 INFO  DistriOptimizer$:408 - [Epoch 7 6400/60000][Iteration 2864][Wall Clock 274.457917144s] Trained 128 records in 0.090428477 seconds. Throughput is 1415.4833 records/second. Loss is 2.068073. Sequentialb692dd65's hyper parameters: Current learning rate is 2.588661661920787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 6528/60000][Iteration 2865][Wall Clock 274.541659608s] Trained 128 records in 0.083742464 seconds. Throughput is 1528.4957 records/second. Loss is 2.0575445. Sequentialb692dd65's hyper parameters: Current learning rate is 2.587991718426501E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 6656/60000][Iteration 2866][Wall Clock 274.625769703s] Trained 128 records in 0.084110095 seconds. Throughput is 1521.815 records/second. Loss is 2.078021. Sequentialb692dd65's hyper parameters: Current learning rate is 2.58732212160414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 6784/60000][Iteration 2867][Wall Clock 274.713062878s] Trained 128 records in 0.087293175 seconds. Throughput is 1466.3231 records/second. Loss is 2.0395956. Sequentialb692dd65's hyper parameters: Current learning rate is 2.586652871184687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 6912/60000][Iteration 2868][Wall Clock 274.798701085s] Trained 128 records in 0.085638207 seconds. Throughput is 1494.6599 records/second. Loss is 2.0498793. Sequentialb692dd65's hyper parameters: Current learning rate is 2.585983966899405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7040/60000][Iteration 2869][Wall Clock 274.881167861s] Trained 128 records in 0.082466776 seconds. Throughput is 1552.1403 records/second. Loss is 2.0501363. Sequentialb692dd65's hyper parameters: Current learning rate is 2.585315408479835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7168/60000][Iteration 2870][Wall Clock 274.966246399s] Trained 128 records in 0.085078538 seconds. Throughput is 1504.4922 records/second. Loss is 2.0158107. Sequentialb692dd65's hyper parameters: Current learning rate is 2.584647195657793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7296/60000][Iteration 2871][Wall Clock 275.049544126s] Trained 128 records in 0.083297727 seconds. Throughput is 1536.6565 records/second. Loss is 2.028114. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5839793281653745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7424/60000][Iteration 2872][Wall Clock 275.133006237s] Trained 128 records in 0.083462111 seconds. Throughput is 1533.63 records/second. Loss is 2.0312183. Sequentialb692dd65's hyper parameters: Current learning rate is 2.583311805734952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7552/60000][Iteration 2873][Wall Clock 275.215674315s] Trained 128 records in 0.082668078 seconds. Throughput is 1548.3606 records/second. Loss is 2.0419345. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5826446280991736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7680/60000][Iteration 2874][Wall Clock 275.298864993s] Trained 128 records in 0.083190678 seconds. Throughput is 1538.6339 records/second. Loss is 2.0461638. Sequentialb692dd65's hyper parameters: Current learning rate is 2.581977794990963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7808/60000][Iteration 2875][Wall Clock 275.386650529s] Trained 128 records in 0.087785536 seconds. Throughput is 1458.099 records/second. Loss is 2.0353863. Sequentialb692dd65's hyper parameters: Current learning rate is 2.581311306143521E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:58 INFO  DistriOptimizer$:408 - [Epoch 7 7936/60000][Iteration 2876][Wall Clock 275.468922082s] Trained 128 records in 0.082271553 seconds. Throughput is 1555.8232 records/second. Loss is 2.0607913. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5806451612903227E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8064/60000][Iteration 2877][Wall Clock 275.553046511s] Trained 128 records in 0.084124429 seconds. Throughput is 1521.5557 records/second. Loss is 2.0404043. Sequentialb692dd65's hyper parameters: Current learning rate is 2.579979360165119E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8192/60000][Iteration 2878][Wall Clock 275.639297896s] Trained 128 records in 0.086251385 seconds. Throughput is 1484.0342 records/second. Loss is 2.0324981. Sequentialb692dd65's hyper parameters: Current learning rate is 2.579313902501934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8320/60000][Iteration 2879][Wall Clock 275.725347103s] Trained 128 records in 0.086049207 seconds. Throughput is 1487.521 records/second. Loss is 2.0623667. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5786487880350697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8448/60000][Iteration 2880][Wall Clock 275.811522523s] Trained 128 records in 0.08617542 seconds. Throughput is 1485.3424 records/second. Loss is 2.0394218. Sequentialb692dd65's hyper parameters: Current learning rate is 2.577984016499098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8576/60000][Iteration 2881][Wall Clock 275.899543339s] Trained 128 records in 0.088020816 seconds. Throughput is 1454.2014 records/second. Loss is 2.056614. Sequentialb692dd65's hyper parameters: Current learning rate is 2.577319587628866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8704/60000][Iteration 2882][Wall Clock 275.986006909s] Trained 128 records in 0.08646357 seconds. Throughput is 1480.3922 records/second. Loss is 2.0487223. Sequentialb692dd65's hyper parameters: Current learning rate is 2.576655501159495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8832/60000][Iteration 2883][Wall Clock 276.071106849s] Trained 128 records in 0.08509994 seconds. Throughput is 1504.1138 records/second. Loss is 2.0246925. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5759917568263783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 8960/60000][Iteration 2884][Wall Clock 276.155898747s] Trained 128 records in 0.084791898 seconds. Throughput is 1509.5781 records/second. Loss is 2.0566165. Sequentialb692dd65's hyper parameters: Current learning rate is 2.575328354365182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 9088/60000][Iteration 2885][Wall Clock 276.246553316s] Trained 128 records in 0.090654569 seconds. Throughput is 1411.9531 records/second. Loss is 2.055673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5746652935118434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 9216/60000][Iteration 2886][Wall Clock 276.333187747s] Trained 128 records in 0.086634431 seconds. Throughput is 1477.4727 records/second. Loss is 2.0429113. Sequentialb692dd65's hyper parameters: Current learning rate is 2.574002574002574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:50:59 INFO  DistriOptimizer$:408 - [Epoch 7 9344/60000][Iteration 2887][Wall Clock 276.414413377s] Trained 128 records in 0.08122563 seconds. Throughput is 1575.8572 records/second. Loss is 2.0527296. Sequentialb692dd65's hyper parameters: Current learning rate is 2.573340195573855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 9472/60000][Iteration 2888][Wall Clock 276.49661488s] Trained 128 records in 0.082201503 seconds. Throughput is 1557.1492 records/second. Loss is 2.034523. Sequentialb692dd65's hyper parameters: Current learning rate is 2.572678157962439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 9600/60000][Iteration 2889][Wall Clock 276.58020199s] Trained 128 records in 0.08358711 seconds. Throughput is 1531.3365 records/second. Loss is 2.0589232. Sequentialb692dd65's hyper parameters: Current learning rate is 2.57201646090535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 9728/60000][Iteration 2890][Wall Clock 276.666108373s] Trained 128 records in 0.085906383 seconds. Throughput is 1489.994 records/second. Loss is 2.0414264. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5713551041398817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 9856/60000][Iteration 2891][Wall Clock 276.75071467s] Trained 128 records in 0.084606297 seconds. Throughput is 1512.8898 records/second. Loss is 2.0669146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.570694087403599E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 9984/60000][Iteration 2892][Wall Clock 276.829573612s] Trained 128 records in 0.078858942 seconds. Throughput is 1623.1514 records/second. Loss is 2.0421846. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5700334104343357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10112/60000][Iteration 2893][Wall Clock 276.918630361s] Trained 128 records in 0.089056749 seconds. Throughput is 1437.2858 records/second. Loss is 2.026306. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5693730729701953E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10240/60000][Iteration 2894][Wall Clock 277.005299797s] Trained 128 records in 0.086669436 seconds. Throughput is 1476.8759 records/second. Loss is 2.0353146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5687130747495504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10368/60000][Iteration 2895][Wall Clock 277.089722429s] Trained 128 records in 0.084422632 seconds. Throughput is 1516.1812 records/second. Loss is 2.0427256. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5680534155110427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10496/60000][Iteration 2896][Wall Clock 277.17518898s] Trained 128 records in 0.085466551 seconds. Throughput is 1497.662 records/second. Loss is 2.0577662. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5673940949935817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10624/60000][Iteration 2897][Wall Clock 277.260147571s] Trained 128 records in 0.084958591 seconds. Throughput is 1506.6163 records/second. Loss is 2.0658987. Sequentialb692dd65's hyper parameters: Current learning rate is 2.566735112936345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10752/60000][Iteration 2898][Wall Clock 277.344849904s] Trained 128 records in 0.084702333 seconds. Throughput is 1511.1744 records/second. Loss is 2.063054. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5660764690787786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:00 INFO  DistriOptimizer$:408 - [Epoch 7 10880/60000][Iteration 2899][Wall Clock 277.429925868s] Trained 128 records in 0.085075964 seconds. Throughput is 1504.5377 records/second. Loss is 2.0211163. Sequentialb692dd65's hyper parameters: Current learning rate is 2.565418163160595E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11008/60000][Iteration 2900][Wall Clock 277.516754155s] Trained 128 records in 0.086828287 seconds. Throughput is 1474.1741 records/second. Loss is 2.0467463. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5647601949217746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11136/60000][Iteration 2901][Wall Clock 277.601763488s] Trained 128 records in 0.085009333 seconds. Throughput is 1505.7169 records/second. Loss is 2.0636096. Sequentialb692dd65's hyper parameters: Current learning rate is 2.564102564102564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11264/60000][Iteration 2902][Wall Clock 277.686482065s] Trained 128 records in 0.084718577 seconds. Throughput is 1510.8846 records/second. Loss is 2.0422513. Sequentialb692dd65's hyper parameters: Current learning rate is 2.563445270443476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11392/60000][Iteration 2903][Wall Clock 277.769893373s] Trained 128 records in 0.083411308 seconds. Throughput is 1534.5642 records/second. Loss is 2.0572357. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5627883136852895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11520/60000][Iteration 2904][Wall Clock 277.854929843s] Trained 128 records in 0.08503647 seconds. Throughput is 1505.2365 records/second. Loss is 2.0336525. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5621316935690495E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11648/60000][Iteration 2905][Wall Clock 277.939486663s] Trained 128 records in 0.08455682 seconds. Throughput is 1513.775 records/second. Loss is 2.053827. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5614754098360657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11776/60000][Iteration 2906][Wall Clock 278.027411439s] Trained 128 records in 0.087924776 seconds. Throughput is 1455.7898 records/second. Loss is 2.072773. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5608194622279127E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 11904/60000][Iteration 2907][Wall Clock 278.113127615s] Trained 128 records in 0.085716176 seconds. Throughput is 1493.3004 records/second. Loss is 2.0450037. Sequentialb692dd65's hyper parameters: Current learning rate is 2.560163850486431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 12032/60000][Iteration 2908][Wall Clock 278.199778608s] Trained 128 records in 0.086650993 seconds. Throughput is 1477.1903 records/second. Loss is 2.0493312. Sequentialb692dd65's hyper parameters: Current learning rate is 2.559508574353724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 12160/60000][Iteration 2909][Wall Clock 278.284733909s] Trained 128 records in 0.084955301 seconds. Throughput is 1506.6747 records/second. Loss is 2.0393496. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5588536335721597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:01 INFO  DistriOptimizer$:408 - [Epoch 7 12288/60000][Iteration 2910][Wall Clock 278.382197273s] Trained 128 records in 0.097463364 seconds. Throughput is 1313.314 records/second. Loss is 2.082453. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5581990278843696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 12416/60000][Iteration 2911][Wall Clock 278.463306882s] Trained 128 records in 0.081109609 seconds. Throughput is 1578.1115 records/second. Loss is 2.0683851. Sequentialb692dd65's hyper parameters: Current learning rate is 2.557544757033248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 12544/60000][Iteration 2912][Wall Clock 278.545163729s] Trained 128 records in 0.081856847 seconds. Throughput is 1563.7054 records/second. Loss is 2.0354629. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5568908207619537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 12672/60000][Iteration 2913][Wall Clock 278.625517466s] Trained 128 records in 0.080353737 seconds. Throughput is 1592.9564 records/second. Loss is 2.0326567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.556237218813906E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 12800/60000][Iteration 2914][Wall Clock 278.71044184s] Trained 128 records in 0.084924374 seconds. Throughput is 1507.2233 records/second. Loss is 2.0241547. Sequentialb692dd65's hyper parameters: Current learning rate is 2.555583950932788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 12928/60000][Iteration 2915][Wall Clock 278.794888213s] Trained 128 records in 0.084446373 seconds. Throughput is 1515.7549 records/second. Loss is 2.0523732. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5549310168625444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13056/60000][Iteration 2916][Wall Clock 278.879281676s] Trained 128 records in 0.084393463 seconds. Throughput is 1516.7051 records/second. Loss is 2.0338092. Sequentialb692dd65's hyper parameters: Current learning rate is 2.554278416347382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13184/60000][Iteration 2917][Wall Clock 278.964733595s] Trained 128 records in 0.085451919 seconds. Throughput is 1497.9185 records/second. Loss is 2.04817. Sequentialb692dd65's hyper parameters: Current learning rate is 2.553626149131767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13312/60000][Iteration 2918][Wall Clock 279.055829381s] Trained 128 records in 0.091095786 seconds. Throughput is 1405.1145 records/second. Loss is 2.0513775. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5529742149604285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13440/60000][Iteration 2919][Wall Clock 279.137037606s] Trained 128 records in 0.081208225 seconds. Throughput is 1576.1951 records/second. Loss is 2.031252. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5523226135783564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13568/60000][Iteration 2920][Wall Clock 279.224796737s] Trained 128 records in 0.087759131 seconds. Throughput is 1458.5377 records/second. Loss is 2.049407. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5516713447307985E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13696/60000][Iteration 2921][Wall Clock 279.315641613s] Trained 128 records in 0.090844876 seconds. Throughput is 1408.9952 records/second. Loss is 2.0199654. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5510204081632655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:02 INFO  DistriOptimizer$:408 - [Epoch 7 13824/60000][Iteration 2922][Wall Clock 279.398225763s] Trained 128 records in 0.08258415 seconds. Throughput is 1549.9342 records/second. Loss is 2.0561066. Sequentialb692dd65's hyper parameters: Current learning rate is 2.550369803621525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 13952/60000][Iteration 2923][Wall Clock 279.484967544s] Trained 128 records in 0.086741781 seconds. Throughput is 1475.644 records/second. Loss is 2.040288. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5497195308516065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14080/60000][Iteration 2924][Wall Clock 279.567815132s] Trained 128 records in 0.082847588 seconds. Throughput is 1545.0057 records/second. Loss is 2.0578856. Sequentialb692dd65's hyper parameters: Current learning rate is 2.549069589599796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14208/60000][Iteration 2925][Wall Clock 279.65222147s] Trained 128 records in 0.084406338 seconds. Throughput is 1516.4738 records/second. Loss is 2.0078151. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5484199796126404E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14336/60000][Iteration 2926][Wall Clock 279.736273813s] Trained 128 records in 0.084052343 seconds. Throughput is 1522.8605 records/second. Loss is 2.064002. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5477707006369424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14464/60000][Iteration 2927][Wall Clock 279.818225893s] Trained 128 records in 0.08195208 seconds. Throughput is 1561.8883 records/second. Loss is 2.031446. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5471217524197657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14592/60000][Iteration 2928][Wall Clock 279.900889892s] Trained 128 records in 0.082663999 seconds. Throughput is 1548.4371 records/second. Loss is 2.0649252. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5464731347084286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14720/60000][Iteration 2929][Wall Clock 279.984907186s] Trained 128 records in 0.084017294 seconds. Throughput is 1523.4958 records/second. Loss is 2.040386. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5458248472505095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14848/60000][Iteration 2930][Wall Clock 280.068142695s] Trained 128 records in 0.083235509 seconds. Throughput is 1537.8052 records/second. Loss is 2.0259557. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5451768897938407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 14976/60000][Iteration 2931][Wall Clock 280.153152981s] Trained 128 records in 0.085010286 seconds. Throughput is 1505.7002 records/second. Loss is 2.0315762. Sequentialb692dd65's hyper parameters: Current learning rate is 2.544529262086514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 15104/60000][Iteration 2932][Wall Clock 280.239500349s] Trained 128 records in 0.086347368 seconds. Throughput is 1482.3844 records/second. Loss is 2.035497. Sequentialb692dd65's hyper parameters: Current learning rate is 2.543881963876876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 15232/60000][Iteration 2933][Wall Clock 280.32648847s] Trained 128 records in 0.086988121 seconds. Throughput is 1471.4653 records/second. Loss is 2.0340824. Sequentialb692dd65's hyper parameters: Current learning rate is 2.54323499491353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:03 INFO  DistriOptimizer$:408 - [Epoch 7 15360/60000][Iteration 2934][Wall Clock 280.411174507s] Trained 128 records in 0.084686037 seconds. Throughput is 1511.4653 records/second. Loss is 2.0543642. Sequentialb692dd65's hyper parameters: Current learning rate is 2.542588354945334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 15488/60000][Iteration 2935][Wall Clock 280.507584056s] Trained 128 records in 0.096409549 seconds. Throughput is 1327.6693 records/second. Loss is 2.0369518. Sequentialb692dd65's hyper parameters: Current learning rate is 2.541942043721403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 15616/60000][Iteration 2936][Wall Clock 280.590907156s] Trained 128 records in 0.0833231 seconds. Throughput is 1536.1887 records/second. Loss is 1.9973752. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5412960609911054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 15744/60000][Iteration 2937][Wall Clock 280.681968331s] Trained 128 records in 0.091061175 seconds. Throughput is 1405.6484 records/second. Loss is 2.0328183. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5406504065040653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 15872/60000][Iteration 2938][Wall Clock 280.769517814s] Trained 128 records in 0.087549483 seconds. Throughput is 1462.0303 records/second. Loss is 2.0423496. Sequentialb692dd65's hyper parameters: Current learning rate is 2.54000508001016E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16000/60000][Iteration 2939][Wall Clock 280.854952302s] Trained 128 records in 0.085434488 seconds. Throughput is 1498.224 records/second. Loss is 2.035535. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5393600812595224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16128/60000][Iteration 2940][Wall Clock 280.941259119s] Trained 128 records in 0.086306817 seconds. Throughput is 1483.0809 records/second. Loss is 2.0199397. Sequentialb692dd65's hyper parameters: Current learning rate is 2.538715410002539E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16256/60000][Iteration 2941][Wall Clock 281.028788163s] Trained 128 records in 0.087529044 seconds. Throughput is 1462.3718 records/second. Loss is 2.0328515. Sequentialb692dd65's hyper parameters: Current learning rate is 2.538071065989848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16384/60000][Iteration 2942][Wall Clock 281.121458201s] Trained 128 records in 0.092670038 seconds. Throughput is 1381.2448 records/second. Loss is 2.0179832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5374270489723417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16512/60000][Iteration 2943][Wall Clock 281.218499491s] Trained 128 records in 0.09704129 seconds. Throughput is 1319.0262 records/second. Loss is 2.0482435. Sequentialb692dd65's hyper parameters: Current learning rate is 2.536783358701167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16640/60000][Iteration 2944][Wall Clock 281.304219328s] Trained 128 records in 0.085719837 seconds. Throughput is 1493.2366 records/second. Loss is 2.054672. Sequentialb692dd65's hyper parameters: Current learning rate is 2.53613999492772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:04 INFO  DistriOptimizer$:408 - [Epoch 7 16768/60000][Iteration 2945][Wall Clock 281.393881867s] Trained 128 records in 0.089662539 seconds. Throughput is 1427.5751 records/second. Loss is 2.0136113. Sequentialb692dd65's hyper parameters: Current learning rate is 2.535496957403651E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 16896/60000][Iteration 2946][Wall Clock 281.479964892s] Trained 128 records in 0.086083025 seconds. Throughput is 1486.9366 records/second. Loss is 1.997357. Sequentialb692dd65's hyper parameters: Current learning rate is 2.534854245880862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17024/60000][Iteration 2947][Wall Clock 281.565895944s] Trained 128 records in 0.085931052 seconds. Throughput is 1489.5663 records/second. Loss is 2.0188668. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5342118601115053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17152/60000][Iteration 2948][Wall Clock 281.656853476s] Trained 128 records in 0.090957532 seconds. Throughput is 1407.2501 records/second. Loss is 2.0249615. Sequentialb692dd65's hyper parameters: Current learning rate is 2.533569799847986E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17280/60000][Iteration 2949][Wall Clock 281.746782567s] Trained 128 records in 0.089929091 seconds. Throughput is 1423.3436 records/second. Loss is 2.0503895. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5329280648429586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17408/60000][Iteration 2950][Wall Clock 281.852510211s] Trained 128 records in 0.105727644 seconds. Throughput is 1210.6578 records/second. Loss is 2.0640762. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5322866548493293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17536/60000][Iteration 2951][Wall Clock 281.939261625s] Trained 128 records in 0.086751414 seconds. Throughput is 1475.4802 records/second. Loss is 2.0548532. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5316455696202533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17664/60000][Iteration 2952][Wall Clock 282.02721046s] Trained 128 records in 0.087948835 seconds. Throughput is 1455.3916 records/second. Loss is 2.0562057. Sequentialb692dd65's hyper parameters: Current learning rate is 2.531004808909137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17792/60000][Iteration 2953][Wall Clock 282.114207768s] Trained 128 records in 0.086997308 seconds. Throughput is 1471.3099 records/second. Loss is 2.054907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5303643724696357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 17920/60000][Iteration 2954][Wall Clock 282.204257002s] Trained 128 records in 0.090049234 seconds. Throughput is 1421.4446 records/second. Loss is 2.0537195. Sequentialb692dd65's hyper parameters: Current learning rate is 2.529724260055654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 18048/60000][Iteration 2955][Wall Clock 282.290548648s] Trained 128 records in 0.086291646 seconds. Throughput is 1483.3417 records/second. Loss is 2.0370505. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5290844714213456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:05 INFO  DistriOptimizer$:408 - [Epoch 7 18176/60000][Iteration 2956][Wall Clock 282.379090589s] Trained 128 records in 0.088541941 seconds. Throughput is 1445.6426 records/second. Loss is 2.0498955. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5284450063211124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18304/60000][Iteration 2957][Wall Clock 282.468742443s] Trained 128 records in 0.089651854 seconds. Throughput is 1427.7451 records/second. Loss is 2.0138006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.527805864509606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18432/60000][Iteration 2958][Wall Clock 282.556172018s] Trained 128 records in 0.087429575 seconds. Throughput is 1464.0355 records/second. Loss is 2.036888. Sequentialb692dd65's hyper parameters: Current learning rate is 2.527167045741724E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18560/60000][Iteration 2959][Wall Clock 282.647634584s] Trained 128 records in 0.091462566 seconds. Throughput is 1399.4796 records/second. Loss is 2.048887. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5265285497726126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18688/60000][Iteration 2960][Wall Clock 282.737402783s] Trained 128 records in 0.089768199 seconds. Throughput is 1425.8947 records/second. Loss is 2.055258. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5258903763576663E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18816/60000][Iteration 2961][Wall Clock 282.836052363s] Trained 128 records in 0.09864958 seconds. Throughput is 1297.5221 records/second. Loss is 2.0208502. Sequentialb692dd65's hyper parameters: Current learning rate is 2.525252525252525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 18944/60000][Iteration 2962][Wall Clock 282.928683172s] Trained 128 records in 0.092630809 seconds. Throughput is 1381.8296 records/second. Loss is 2.0533116. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5246149962130775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 19072/60000][Iteration 2963][Wall Clock 283.023370816s] Trained 128 records in 0.094687644 seconds. Throughput is 1351.8132 records/second. Loss is 2.01722. Sequentialb692dd65's hyper parameters: Current learning rate is 2.523977788995457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 19200/60000][Iteration 2964][Wall Clock 283.113891886s] Trained 128 records in 0.09052107 seconds. Throughput is 1414.0355 records/second. Loss is 2.0866106. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5233409033560434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 19328/60000][Iteration 2965][Wall Clock 283.202746123s] Trained 128 records in 0.088854237 seconds. Throughput is 1440.5615 records/second. Loss is 2.030471. Sequentialb692dd65's hyper parameters: Current learning rate is 2.522704339051463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 19456/60000][Iteration 2966][Wall Clock 283.289181899s] Trained 128 records in 0.086435776 seconds. Throughput is 1480.8684 records/second. Loss is 2.0411305. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5220680958385876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:06 INFO  DistriOptimizer$:408 - [Epoch 7 19584/60000][Iteration 2967][Wall Clock 283.376808543s] Trained 128 records in 0.087626644 seconds. Throughput is 1460.7429 records/second. Loss is 2.0102978. Sequentialb692dd65's hyper parameters: Current learning rate is 2.521432173474533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 19712/60000][Iteration 2968][Wall Clock 283.464225235s] Trained 128 records in 0.087416692 seconds. Throughput is 1464.2512 records/second. Loss is 2.036777. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5207965717166626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 19840/60000][Iteration 2969][Wall Clock 283.562925692s] Trained 128 records in 0.098700457 seconds. Throughput is 1296.8531 records/second. Loss is 2.055486. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5201612903225806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 19968/60000][Iteration 2970][Wall Clock 283.650279805s] Trained 128 records in 0.087354113 seconds. Throughput is 1465.3002 records/second. Loss is 2.0395052. Sequentialb692dd65's hyper parameters: Current learning rate is 2.519526329050139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20096/60000][Iteration 2971][Wall Clock 283.738348702s] Trained 128 records in 0.088068897 seconds. Throughput is 1453.4076 records/second. Loss is 2.051322. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5188916876574307E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20224/60000][Iteration 2972][Wall Clock 283.828441689s] Trained 128 records in 0.090092987 seconds. Throughput is 1420.7543 records/second. Loss is 2.032782. Sequentialb692dd65's hyper parameters: Current learning rate is 2.518257365902795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20352/60000][Iteration 2973][Wall Clock 283.915597294s] Trained 128 records in 0.087155605 seconds. Throughput is 1468.6377 records/second. Loss is 2.0470808. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5176233635448137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20480/60000][Iteration 2974][Wall Clock 284.004855771s] Trained 128 records in 0.089258477 seconds. Throughput is 1434.0375 records/second. Loss is 2.0431838. Sequentialb692dd65's hyper parameters: Current learning rate is 2.516989680342311E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20608/60000][Iteration 2975][Wall Clock 284.093424919s] Trained 128 records in 0.088569148 seconds. Throughput is 1445.1985 records/second. Loss is 2.053238. Sequentialb692dd65's hyper parameters: Current learning rate is 2.516356316054353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20736/60000][Iteration 2976][Wall Clock 284.183854957s] Trained 128 records in 0.090430038 seconds. Throughput is 1415.4589 records/second. Loss is 2.0565865. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5157232704402514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20864/60000][Iteration 2977][Wall Clock 284.272195183s] Trained 128 records in 0.088340226 seconds. Throughput is 1448.9436 records/second. Loss is 2.0204062. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5150905432595576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:07 INFO  DistriOptimizer$:408 - [Epoch 7 20992/60000][Iteration 2978][Wall Clock 284.360243827s] Trained 128 records in 0.088048644 seconds. Throughput is 1453.7418 records/second. Loss is 2.013602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5144581342720644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21120/60000][Iteration 2979][Wall Clock 284.448304699s] Trained 128 records in 0.088060872 seconds. Throughput is 1453.54 records/second. Loss is 2.0635166. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5138260432378077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21248/60000][Iteration 2980][Wall Clock 284.538264203s] Trained 128 records in 0.089959504 seconds. Throughput is 1422.8624 records/second. Loss is 2.0348604. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5131942699170643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21376/60000][Iteration 2981][Wall Clock 284.625159343s] Trained 128 records in 0.08689514 seconds. Throughput is 1473.0398 records/second. Loss is 2.045456. Sequentialb692dd65's hyper parameters: Current learning rate is 2.512562814070352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21504/60000][Iteration 2982][Wall Clock 284.716427368s] Trained 128 records in 0.091268025 seconds. Throughput is 1402.4626 records/second. Loss is 2.059504. Sequentialb692dd65's hyper parameters: Current learning rate is 2.511931675458428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21632/60000][Iteration 2983][Wall Clock 284.803155683s] Trained 128 records in 0.086728315 seconds. Throughput is 1475.8733 records/second. Loss is 2.0255883. Sequentialb692dd65's hyper parameters: Current learning rate is 2.51130085384229E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21760/60000][Iteration 2984][Wall Clock 284.895233757s] Trained 128 records in 0.092078074 seconds. Throughput is 1390.1246 records/second. Loss is 2.0369668. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5106703489831785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 21888/60000][Iteration 2985][Wall Clock 284.984690504s] Trained 128 records in 0.089456747 seconds. Throughput is 1430.8591 records/second. Loss is 2.052966. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5100401606425706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 22016/60000][Iteration 2986][Wall Clock 285.085272379s] Trained 128 records in 0.100581875 seconds. Throughput is 1272.5951 records/second. Loss is 2.0378928. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5094102885821835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 22144/60000][Iteration 2987][Wall Clock 285.173094066s] Trained 128 records in 0.087821687 seconds. Throughput is 1457.4988 records/second. Loss is 2.0545456. Sequentialb692dd65's hyper parameters: Current learning rate is 2.508780732563974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 22272/60000][Iteration 2988][Wall Clock 285.259685119s] Trained 128 records in 0.086591053 seconds. Throughput is 1478.2128 records/second. Loss is 2.0640829. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5081514923501377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:08 INFO  DistriOptimizer$:408 - [Epoch 7 22400/60000][Iteration 2989][Wall Clock 285.346749365s] Trained 128 records in 0.087064246 seconds. Throughput is 1470.1787 records/second. Loss is 2.034209. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5075225677031093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 22528/60000][Iteration 2990][Wall Clock 285.436501328s] Trained 128 records in 0.089751963 seconds. Throughput is 1426.1526 records/second. Loss is 2.0277143. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5068939583855606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 22656/60000][Iteration 2991][Wall Clock 285.523553923s] Trained 128 records in 0.087052595 seconds. Throughput is 1470.3754 records/second. Loss is 2.0259962. Sequentialb692dd65's hyper parameters: Current learning rate is 2.506265664160401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 22784/60000][Iteration 2992][Wall Clock 285.611545355s] Trained 128 records in 0.087991432 seconds. Throughput is 1454.6871 records/second. Loss is 2.0284173. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5056376847907793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 22912/60000][Iteration 2993][Wall Clock 285.702459151s] Trained 128 records in 0.090913796 seconds. Throughput is 1407.9271 records/second. Loss is 2.0034974. Sequentialb692dd65's hyper parameters: Current learning rate is 2.50501002004008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23040/60000][Iteration 2994][Wall Clock 285.800460379s] Trained 128 records in 0.098001228 seconds. Throughput is 1306.1061 records/second. Loss is 2.0334995. Sequentialb692dd65's hyper parameters: Current learning rate is 2.504382669671926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23168/60000][Iteration 2995][Wall Clock 285.889958376s] Trained 128 records in 0.089497997 seconds. Throughput is 1430.1996 records/second. Loss is 2.0612812. Sequentialb692dd65's hyper parameters: Current learning rate is 2.503755633450175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23296/60000][Iteration 2996][Wall Clock 285.977760408s] Trained 128 records in 0.087802032 seconds. Throughput is 1457.8251 records/second. Loss is 2.0587656. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5031289111389235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23424/60000][Iteration 2997][Wall Clock 286.069966657s] Trained 128 records in 0.092206249 seconds. Throughput is 1388.1923 records/second. Loss is 2.0776558. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5025025025025025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23552/60000][Iteration 2998][Wall Clock 286.161044072s] Trained 128 records in 0.091077415 seconds. Throughput is 1405.3978 records/second. Loss is 2.0139325. Sequentialb692dd65's hyper parameters: Current learning rate is 2.501876407305479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23680/60000][Iteration 2999][Wall Clock 286.252514284s] Trained 128 records in 0.091470212 seconds. Throughput is 1399.3627 records/second. Loss is 2.014825. Sequentialb692dd65's hyper parameters: Current learning rate is 2.501250625312656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:09 INFO  DistriOptimizer$:408 - [Epoch 7 23808/60000][Iteration 3000][Wall Clock 286.343015417s] Trained 128 records in 0.090501133 seconds. Throughput is 1414.347 records/second. Loss is 2.0402665. Sequentialb692dd65's hyper parameters: Current learning rate is 2.500625156289072E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 23936/60000][Iteration 3001][Wall Clock 286.433569327s] Trained 128 records in 0.09055391 seconds. Throughput is 1413.5226 records/second. Loss is 2.0166948. Sequentialb692dd65's hyper parameters: Current learning rate is 2.5E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24064/60000][Iteration 3002][Wall Clock 286.519565518s] Trained 128 records in 0.085996191 seconds. Throughput is 1488.4381 records/second. Loss is 2.0148873. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4993751562109475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24192/60000][Iteration 3003][Wall Clock 286.607521145s] Trained 128 records in 0.087955627 seconds. Throughput is 1455.2793 records/second. Loss is 2.0326495. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4987506246876555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24320/60000][Iteration 3004][Wall Clock 286.695091549s] Trained 128 records in 0.087570404 seconds. Throughput is 1461.681 records/second. Loss is 2.008669. Sequentialb692dd65's hyper parameters: Current learning rate is 2.498126405196103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24448/60000][Iteration 3005][Wall Clock 286.781807342s] Trained 128 records in 0.086715793 seconds. Throughput is 1476.0863 records/second. Loss is 2.0428276. Sequentialb692dd65's hyper parameters: Current learning rate is 2.497502497502498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24576/60000][Iteration 3006][Wall Clock 286.867009079s] Trained 128 records in 0.085201737 seconds. Throughput is 1502.3168 records/second. Loss is 2.0564523. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4968789013732833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24704/60000][Iteration 3007][Wall Clock 286.951565491s] Trained 128 records in 0.084556412 seconds. Throughput is 1513.7822 records/second. Loss is 2.0259075. Sequentialb692dd65's hyper parameters: Current learning rate is 2.496255616575137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24832/60000][Iteration 3008][Wall Clock 287.036970793s] Trained 128 records in 0.085405302 seconds. Throughput is 1498.736 records/second. Loss is 2.0246227. Sequentialb692dd65's hyper parameters: Current learning rate is 2.495632642874969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 24960/60000][Iteration 3009][Wall Clock 287.125519685s] Trained 128 records in 0.088548892 seconds. Throughput is 1445.529 records/second. Loss is 2.0405488. Sequentialb692dd65's hyper parameters: Current learning rate is 2.49500998003992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 25088/60000][Iteration 3010][Wall Clock 287.207643358s] Trained 128 records in 0.082123673 seconds. Throughput is 1558.6249 records/second. Loss is 2.0223951. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4943876278373656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 25216/60000][Iteration 3011][Wall Clock 287.303809737s] Trained 128 records in 0.096166379 seconds. Throughput is 1331.0265 records/second. Loss is 2.0353556. Sequentialb692dd65's hyper parameters: Current learning rate is 2.493765586034913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:10 INFO  DistriOptimizer$:408 - [Epoch 7 25344/60000][Iteration 3012][Wall Clock 287.385983439s] Trained 128 records in 0.082173702 seconds. Throughput is 1557.6759 records/second. Loss is 2.0351202. Sequentialb692dd65's hyper parameters: Current learning rate is 2.493143854400399E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 25472/60000][Iteration 3013][Wall Clock 287.468373351s] Trained 128 records in 0.082389912 seconds. Throughput is 1553.5883 records/second. Loss is 2.0383675. Sequentialb692dd65's hyper parameters: Current learning rate is 2.492522432701894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 25600/60000][Iteration 3014][Wall Clock 287.554873962s] Trained 128 records in 0.086500611 seconds. Throughput is 1479.7584 records/second. Loss is 2.0454662. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4919013207077E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 25728/60000][Iteration 3015][Wall Clock 287.640909049s] Trained 128 records in 0.086035087 seconds. Throughput is 1487.7651 records/second. Loss is 2.0221007. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4912805181863477E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 25856/60000][Iteration 3016][Wall Clock 287.726736355s] Trained 128 records in 0.085827306 seconds. Throughput is 1491.3668 records/second. Loss is 2.0123346. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4906600249066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 25984/60000][Iteration 3017][Wall Clock 287.811309664s] Trained 128 records in 0.084573309 seconds. Throughput is 1513.4799 records/second. Loss is 2.0203834. Sequentialb692dd65's hyper parameters: Current learning rate is 2.49003984063745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26112/60000][Iteration 3018][Wall Clock 287.89456581s] Trained 128 records in 0.083256146 seconds. Throughput is 1537.424 records/second. Loss is 2.0503173. Sequentialb692dd65's hyper parameters: Current learning rate is 2.489419965148121E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26240/60000][Iteration 3019][Wall Clock 287.985284761s] Trained 128 records in 0.090718951 seconds. Throughput is 1410.9512 records/second. Loss is 2.0099645. Sequentialb692dd65's hyper parameters: Current learning rate is 2.488800398208063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26368/60000][Iteration 3020][Wall Clock 288.066298532s] Trained 128 records in 0.081013771 seconds. Throughput is 1579.9784 records/second. Loss is 2.0171983. Sequentialb692dd65's hyper parameters: Current learning rate is 2.488181139586962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26496/60000][Iteration 3021][Wall Clock 288.145031491s] Trained 128 records in 0.078732959 seconds. Throughput is 1625.7487 records/second. Loss is 2.041605. Sequentialb692dd65's hyper parameters: Current learning rate is 2.487562189054727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26624/60000][Iteration 3022][Wall Clock 288.229230763s] Trained 128 records in 0.084199272 seconds. Throughput is 1520.2031 records/second. Loss is 2.0561478. Sequentialb692dd65's hyper parameters: Current learning rate is 2.486943546381497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26752/60000][Iteration 3023][Wall Clock 288.310292228s] Trained 128 records in 0.081061465 seconds. Throughput is 1579.0486 records/second. Loss is 2.0228393. Sequentialb692dd65's hyper parameters: Current learning rate is 2.486325211337643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:11 INFO  DistriOptimizer$:408 - [Epoch 7 26880/60000][Iteration 3024][Wall Clock 288.392103206s] Trained 128 records in 0.081810978 seconds. Throughput is 1564.5822 records/second. Loss is 2.030016. Sequentialb692dd65's hyper parameters: Current learning rate is 2.485707183693761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27008/60000][Iteration 3025][Wall Clock 288.476409644s] Trained 128 records in 0.084306438 seconds. Throughput is 1518.2708 records/second. Loss is 2.0550218. Sequentialb692dd65's hyper parameters: Current learning rate is 2.485089463220676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27136/60000][Iteration 3026][Wall Clock 288.55981838s] Trained 128 records in 0.083408736 seconds. Throughput is 1534.6115 records/second. Loss is 1.9883854. Sequentialb692dd65's hyper parameters: Current learning rate is 2.484472049689441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27264/60000][Iteration 3027][Wall Clock 288.64350006s] Trained 128 records in 0.08368168 seconds. Throughput is 1529.606 records/second. Loss is 2.0332146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4838549428713363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27392/60000][Iteration 3028][Wall Clock 288.727198789s] Trained 128 records in 0.083698729 seconds. Throughput is 1529.2944 records/second. Loss is 2.048955. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4832381425378696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27520/60000][Iteration 3029][Wall Clock 288.812632259s] Trained 128 records in 0.08543347 seconds. Throughput is 1498.2418 records/second. Loss is 2.0190692. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4826216484607745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27648/60000][Iteration 3030][Wall Clock 288.896984605s] Trained 128 records in 0.084352346 seconds. Throughput is 1517.4445 records/second. Loss is 2.0684884. Sequentialb692dd65's hyper parameters: Current learning rate is 2.482005460412013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27776/60000][Iteration 3031][Wall Clock 288.982232106s] Trained 128 records in 0.085247501 seconds. Throughput is 1501.5103 records/second. Loss is 2.0214114. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4813895781637717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 27904/60000][Iteration 3032][Wall Clock 289.067489937s] Trained 128 records in 0.085257831 seconds. Throughput is 1501.3284 records/second. Loss is 2.0164504. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4807740014884643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 28032/60000][Iteration 3033][Wall Clock 289.154745192s] Trained 128 records in 0.087255255 seconds. Throughput is 1466.9603 records/second. Loss is 2.0296612. Sequentialb692dd65's hyper parameters: Current learning rate is 2.48015873015873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 28160/60000][Iteration 3034][Wall Clock 289.239988073s] Trained 128 records in 0.085242881 seconds. Throughput is 1501.5917 records/second. Loss is 2.0372262. Sequentialb692dd65's hyper parameters: Current learning rate is 2.479543763947434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:12 INFO  DistriOptimizer$:408 - [Epoch 7 28288/60000][Iteration 3035][Wall Clock 289.324560448s] Trained 128 records in 0.084572375 seconds. Throughput is 1513.4966 records/second. Loss is 2.0293138. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4789291026276647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 28416/60000][Iteration 3036][Wall Clock 289.410245096s] Trained 128 records in 0.085684648 seconds. Throughput is 1493.8499 records/second. Loss is 2.021585. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4783147459727387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 28544/60000][Iteration 3037][Wall Clock 289.501413373s] Trained 128 records in 0.091168277 seconds. Throughput is 1403.9972 records/second. Loss is 2.0236058. Sequentialb692dd65's hyper parameters: Current learning rate is 2.477700693756195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 28672/60000][Iteration 3038][Wall Clock 289.58891269s] Trained 128 records in 0.087499317 seconds. Throughput is 1462.8685 records/second. Loss is 2.0379407. Sequentialb692dd65's hyper parameters: Current learning rate is 2.477086945751796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 28800/60000][Iteration 3039][Wall Clock 289.676674269s] Trained 128 records in 0.087761579 seconds. Throughput is 1458.497 records/second. Loss is 2.0525699. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4764735017335313E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 28928/60000][Iteration 3040][Wall Clock 289.765011048s] Trained 128 records in 0.088336779 seconds. Throughput is 1449.0 records/second. Loss is 2.0533755. Sequentialb692dd65's hyper parameters: Current learning rate is 2.475860361475613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29056/60000][Iteration 3041][Wall Clock 289.852900914s] Trained 128 records in 0.087889866 seconds. Throughput is 1456.3682 records/second. Loss is 2.0349972. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4752475247524753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29184/60000][Iteration 3042][Wall Clock 289.93847702s] Trained 128 records in 0.085576106 seconds. Throughput is 1495.7445 records/second. Loss is 2.016862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4746349913387774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29312/60000][Iteration 3043][Wall Clock 290.02479626s] Trained 128 records in 0.08631924 seconds. Throughput is 1482.8676 records/second. Loss is 2.022627. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4740227610094015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29440/60000][Iteration 3044][Wall Clock 290.11152897s] Trained 128 records in 0.08673271 seconds. Throughput is 1475.7985 records/second. Loss is 2.063904. Sequentialb692dd65's hyper parameters: Current learning rate is 2.473410833539451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29568/60000][Iteration 3045][Wall Clock 290.197973683s] Trained 128 records in 0.086444713 seconds. Throughput is 1480.7152 records/second. Loss is 2.037092. Sequentialb692dd65's hyper parameters: Current learning rate is 2.472799208704253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29696/60000][Iteration 3046][Wall Clock 290.286543099s] Trained 128 records in 0.088569416 seconds. Throughput is 1445.1941 records/second. Loss is 2.041687. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4721878862793575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:13 INFO  DistriOptimizer$:408 - [Epoch 7 29824/60000][Iteration 3047][Wall Clock 290.372224111s] Trained 128 records in 0.085681012 seconds. Throughput is 1493.9132 records/second. Loss is 2.0696385. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4715768660405336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 29952/60000][Iteration 3048][Wall Clock 290.457585079s] Trained 128 records in 0.085360968 seconds. Throughput is 1499.5144 records/second. Loss is 2.0283434. Sequentialb692dd65's hyper parameters: Current learning rate is 2.470966147763775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30080/60000][Iteration 3049][Wall Clock 290.543689979s] Trained 128 records in 0.0861049 seconds. Throughput is 1486.5588 records/second. Loss is 2.0719936. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4703557312252963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30208/60000][Iteration 3050][Wall Clock 290.628510523s] Trained 128 records in 0.084820544 seconds. Throughput is 1509.0684 records/second. Loss is 2.055312. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4697456162015317E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30336/60000][Iteration 3051][Wall Clock 290.711857386s] Trained 128 records in 0.083346863 seconds. Throughput is 1535.7506 records/second. Loss is 2.0449338. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4691358024691353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30464/60000][Iteration 3052][Wall Clock 290.794571502s] Trained 128 records in 0.082714116 seconds. Throughput is 1547.4988 records/second. Loss is 2.0218656. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4685262898049864E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30592/60000][Iteration 3053][Wall Clock 290.879613055s] Trained 128 records in 0.085041553 seconds. Throughput is 1505.1466 records/second. Loss is 2.0229673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.46791707798618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30720/60000][Iteration 3054][Wall Clock 290.965720056s] Trained 128 records in 0.086107001 seconds. Throughput is 1486.5226 records/second. Loss is 2.0563862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.467308166790032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30848/60000][Iteration 3055][Wall Clock 291.051117367s] Trained 128 records in 0.085397311 seconds. Throughput is 1498.8762 records/second. Loss is 2.056565. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4666995559940796E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 30976/60000][Iteration 3056][Wall Clock 291.14109745s] Trained 128 records in 0.089980083 seconds. Throughput is 1422.5371 records/second. Loss is 1.9953259. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4660912453760794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 31104/60000][Iteration 3057][Wall Clock 291.230251039s] Trained 128 records in 0.089153589 seconds. Throughput is 1435.7246 records/second. Loss is 2.0534625. Sequentialb692dd65's hyper parameters: Current learning rate is 2.465483234714004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:14 INFO  DistriOptimizer$:408 - [Epoch 7 31232/60000][Iteration 3058][Wall Clock 291.314264888s] Trained 128 records in 0.084013849 seconds. Throughput is 1523.5583 records/second. Loss is 2.0325418. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4648755237860487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 31360/60000][Iteration 3059][Wall Clock 291.396666653s] Trained 128 records in 0.082401765 seconds. Throughput is 1553.3647 records/second. Loss is 2.0455325. Sequentialb692dd65's hyper parameters: Current learning rate is 2.464268112370626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 31488/60000][Iteration 3060][Wall Clock 291.478694052s] Trained 128 records in 0.082027399 seconds. Throughput is 1560.4542 records/second. Loss is 2.0369651. Sequentialb692dd65's hyper parameters: Current learning rate is 2.463661000246366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 31616/60000][Iteration 3061][Wall Clock 291.564568395s] Trained 128 records in 0.085874343 seconds. Throughput is 1490.55 records/second. Loss is 2.0032911. Sequentialb692dd65's hyper parameters: Current learning rate is 2.463054187192118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 31744/60000][Iteration 3062][Wall Clock 291.662910291s] Trained 128 records in 0.098341896 seconds. Throughput is 1301.5815 records/second. Loss is 2.0252793. Sequentialb692dd65's hyper parameters: Current learning rate is 2.462447672986949E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 31872/60000][Iteration 3063][Wall Clock 291.746322874s] Trained 128 records in 0.083412583 seconds. Throughput is 1534.5406 records/second. Loss is 2.0404994. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4618414574101424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32000/60000][Iteration 3064][Wall Clock 291.825893666s] Trained 128 records in 0.079570792 seconds. Throughput is 1608.6305 records/second. Loss is 2.0411575. Sequentialb692dd65's hyper parameters: Current learning rate is 2.461235540241201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32128/60000][Iteration 3065][Wall Clock 291.904894189s] Trained 128 records in 0.079000523 seconds. Throughput is 1620.2424 records/second. Loss is 2.04967. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4606299212598425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32256/60000][Iteration 3066][Wall Clock 291.987371485s] Trained 128 records in 0.082477296 seconds. Throughput is 1551.9423 records/second. Loss is 2.0542445. Sequentialb692dd65's hyper parameters: Current learning rate is 2.460024600246003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32384/60000][Iteration 3067][Wall Clock 292.073621422s] Trained 128 records in 0.086249937 seconds. Throughput is 1484.059 records/second. Loss is 2.0267093. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4594195769798326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32512/60000][Iteration 3068][Wall Clock 292.158970504s] Trained 128 records in 0.085349082 seconds. Throughput is 1499.7231 records/second. Loss is 2.021452. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4588148512417015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32640/60000][Iteration 3069][Wall Clock 292.244271914s] Trained 128 records in 0.08530141 seconds. Throughput is 1500.5614 records/second. Loss is 2.0513496. Sequentialb692dd65's hyper parameters: Current learning rate is 2.458210422812193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:15 INFO  DistriOptimizer$:408 - [Epoch 7 32768/60000][Iteration 3070][Wall Clock 292.331834433s] Trained 128 records in 0.087562519 seconds. Throughput is 1461.8127 records/second. Loss is 2.0212464. Sequentialb692dd65's hyper parameters: Current learning rate is 2.457606291472106E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 32896/60000][Iteration 3071][Wall Clock 292.413089425s] Trained 128 records in 0.081254992 seconds. Throughput is 1575.2878 records/second. Loss is 2.03187. Sequentialb692dd65's hyper parameters: Current learning rate is 2.457002457002457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33024/60000][Iteration 3072][Wall Clock 292.497678024s] Trained 128 records in 0.084588599 seconds. Throughput is 1513.2062 records/second. Loss is 2.0587626. Sequentialb692dd65's hyper parameters: Current learning rate is 2.456398919184476E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33152/60000][Iteration 3073][Wall Clock 292.582991553s] Trained 128 records in 0.085313529 seconds. Throughput is 1500.3483 records/second. Loss is 2.0075982. Sequentialb692dd65's hyper parameters: Current learning rate is 2.455795677799607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33280/60000][Iteration 3074][Wall Clock 292.667940128s] Trained 128 records in 0.084948575 seconds. Throughput is 1506.794 records/second. Loss is 2.02832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4551927326295114E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33408/60000][Iteration 3075][Wall Clock 292.755992107s] Trained 128 records in 0.088051979 seconds. Throughput is 1453.6868 records/second. Loss is 2.0375125. Sequentialb692dd65's hyper parameters: Current learning rate is 2.454590083456063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33536/60000][Iteration 3076][Wall Clock 292.84620339s] Trained 128 records in 0.090211283 seconds. Throughput is 1418.8914 records/second. Loss is 2.0159018. Sequentialb692dd65's hyper parameters: Current learning rate is 2.45398773006135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33664/60000][Iteration 3077][Wall Clock 292.931544418s] Trained 128 records in 0.085341028 seconds. Throughput is 1499.8647 records/second. Loss is 2.0216355. Sequentialb692dd65's hyper parameters: Current learning rate is 2.453385672227674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33792/60000][Iteration 3078][Wall Clock 293.016590258s] Trained 128 records in 0.08504584 seconds. Throughput is 1505.0707 records/second. Loss is 2.0072327. Sequentialb692dd65's hyper parameters: Current learning rate is 2.452783909737552E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 33920/60000][Iteration 3079][Wall Clock 293.100995593s] Trained 128 records in 0.084405335 seconds. Throughput is 1516.4918 records/second. Loss is 2.0490012. Sequentialb692dd65's hyper parameters: Current learning rate is 2.452182442373713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 34048/60000][Iteration 3080][Wall Clock 293.184631044s] Trained 128 records in 0.083635451 seconds. Throughput is 1530.4515 records/second. Loss is 2.0387263. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4515812699190976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 34176/60000][Iteration 3081][Wall Clock 293.2691097s] Trained 128 records in 0.084478656 seconds. Throughput is 1515.1757 records/second. Loss is 2.044221. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4509803921568627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:16 INFO  DistriOptimizer$:408 - [Epoch 7 34304/60000][Iteration 3082][Wall Clock 293.353092402s] Trained 128 records in 0.083982702 seconds. Throughput is 1524.1234 records/second. Loss is 2.0483372. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4503798088703753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 34432/60000][Iteration 3083][Wall Clock 293.436673439s] Trained 128 records in 0.083581037 seconds. Throughput is 1531.4479 records/second. Loss is 2.029898. Sequentialb692dd65's hyper parameters: Current learning rate is 2.449779519843214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 34560/60000][Iteration 3084][Wall Clock 293.5200925s] Trained 128 records in 0.083419061 seconds. Throughput is 1534.4215 records/second. Loss is 2.0580437. Sequentialb692dd65's hyper parameters: Current learning rate is 2.449179524859172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 34688/60000][Iteration 3085][Wall Clock 293.60593678s] Trained 128 records in 0.08584428 seconds. Throughput is 1491.072 records/second. Loss is 2.0312428. Sequentialb692dd65's hyper parameters: Current learning rate is 2.448579823702253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 34816/60000][Iteration 3086][Wall Clock 293.691382168s] Trained 128 records in 0.085445388 seconds. Throughput is 1498.0328 records/second. Loss is 2.0494533. Sequentialb692dd65's hyper parameters: Current learning rate is 2.447980416156671E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 34944/60000][Iteration 3087][Wall Clock 293.778770614s] Trained 128 records in 0.087388446 seconds. Throughput is 1464.7245 records/second. Loss is 2.0632677. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4473813020068524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35072/60000][Iteration 3088][Wall Clock 293.861288014s] Trained 128 records in 0.0825174 seconds. Throughput is 1551.188 records/second. Loss is 2.016076. Sequentialb692dd65's hyper parameters: Current learning rate is 2.446782481037436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35200/60000][Iteration 3089][Wall Clock 293.940459738s] Trained 128 records in 0.079171724 seconds. Throughput is 1616.7388 records/second. Loss is 2.040805. Sequentialb692dd65's hyper parameters: Current learning rate is 2.446183953033268E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35328/60000][Iteration 3090][Wall Clock 294.016661651s] Trained 128 records in 0.076201913 seconds. Throughput is 1679.7478 records/second. Loss is 2.032583. Sequentialb692dd65's hyper parameters: Current learning rate is 2.445585717779408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35456/60000][Iteration 3091][Wall Clock 294.101215936s] Trained 128 records in 0.084554285 seconds. Throughput is 1513.8204 records/second. Loss is 2.0233505. Sequentialb692dd65's hyper parameters: Current learning rate is 2.444987775061125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35584/60000][Iteration 3092][Wall Clock 294.184834041s] Trained 128 records in 0.083618105 seconds. Throughput is 1530.7689 records/second. Loss is 2.02935. Sequentialb692dd65's hyper parameters: Current learning rate is 2.444390124663896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35712/60000][Iteration 3093][Wall Clock 294.27016005s] Trained 128 records in 0.085326009 seconds. Throughput is 1500.1288 records/second. Loss is 2.0183382. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4437927663734115E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:17 INFO  DistriOptimizer$:408 - [Epoch 7 35840/60000][Iteration 3094][Wall Clock 294.354035594s] Trained 128 records in 0.083875544 seconds. Throughput is 1526.0706 records/second. Loss is 2.0174212. Sequentialb692dd65's hyper parameters: Current learning rate is 2.443195699975568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 35968/60000][Iteration 3095][Wall Clock 294.443639095s] Trained 128 records in 0.089603501 seconds. Throughput is 1428.5156 records/second. Loss is 2.0319946. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4425989252564734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36096/60000][Iteration 3096][Wall Clock 294.522645187s] Trained 128 records in 0.079006092 seconds. Throughput is 1620.1283 records/second. Loss is 1.9968792. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4420024420024415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36224/60000][Iteration 3097][Wall Clock 294.602537856s] Trained 128 records in 0.079892669 seconds. Throughput is 1602.1494 records/second. Loss is 2.001848. Sequentialb692dd65's hyper parameters: Current learning rate is 2.44140625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36352/60000][Iteration 3098][Wall Clock 294.687327163s] Trained 128 records in 0.084789307 seconds. Throughput is 1509.6244 records/second. Loss is 2.0141053. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4408103490358802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36480/60000][Iteration 3099][Wall Clock 294.773474073s] Trained 128 records in 0.08614691 seconds. Throughput is 1485.8339 records/second. Loss is 2.0736184. Sequentialb692dd65's hyper parameters: Current learning rate is 2.440214738897023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36608/60000][Iteration 3100][Wall Clock 294.856799911s] Trained 128 records in 0.083325838 seconds. Throughput is 1536.1381 records/second. Loss is 2.0116804. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4396194193705782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36736/60000][Iteration 3101][Wall Clock 294.942228965s] Trained 128 records in 0.085429054 seconds. Throughput is 1498.3192 records/second. Loss is 2.062713. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4390243902439027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36864/60000][Iteration 3102][Wall Clock 295.027171987s] Trained 128 records in 0.084943022 seconds. Throughput is 1506.8926 records/second. Loss is 2.0110176. Sequentialb692dd65's hyper parameters: Current learning rate is 2.43842965130456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 36992/60000][Iteration 3103][Wall Clock 295.113173571s] Trained 128 records in 0.086001584 seconds. Throughput is 1488.3447 records/second. Loss is 2.0144682. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4378352023403217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 37120/60000][Iteration 3104][Wall Clock 295.197121109s] Trained 128 records in 0.083947538 seconds. Throughput is 1524.7618 records/second. Loss is 2.0083287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4372410431391668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 37248/60000][Iteration 3105][Wall Clock 295.279666849s] Trained 128 records in 0.08254574 seconds. Throughput is 1550.6554 records/second. Loss is 2.035301. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4366471734892786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:18 INFO  DistriOptimizer$:408 - [Epoch 7 37376/60000][Iteration 3106][Wall Clock 295.363668252s] Trained 128 records in 0.084001403 seconds. Throughput is 1523.7842 records/second. Loss is 2.0389175. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4360535931790498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 37504/60000][Iteration 3107][Wall Clock 295.446054819s] Trained 128 records in 0.082386567 seconds. Throughput is 1553.6514 records/second. Loss is 2.0113745. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4354603019970775E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 37632/60000][Iteration 3108][Wall Clock 295.53171804s] Trained 128 records in 0.085663221 seconds. Throughput is 1494.2235 records/second. Loss is 2.0015633. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4348672997321646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 37760/60000][Iteration 3109][Wall Clock 295.617278141s] Trained 128 records in 0.085560101 seconds. Throughput is 1496.0244 records/second. Loss is 2.0256994. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4342745861733202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 37888/60000][Iteration 3110][Wall Clock 295.700823194s] Trained 128 records in 0.083545053 seconds. Throughput is 1532.1075 records/second. Loss is 2.0287607. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4336821611097592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38016/60000][Iteration 3111][Wall Clock 295.787181973s] Trained 128 records in 0.086358779 seconds. Throughput is 1482.1886 records/second. Loss is 2.030189. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4330900243309006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38144/60000][Iteration 3112][Wall Clock 295.870126816s] Trained 128 records in 0.082944843 seconds. Throughput is 1543.1942 records/second. Loss is 2.0078437. Sequentialb692dd65's hyper parameters: Current learning rate is 2.432498175626368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38272/60000][Iteration 3113][Wall Clock 295.965177743s] Trained 128 records in 0.095050927 seconds. Throughput is 1346.6466 records/second. Loss is 2.0399024. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4319066147859923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38400/60000][Iteration 3114][Wall Clock 296.052858313s] Trained 128 records in 0.08768057 seconds. Throughput is 1459.8445 records/second. Loss is 2.043871. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4313153415998057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38528/60000][Iteration 3115][Wall Clock 296.135758253s] Trained 128 records in 0.08289994 seconds. Throughput is 1544.03 records/second. Loss is 2.0245712. Sequentialb692dd65's hyper parameters: Current learning rate is 2.430724355858046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38656/60000][Iteration 3116][Wall Clock 296.220886832s] Trained 128 records in 0.085128579 seconds. Throughput is 1503.6079 records/second. Loss is 2.0124402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4301336573511544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:19 INFO  DistriOptimizer$:408 - [Epoch 7 38784/60000][Iteration 3117][Wall Clock 296.306323204s] Trained 128 records in 0.085436372 seconds. Throughput is 1498.1909 records/second. Loss is 2.013237. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4295432458697766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 38912/60000][Iteration 3118][Wall Clock 296.390212899s] Trained 128 records in 0.083889695 seconds. Throughput is 1525.8132 records/second. Loss is 2.038106. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4289531212047608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39040/60000][Iteration 3119][Wall Clock 296.473045664s] Trained 128 records in 0.082832765 seconds. Throughput is 1545.2822 records/second. Loss is 1.9960679. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4283632831471587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39168/60000][Iteration 3120][Wall Clock 296.556653388s] Trained 128 records in 0.083607724 seconds. Throughput is 1530.959 records/second. Loss is 2.0104809. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4277737314882256E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39296/60000][Iteration 3121][Wall Clock 296.649594841s] Trained 128 records in 0.092941453 seconds. Throughput is 1377.211 records/second. Loss is 2.007035. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4271844660194174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39424/60000][Iteration 3122][Wall Clock 296.735099827s] Trained 128 records in 0.085504986 seconds. Throughput is 1496.9888 records/second. Loss is 2.0545027. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4265954865323948E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39552/60000][Iteration 3123][Wall Clock 296.819925965s] Trained 128 records in 0.084826138 seconds. Throughput is 1508.9688 records/second. Loss is 2.0198941. Sequentialb692dd65's hyper parameters: Current learning rate is 2.42600679281902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39680/60000][Iteration 3124][Wall Clock 296.902355425s] Trained 128 records in 0.08242946 seconds. Throughput is 1552.8429 records/second. Loss is 2.0113916. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4254183846713557E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39808/60000][Iteration 3125][Wall Clock 296.985752176s] Trained 128 records in 0.083396751 seconds. Throughput is 1534.832 records/second. Loss is 2.0172815. Sequentialb692dd65's hyper parameters: Current learning rate is 2.424830261881668E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 39936/60000][Iteration 3126][Wall Clock 297.069973598s] Trained 128 records in 0.084221422 seconds. Throughput is 1519.8033 records/second. Loss is 2.0043435. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4242424242424242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 40064/60000][Iteration 3127][Wall Clock 297.158137968s] Trained 128 records in 0.08816437 seconds. Throughput is 1451.8337 records/second. Loss is 2.061752. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4236548715462922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 40192/60000][Iteration 3128][Wall Clock 297.244714863s] Trained 128 records in 0.086576895 seconds. Throughput is 1478.4545 records/second. Loss is 2.0270183. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4230676035861398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:20 INFO  DistriOptimizer$:408 - [Epoch 7 40320/60000][Iteration 3129][Wall Clock 297.329946094s] Trained 128 records in 0.085231231 seconds. Throughput is 1501.797 records/second. Loss is 2.0423768. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4224806201550387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 40448/60000][Iteration 3130][Wall Clock 297.416403479s] Trained 128 records in 0.086457385 seconds. Throughput is 1480.4982 records/second. Loss is 2.0172322. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4218939210462584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 40576/60000][Iteration 3131][Wall Clock 297.501732629s] Trained 128 records in 0.08532915 seconds. Throughput is 1500.0735 records/second. Loss is 2.029691. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4213075060532688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 40704/60000][Iteration 3132][Wall Clock 297.585712299s] Trained 128 records in 0.08397967 seconds. Throughput is 1524.1783 records/second. Loss is 2.0160797. Sequentialb692dd65's hyper parameters: Current learning rate is 2.420721374969741E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 40832/60000][Iteration 3133][Wall Clock 297.67089996s] Trained 128 records in 0.085187661 seconds. Throughput is 1502.5651 records/second. Loss is 2.023535. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4201355275895454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 40960/60000][Iteration 3134][Wall Clock 297.756833728s] Trained 128 records in 0.085933768 seconds. Throughput is 1489.5193 records/second. Loss is 2.017371. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4195499637067505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41088/60000][Iteration 3135][Wall Clock 297.845371383s] Trained 128 records in 0.088537655 seconds. Throughput is 1445.7125 records/second. Loss is 2.022271. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4189646831156264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41216/60000][Iteration 3136][Wall Clock 297.930360462s] Trained 128 records in 0.084989079 seconds. Throughput is 1506.0759 records/second. Loss is 2.0203757. Sequentialb692dd65's hyper parameters: Current learning rate is 2.418379685610641E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41344/60000][Iteration 3137][Wall Clock 298.013362818s] Trained 128 records in 0.083002356 seconds. Throughput is 1542.1249 records/second. Loss is 2.0278242. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4177949709864604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41472/60000][Iteration 3138][Wall Clock 298.106525257s] Trained 128 records in 0.093162439 seconds. Throughput is 1373.9442 records/second. Loss is 2.0609162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.41721053903795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41600/60000][Iteration 3139][Wall Clock 298.200785909s] Trained 128 records in 0.094260652 seconds. Throughput is 1357.9366 records/second. Loss is 2.006337. Sequentialb692dd65's hyper parameters: Current learning rate is 2.416626389560174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:21 INFO  DistriOptimizer$:408 - [Epoch 7 41728/60000][Iteration 3140][Wall Clock 298.278671566s] Trained 128 records in 0.077885657 seconds. Throughput is 1643.4348 records/second. Loss is 2.019219. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4160425223483932E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 41856/60000][Iteration 3141][Wall Clock 298.360168634s] Trained 128 records in 0.081497068 seconds. Throughput is 1570.6086 records/second. Loss is 1.9959006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4154589371980673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 41984/60000][Iteration 3142][Wall Clock 298.44270682s] Trained 128 records in 0.082538186 seconds. Throughput is 1550.7974 records/second. Loss is 2.0316195. Sequentialb692dd65's hyper parameters: Current learning rate is 2.414875633904854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42112/60000][Iteration 3143][Wall Clock 298.527022792s] Trained 128 records in 0.084315972 seconds. Throughput is 1518.0991 records/second. Loss is 2.0233462. Sequentialb692dd65's hyper parameters: Current learning rate is 2.414292612264607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42240/60000][Iteration 3144][Wall Clock 298.614088464s] Trained 128 records in 0.087065672 seconds. Throughput is 1470.1545 records/second. Loss is 2.0685062. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4137098720733763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42368/60000][Iteration 3145][Wall Clock 298.697968532s] Trained 128 records in 0.083880068 seconds. Throughput is 1525.9883 records/second. Loss is 2.021138. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4131274131274132E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42496/60000][Iteration 3146][Wall Clock 298.787077273s] Trained 128 records in 0.089108741 seconds. Throughput is 1436.4471 records/second. Loss is 2.0515475. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4125452352231607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42624/60000][Iteration 3147][Wall Clock 298.866619749s] Trained 128 records in 0.079542476 seconds. Throughput is 1609.2031 records/second. Loss is 2.0013304. Sequentialb692dd65's hyper parameters: Current learning rate is 2.41196333815726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42752/60000][Iteration 3148][Wall Clock 298.94957655s] Trained 128 records in 0.082956801 seconds. Throughput is 1542.9718 records/second. Loss is 2.012755. Sequentialb692dd65's hyper parameters: Current learning rate is 2.411381721726549E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 42880/60000][Iteration 3149][Wall Clock 299.034779362s] Trained 128 records in 0.085202812 seconds. Throughput is 1502.2979 records/second. Loss is 2.049378. Sequentialb692dd65's hyper parameters: Current learning rate is 2.410800385728062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 43008/60000][Iteration 3150][Wall Clock 299.120177697s] Trained 128 records in 0.085398335 seconds. Throughput is 1498.8583 records/second. Loss is 2.0169208. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4102193299590263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 43136/60000][Iteration 3151][Wall Clock 299.207828437s] Trained 128 records in 0.08765074 seconds. Throughput is 1460.3414 records/second. Loss is 1.9889101. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4096385542168674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:22 INFO  DistriOptimizer$:408 - [Epoch 7 43264/60000][Iteration 3152][Wall Clock 299.294236931s] Trained 128 records in 0.086408494 seconds. Throughput is 1481.3358 records/second. Loss is 2.0344594. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4090580582992053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 43392/60000][Iteration 3153][Wall Clock 299.37825942s] Trained 128 records in 0.084022489 seconds. Throughput is 1523.4016 records/second. Loss is 2.0061476. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4084778420038535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 43520/60000][Iteration 3154][Wall Clock 299.46422875s] Trained 128 records in 0.08596933 seconds. Throughput is 1488.9031 records/second. Loss is 2.0306954. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4078979051288222E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 43648/60000][Iteration 3155][Wall Clock 299.55065862s] Trained 128 records in 0.08642987 seconds. Throughput is 1480.9695 records/second. Loss is 2.0337787. Sequentialb692dd65's hyper parameters: Current learning rate is 2.407318247472316E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 43776/60000][Iteration 3156][Wall Clock 299.636698437s] Trained 128 records in 0.086039817 seconds. Throughput is 1487.6832 records/second. Loss is 2.0231857. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4067388688327315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 43904/60000][Iteration 3157][Wall Clock 299.723927164s] Trained 128 records in 0.087228727 seconds. Throughput is 1467.4064 records/second. Loss is 1.9774346. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4061597690086618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44032/60000][Iteration 3158][Wall Clock 299.808009238s] Trained 128 records in 0.084082074 seconds. Throughput is 1522.3221 records/second. Loss is 2.0516162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4055809477988935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44160/60000][Iteration 3159][Wall Clock 299.890864538s] Trained 128 records in 0.0828553 seconds. Throughput is 1544.8619 records/second. Loss is 1.99518. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4050024050024054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44288/60000][Iteration 3160][Wall Clock 299.974856282s] Trained 128 records in 0.083991744 seconds. Throughput is 1523.9594 records/second. Loss is 2.0480313. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4044241404183695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44416/60000][Iteration 3161][Wall Clock 300.05936883s] Trained 128 records in 0.084512548 seconds. Throughput is 1514.568 records/second. Loss is 2.0224295. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4038461538461537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44544/60000][Iteration 3162][Wall Clock 300.142586987s] Trained 128 records in 0.083218157 seconds. Throughput is 1538.1259 records/second. Loss is 2.017575. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4032684450853164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44672/60000][Iteration 3163][Wall Clock 300.245436413s] Trained 128 records in 0.102849426 seconds. Throughput is 1244.5378 records/second. Loss is 2.0456474. Sequentialb692dd65's hyper parameters: Current learning rate is 2.402691013935608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:23 INFO  DistriOptimizer$:408 - [Epoch 7 44800/60000][Iteration 3164][Wall Clock 300.323308608s] Trained 128 records in 0.077872195 seconds. Throughput is 1643.7189 records/second. Loss is 2.0264783. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4021138601969732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 44928/60000][Iteration 3165][Wall Clock 300.405476119s] Trained 128 records in 0.082167511 seconds. Throughput is 1557.7932 records/second. Loss is 2.0387547. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4015369836695487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45056/60000][Iteration 3166][Wall Clock 300.48337679s] Trained 128 records in 0.077900671 seconds. Throughput is 1643.118 records/second. Loss is 2.0356967. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4009603841536616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45184/60000][Iteration 3167][Wall Clock 300.569172021s] Trained 128 records in 0.085795231 seconds. Throughput is 1491.9244 records/second. Loss is 2.0223992. Sequentialb692dd65's hyper parameters: Current learning rate is 2.4003840614498319E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45312/60000][Iteration 3168][Wall Clock 300.654674334s] Trained 128 records in 0.085502313 seconds. Throughput is 1497.0355 records/second. Loss is 2.03172. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3998080153587716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45440/60000][Iteration 3169][Wall Clock 300.738761326s] Trained 128 records in 0.084086992 seconds. Throughput is 1522.233 records/second. Loss is 2.0133748. Sequentialb692dd65's hyper parameters: Current learning rate is 2.399232245681382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45568/60000][Iteration 3170][Wall Clock 300.823697121s] Trained 128 records in 0.084935795 seconds. Throughput is 1507.0208 records/second. Loss is 2.022246. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3986567522187572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45696/60000][Iteration 3171][Wall Clock 300.908134189s] Trained 128 records in 0.084437068 seconds. Throughput is 1515.922 records/second. Loss is 2.0415673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3980815347721823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45824/60000][Iteration 3172][Wall Clock 301.002041537s] Trained 128 records in 0.093907348 seconds. Throughput is 1363.0457 records/second. Loss is 2.007146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.397506593143131E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 45952/60000][Iteration 3173][Wall Clock 301.085057967s] Trained 128 records in 0.08301643 seconds. Throughput is 1541.8634 records/second. Loss is 2.0197823. Sequentialb692dd65's hyper parameters: Current learning rate is 2.396931927133269E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 46080/60000][Iteration 3174][Wall Clock 301.170499767s] Trained 128 records in 0.0854418 seconds. Throughput is 1498.0958 records/second. Loss is 2.0582538. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3963575365444525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:24 INFO  DistriOptimizer$:408 - [Epoch 7 46208/60000][Iteration 3175][Wall Clock 301.253819841s] Trained 128 records in 0.083320074 seconds. Throughput is 1536.2444 records/second. Loss is 1.9931298. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3957834211787258E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46336/60000][Iteration 3176][Wall Clock 301.338347599s] Trained 128 records in 0.084527758 seconds. Throughput is 1514.2954 records/second. Loss is 2.0162287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.395209580838323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46464/60000][Iteration 3177][Wall Clock 301.423365865s] Trained 128 records in 0.085018266 seconds. Throughput is 1505.5587 records/second. Loss is 2.031289. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3946360153256704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46592/60000][Iteration 3178][Wall Clock 301.510635636s] Trained 128 records in 0.087269771 seconds. Throughput is 1466.7164 records/second. Loss is 1.9818561. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3940627244433806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46720/60000][Iteration 3179][Wall Clock 301.596293653s] Trained 128 records in 0.085658017 seconds. Throughput is 1494.3143 records/second. Loss is 2.036393. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3934897079942556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46848/60000][Iteration 3180][Wall Clock 301.685230171s] Trained 128 records in 0.088936518 seconds. Throughput is 1439.2289 records/second. Loss is 2.0069394. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3929169657812874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 46976/60000][Iteration 3181][Wall Clock 301.776238704s] Trained 128 records in 0.091008533 seconds. Throughput is 1406.4614 records/second. Loss is 2.0174613. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3923444976076558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 47104/60000][Iteration 3182][Wall Clock 301.872986104s] Trained 128 records in 0.0967474 seconds. Throughput is 1323.033 records/second. Loss is 2.0427744. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3917723032767282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 47232/60000][Iteration 3183][Wall Clock 301.969714804s] Trained 128 records in 0.0967287 seconds. Throughput is 1323.2888 records/second. Loss is 2.0225017. Sequentialb692dd65's hyper parameters: Current learning rate is 2.391200382592061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 47360/60000][Iteration 3184][Wall Clock 302.078415698s] Trained 128 records in 0.108700894 seconds. Throughput is 1177.5432 records/second. Loss is 2.016459. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3906287353573993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 47488/60000][Iteration 3185][Wall Clock 302.185793279s] Trained 128 records in 0.107377581 seconds. Throughput is 1192.0552 records/second. Loss is 1.9932487. Sequentialb692dd65's hyper parameters: Current learning rate is 2.390057361376673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:25 INFO  DistriOptimizer$:408 - [Epoch 7 47616/60000][Iteration 3186][Wall Clock 302.293606451s] Trained 128 records in 0.107813172 seconds. Throughput is 1187.239 records/second. Loss is 2.047472. Sequentialb692dd65's hyper parameters: Current learning rate is 2.389486260454002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 47744/60000][Iteration 3187][Wall Clock 302.400464318s] Trained 128 records in 0.106857867 seconds. Throughput is 1197.8529 records/second. Loss is 2.0373712. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3889154323936934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 47872/60000][Iteration 3188][Wall Clock 302.515750195s] Trained 128 records in 0.115285877 seconds. Throughput is 1110.2834 records/second. Loss is 2.0384486. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3883448770002386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48000/60000][Iteration 3189][Wall Clock 302.642165921s] Trained 128 records in 0.126415726 seconds. Throughput is 1012.5322 records/second. Loss is 2.0318182. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3877745940783187E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48128/60000][Iteration 3190][Wall Clock 302.761303255s] Trained 128 records in 0.119137334 seconds. Throughput is 1074.3904 records/second. Loss is 2.0116806. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3872045834328001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48256/60000][Iteration 3191][Wall Clock 302.873649344s] Trained 128 records in 0.112346089 seconds. Throughput is 1139.3365 records/second. Loss is 2.0352156. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3866348448687354E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48384/60000][Iteration 3192][Wall Clock 302.964325958s] Trained 128 records in 0.090676614 seconds. Throughput is 1411.6099 records/second. Loss is 2.0102985. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3860653781913622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48512/60000][Iteration 3193][Wall Clock 303.050281082s] Trained 128 records in 0.085955124 seconds. Throughput is 1489.1492 records/second. Loss is 2.0211647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3854961832061068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48640/60000][Iteration 3194][Wall Clock 303.135740181s] Trained 128 records in 0.085459099 seconds. Throughput is 1497.7926 records/second. Loss is 2.0258846. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3849272597185788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48768/60000][Iteration 3195][Wall Clock 303.22266466s] Trained 128 records in 0.086924479 seconds. Throughput is 1472.5426 records/second. Loss is 2.0159767. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3843586075345734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:26 INFO  DistriOptimizer$:408 - [Epoch 7 48896/60000][Iteration 3196][Wall Clock 303.314937401s] Trained 128 records in 0.092272741 seconds. Throughput is 1387.1919 records/second. Loss is 2.0441594. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3837902264600713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49024/60000][Iteration 3197][Wall Clock 303.417350463s] Trained 128 records in 0.102413062 seconds. Throughput is 1249.8406 records/second. Loss is 2.0091696. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3832221163012395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49152/60000][Iteration 3198][Wall Clock 303.506985013s] Trained 128 records in 0.08963455 seconds. Throughput is 1428.0208 records/second. Loss is 2.0042348. Sequentialb692dd65's hyper parameters: Current learning rate is 2.382654276864427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49280/60000][Iteration 3199][Wall Clock 303.598731911s] Trained 128 records in 0.091746898 seconds. Throughput is 1395.1426 records/second. Loss is 1.9882526. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3820867079561695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49408/60000][Iteration 3200][Wall Clock 303.707849276s] Trained 128 records in 0.109117365 seconds. Throughput is 1173.0488 records/second. Loss is 2.017564. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3815194093831867E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49536/60000][Iteration 3201][Wall Clock 303.794434381s] Trained 128 records in 0.086585105 seconds. Throughput is 1478.3143 records/second. Loss is 1.996625. Sequentialb692dd65's hyper parameters: Current learning rate is 2.380952380952381E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49664/60000][Iteration 3202][Wall Clock 303.880536087s] Trained 128 records in 0.086101706 seconds. Throughput is 1486.614 records/second. Loss is 2.0162616. Sequentialb692dd65's hyper parameters: Current learning rate is 2.38038562247084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49792/60000][Iteration 3203][Wall Clock 303.965506493s] Trained 128 records in 0.084970406 seconds. Throughput is 1506.4069 records/second. Loss is 1.9945927. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3798191337458355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 49920/60000][Iteration 3204][Wall Clock 304.051560091s] Trained 128 records in 0.086053598 seconds. Throughput is 1487.4451 records/second. Loss is 2.0540295. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3792529145848207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 50048/60000][Iteration 3205][Wall Clock 304.139910202s] Trained 128 records in 0.088350111 seconds. Throughput is 1448.7815 records/second. Loss is 2.0382938. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3786869647954325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 50176/60000][Iteration 3206][Wall Clock 304.227506662s] Trained 128 records in 0.08759646 seconds. Throughput is 1461.2462 records/second. Loss is 1.9981318. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3781212841854935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:27 INFO  DistriOptimizer$:408 - [Epoch 7 50304/60000][Iteration 3207][Wall Clock 304.312043371s] Trained 128 records in 0.084536709 seconds. Throughput is 1514.1351 records/second. Loss is 2.0264075. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3775558725630056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 50432/60000][Iteration 3208][Wall Clock 304.396809064s] Trained 128 records in 0.084765693 seconds. Throughput is 1510.0448 records/second. Loss is 2.0253792. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3769907297361542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 50560/60000][Iteration 3209][Wall Clock 304.483010169s] Trained 128 records in 0.086201105 seconds. Throughput is 1484.8998 records/second. Loss is 2.0191028. Sequentialb692dd65's hyper parameters: Current learning rate is 2.376425855513308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 50688/60000][Iteration 3210][Wall Clock 304.572603941s] Trained 128 records in 0.089593772 seconds. Throughput is 1428.6707 records/second. Loss is 1.996418. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3758612497030176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 50816/60000][Iteration 3211][Wall Clock 304.659611545s] Trained 128 records in 0.087007604 seconds. Throughput is 1471.1357 records/second. Loss is 2.0231376. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3752969121140142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 50944/60000][Iteration 3212][Wall Clock 304.749660643s] Trained 128 records in 0.090049098 seconds. Throughput is 1421.4468 records/second. Loss is 2.043831. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3747328425552123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51072/60000][Iteration 3213][Wall Clock 304.834500767s] Trained 128 records in 0.084840124 seconds. Throughput is 1508.7201 records/second. Loss is 2.024047. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3741690408357076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51200/60000][Iteration 3214][Wall Clock 304.925081476s] Trained 128 records in 0.090580709 seconds. Throughput is 1413.1044 records/second. Loss is 2.0255044. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3736055067647758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51328/60000][Iteration 3215][Wall Clock 305.009967163s] Trained 128 records in 0.084885687 seconds. Throughput is 1507.9103 records/second. Loss is 2.0009532. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3730422401518745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51456/60000][Iteration 3216][Wall Clock 305.095209185s] Trained 128 records in 0.085242022 seconds. Throughput is 1501.6067 records/second. Loss is 1.9935126. Sequentialb692dd65's hyper parameters: Current learning rate is 2.372479240806643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51584/60000][Iteration 3217][Wall Clock 305.187849474s] Trained 128 records in 0.092640289 seconds. Throughput is 1381.6882 records/second. Loss is 2.0429955. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3719165085388995E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:28 INFO  DistriOptimizer$:408 - [Epoch 7 51712/60000][Iteration 3218][Wall Clock 305.275029451s] Trained 128 records in 0.087179977 seconds. Throughput is 1468.227 records/second. Loss is 2.0193632. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3713540431586434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 51840/60000][Iteration 3219][Wall Clock 305.358111298s] Trained 128 records in 0.083081847 seconds. Throughput is 1540.6494 records/second. Loss is 2.0090885. Sequentialb692dd65's hyper parameters: Current learning rate is 2.370791844476055E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 51968/60000][Iteration 3220][Wall Clock 305.444147024s] Trained 128 records in 0.086035726 seconds. Throughput is 1487.754 records/second. Loss is 2.041288. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3702299123014937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52096/60000][Iteration 3221][Wall Clock 305.529035218s] Trained 128 records in 0.084888194 seconds. Throughput is 1507.8657 records/second. Loss is 2.0030665. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3696682464454974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52224/60000][Iteration 3222][Wall Clock 305.614677351s] Trained 128 records in 0.085642133 seconds. Throughput is 1494.5914 records/second. Loss is 1.9956121. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3691068467187872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52352/60000][Iteration 3223][Wall Clock 305.707344915s] Trained 128 records in 0.092667564 seconds. Throughput is 1381.2816 records/second. Loss is 2.0196705. Sequentialb692dd65's hyper parameters: Current learning rate is 2.36854571293226E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52480/60000][Iteration 3224][Wall Clock 305.784400607s] Trained 128 records in 0.077055692 seconds. Throughput is 1661.1362 records/second. Loss is 2.0046911. Sequentialb692dd65's hyper parameters: Current learning rate is 2.367984844896993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52608/60000][Iteration 3225][Wall Clock 305.868267983s] Trained 128 records in 0.083867376 seconds. Throughput is 1526.2191 records/second. Loss is 1.9792213. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3674242424242425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52736/60000][Iteration 3226][Wall Clock 305.95361562s] Trained 128 records in 0.085347637 seconds. Throughput is 1499.7487 records/second. Loss is 2.043637. Sequentialb692dd65's hyper parameters: Current learning rate is 2.366863905325444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52864/60000][Iteration 3227][Wall Clock 306.039594571s] Trained 128 records in 0.085978951 seconds. Throughput is 1488.7366 records/second. Loss is 2.0271623. Sequentialb692dd65's hyper parameters: Current learning rate is 2.36630383341221E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 52992/60000][Iteration 3228][Wall Clock 306.124276168s] Trained 128 records in 0.084681597 seconds. Throughput is 1511.5444 records/second. Loss is 2.0208929. Sequentialb692dd65's hyper parameters: Current learning rate is 2.365744026496333E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 53120/60000][Iteration 3229][Wall Clock 306.208748336s] Trained 128 records in 0.084472168 seconds. Throughput is 1515.2921 records/second. Loss is 2.0066578. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3651844843897827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:29 INFO  DistriOptimizer$:408 - [Epoch 7 53248/60000][Iteration 3230][Wall Clock 306.294992772s] Trained 128 records in 0.086244436 seconds. Throughput is 1484.1537 records/second. Loss is 2.0282989. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3646252069047056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 53376/60000][Iteration 3231][Wall Clock 306.380392047s] Trained 128 records in 0.085399275 seconds. Throughput is 1498.8417 records/second. Loss is 2.0136552. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3640661938534278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 53504/60000][Iteration 3232][Wall Clock 306.466935246s] Trained 128 records in 0.086543199 seconds. Throughput is 1479.03 records/second. Loss is 2.0271122. Sequentialb692dd65's hyper parameters: Current learning rate is 2.363507445048452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 53632/60000][Iteration 3233][Wall Clock 306.554029821s] Trained 128 records in 0.087094575 seconds. Throughput is 1469.6667 records/second. Loss is 2.0088248. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3629489603024575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 53760/60000][Iteration 3234][Wall Clock 306.642288193s] Trained 128 records in 0.088258372 seconds. Throughput is 1450.2874 records/second. Loss is 1.9986454. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3623907394283012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 53888/60000][Iteration 3235][Wall Clock 306.728252449s] Trained 128 records in 0.085964256 seconds. Throughput is 1488.991 records/second. Loss is 2.0146775. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3618327822390176E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54016/60000][Iteration 3236][Wall Clock 306.817372606s] Trained 128 records in 0.089120157 seconds. Throughput is 1436.2632 records/second. Loss is 1.9853144. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3612750885478162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54144/60000][Iteration 3237][Wall Clock 306.905177207s] Trained 128 records in 0.087804601 seconds. Throughput is 1457.7823 records/second. Loss is 2.0354548. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3607176581680827E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54272/60000][Iteration 3238][Wall Clock 307.015891571s] Trained 128 records in 0.110714364 seconds. Throughput is 1156.1283 records/second. Loss is 2.0095973. Sequentialb692dd65's hyper parameters: Current learning rate is 2.360160490913382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54400/60000][Iteration 3239][Wall Clock 307.095959686s] Trained 128 records in 0.080068115 seconds. Throughput is 1598.6389 records/second. Loss is 1.986725. Sequentialb692dd65's hyper parameters: Current learning rate is 2.359603586597452E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54528/60000][Iteration 3240][Wall Clock 307.177961406s] Trained 128 records in 0.08200172 seconds. Throughput is 1560.9427 records/second. Loss is 1.9756233. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3590469450342062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:30 INFO  DistriOptimizer$:408 - [Epoch 7 54656/60000][Iteration 3241][Wall Clock 307.263675266s] Trained 128 records in 0.08571386 seconds. Throughput is 1493.3407 records/second. Loss is 2.0051162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.358490566037736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 54784/60000][Iteration 3242][Wall Clock 307.349703868s] Trained 128 records in 0.086028602 seconds. Throughput is 1487.8772 records/second. Loss is 2.0339108. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3579344494223064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 54912/60000][Iteration 3243][Wall Clock 307.43714298s] Trained 128 records in 0.087439112 seconds. Throughput is 1463.8759 records/second. Loss is 2.0306728. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3573785950023574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55040/60000][Iteration 3244][Wall Clock 307.527415785s] Trained 128 records in 0.090272805 seconds. Throughput is 1417.9242 records/second. Loss is 2.0086877. Sequentialb692dd65's hyper parameters: Current learning rate is 2.356823002592505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55168/60000][Iteration 3245][Wall Clock 307.619829684s] Trained 128 records in 0.092413899 seconds. Throughput is 1385.073 records/second. Loss is 2.0409062. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3562676720075403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55296/60000][Iteration 3246][Wall Clock 307.709995268s] Trained 128 records in 0.090165584 seconds. Throughput is 1419.6104 records/second. Loss is 1.985888. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3557126030624264E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55424/60000][Iteration 3247][Wall Clock 307.810906872s] Trained 128 records in 0.100911604 seconds. Throughput is 1268.4369 records/second. Loss is 2.0075972. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3551577955723032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55552/60000][Iteration 3248][Wall Clock 307.89827939s] Trained 128 records in 0.087372518 seconds. Throughput is 1464.9916 records/second. Loss is 1.9981167. Sequentialb692dd65's hyper parameters: Current learning rate is 2.354603249352484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55680/60000][Iteration 3249][Wall Clock 308.009234979s] Trained 128 records in 0.110955589 seconds. Throughput is 1153.6147 records/second. Loss is 2.0225341. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3540489642184556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55808/60000][Iteration 3250][Wall Clock 308.101292868s] Trained 128 records in 0.092057889 seconds. Throughput is 1390.4294 records/second. Loss is 1.9959242. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3534949399858787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 55936/60000][Iteration 3251][Wall Clock 308.199157702s] Trained 128 records in 0.097864834 seconds. Throughput is 1307.9264 records/second. Loss is 2.0003254. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3529411764705883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:31 INFO  DistriOptimizer$:408 - [Epoch 7 56064/60000][Iteration 3252][Wall Clock 308.2851669s] Trained 128 records in 0.086009198 seconds. Throughput is 1488.2129 records/second. Loss is 2.020075. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3523876734885912E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56192/60000][Iteration 3253][Wall Clock 308.390418286s] Trained 128 records in 0.105251386 seconds. Throughput is 1216.136 records/second. Loss is 2.0305789. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3518344308560675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56320/60000][Iteration 3254][Wall Clock 308.478914423s] Trained 128 records in 0.088496137 seconds. Throughput is 1446.3909 records/second. Loss is 1.998635. Sequentialb692dd65's hyper parameters: Current learning rate is 2.351281448389372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56448/60000][Iteration 3255][Wall Clock 308.564424363s] Trained 128 records in 0.08550994 seconds. Throughput is 1496.902 records/second. Loss is 2.018232. Sequentialb692dd65's hyper parameters: Current learning rate is 2.350728725905031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56576/60000][Iteration 3256][Wall Clock 308.651290155s] Trained 128 records in 0.086865792 seconds. Throughput is 1473.5375 records/second. Loss is 2.0316877. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3501762632197415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56704/60000][Iteration 3257][Wall Clock 308.73499329s] Trained 128 records in 0.083703135 seconds. Throughput is 1529.2139 records/second. Loss is 2.0098445. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3496240601503758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56832/60000][Iteration 3258][Wall Clock 308.822980555s] Trained 128 records in 0.087987265 seconds. Throughput is 1454.756 records/second. Loss is 2.005497. Sequentialb692dd65's hyper parameters: Current learning rate is 2.349072116513977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 56960/60000][Iteration 3259][Wall Clock 308.908679872s] Trained 128 records in 0.085699317 seconds. Throughput is 1493.5941 records/second. Loss is 2.000703. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3485204321277596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 57088/60000][Iteration 3260][Wall Clock 308.993104786s] Trained 128 records in 0.084424914 seconds. Throughput is 1516.1401 records/second. Loss is 1.9953836. Sequentialb692dd65's hyper parameters: Current learning rate is 2.34796900680911E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 57216/60000][Iteration 3261][Wall Clock 309.080958995s] Trained 128 records in 0.087854209 seconds. Throughput is 1456.9592 records/second. Loss is 2.0163693. Sequentialb692dd65's hyper parameters: Current learning rate is 2.347417840375587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 57344/60000][Iteration 3262][Wall Clock 309.164682037s] Trained 128 records in 0.083723042 seconds. Throughput is 1528.8503 records/second. Loss is 1.9792022. Sequentialb692dd65's hyper parameters: Current learning rate is 2.346866932644919E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:32 INFO  DistriOptimizer$:408 - [Epoch 7 57472/60000][Iteration 3263][Wall Clock 309.258002716s] Trained 128 records in 0.093320679 seconds. Throughput is 1371.6145 records/second. Loss is 2.0378308. Sequentialb692dd65's hyper parameters: Current learning rate is 2.346316283435007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 57600/60000][Iteration 3264][Wall Clock 309.3414959s] Trained 128 records in 0.083493184 seconds. Throughput is 1533.0593 records/second. Loss is 2.010777. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3457658925639223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 57728/60000][Iteration 3265][Wall Clock 309.426211783s] Trained 128 records in 0.084715883 seconds. Throughput is 1510.9327 records/second. Loss is 2.0114288. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3452157598499062E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 57856/60000][Iteration 3266][Wall Clock 309.506541563s] Trained 128 records in 0.08032978 seconds. Throughput is 1593.4314 records/second. Loss is 2.0309572. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3446658851113714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 57984/60000][Iteration 3267][Wall Clock 309.591513498s] Trained 128 records in 0.084971935 seconds. Throughput is 1506.3798 records/second. Loss is 2.0248592. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3441162681669012E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58112/60000][Iteration 3268][Wall Clock 309.677105564s] Trained 128 records in 0.085592066 seconds. Throughput is 1495.4657 records/second. Loss is 2.02337. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3435669088352475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58240/60000][Iteration 3269][Wall Clock 309.760012959s] Trained 128 records in 0.082907395 seconds. Throughput is 1543.8912 records/second. Loss is 2.0340316. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3430178069353325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58368/60000][Iteration 3270][Wall Clock 309.847862825s] Trained 128 records in 0.087849866 seconds. Throughput is 1457.0312 records/second. Loss is 2.0747306. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3424689622862497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58496/60000][Iteration 3271][Wall Clock 309.931928111s] Trained 128 records in 0.084065286 seconds. Throughput is 1522.6261 records/second. Loss is 2.0138376. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3419203747072602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58624/60000][Iteration 3272][Wall Clock 310.01620202s] Trained 128 records in 0.084273909 seconds. Throughput is 1518.8567 records/second. Loss is 2.0218205. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3413720440177945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58752/60000][Iteration 3273][Wall Clock 310.100048989s] Trained 128 records in 0.083846969 seconds. Throughput is 1526.5906 records/second. Loss is 1.9904014. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3408239700374532E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 58880/60000][Iteration 3274][Wall Clock 310.192915975s] Trained 128 records in 0.092866986 seconds. Throughput is 1378.3154 records/second. Loss is 2.0152414. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3402761525860054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:33 INFO  DistriOptimizer$:408 - [Epoch 7 59008/60000][Iteration 3275][Wall Clock 310.274198471s] Trained 128 records in 0.081282496 seconds. Throughput is 1574.7548 records/second. Loss is 1.9729643. Sequentialb692dd65's hyper parameters: Current learning rate is 2.339728591483388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59136/60000][Iteration 3276][Wall Clock 310.353948558s] Trained 128 records in 0.079750087 seconds. Throughput is 1605.014 records/second. Loss is 2.0306845. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3391812865497074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59264/60000][Iteration 3277][Wall Clock 310.441137541s] Trained 128 records in 0.087188983 seconds. Throughput is 1468.0754 records/second. Loss is 1.9976091. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3386342376052386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59392/60000][Iteration 3278][Wall Clock 310.527890452s] Trained 128 records in 0.086752911 seconds. Throughput is 1475.4547 records/second. Loss is 1.968459. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3380874444704232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59520/60000][Iteration 3279][Wall Clock 310.617745337s] Trained 128 records in 0.089854885 seconds. Throughput is 1424.519 records/second. Loss is 2.0164602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3375409069658717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59648/60000][Iteration 3280][Wall Clock 310.703832141s] Trained 128 records in 0.086086804 seconds. Throughput is 1486.8713 records/second. Loss is 2.0165365. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3369946249123628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59776/60000][Iteration 3281][Wall Clock 310.789105372s] Trained 128 records in 0.085273231 seconds. Throughput is 1501.0573 records/second. Loss is 2.010886. Sequentialb692dd65's hyper parameters: Current learning rate is 2.336448598130841E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 59904/60000][Iteration 3282][Wall Clock 310.877473295s] Trained 128 records in 0.088367923 seconds. Throughput is 1448.4894 records/second. Loss is 1.9838829. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3359028264424196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:408 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 310.963229506s] Trained 128 records in 0.085756211 seconds. Throughput is 1492.6033 records/second. Loss is 2.001854. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3353573096683794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:34 INFO  DistriOptimizer$:452 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 310.963229506s] Epoch finished. Wall clock time is 312071.94123 ms
2019-10-15 07:51:34 INFO  DistriOptimizer$:111 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 310.963229506s] Validate model...
2019-10-15 07:51:35 INFO  DistriOptimizer$:178 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 310.963229506s] validate model throughput is 12387.047 records/second
2019-10-15 07:51:35 INFO  DistriOptimizer$:181 - [Epoch 7 60032/60000][Iteration 3283][Wall Clock 310.963229506s] Top1Accuracy is Accuracy(correct: 5848, count: 10000, accuracy: 0.5848)
2019-10-15 07:51:35 INFO  DistriOptimizer$:221 - [Wall Clock 312.07194123s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:51:35 INFO  DistriOptimizer$:226 - [Wall Clock 312.07194123s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:51:35 INFO  DistriOptimizer$:408 - [Epoch 8 128/60000][Iteration 3284][Wall Clock 312.162529497s] Trained 128 records in 0.090588267 seconds. Throughput is 1412.9866 records/second. Loss is 2.0241249. Sequentialb692dd65's hyper parameters: Current learning rate is 2.334812047630166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:35 INFO  DistriOptimizer$:408 - [Epoch 8 256/60000][Iteration 3285][Wall Clock 312.238778944s] Trained 128 records in 0.076249447 seconds. Throughput is 1678.7007 records/second. Loss is 1.9836969. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3342670401493927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:35 INFO  DistriOptimizer$:408 - [Epoch 8 384/60000][Iteration 3286][Wall Clock 312.329409606s] Trained 128 records in 0.090630662 seconds. Throughput is 1412.3256 records/second. Loss is 2.0496345. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3337222870478412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:35 INFO  DistriOptimizer$:408 - [Epoch 8 512/60000][Iteration 3287][Wall Clock 312.408030144s] Trained 128 records in 0.078620538 seconds. Throughput is 1628.0734 records/second. Loss is 2.0499456. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3331777881474572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:35 INFO  DistriOptimizer$:408 - [Epoch 8 640/60000][Iteration 3288][Wall Clock 312.489062978s] Trained 128 records in 0.081032834 seconds. Throughput is 1579.6066 records/second. Loss is 2.0063183. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3326335432703523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 768/60000][Iteration 3289][Wall Clock 312.565139415s] Trained 128 records in 0.076076437 seconds. Throughput is 1682.5183 records/second. Loss is 1.9699464. Sequentialb692dd65's hyper parameters: Current learning rate is 2.332089552238806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 896/60000][Iteration 3290][Wall Clock 312.645825926s] Trained 128 records in 0.080686511 seconds. Throughput is 1586.3866 records/second. Loss is 2.029812. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3315458148752625E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1024/60000][Iteration 3291][Wall Clock 312.730853563s] Trained 128 records in 0.085027637 seconds. Throughput is 1505.393 records/second. Loss is 2.0134132. Sequentialb692dd65's hyper parameters: Current learning rate is 2.331002331002331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1152/60000][Iteration 3292][Wall Clock 312.812801491s] Trained 128 records in 0.081947928 seconds. Throughput is 1561.9674 records/second. Loss is 2.0241647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.330459100442787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1280/60000][Iteration 3293][Wall Clock 312.895727131s] Trained 128 records in 0.08292564 seconds. Throughput is 1543.5515 records/second. Loss is 2.0099943. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3299161230195715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1408/60000][Iteration 3294][Wall Clock 312.979799898s] Trained 128 records in 0.084072767 seconds. Throughput is 1522.4906 records/second. Loss is 2.0377672. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3293733985557886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1536/60000][Iteration 3295][Wall Clock 313.067524991s] Trained 128 records in 0.087725093 seconds. Throughput is 1459.1035 records/second. Loss is 2.01854. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3288309268747087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1664/60000][Iteration 3296][Wall Clock 313.15320613s] Trained 128 records in 0.085681139 seconds. Throughput is 1493.911 records/second. Loss is 2.022149. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3282887077997672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1792/60000][Iteration 3297][Wall Clock 313.239515324s] Trained 128 records in 0.086309194 seconds. Throughput is 1483.0402 records/second. Loss is 1.9841905. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3277467411545624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 1920/60000][Iteration 3298][Wall Clock 313.327241782s] Trained 128 records in 0.087726458 seconds. Throughput is 1459.0809 records/second. Loss is 2.0167005. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3272050267628575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:36 INFO  DistriOptimizer$:408 - [Epoch 8 2048/60000][Iteration 3299][Wall Clock 313.42552557s] Trained 128 records in 0.098283788 seconds. Throughput is 1302.3511 records/second. Loss is 2.019825. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3266635644485808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2176/60000][Iteration 3300][Wall Clock 313.509478343s] Trained 128 records in 0.083952773 seconds. Throughput is 1524.6667 records/second. Loss is 2.010769. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3261223540358225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2304/60000][Iteration 3301][Wall Clock 313.598870545s] Trained 128 records in 0.089392202 seconds. Throughput is 1431.8922 records/second. Loss is 1.9798086. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3255813953488368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2432/60000][Iteration 3302][Wall Clock 313.686149463s] Trained 128 records in 0.087278918 seconds. Throughput is 1466.5626 records/second. Loss is 2.0758138. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3250406882120437E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2560/60000][Iteration 3303][Wall Clock 313.774104954s] Trained 128 records in 0.087955491 seconds. Throughput is 1455.2815 records/second. Loss is 2.0263016. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3245002324500234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2688/60000][Iteration 3304][Wall Clock 313.858743914s] Trained 128 records in 0.08463896 seconds. Throughput is 1512.3059 records/second. Loss is 1.9759307. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3239600278875203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2816/60000][Iteration 3305][Wall Clock 313.946425214s] Trained 128 records in 0.0876813 seconds. Throughput is 1459.8324 records/second. Loss is 1.9739374. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3234200743494423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 2944/60000][Iteration 3306][Wall Clock 314.030336852s] Trained 128 records in 0.083911638 seconds. Throughput is 1525.4142 records/second. Loss is 2.0165448. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3228803716608597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 3072/60000][Iteration 3307][Wall Clock 314.113189741s] Trained 128 records in 0.082852889 seconds. Throughput is 1544.9069 records/second. Loss is 2.0043998. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3223409196470042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 3200/60000][Iteration 3308][Wall Clock 314.197739295s] Trained 128 records in 0.084549554 seconds. Throughput is 1513.9052 records/second. Loss is 1.9979186. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3218017181332712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 3328/60000][Iteration 3309][Wall Clock 314.281211064s] Trained 128 records in 0.083471769 seconds. Throughput is 1533.4526 records/second. Loss is 2.0089843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3212627669452182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 3456/60000][Iteration 3310][Wall Clock 314.369500931s] Trained 128 records in 0.088289867 seconds. Throughput is 1449.77 records/second. Loss is 2.0078893. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3207240659085633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:37 INFO  DistriOptimizer$:408 - [Epoch 8 3584/60000][Iteration 3311][Wall Clock 314.462305207s] Trained 128 records in 0.092804276 seconds. Throughput is 1379.2468 records/second. Loss is 2.0004792. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3201856148491877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 3712/60000][Iteration 3312][Wall Clock 314.543766194s] Trained 128 records in 0.081460987 seconds. Throughput is 1571.3042 records/second. Loss is 2.0096989. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3196474135931338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 3840/60000][Iteration 3313][Wall Clock 314.662094072s] Trained 128 records in 0.118327878 seconds. Throughput is 1081.74 records/second. Loss is 2.028598. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3191094619666046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 3968/60000][Iteration 3314][Wall Clock 314.777920422s] Trained 128 records in 0.11582635 seconds. Throughput is 1105.1025 records/second. Loss is 2.014575. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3185717597959654E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4096/60000][Iteration 3315][Wall Clock 314.889338177s] Trained 128 records in 0.111417755 seconds. Throughput is 1148.8295 records/second. Loss is 2.0011225. Sequentialb692dd65's hyper parameters: Current learning rate is 2.318034306907742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4224/60000][Iteration 3316][Wall Clock 314.975845483s] Trained 128 records in 0.086507306 seconds. Throughput is 1479.6438 records/second. Loss is 2.018971. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3174971031286214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4352/60000][Iteration 3317][Wall Clock 315.059348638s] Trained 128 records in 0.083503155 seconds. Throughput is 1532.8762 records/second. Loss is 2.0017805. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3169601482854493E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4480/60000][Iteration 3318][Wall Clock 315.141263633s] Trained 128 records in 0.081914995 seconds. Throughput is 1562.5955 records/second. Loss is 2.0377402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.316423442205235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4608/60000][Iteration 3319][Wall Clock 315.224411491s] Trained 128 records in 0.083147858 seconds. Throughput is 1539.4263 records/second. Loss is 1.968857. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3158869847151461E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4736/60000][Iteration 3320][Wall Clock 315.310793387s] Trained 128 records in 0.086381896 seconds. Throughput is 1481.792 records/second. Loss is 2.027082. Sequentialb692dd65's hyper parameters: Current learning rate is 2.31535077564251E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4864/60000][Iteration 3321][Wall Clock 315.39621918s] Trained 128 records in 0.085425793 seconds. Throughput is 1498.3765 records/second. Loss is 2.0009136. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3148148148148146E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:38 INFO  DistriOptimizer$:408 - [Epoch 8 4992/60000][Iteration 3322][Wall Clock 315.478306027s] Trained 128 records in 0.082086847 seconds. Throughput is 1559.3241 records/second. Loss is 1.9725511. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3142791020597085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5120/60000][Iteration 3323][Wall Clock 315.562336945s] Trained 128 records in 0.084030918 seconds. Throughput is 1523.2489 records/second. Loss is 2.0450733. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3137436372049977E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5248/60000][Iteration 3324][Wall Clock 315.64421067s] Trained 128 records in 0.081873725 seconds. Throughput is 1563.3832 records/second. Loss is 2.0010128. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3132084200786488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5376/60000][Iteration 3325][Wall Clock 315.747710804s] Trained 128 records in 0.103500134 seconds. Throughput is 1236.7134 records/second. Loss is 2.0149124. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3126734505087883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5504/60000][Iteration 3326][Wall Clock 315.832476289s] Trained 128 records in 0.084765485 seconds. Throughput is 1510.0486 records/second. Loss is 2.009623. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3121387283236994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5632/60000][Iteration 3327][Wall Clock 315.919290356s] Trained 128 records in 0.086814067 seconds. Throughput is 1474.4154 records/second. Loss is 1.9980065. Sequentialb692dd65's hyper parameters: Current learning rate is 2.311604253351826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5760/60000][Iteration 3328][Wall Clock 316.004272074s] Trained 128 records in 0.084981718 seconds. Throughput is 1506.2063 records/second. Loss is 1.9957305. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3110700254217703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 5888/60000][Iteration 3329][Wall Clock 316.088299997s] Trained 128 records in 0.084027923 seconds. Throughput is 1523.3031 records/second. Loss is 2.036611. Sequentialb692dd65's hyper parameters: Current learning rate is 2.310536044362292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 6016/60000][Iteration 3330][Wall Clock 316.1729086s] Trained 128 records in 0.084608603 seconds. Throughput is 1512.8486 records/second. Loss is 1.9715941. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3100023100023096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 6144/60000][Iteration 3331][Wall Clock 316.257537173s] Trained 128 records in 0.084628573 seconds. Throughput is 1512.4915 records/second. Loss is 2.0176585. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3094688221709007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 6272/60000][Iteration 3332][Wall Clock 316.34302595s] Trained 128 records in 0.085488777 seconds. Throughput is 1497.2726 records/second. Loss is 1.989701. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3089355806972989E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:39 INFO  DistriOptimizer$:408 - [Epoch 8 6400/60000][Iteration 3333][Wall Clock 316.427174219s] Trained 128 records in 0.084148269 seconds. Throughput is 1521.1246 records/second. Loss is 2.03264. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3084025854108958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 6528/60000][Iteration 3334][Wall Clock 316.509754753s] Trained 128 records in 0.082580534 seconds. Throughput is 1550.0021 records/second. Loss is 2.0050955. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3078698361412415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 6656/60000][Iteration 3335][Wall Clock 316.593883341s] Trained 128 records in 0.084128588 seconds. Throughput is 1521.4805 records/second. Loss is 2.0013032. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3073373327180436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 6784/60000][Iteration 3336][Wall Clock 316.690278759s] Trained 128 records in 0.096395418 seconds. Throughput is 1327.8639 records/second. Loss is 2.0232522. Sequentialb692dd65's hyper parameters: Current learning rate is 2.306805074971165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 6912/60000][Iteration 3337][Wall Clock 316.771853946s] Trained 128 records in 0.081575187 seconds. Throughput is 1569.1046 records/second. Loss is 2.014402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3062730627306272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7040/60000][Iteration 3338][Wall Clock 316.858413253s] Trained 128 records in 0.086559307 seconds. Throughput is 1478.7549 records/second. Loss is 2.0343692. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3057412958266084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7168/60000][Iteration 3339][Wall Clock 316.941837633s] Trained 128 records in 0.08342438 seconds. Throughput is 1534.3236 records/second. Loss is 2.0215092. Sequentialb692dd65's hyper parameters: Current learning rate is 2.305209774089442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7296/60000][Iteration 3340][Wall Clock 317.027780429s] Trained 128 records in 0.085942796 seconds. Throughput is 1489.3628 records/second. Loss is 2.0501819. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3046784973496196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7424/60000][Iteration 3341][Wall Clock 317.112714276s] Trained 128 records in 0.084933847 seconds. Throughput is 1507.0553 records/second. Loss is 1.9907393. Sequentialb692dd65's hyper parameters: Current learning rate is 2.304147465437788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7552/60000][Iteration 3342][Wall Clock 317.197192605s] Trained 128 records in 0.084478329 seconds. Throughput is 1515.1815 records/second. Loss is 2.000464. Sequentialb692dd65's hyper parameters: Current learning rate is 2.30361667818475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7680/60000][Iteration 3343][Wall Clock 317.278736524s] Trained 128 records in 0.081543919 seconds. Throughput is 1569.7062 records/second. Loss is 2.004394. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3030861354214645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7808/60000][Iteration 3344][Wall Clock 317.362869845s] Trained 128 records in 0.084133321 seconds. Throughput is 1521.3949 records/second. Loss is 2.0300727. Sequentialb692dd65's hyper parameters: Current learning rate is 2.302555836979047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:40 INFO  DistriOptimizer$:408 - [Epoch 8 7936/60000][Iteration 3345][Wall Clock 317.447598497s] Trained 128 records in 0.084728652 seconds. Throughput is 1510.7051 records/second. Loss is 2.0000098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.3020257826887665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8064/60000][Iteration 3346][Wall Clock 317.533945232s] Trained 128 records in 0.086346735 seconds. Throughput is 1482.3953 records/second. Loss is 2.0269148. Sequentialb692dd65's hyper parameters: Current learning rate is 2.301495972382048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8192/60000][Iteration 3347][Wall Clock 317.618552678s] Trained 128 records in 0.084607446 seconds. Throughput is 1512.8693 records/second. Loss is 2.0109162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.300966405890474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8320/60000][Iteration 3348][Wall Clock 317.70316749s] Trained 128 records in 0.084614812 seconds. Throughput is 1512.7374 records/second. Loss is 2.029429. Sequentialb692dd65's hyper parameters: Current learning rate is 2.300437083045779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8448/60000][Iteration 3349][Wall Clock 317.789108717s] Trained 128 records in 0.085941227 seconds. Throughput is 1489.39 records/second. Loss is 2.0256498. Sequentialb692dd65's hyper parameters: Current learning rate is 2.299908003679853E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8576/60000][Iteration 3350][Wall Clock 317.874274011s] Trained 128 records in 0.085165294 seconds. Throughput is 1502.9597 records/second. Loss is 1.9768417. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2993791676247414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8704/60000][Iteration 3351][Wall Clock 317.971857339s] Trained 128 records in 0.097583328 seconds. Throughput is 1311.6995 records/second. Loss is 2.0225909. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2988505747126439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8832/60000][Iteration 3352][Wall Clock 318.054204107s] Trained 128 records in 0.082346768 seconds. Throughput is 1554.4022 records/second. Loss is 1.9944487. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2983222247759135E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 8960/60000][Iteration 3353][Wall Clock 318.134853722s] Trained 128 records in 0.080649615 seconds. Throughput is 1587.1123 records/second. Loss is 2.01039. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2977941176470588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 9088/60000][Iteration 3354][Wall Clock 318.220649692s] Trained 128 records in 0.08579597 seconds. Throughput is 1491.9116 records/second. Loss is 1.9753783. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2972662531587412E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 9216/60000][Iteration 3355][Wall Clock 318.305065068s] Trained 128 records in 0.084415376 seconds. Throughput is 1516.3114 records/second. Loss is 2.0365481. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2967386311437759E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:41 INFO  DistriOptimizer$:408 - [Epoch 8 9344/60000][Iteration 3356][Wall Clock 318.390083756s] Trained 128 records in 0.085018688 seconds. Throughput is 1505.5514 records/second. Loss is 2.0024033. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2962112514351318E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 9472/60000][Iteration 3357][Wall Clock 318.476896382s] Trained 128 records in 0.086812626 seconds. Throughput is 1474.44 records/second. Loss is 1.9874579. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2956841138659323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 9600/60000][Iteration 3358][Wall Clock 318.559709902s] Trained 128 records in 0.08281352 seconds. Throughput is 1545.6412 records/second. Loss is 1.9735123. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2951572182694513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 9728/60000][Iteration 3359][Wall Clock 318.6437328s] Trained 128 records in 0.084022898 seconds. Throughput is 1523.3943 records/second. Loss is 1.999881. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2946305644791186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 9856/60000][Iteration 3360][Wall Clock 318.729751899s] Trained 128 records in 0.086019099 seconds. Throughput is 1488.0416 records/second. Loss is 2.0105674. Sequentialb692dd65's hyper parameters: Current learning rate is 2.294104152328516E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 9984/60000][Iteration 3361][Wall Clock 318.810902973s] Trained 128 records in 0.081151074 seconds. Throughput is 1577.305 records/second. Loss is 2.0092704. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2935779816513765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10112/60000][Iteration 3362][Wall Clock 318.900872388s] Trained 128 records in 0.089969415 seconds. Throughput is 1422.7058 records/second. Loss is 1.9905964. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2930520522815865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10240/60000][Iteration 3363][Wall Clock 318.980626653s] Trained 128 records in 0.079754265 seconds. Throughput is 1604.9299 records/second. Loss is 1.9996432. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2925263640531865E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10368/60000][Iteration 3364][Wall Clock 319.063225625s] Trained 128 records in 0.082598972 seconds. Throughput is 1549.6561 records/second. Loss is 2.0366232. Sequentialb692dd65's hyper parameters: Current learning rate is 2.292000916800367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10496/60000][Iteration 3365][Wall Clock 319.146219519s] Trained 128 records in 0.082993894 seconds. Throughput is 1542.2821 records/second. Loss is 1.9975754. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2914757103574703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10624/60000][Iteration 3366][Wall Clock 319.230670583s] Trained 128 records in 0.084451064 seconds. Throughput is 1515.6707 records/second. Loss is 2.0213954. Sequentialb692dd65's hyper parameters: Current learning rate is 2.290950744558992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10752/60000][Iteration 3367][Wall Clock 319.31588011s] Trained 128 records in 0.085209527 seconds. Throughput is 1502.1794 records/second. Loss is 2.005011. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2904260192395788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:42 INFO  DistriOptimizer$:408 - [Epoch 8 10880/60000][Iteration 3368][Wall Clock 319.401585784s] Trained 128 records in 0.085705674 seconds. Throughput is 1493.4834 records/second. Loss is 1.9766273. Sequentialb692dd65's hyper parameters: Current learning rate is 2.289901534234028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11008/60000][Iteration 3369][Wall Clock 319.489076795s] Trained 128 records in 0.087491011 seconds. Throughput is 1463.0074 records/second. Loss is 2.0275388. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2893772893772894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11136/60000][Iteration 3370][Wall Clock 319.574620231s] Trained 128 records in 0.085543436 seconds. Throughput is 1496.3158 records/second. Loss is 1.9733708. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2888532845044635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11264/60000][Iteration 3371][Wall Clock 319.657961003s] Trained 128 records in 0.083340772 seconds. Throughput is 1535.8629 records/second. Loss is 1.9904364. Sequentialb692dd65's hyper parameters: Current learning rate is 2.288329519450801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11392/60000][Iteration 3372][Wall Clock 319.743340848s] Trained 128 records in 0.085379845 seconds. Throughput is 1499.1829 records/second. Loss is 1.9930866. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2878059940517042E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11520/60000][Iteration 3373][Wall Clock 319.82832346s] Trained 128 records in 0.084982612 seconds. Throughput is 1506.1904 records/second. Loss is 1.9951197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2872827081427266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11648/60000][Iteration 3374][Wall Clock 319.915093658s] Trained 128 records in 0.086770198 seconds. Throughput is 1475.1609 records/second. Loss is 2.0205336. Sequentialb692dd65's hyper parameters: Current learning rate is 2.28675966155957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11776/60000][Iteration 3375][Wall Clock 319.999707609s] Trained 128 records in 0.084613951 seconds. Throughput is 1512.7529 records/second. Loss is 2.0006528. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2862368541380884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 11904/60000][Iteration 3376][Wall Clock 320.094020428s] Trained 128 records in 0.094312819 seconds. Throughput is 1357.1857 records/second. Loss is 1.9967145. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2857142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 12032/60000][Iteration 3377][Wall Clock 320.175740608s] Trained 128 records in 0.08172018 seconds. Throughput is 1566.3206 records/second. Loss is 2.0265534. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2851919561243147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 12160/60000][Iteration 3378][Wall Clock 320.261189282s] Trained 128 records in 0.085448674 seconds. Throughput is 1497.9752 records/second. Loss is 1.9871053. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2846698652044777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 12288/60000][Iteration 3379][Wall Clock 320.337135229s] Trained 128 records in 0.075945947 seconds. Throughput is 1685.4093 records/second. Loss is 2.0169046. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2841480127912289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:43 INFO  DistriOptimizer$:408 - [Epoch 8 12416/60000][Iteration 3380][Wall Clock 320.420929718s] Trained 128 records in 0.083794489 seconds. Throughput is 1527.5468 records/second. Loss is 1.9933697. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2836263987211696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 12544/60000][Iteration 3381][Wall Clock 320.505265997s] Trained 128 records in 0.084336279 seconds. Throughput is 1517.7335 records/second. Loss is 1.9974648. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2831050228310504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 12672/60000][Iteration 3382][Wall Clock 320.588525717s] Trained 128 records in 0.08325972 seconds. Throughput is 1537.3582 records/second. Loss is 2.0031848. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2825838849577722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 12800/60000][Iteration 3383][Wall Clock 320.672306596s] Trained 128 records in 0.083780879 seconds. Throughput is 1527.7949 records/second. Loss is 1.9894348. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2820629849383846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 12928/60000][Iteration 3384][Wall Clock 320.756680079s] Trained 128 records in 0.084373483 seconds. Throughput is 1517.0643 records/second. Loss is 2.0130832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2815423226100844E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13056/60000][Iteration 3385][Wall Clock 320.840054063s] Trained 128 records in 0.083373984 seconds. Throughput is 1535.2511 records/second. Loss is 2.0231724. Sequentialb692dd65's hyper parameters: Current learning rate is 2.281021897810219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13184/60000][Iteration 3386][Wall Clock 320.927952809s] Trained 128 records in 0.087898746 seconds. Throughput is 1456.221 records/second. Loss is 1.9922415. Sequentialb692dd65's hyper parameters: Current learning rate is 2.280501710376283E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13312/60000][Iteration 3387][Wall Clock 321.021708851s] Trained 128 records in 0.093756042 seconds. Throughput is 1365.2454 records/second. Loss is 1.9749734. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2799817601459188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13440/60000][Iteration 3388][Wall Clock 321.107902252s] Trained 128 records in 0.086193401 seconds. Throughput is 1485.0326 records/second. Loss is 2.0181882. Sequentialb692dd65's hyper parameters: Current learning rate is 2.279462046956918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13568/60000][Iteration 3389][Wall Clock 321.191542399s] Trained 128 records in 0.083640147 seconds. Throughput is 1530.3656 records/second. Loss is 2.0623925. Sequentialb692dd65's hyper parameters: Current learning rate is 2.27894257064722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13696/60000][Iteration 3390][Wall Clock 321.277755248s] Trained 128 records in 0.086212849 seconds. Throughput is 1484.6974 records/second. Loss is 2.0010965. Sequentialb692dd65's hyper parameters: Current learning rate is 2.27842333105491E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13824/60000][Iteration 3391][Wall Clock 321.361333968s] Trained 128 records in 0.08357872 seconds. Throughput is 1531.4904 records/second. Loss is 2.0483973. Sequentialb692dd65's hyper parameters: Current learning rate is 2.277904328018223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:44 INFO  DistriOptimizer$:408 - [Epoch 8 13952/60000][Iteration 3392][Wall Clock 321.444816361s] Trained 128 records in 0.083482393 seconds. Throughput is 1533.2574 records/second. Loss is 2.0074098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.277385561375541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14080/60000][Iteration 3393][Wall Clock 321.528201111s] Trained 128 records in 0.08338475 seconds. Throughput is 1535.0529 records/second. Loss is 2.0090337. Sequentialb692dd65's hyper parameters: Current learning rate is 2.276867030965392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14208/60000][Iteration 3394][Wall Clock 321.610589305s] Trained 128 records in 0.082388194 seconds. Throughput is 1553.6207 records/second. Loss is 2.0110128. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2763487366264507E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14336/60000][Iteration 3395][Wall Clock 321.695700386s] Trained 128 records in 0.085111081 seconds. Throughput is 1503.917 records/second. Loss is 2.0075536. Sequentialb692dd65's hyper parameters: Current learning rate is 2.275830678197542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14464/60000][Iteration 3396][Wall Clock 321.778820277s] Trained 128 records in 0.083119891 seconds. Throughput is 1539.9442 records/second. Loss is 1.9646678. Sequentialb692dd65's hyper parameters: Current learning rate is 2.275312855517634E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14592/60000][Iteration 3397][Wall Clock 321.863838474s] Trained 128 records in 0.085018197 seconds. Throughput is 1505.56 records/second. Loss is 2.00254. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2747952684258417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14720/60000][Iteration 3398][Wall Clock 321.947530868s] Trained 128 records in 0.083692394 seconds. Throughput is 1529.4102 records/second. Loss is 2.0169196. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2742779167614282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14848/60000][Iteration 3399][Wall Clock 322.03573827s] Trained 128 records in 0.088207402 seconds. Throughput is 1451.1254 records/second. Loss is 2.0092103. Sequentialb692dd65's hyper parameters: Current learning rate is 2.273760800363802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 14976/60000][Iteration 3400][Wall Clock 322.123872996s] Trained 128 records in 0.088134726 seconds. Throughput is 1452.3219 records/second. Loss is 1.991813. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2732439190725165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 15104/60000][Iteration 3401][Wall Clock 322.210895858s] Trained 128 records in 0.087022862 seconds. Throughput is 1470.8778 records/second. Loss is 2.0376852. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2727272727272727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 15232/60000][Iteration 3402][Wall Clock 322.299078876s] Trained 128 records in 0.088183018 seconds. Throughput is 1451.5267 records/second. Loss is 2.01314. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2722108611679165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:45 INFO  DistriOptimizer$:408 - [Epoch 8 15360/60000][Iteration 3403][Wall Clock 322.398856797s] Trained 128 records in 0.099777921 seconds. Throughput is 1282.8489 records/second. Loss is 2.0378628. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2716946842344388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 15488/60000][Iteration 3404][Wall Clock 322.479323011s] Trained 128 records in 0.080466214 seconds. Throughput is 1590.7299 records/second. Loss is 1.9884107. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2711787417669768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 15616/60000][Iteration 3405][Wall Clock 322.556205039s] Trained 128 records in 0.076882028 seconds. Throughput is 1664.8884 records/second. Loss is 1.9968377. Sequentialb692dd65's hyper parameters: Current learning rate is 2.270663033605813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 15744/60000][Iteration 3406][Wall Clock 322.638692215s] Trained 128 records in 0.082487176 seconds. Throughput is 1551.7565 records/second. Loss is 2.012027. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2701475595913735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 15872/60000][Iteration 3407][Wall Clock 322.724662602s] Trained 128 records in 0.085970387 seconds. Throughput is 1488.8848 records/second. Loss is 2.0003264. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2696323195642304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16000/60000][Iteration 3408][Wall Clock 322.810513901s] Trained 128 records in 0.085851299 seconds. Throughput is 1490.9501 records/second. Loss is 2.0032341. Sequentialb692dd65's hyper parameters: Current learning rate is 2.269117313365101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16128/60000][Iteration 3409][Wall Clock 322.897128819s] Trained 128 records in 0.086614918 seconds. Throughput is 1477.8054 records/second. Loss is 1.9630357. Sequentialb692dd65's hyper parameters: Current learning rate is 2.268602540834846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16256/60000][Iteration 3410][Wall Clock 322.983395223s] Trained 128 records in 0.086266404 seconds. Throughput is 1483.7758 records/second. Loss is 1.9955035. Sequentialb692dd65's hyper parameters: Current learning rate is 2.26808800181447E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16384/60000][Iteration 3411][Wall Clock 323.066154058s] Trained 128 records in 0.082758835 seconds. Throughput is 1546.6626 records/second. Loss is 2.003664. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2675736961451246E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16512/60000][Iteration 3412][Wall Clock 323.15145248s] Trained 128 records in 0.085298422 seconds. Throughput is 1500.614 records/second. Loss is 2.0273192. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2670596236681027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16640/60000][Iteration 3413][Wall Clock 323.232226685s] Trained 128 records in 0.080774205 seconds. Throughput is 1584.6643 records/second. Loss is 2.0025759. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2665457842248413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16768/60000][Iteration 3414][Wall Clock 323.313366853s] Trained 128 records in 0.081140168 seconds. Throughput is 1577.5171 records/second. Loss is 2.0016508. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2660321776569228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:46 INFO  DistriOptimizer$:408 - [Epoch 8 16896/60000][Iteration 3415][Wall Clock 323.39809384s] Trained 128 records in 0.084726987 seconds. Throughput is 1510.7346 records/second. Loss is 1.9929037. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2655188038060717E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17024/60000][Iteration 3416][Wall Clock 323.483669358s] Trained 128 records in 0.085575518 seconds. Throughput is 1495.7549 records/second. Loss is 2.0168319. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2650056625141563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17152/60000][Iteration 3417][Wall Clock 323.574359265s] Trained 128 records in 0.090689907 seconds. Throughput is 1411.403 records/second. Loss is 1.9878623. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2644927536231882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17280/60000][Iteration 3418][Wall Clock 323.661376292s] Trained 128 records in 0.087017027 seconds. Throughput is 1470.9764 records/second. Loss is 1.9962095. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2639800769753228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17408/60000][Iteration 3419][Wall Clock 323.747826897s] Trained 128 records in 0.086450605 seconds. Throughput is 1480.6143 records/second. Loss is 2.0182378. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2634676324128565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17536/60000][Iteration 3420][Wall Clock 323.833186629s] Trained 128 records in 0.085359732 seconds. Throughput is 1499.5361 records/second. Loss is 2.0120974. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2629554197782303E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17664/60000][Iteration 3421][Wall Clock 323.917349813s] Trained 128 records in 0.084163184 seconds. Throughput is 1520.8551 records/second. Loss is 1.9403874. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2624434389140272E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17792/60000][Iteration 3422][Wall Clock 324.003181445s] Trained 128 records in 0.085831632 seconds. Throughput is 1491.2916 records/second. Loss is 1.98573. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2619316896629722E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 17920/60000][Iteration 3423][Wall Clock 324.087221361s] Trained 128 records in 0.084039916 seconds. Throughput is 1523.0857 records/second. Loss is 1.9923265. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2614201718679328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 18048/60000][Iteration 3424][Wall Clock 324.172088604s] Trained 128 records in 0.084867243 seconds. Throughput is 1508.2379 records/second. Loss is 1.9882438. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2609088853719196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 18176/60000][Iteration 3425][Wall Clock 324.255399487s] Trained 128 records in 0.083310883 seconds. Throughput is 1536.414 records/second. Loss is 1.9623784. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2603978300180834E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 18304/60000][Iteration 3426][Wall Clock 324.344100379s] Trained 128 records in 0.088700892 seconds. Throughput is 1443.052 records/second. Loss is 2.0225358. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2598870056497172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:47 INFO  DistriOptimizer$:408 - [Epoch 8 18432/60000][Iteration 3427][Wall Clock 324.429769822s] Trained 128 records in 0.085669443 seconds. Throughput is 1494.115 records/second. Loss is 1.9829402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2593764121102577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 18560/60000][Iteration 3428][Wall Clock 324.515999002s] Trained 128 records in 0.08622918 seconds. Throughput is 1484.4163 records/second. Loss is 1.9402213. Sequentialb692dd65's hyper parameters: Current learning rate is 2.25886604924328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 18688/60000][Iteration 3429][Wall Clock 324.609118019s] Trained 128 records in 0.093119017 seconds. Throughput is 1374.585 records/second. Loss is 2.0388389. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2583559168925024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 18816/60000][Iteration 3430][Wall Clock 324.692258014s] Trained 128 records in 0.083139995 seconds. Throughput is 1539.5719 records/second. Loss is 2.0085366. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2578460149017836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 18944/60000][Iteration 3431][Wall Clock 324.77109808s] Trained 128 records in 0.078840066 seconds. Throughput is 1623.5399 records/second. Loss is 2.0067832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2573363431151243E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19072/60000][Iteration 3432][Wall Clock 324.853709743s] Trained 128 records in 0.082611663 seconds. Throughput is 1549.418 records/second. Loss is 2.0278325. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2568269013766644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19200/60000][Iteration 3433][Wall Clock 324.937470967s] Trained 128 records in 0.083761224 seconds. Throughput is 1528.1534 records/second. Loss is 1.9991016. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2563176895306857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19328/60000][Iteration 3434][Wall Clock 325.020283571s] Trained 128 records in 0.082812604 seconds. Throughput is 1545.6583 records/second. Loss is 1.9341955. Sequentialb692dd65's hyper parameters: Current learning rate is 2.255808707421611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19456/60000][Iteration 3435][Wall Clock 325.105078266s] Trained 128 records in 0.084794695 seconds. Throughput is 1509.5284 records/second. Loss is 1.9978377. Sequentialb692dd65's hyper parameters: Current learning rate is 2.255299954894001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19584/60000][Iteration 3436][Wall Clock 325.194430776s] Trained 128 records in 0.08935251 seconds. Throughput is 1432.5283 records/second. Loss is 2.0174916. Sequentialb692dd65's hyper parameters: Current learning rate is 2.254791431792559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19712/60000][Iteration 3437][Wall Clock 325.283492346s] Trained 128 records in 0.08906157 seconds. Throughput is 1437.2079 records/second. Loss is 2.0194843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2542831379621282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:48 INFO  DistriOptimizer$:408 - [Epoch 8 19840/60000][Iteration 3438][Wall Clock 325.359890078s] Trained 128 records in 0.076397732 seconds. Throughput is 1675.4424 records/second. Loss is 2.0307713. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2537750732476897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 19968/60000][Iteration 3439][Wall Clock 325.438493435s] Trained 128 records in 0.078603357 seconds. Throughput is 1628.4292 records/second. Loss is 1.9967501. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2532672374943666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20096/60000][Iteration 3440][Wall Clock 325.521935122s] Trained 128 records in 0.083441687 seconds. Throughput is 1534.0054 records/second. Loss is 1.9839697. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2527596305474206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20224/60000][Iteration 3441][Wall Clock 325.608939753s] Trained 128 records in 0.087004631 seconds. Throughput is 1471.186 records/second. Loss is 2.0025408. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2522522522522526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20352/60000][Iteration 3442][Wall Clock 325.693543094s] Trained 128 records in 0.084603341 seconds. Throughput is 1512.9426 records/second. Loss is 1.9991261. Sequentialb692dd65's hyper parameters: Current learning rate is 2.251745102454402E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20480/60000][Iteration 3443][Wall Clock 325.779477702s] Trained 128 records in 0.085934608 seconds. Throughput is 1489.5046 records/second. Loss is 2.0023372. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2512381809995497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20608/60000][Iteration 3444][Wall Clock 325.866368344s] Trained 128 records in 0.086890642 seconds. Throughput is 1473.116 records/second. Loss is 1.9882474. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2507314877335136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20736/60000][Iteration 3445][Wall Clock 325.953717524s] Trained 128 records in 0.08734918 seconds. Throughput is 1465.383 records/second. Loss is 1.9670683. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2502250225022504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20864/60000][Iteration 3446][Wall Clock 326.03995188s] Trained 128 records in 0.086234356 seconds. Throughput is 1484.3273 records/second. Loss is 1.9744952. Sequentialb692dd65's hyper parameters: Current learning rate is 2.249718785151856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 20992/60000][Iteration 3447][Wall Clock 326.126529184s] Trained 128 records in 0.086577304 seconds. Throughput is 1478.4475 records/second. Loss is 2.008105. Sequentialb692dd65's hyper parameters: Current learning rate is 2.249212775528565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 21120/60000][Iteration 3448][Wall Clock 326.211684469s] Trained 128 records in 0.085155285 seconds. Throughput is 1503.1362 records/second. Loss is 2.0117648. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2487069934787497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 21248/60000][Iteration 3449][Wall Clock 326.299243043s] Trained 128 records in 0.087558574 seconds. Throughput is 1461.8785 records/second. Loss is 1.9847388. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2482014388489207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:49 INFO  DistriOptimizer$:408 - [Epoch 8 21376/60000][Iteration 3450][Wall Clock 326.384888623s] Trained 128 records in 0.08564558 seconds. Throughput is 1494.5314 records/second. Loss is 2.0088043. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2476961114857274E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 21504/60000][Iteration 3451][Wall Clock 326.471595765s] Trained 128 records in 0.086707142 seconds. Throughput is 1476.2336 records/second. Loss is 1.9824907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2471910112359551E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 21632/60000][Iteration 3452][Wall Clock 326.557774095s] Trained 128 records in 0.08617833 seconds. Throughput is 1485.2921 records/second. Loss is 2.0104227. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2466861379465288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 21760/60000][Iteration 3453][Wall Clock 326.645295819s] Trained 128 records in 0.087521724 seconds. Throughput is 1462.494 records/second. Loss is 1.9844837. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2461814914645105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 21888/60000][Iteration 3454][Wall Clock 326.730144732s] Trained 128 records in 0.084848913 seconds. Throughput is 1508.5638 records/second. Loss is 2.0411954. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2456770716370984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22016/60000][Iteration 3455][Wall Clock 326.827707882s] Trained 128 records in 0.09756315 seconds. Throughput is 1311.9708 records/second. Loss is 2.0153253. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2451728783116296E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22144/60000][Iteration 3456][Wall Clock 326.907206971s] Trained 128 records in 0.079499089 seconds. Throughput is 1610.0813 records/second. Loss is 2.014566. Sequentialb692dd65's hyper parameters: Current learning rate is 2.244668911335578E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22272/60000][Iteration 3457][Wall Clock 326.989064397s] Trained 128 records in 0.081857426 seconds. Throughput is 1563.6943 records/second. Loss is 1.9953538. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2441651705565533E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22400/60000][Iteration 3458][Wall Clock 327.071297074s] Trained 128 records in 0.082232677 seconds. Throughput is 1556.5588 records/second. Loss is 1.9869281. Sequentialb692dd65's hyper parameters: Current learning rate is 2.243661655822302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22528/60000][Iteration 3459][Wall Clock 327.155564209s] Trained 128 records in 0.084267135 seconds. Throughput is 1518.979 records/second. Loss is 2.0041158. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2431583669807088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22656/60000][Iteration 3460][Wall Clock 327.238385519s] Trained 128 records in 0.08282131 seconds. Throughput is 1545.496 records/second. Loss is 1.9850593. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2426553038797938E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22784/60000][Iteration 3461][Wall Clock 327.323522524s] Trained 128 records in 0.085137005 seconds. Throughput is 1503.4591 records/second. Loss is 1.9642869. Sequentialb692dd65's hyper parameters: Current learning rate is 2.242152466367713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:50 INFO  DistriOptimizer$:408 - [Epoch 8 22912/60000][Iteration 3462][Wall Clock 327.412444226s] Trained 128 records in 0.088921702 seconds. Throughput is 1439.4686 records/second. Loss is 1.9564918. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2416498542927594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23040/60000][Iteration 3463][Wall Clock 327.500144577s] Trained 128 records in 0.087700351 seconds. Throughput is 1459.5153 records/second. Loss is 1.9960715. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2411474675033618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23168/60000][Iteration 3464][Wall Clock 327.58421681s] Trained 128 records in 0.084072233 seconds. Throughput is 1522.5004 records/second. Loss is 1.9779427. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2406453058480843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23296/60000][Iteration 3465][Wall Clock 327.670506153s] Trained 128 records in 0.086289343 seconds. Throughput is 1483.3812 records/second. Loss is 2.0246716. Sequentialb692dd65's hyper parameters: Current learning rate is 2.240143369175627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23424/60000][Iteration 3466][Wall Clock 327.754344577s] Trained 128 records in 0.083838424 seconds. Throughput is 1526.7462 records/second. Loss is 2.006465. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2396416573348266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23552/60000][Iteration 3467][Wall Clock 327.839270888s] Trained 128 records in 0.084926311 seconds. Throughput is 1507.189 records/second. Loss is 2.0230305. Sequentialb692dd65's hyper parameters: Current learning rate is 2.239140170174653E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23680/60000][Iteration 3468][Wall Clock 327.923983443s] Trained 128 records in 0.084712555 seconds. Throughput is 1510.9921 records/second. Loss is 1.9946232. Sequentialb692dd65's hyper parameters: Current learning rate is 2.238638907544213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23808/60000][Iteration 3469][Wall Clock 328.011305403s] Trained 128 records in 0.08732196 seconds. Throughput is 1465.8397 records/second. Loss is 1.9825594. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2381378692927484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 23936/60000][Iteration 3470][Wall Clock 328.096457482s] Trained 128 records in 0.085152079 seconds. Throughput is 1503.1929 records/second. Loss is 2.0036378. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2376370552696357E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 24064/60000][Iteration 3471][Wall Clock 328.181790601s] Trained 128 records in 0.085333119 seconds. Throughput is 1500.0038 records/second. Loss is 1.9794818. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2371364653243846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 24192/60000][Iteration 3472][Wall Clock 328.267970949s] Trained 128 records in 0.086180348 seconds. Throughput is 1485.2573 records/second. Loss is 1.9726131. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2366360993066427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:51 INFO  DistriOptimizer$:408 - [Epoch 8 24320/60000][Iteration 3473][Wall Clock 328.351801868s] Trained 128 records in 0.083830919 seconds. Throughput is 1526.883 records/second. Loss is 2.000846. Sequentialb692dd65's hyper parameters: Current learning rate is 2.23613595706619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 24448/60000][Iteration 3474][Wall Clock 328.435938892s] Trained 128 records in 0.084137024 seconds. Throughput is 1521.3279 records/second. Loss is 1.991277. Sequentialb692dd65's hyper parameters: Current learning rate is 2.23563603845294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 24576/60000][Iteration 3475][Wall Clock 328.51873498s] Trained 128 records in 0.082796088 seconds. Throughput is 1545.9668 records/second. Loss is 2.0035715. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2351363433169424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 24704/60000][Iteration 3476][Wall Clock 328.605987135s] Trained 128 records in 0.087252155 seconds. Throughput is 1467.0125 records/second. Loss is 1.9953598. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2346368715083802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 24832/60000][Iteration 3477][Wall Clock 328.692408714s] Trained 128 records in 0.086421579 seconds. Throughput is 1481.1116 records/second. Loss is 1.9476438. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2341376228775692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 24960/60000][Iteration 3478][Wall Clock 328.777437626s] Trained 128 records in 0.085028912 seconds. Throughput is 1505.3704 records/second. Loss is 1.9847604. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2336385972749609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25088/60000][Iteration 3479][Wall Clock 328.861655225s] Trained 128 records in 0.084217599 seconds. Throughput is 1519.8723 records/second. Loss is 2.0029693. Sequentialb692dd65's hyper parameters: Current learning rate is 2.233139794551139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25216/60000][Iteration 3480][Wall Clock 328.956743088s] Trained 128 records in 0.095087863 seconds. Throughput is 1346.1234 records/second. Loss is 2.0307677. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2326412145568208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25344/60000][Iteration 3481][Wall Clock 329.040856587s] Trained 128 records in 0.084113499 seconds. Throughput is 1521.7533 records/second. Loss is 1.9920412. Sequentialb692dd65's hyper parameters: Current learning rate is 2.232142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25472/60000][Iteration 3482][Wall Clock 329.123774871s] Trained 128 records in 0.082918284 seconds. Throughput is 1543.6885 records/second. Loss is 2.0370169. Sequentialb692dd65's hyper parameters: Current learning rate is 2.231644722160232E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25600/60000][Iteration 3483][Wall Clock 329.205115343s] Trained 128 records in 0.081340472 seconds. Throughput is 1573.6324 records/second. Loss is 2.031093. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2311468094600624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25728/60000][Iteration 3484][Wall Clock 329.288108997s] Trained 128 records in 0.082993654 seconds. Throughput is 1542.2865 records/second. Loss is 1.9675364. Sequentialb692dd65's hyper parameters: Current learning rate is 2.230649118893598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:52 INFO  DistriOptimizer$:408 - [Epoch 8 25856/60000][Iteration 3485][Wall Clock 329.372623632s] Trained 128 records in 0.084514635 seconds. Throughput is 1514.5306 records/second. Loss is 2.0228386. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2301516503122213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 25984/60000][Iteration 3486][Wall Clock 329.461990123s] Trained 128 records in 0.089366491 seconds. Throughput is 1432.3042 records/second. Loss is 1.9624423. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2296544035674474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26112/60000][Iteration 3487][Wall Clock 329.549660727s] Trained 128 records in 0.087670604 seconds. Throughput is 1460.0105 records/second. Loss is 2.009804. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2291573785109225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26240/60000][Iteration 3488][Wall Clock 329.63666384s] Trained 128 records in 0.087003113 seconds. Throughput is 1471.2118 records/second. Loss is 1.9795331. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2286605749944285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26368/60000][Iteration 3489][Wall Clock 329.726849884s] Trained 128 records in 0.090186044 seconds. Throughput is 1419.2883 records/second. Loss is 1.9959728. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2281639928698754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26496/60000][Iteration 3490][Wall Clock 329.81658521s] Trained 128 records in 0.089735326 seconds. Throughput is 1426.417 records/second. Loss is 2.0117717. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2276676319893073E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26624/60000][Iteration 3491][Wall Clock 329.899217398s] Trained 128 records in 0.082632188 seconds. Throughput is 1549.0331 records/second. Loss is 1.9930857. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2271714922048998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26752/60000][Iteration 3492][Wall Clock 329.983915243s] Trained 128 records in 0.084697845 seconds. Throughput is 1511.2545 records/second. Loss is 2.0152414. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2266755733689602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 26880/60000][Iteration 3493][Wall Clock 330.068703099s] Trained 128 records in 0.084787856 seconds. Throughput is 1509.6503 records/second. Loss is 2.0062604. Sequentialb692dd65's hyper parameters: Current learning rate is 2.226179875333927E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 27008/60000][Iteration 3494][Wall Clock 330.154320475s] Trained 128 records in 0.085617376 seconds. Throughput is 1495.0236 records/second. Loss is 2.0000596. Sequentialb692dd65's hyper parameters: Current learning rate is 2.22568439795237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 27136/60000][Iteration 3495][Wall Clock 330.238227972s] Trained 128 records in 0.083907497 seconds. Throughput is 1525.4894 records/second. Loss is 1.9848429. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2251891410769918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:53 INFO  DistriOptimizer$:408 - [Epoch 8 27264/60000][Iteration 3496][Wall Clock 330.323335089s] Trained 128 records in 0.085107117 seconds. Throughput is 1503.987 records/second. Loss is 1.9831477. Sequentialb692dd65's hyper parameters: Current learning rate is 2.224694104560623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 27392/60000][Iteration 3497][Wall Clock 330.407398586s] Trained 128 records in 0.084063497 seconds. Throughput is 1522.6584 records/second. Loss is 1.9912112. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2241992882562276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 27520/60000][Iteration 3498][Wall Clock 330.490617388s] Trained 128 records in 0.083218802 seconds. Throughput is 1538.1139 records/second. Loss is 1.9721346. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2237046920169003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 27648/60000][Iteration 3499][Wall Clock 330.57532315s] Trained 128 records in 0.084705762 seconds. Throughput is 1511.1133 records/second. Loss is 2.007644. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2232103156958648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 27776/60000][Iteration 3500][Wall Clock 330.661829224s] Trained 128 records in 0.086506074 seconds. Throughput is 1479.6648 records/second. Loss is 1.963705. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2227161591464767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 27904/60000][Iteration 3501][Wall Clock 330.746909867s] Trained 128 records in 0.085080643 seconds. Throughput is 1504.455 records/second. Loss is 2.0011065. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2222222222222223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28032/60000][Iteration 3502][Wall Clock 330.83452418s] Trained 128 records in 0.087614313 seconds. Throughput is 1460.9485 records/second. Loss is 2.0039115. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2217285047767166E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28160/60000][Iteration 3503][Wall Clock 330.920044457s] Trained 128 records in 0.085520277 seconds. Throughput is 1496.7211 records/second. Loss is 1.9660201. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2212350066637046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28288/60000][Iteration 3504][Wall Clock 331.00508345s] Trained 128 records in 0.085038993 seconds. Throughput is 1505.1919 records/second. Loss is 2.0174923. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2207417277370642E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28416/60000][Iteration 3505][Wall Clock 331.093691905s] Trained 128 records in 0.088608455 seconds. Throughput is 1444.5574 records/second. Loss is 2.0094404. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2202486678507996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28544/60000][Iteration 3506][Wall Clock 331.191526138s] Trained 128 records in 0.097834233 seconds. Throughput is 1308.3356 records/second. Loss is 2.0019114. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2197558268590456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28672/60000][Iteration 3507][Wall Clock 331.272109726s] Trained 128 records in 0.080583588 seconds. Throughput is 1588.4128 records/second. Loss is 1.9783233. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2192632046160674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:54 INFO  DistriOptimizer$:408 - [Epoch 8 28800/60000][Iteration 3508][Wall Clock 331.35365411s] Trained 128 records in 0.081544384 seconds. Throughput is 1569.6973 records/second. Loss is 1.9588194. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2187708009762592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 28928/60000][Iteration 3509][Wall Clock 331.431624145s] Trained 128 records in 0.077970035 seconds. Throughput is 1641.6562 records/second. Loss is 2.0166142. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2182786157941438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29056/60000][Iteration 3510][Wall Clock 331.514094829s] Trained 128 records in 0.082470684 seconds. Throughput is 1552.0667 records/second. Loss is 2.0333047. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2177866489243733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29184/60000][Iteration 3511][Wall Clock 331.600701978s] Trained 128 records in 0.086607149 seconds. Throughput is 1477.938 records/second. Loss is 2.0161252. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2172949002217298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29312/60000][Iteration 3512][Wall Clock 331.685676763s] Trained 128 records in 0.084974785 seconds. Throughput is 1506.3291 records/second. Loss is 2.0280867. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2168033695411216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29440/60000][Iteration 3513][Wall Clock 331.771303223s] Trained 128 records in 0.08562646 seconds. Throughput is 1494.865 records/second. Loss is 1.9899862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2163120567375886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29568/60000][Iteration 3514][Wall Clock 331.864829766s] Trained 128 records in 0.093526543 seconds. Throughput is 1368.5955 records/second. Loss is 1.9869106. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2158209616662973E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29696/60000][Iteration 3515][Wall Clock 331.946346385s] Trained 128 records in 0.081516619 seconds. Throughput is 1570.232 records/second. Loss is 1.9957211. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2153300841825432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29824/60000][Iteration 3516][Wall Clock 332.031205903s] Trained 128 records in 0.084859518 seconds. Throughput is 1508.3752 records/second. Loss is 1.9863786. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2148394241417496E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 29952/60000][Iteration 3517][Wall Clock 332.116476608s] Trained 128 records in 0.085270705 seconds. Throughput is 1501.1017 records/second. Loss is 2.0128453. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2143489813994686E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 30080/60000][Iteration 3518][Wall Clock 332.20190416s] Trained 128 records in 0.085427552 seconds. Throughput is 1498.3456 records/second. Loss is 1.9822323. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2138587558113794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 30208/60000][Iteration 3519][Wall Clock 332.286162696s] Trained 128 records in 0.084258536 seconds. Throughput is 1519.1339 records/second. Loss is 1.974303. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2133687472332888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:55 INFO  DistriOptimizer$:408 - [Epoch 8 30336/60000][Iteration 3520][Wall Clock 332.37213726s] Trained 128 records in 0.085974564 seconds. Throughput is 1488.8124 records/second. Loss is 1.9752442. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2128789555211329E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 30464/60000][Iteration 3521][Wall Clock 332.458878832s] Trained 128 records in 0.086741572 seconds. Throughput is 1475.6477 records/second. Loss is 1.9995487. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2123893805309737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 30592/60000][Iteration 3522][Wall Clock 332.543646932s] Trained 128 records in 0.0847681 seconds. Throughput is 1510.002 records/second. Loss is 1.9848832. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2119000221190003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 30720/60000][Iteration 3523][Wall Clock 332.629210923s] Trained 128 records in 0.085563991 seconds. Throughput is 1495.9564 records/second. Loss is 1.9888903. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2114108801415302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 30848/60000][Iteration 3524][Wall Clock 332.716378151s] Trained 128 records in 0.087167228 seconds. Throughput is 1468.4418 records/second. Loss is 1.9503242. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2109219544550078E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 30976/60000][Iteration 3525][Wall Clock 332.80118023s] Trained 128 records in 0.084802079 seconds. Throughput is 1509.397 records/second. Loss is 1.9609323. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2104332449160037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31104/60000][Iteration 3526][Wall Clock 332.886548941s] Trained 128 records in 0.085368711 seconds. Throughput is 1499.3784 records/second. Loss is 2.0258396. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2099447513812155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31232/60000][Iteration 3527][Wall Clock 332.975348168s] Trained 128 records in 0.088799227 seconds. Throughput is 1441.4541 records/second. Loss is 1.9934988. Sequentialb692dd65's hyper parameters: Current learning rate is 2.209456473707468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31360/60000][Iteration 3528][Wall Clock 333.060537617s] Trained 128 records in 0.085189449 seconds. Throughput is 1502.5336 records/second. Loss is 1.9797009. Sequentialb692dd65's hyper parameters: Current learning rate is 2.208968411751712E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31488/60000][Iteration 3529][Wall Clock 333.146726337s] Trained 128 records in 0.08618872 seconds. Throughput is 1485.1132 records/second. Loss is 1.9587332. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2084805653710244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31616/60000][Iteration 3530][Wall Clock 333.232557147s] Trained 128 records in 0.08583081 seconds. Throughput is 1491.306 records/second. Loss is 2.0268028. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2079929344226098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:56 INFO  DistriOptimizer$:408 - [Epoch 8 31744/60000][Iteration 3531][Wall Clock 333.316848536s] Trained 128 records in 0.084291389 seconds. Throughput is 1518.5417 records/second. Loss is 1.9900161. Sequentialb692dd65's hyper parameters: Current learning rate is 2.207505518763797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 31872/60000][Iteration 3532][Wall Clock 333.417630231s] Trained 128 records in 0.100781695 seconds. Throughput is 1270.0719 records/second. Loss is 1.9984736. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2070183182520414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32000/60000][Iteration 3533][Wall Clock 333.499499408s] Trained 128 records in 0.081869177 seconds. Throughput is 1563.47 records/second. Loss is 2.0088959. Sequentialb692dd65's hyper parameters: Current learning rate is 2.206531332744925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32128/60000][Iteration 3534][Wall Clock 333.585749673s] Trained 128 records in 0.086250265 seconds. Throughput is 1484.0533 records/second. Loss is 2.0170238. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2060445621001546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32256/60000][Iteration 3535][Wall Clock 333.669557402s] Trained 128 records in 0.083807729 seconds. Throughput is 1527.3054 records/second. Loss is 2.0320587. Sequentialb692dd65's hyper parameters: Current learning rate is 2.205558006175562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32384/60000][Iteration 3536][Wall Clock 333.763903235s] Trained 128 records in 0.094345833 seconds. Throughput is 1356.7107 records/second. Loss is 2.0064197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.205071664829107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32512/60000][Iteration 3537][Wall Clock 333.85205429s] Trained 128 records in 0.088151055 seconds. Throughput is 1452.053 records/second. Loss is 2.0070515. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2045855379188714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32640/60000][Iteration 3538][Wall Clock 333.939449166s] Trained 128 records in 0.087394876 seconds. Throughput is 1464.6167 records/second. Loss is 1.9917493. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2040996253030638E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32768/60000][Iteration 3539][Wall Clock 334.026217978s] Trained 128 records in 0.086768812 seconds. Throughput is 1475.1844 records/second. Loss is 1.9910889. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2036139268400174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 32896/60000][Iteration 3540][Wall Clock 334.115089562s] Trained 128 records in 0.088871584 seconds. Throughput is 1440.2804 records/second. Loss is 2.007451. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2031284423881914E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 33024/60000][Iteration 3541][Wall Clock 334.199666761s] Trained 128 records in 0.084577199 seconds. Throughput is 1513.4103 records/second. Loss is 1.9757221. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2026431718061675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 33152/60000][Iteration 3542][Wall Clock 334.2829759s] Trained 128 records in 0.083309139 seconds. Throughput is 1536.4462 records/second. Loss is 1.9940938. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2021581149526536E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:57 INFO  DistriOptimizer$:408 - [Epoch 8 33280/60000][Iteration 3543][Wall Clock 334.369545941s] Trained 128 records in 0.086570041 seconds. Throughput is 1478.5715 records/second. Loss is 1.9434961. Sequentialb692dd65's hyper parameters: Current learning rate is 2.201673271686482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 33408/60000][Iteration 3544][Wall Clock 334.453739246s] Trained 128 records in 0.084193305 seconds. Throughput is 1520.3109 records/second. Loss is 1.9723808. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2011886418666079E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 33536/60000][Iteration 3545][Wall Clock 334.542538389s] Trained 128 records in 0.088799143 seconds. Throughput is 1441.4553 records/second. Loss is 2.0055602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2007042253521125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 33664/60000][Iteration 3546][Wall Clock 334.633614836s] Trained 128 records in 0.091076447 seconds. Throughput is 1405.4127 records/second. Loss is 1.9891791. Sequentialb692dd65's hyper parameters: Current learning rate is 2.2002200220022004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 33792/60000][Iteration 3547][Wall Clock 334.71864222s] Trained 128 records in 0.085027384 seconds. Throughput is 1505.3975 records/second. Loss is 1.9852209. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1997360316761987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 33920/60000][Iteration 3548][Wall Clock 334.805777029s] Trained 128 records in 0.087134809 seconds. Throughput is 1468.9882 records/second. Loss is 1.9414026. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1992522542335603E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34048/60000][Iteration 3549][Wall Clock 334.89271531s] Trained 128 records in 0.086938281 seconds. Throughput is 1472.3088 records/second. Loss is 1.928215. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1987686895338611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34176/60000][Iteration 3550][Wall Clock 334.978874465s] Trained 128 records in 0.086159155 seconds. Throughput is 1485.6228 records/second. Loss is 1.9947745. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1982853374367996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34304/60000][Iteration 3551][Wall Clock 335.06202965s] Trained 128 records in 0.083155185 seconds. Throughput is 1539.2906 records/second. Loss is 1.9860556. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1978021978021975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34432/60000][Iteration 3552][Wall Clock 335.149109393s] Trained 128 records in 0.087079743 seconds. Throughput is 1469.9171 records/second. Loss is 1.9948479. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1973192704900023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34560/60000][Iteration 3553][Wall Clock 335.234384201s] Trained 128 records in 0.085274808 seconds. Throughput is 1501.0294 records/second. Loss is 2.03098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1968365553602813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:58 INFO  DistriOptimizer$:408 - [Epoch 8 34688/60000][Iteration 3554][Wall Clock 335.323702384s] Trained 128 records in 0.089318183 seconds. Throughput is 1433.0789 records/second. Loss is 1.9942812. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1963540522732265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 34816/60000][Iteration 3555][Wall Clock 335.41109976s] Trained 128 records in 0.087397376 seconds. Throughput is 1464.575 records/second. Loss is 2.0111706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1958717610891522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 34944/60000][Iteration 3556][Wall Clock 335.498923572s] Trained 128 records in 0.087823812 seconds. Throughput is 1457.4634 records/second. Loss is 1.9814428. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1953896816684964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35072/60000][Iteration 3557][Wall Clock 335.587260074s] Trained 128 records in 0.088336502 seconds. Throughput is 1449.0045 records/second. Loss is 1.9920374. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1949078138718174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35200/60000][Iteration 3558][Wall Clock 335.688679081s] Trained 128 records in 0.101419007 seconds. Throughput is 1262.0908 records/second. Loss is 1.9913753. Sequentialb692dd65's hyper parameters: Current learning rate is 2.194426157559798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35328/60000][Iteration 3559][Wall Clock 335.770811232s] Trained 128 records in 0.082132151 seconds. Throughput is 1558.464 records/second. Loss is 1.9839816. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1939447125932427E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35456/60000][Iteration 3560][Wall Clock 335.85552315s] Trained 128 records in 0.084711918 seconds. Throughput is 1511.0034 records/second. Loss is 1.9920796. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1934634788330773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35584/60000][Iteration 3561][Wall Clock 335.940061113s] Trained 128 records in 0.084537963 seconds. Throughput is 1514.1127 records/second. Loss is 1.9926269. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1929824561403506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35712/60000][Iteration 3562][Wall Clock 336.027141097s] Trained 128 records in 0.087079984 seconds. Throughput is 1469.913 records/second. Loss is 2.014416. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1925016443762334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35840/60000][Iteration 3563][Wall Clock 336.114795568s] Trained 128 records in 0.087654471 seconds. Throughput is 1460.2792 records/second. Loss is 1.9872377. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1920210434020165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 35968/60000][Iteration 3564][Wall Clock 336.198689652s] Trained 128 records in 0.083894084 seconds. Throughput is 1525.7334 records/second. Loss is 1.9501693. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1915406530791145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:51:59 INFO  DistriOptimizer$:408 - [Epoch 8 36096/60000][Iteration 3565][Wall Clock 336.282946028s] Trained 128 records in 0.084256376 seconds. Throughput is 1519.1729 records/second. Loss is 2.003637. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1910604732690623E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36224/60000][Iteration 3566][Wall Clock 336.37388329s] Trained 128 records in 0.090937262 seconds. Throughput is 1407.5638 records/second. Loss is 1.9930354. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1905805038335163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36352/60000][Iteration 3567][Wall Clock 336.46102518s] Trained 128 records in 0.08714189 seconds. Throughput is 1468.8688 records/second. Loss is 2.0002363. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1901007446342529E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36480/60000][Iteration 3568][Wall Clock 336.551913273s] Trained 128 records in 0.090888093 seconds. Throughput is 1408.3253 records/second. Loss is 2.0208957. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1896211955331726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36608/60000][Iteration 3569][Wall Clock 336.637422204s] Trained 128 records in 0.085508931 seconds. Throughput is 1496.9197 records/second. Loss is 2.0273755. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1891418563922945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36736/60000][Iteration 3570][Wall Clock 336.722871551s] Trained 128 records in 0.085449347 seconds. Throughput is 1497.9635 records/second. Loss is 2.0103986. Sequentialb692dd65's hyper parameters: Current learning rate is 2.188662727073758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36864/60000][Iteration 3571][Wall Clock 336.810168892s] Trained 128 records in 0.087297341 seconds. Throughput is 1466.253 records/second. Loss is 2.0030663. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1881838074398248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 36992/60000][Iteration 3572][Wall Clock 336.900548641s] Trained 128 records in 0.090379749 seconds. Throughput is 1416.2465 records/second. Loss is 1.981308. Sequentialb692dd65's hyper parameters: Current learning rate is 2.187705097352877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 37120/60000][Iteration 3573][Wall Clock 336.987700089s] Trained 128 records in 0.087151448 seconds. Throughput is 1468.7078 records/second. Loss is 2.0080068. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1872265966754156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 37248/60000][Iteration 3574][Wall Clock 337.076870396s] Trained 128 records in 0.089170307 seconds. Throughput is 1435.4554 records/second. Loss is 2.0072906. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1867483052700633E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 37376/60000][Iteration 3575][Wall Clock 337.163798591s] Trained 128 records in 0.086928195 seconds. Throughput is 1472.4796 records/second. Loss is 2.0044577. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1862702229995628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 37504/60000][Iteration 3576][Wall Clock 337.248169309s] Trained 128 records in 0.084370718 seconds. Throughput is 1517.114 records/second. Loss is 1.975039. Sequentialb692dd65's hyper parameters: Current learning rate is 2.185792349726776E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:00 INFO  DistriOptimizer$:408 - [Epoch 8 37632/60000][Iteration 3577][Wall Clock 337.336414877s] Trained 128 records in 0.088245568 seconds. Throughput is 1450.4977 records/second. Loss is 1.9951907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.185314685314685E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 37760/60000][Iteration 3578][Wall Clock 337.423879445s] Trained 128 records in 0.087464568 seconds. Throughput is 1463.4497 records/second. Loss is 1.9856209. Sequentialb692dd65's hyper parameters: Current learning rate is 2.184837229626393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 37888/60000][Iteration 3579][Wall Clock 337.506945948s] Trained 128 records in 0.083066503 seconds. Throughput is 1540.9341 records/second. Loss is 2.0345438. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1843599825251202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38016/60000][Iteration 3580][Wall Clock 337.594532211s] Trained 128 records in 0.087586263 seconds. Throughput is 1461.4164 records/second. Loss is 1.9521748. Sequentialb692dd65's hyper parameters: Current learning rate is 2.183882943874208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38144/60000][Iteration 3581][Wall Clock 337.679511334s] Trained 128 records in 0.084979123 seconds. Throughput is 1506.2523 records/second. Loss is 2.0022905. Sequentialb692dd65's hyper parameters: Current learning rate is 2.183406113537118E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38272/60000][Iteration 3582][Wall Clock 337.766966076s] Trained 128 records in 0.087454742 seconds. Throughput is 1463.6141 records/second. Loss is 1.9857024. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1829294913774288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38400/60000][Iteration 3583][Wall Clock 337.863048409s] Trained 128 records in 0.096082333 seconds. Throughput is 1332.1908 records/second. Loss is 1.9528325. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1824530772588386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38528/60000][Iteration 3584][Wall Clock 337.946347736s] Trained 128 records in 0.083299327 seconds. Throughput is 1536.6271 records/second. Loss is 1.9810128. Sequentialb692dd65's hyper parameters: Current learning rate is 2.181976871045167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38656/60000][Iteration 3585][Wall Clock 338.023242964s] Trained 128 records in 0.076895228 seconds. Throughput is 1664.6027 records/second. Loss is 1.9852376. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1815008726003494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38784/60000][Iteration 3586][Wall Clock 338.107364858s] Trained 128 records in 0.084121894 seconds. Throughput is 1521.6016 records/second. Loss is 2.0264003. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1810250817884405E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 38912/60000][Iteration 3587][Wall Clock 338.189585165s] Trained 128 records in 0.082220307 seconds. Throughput is 1556.793 records/second. Loss is 2.008162. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1805494984736151E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:01 INFO  DistriOptimizer$:408 - [Epoch 8 39040/60000][Iteration 3588][Wall Clock 338.278880206s] Trained 128 records in 0.089295041 seconds. Throughput is 1433.4502 records/second. Loss is 2.024876. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1800741225201658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39168/60000][Iteration 3589][Wall Clock 338.368080443s] Trained 128 records in 0.089200237 seconds. Throughput is 1434.9738 records/second. Loss is 2.0051947. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1795989537925023E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39296/60000][Iteration 3590][Wall Clock 338.452353354s] Trained 128 records in 0.084272911 seconds. Throughput is 1518.8748 records/second. Loss is 2.0191617. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1791239921551534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39424/60000][Iteration 3591][Wall Clock 338.542455477s] Trained 128 records in 0.090102123 seconds. Throughput is 1420.6102 records/second. Loss is 1.9810767. Sequentialb692dd65's hyper parameters: Current learning rate is 2.178649237472767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39552/60000][Iteration 3592][Wall Clock 338.631388191s] Trained 128 records in 0.088932714 seconds. Throughput is 1439.2904 records/second. Loss is 1.9755371. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1781746896101068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39680/60000][Iteration 3593][Wall Clock 338.713843463s] Trained 128 records in 0.082455272 seconds. Throughput is 1552.3568 records/second. Loss is 1.99756. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1777003484320555E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39808/60000][Iteration 3594][Wall Clock 338.799818064s] Trained 128 records in 0.085974601 seconds. Throughput is 1488.8118 records/second. Loss is 1.9779267. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1772262138036142E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 39936/60000][Iteration 3595][Wall Clock 338.883824586s] Trained 128 records in 0.084006522 seconds. Throughput is 1523.6912 records/second. Loss is 2.0016448. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1767522855899003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 40064/60000][Iteration 3596][Wall Clock 338.968338619s] Trained 128 records in 0.084514033 seconds. Throughput is 1514.5415 records/second. Loss is 2.0114038. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1762785636561478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 40192/60000][Iteration 3597][Wall Clock 339.054332973s] Trained 128 records in 0.085994354 seconds. Throughput is 1488.4698 records/second. Loss is 2.0128555. Sequentialb692dd65's hyper parameters: Current learning rate is 2.175805047867711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 40320/60000][Iteration 3598][Wall Clock 339.140076357s] Trained 128 records in 0.085743384 seconds. Throughput is 1492.8265 records/second. Loss is 1.986886. Sequentialb692dd65's hyper parameters: Current learning rate is 2.175331738090059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 40448/60000][Iteration 3599][Wall Clock 339.222843829s] Trained 128 records in 0.082767472 seconds. Throughput is 1546.5012 records/second. Loss is 1.9970483. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1748586341887777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:02 INFO  DistriOptimizer$:408 - [Epoch 8 40576/60000][Iteration 3600][Wall Clock 339.308900271s] Trained 128 records in 0.086056442 seconds. Throughput is 1487.3959 records/second. Loss is 1.9985801. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1743857360295715E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 40704/60000][Iteration 3601][Wall Clock 339.391335936s] Trained 128 records in 0.082435665 seconds. Throughput is 1552.726 records/second. Loss is 2.005245. Sequentialb692dd65's hyper parameters: Current learning rate is 2.173913043478261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 40832/60000][Iteration 3602][Wall Clock 339.47284755s] Trained 128 records in 0.081511614 seconds. Throughput is 1570.3284 records/second. Loss is 1.9487386. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1734405564007825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 40960/60000][Iteration 3603][Wall Clock 339.559276305s] Trained 128 records in 0.086428755 seconds. Throughput is 1480.9886 records/second. Loss is 1.9827379. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1729682746631898E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41088/60000][Iteration 3604][Wall Clock 339.64463952s] Trained 128 records in 0.085363215 seconds. Throughput is 1499.4749 records/second. Loss is 1.9707277. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1724961981316534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41216/60000][Iteration 3605][Wall Clock 339.731418329s] Trained 128 records in 0.086778809 seconds. Throughput is 1475.0144 records/second. Loss is 1.9744468. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1720243266724586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41344/60000][Iteration 3606][Wall Clock 339.816311134s] Trained 128 records in 0.084892805 seconds. Throughput is 1507.7839 records/second. Loss is 2.0097218. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1715526601520085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41472/60000][Iteration 3607][Wall Clock 339.905484606s] Trained 128 records in 0.089173472 seconds. Throughput is 1435.4044 records/second. Loss is 1.9630706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1710811984368216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41600/60000][Iteration 3608][Wall Clock 339.991278903s] Trained 128 records in 0.085794297 seconds. Throughput is 1491.9406 records/second. Loss is 1.9550033. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1706099413935315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41728/60000][Iteration 3609][Wall Clock 340.089651069s] Trained 128 records in 0.098372166 seconds. Throughput is 1301.181 records/second. Loss is 1.9777657. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1701388888888888E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41856/60000][Iteration 3610][Wall Clock 340.175058346s] Trained 128 records in 0.085407277 seconds. Throughput is 1498.7013 records/second. Loss is 1.971856. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1696680407897592E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 41984/60000][Iteration 3611][Wall Clock 340.256171971s] Trained 128 records in 0.081113625 seconds. Throughput is 1578.0333 records/second. Loss is 1.9631816. Sequentialb692dd65's hyper parameters: Current learning rate is 2.169197396963124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:03 INFO  DistriOptimizer$:408 - [Epoch 8 42112/60000][Iteration 3612][Wall Clock 340.336050588s] Trained 128 records in 0.079878617 seconds. Throughput is 1602.4314 records/second. Loss is 1.9991144. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1687269572760786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42240/60000][Iteration 3613][Wall Clock 340.41945056s] Trained 128 records in 0.083399972 seconds. Throughput is 1534.7727 records/second. Loss is 1.9458606. Sequentialb692dd65's hyper parameters: Current learning rate is 2.168256721595837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42368/60000][Iteration 3614][Wall Clock 340.502565418s] Trained 128 records in 0.083114858 seconds. Throughput is 1540.0376 records/second. Loss is 2.013231. Sequentialb692dd65's hyper parameters: Current learning rate is 2.167786689789725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42496/60000][Iteration 3615][Wall Clock 340.587707858s] Trained 128 records in 0.08514244 seconds. Throughput is 1503.363 records/second. Loss is 2.0007133. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1673168617251845E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42624/60000][Iteration 3616][Wall Clock 340.670362391s] Trained 128 records in 0.082654533 seconds. Throughput is 1548.6144 records/second. Loss is 1.9923831. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1668472372697725E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42752/60000][Iteration 3617][Wall Clock 340.762121828s] Trained 128 records in 0.091759437 seconds. Throughput is 1394.9519 records/second. Loss is 1.9592073. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1663778162911613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 42880/60000][Iteration 3618][Wall Clock 340.843147334s] Trained 128 records in 0.081025506 seconds. Throughput is 1579.7495 records/second. Loss is 1.9982027. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1659085986571366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 43008/60000][Iteration 3619][Wall Clock 340.925831603s] Trained 128 records in 0.082684269 seconds. Throughput is 1548.0574 records/second. Loss is 2.0106437. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1654395842355997E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 43136/60000][Iteration 3620][Wall Clock 341.009206643s] Trained 128 records in 0.08337504 seconds. Throughput is 1535.2317 records/second. Loss is 1.9714676. Sequentialb692dd65's hyper parameters: Current learning rate is 2.164970772894566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 43264/60000][Iteration 3621][Wall Clock 341.093725038s] Trained 128 records in 0.084518395 seconds. Throughput is 1514.4633 records/second. Loss is 2.0259533. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1645021645021645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 43392/60000][Iteration 3622][Wall Clock 341.178264736s] Trained 128 records in 0.084539698 seconds. Throughput is 1514.0817 records/second. Loss is 1.9570287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1640337589266391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:04 INFO  DistriOptimizer$:408 - [Epoch 8 43520/60000][Iteration 3623][Wall Clock 341.261617828s] Trained 128 records in 0.083353092 seconds. Throughput is 1535.6359 records/second. Loss is 1.9895078. Sequentialb692dd65's hyper parameters: Current learning rate is 2.163565556036348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 43648/60000][Iteration 3624][Wall Clock 341.345387759s] Trained 128 records in 0.083769931 seconds. Throughput is 1527.9945 records/second. Loss is 1.942133. Sequentialb692dd65's hyper parameters: Current learning rate is 2.163097555699762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 43776/60000][Iteration 3625][Wall Clock 341.430618355s] Trained 128 records in 0.085230596 seconds. Throughput is 1501.8081 records/second. Loss is 1.9905406. Sequentialb692dd65's hyper parameters: Current learning rate is 2.162629757785467E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 43904/60000][Iteration 3626][Wall Clock 341.515631263s] Trained 128 records in 0.085012908 seconds. Throughput is 1505.6538 records/second. Loss is 1.9778647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1621621621621621E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44032/60000][Iteration 3627][Wall Clock 341.601453858s] Trained 128 records in 0.085822595 seconds. Throughput is 1491.4487 records/second. Loss is 1.9966711. Sequentialb692dd65's hyper parameters: Current learning rate is 2.16169476869866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44160/60000][Iteration 3628][Wall Clock 341.686371364s] Trained 128 records in 0.084917506 seconds. Throughput is 1507.3452 records/second. Loss is 1.9811815. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1612275772638857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44288/60000][Iteration 3629][Wall Clock 341.771259884s] Trained 128 records in 0.08488852 seconds. Throughput is 1507.86 records/second. Loss is 1.9578487. Sequentialb692dd65's hyper parameters: Current learning rate is 2.16076058772688E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44416/60000][Iteration 3630][Wall Clock 341.857406922s] Trained 128 records in 0.086147038 seconds. Throughput is 1485.8317 records/second. Loss is 1.9822636. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1602937999567944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44544/60000][Iteration 3631][Wall Clock 341.939854778s] Trained 128 records in 0.082447856 seconds. Throughput is 1552.4963 records/second. Loss is 1.9566851. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1598272138228941E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44672/60000][Iteration 3632][Wall Clock 342.021239257s] Trained 128 records in 0.081384479 seconds. Throughput is 1572.7815 records/second. Loss is 1.9395655. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1593608291945585E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44800/60000][Iteration 3633][Wall Clock 342.104426364s] Trained 128 records in 0.083187107 seconds. Throughput is 1538.7 records/second. Loss is 1.9566333. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1588946459412782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 44928/60000][Iteration 3634][Wall Clock 342.189011949s] Trained 128 records in 0.084585585 seconds. Throughput is 1513.2603 records/second. Loss is 1.9555212. Sequentialb692dd65's hyper parameters: Current learning rate is 2.158428663932657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:05 INFO  DistriOptimizer$:408 - [Epoch 8 45056/60000][Iteration 3635][Wall Clock 342.294785661s] Trained 128 records in 0.105773712 seconds. Throughput is 1210.1306 records/second. Loss is 2.000241. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1579628830384117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45184/60000][Iteration 3636][Wall Clock 342.373360577s] Trained 128 records in 0.078574916 seconds. Throughput is 1629.0186 records/second. Loss is 1.9439625. Sequentialb692dd65's hyper parameters: Current learning rate is 2.157497303128371E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45312/60000][Iteration 3637][Wall Clock 342.455016554s] Trained 128 records in 0.081655977 seconds. Throughput is 1567.5521 records/second. Loss is 1.977553. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1570319240724764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45440/60000][Iteration 3638][Wall Clock 342.537379389s] Trained 128 records in 0.082362835 seconds. Throughput is 1554.099 records/second. Loss is 1.9824251. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1565667457407804E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45568/60000][Iteration 3639][Wall Clock 342.62481669s] Trained 128 records in 0.087437301 seconds. Throughput is 1463.9061 records/second. Loss is 1.9335402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1561017680034498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45696/60000][Iteration 3640][Wall Clock 342.708864775s] Trained 128 records in 0.084048085 seconds. Throughput is 1522.9377 records/second. Loss is 1.9816049. Sequentialb692dd65's hyper parameters: Current learning rate is 2.155636990730761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45824/60000][Iteration 3641][Wall Clock 342.794674513s] Trained 128 records in 0.085809738 seconds. Throughput is 1491.6722 records/second. Loss is 1.9622413. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1551724137931031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 45952/60000][Iteration 3642][Wall Clock 342.878785585s] Trained 128 records in 0.084111072 seconds. Throughput is 1521.7972 records/second. Loss is 1.9776164. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1547080370609782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 46080/60000][Iteration 3643][Wall Clock 342.977217326s] Trained 128 records in 0.098431741 seconds. Throughput is 1300.3936 records/second. Loss is 1.9808456. Sequentialb692dd65's hyper parameters: Current learning rate is 2.154243860404998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 46208/60000][Iteration 3644][Wall Clock 343.05704655s] Trained 128 records in 0.079829224 seconds. Throughput is 1603.4229 records/second. Loss is 1.9691125. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1537798836958861E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 46336/60000][Iteration 3645][Wall Clock 343.141688583s] Trained 128 records in 0.084642033 seconds. Throughput is 1512.2511 records/second. Loss is 1.9895991. Sequentialb692dd65's hyper parameters: Current learning rate is 2.153316106804479E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 46464/60000][Iteration 3646][Wall Clock 343.224853054s] Trained 128 records in 0.083164471 seconds. Throughput is 1539.1189 records/second. Loss is 1.9802463. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1528525296017224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:06 INFO  DistriOptimizer$:408 - [Epoch 8 46592/60000][Iteration 3647][Wall Clock 343.308723708s] Trained 128 records in 0.083870654 seconds. Throughput is 1526.1595 records/second. Loss is 1.9485601. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1523891519586742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 46720/60000][Iteration 3648][Wall Clock 343.3952354s] Trained 128 records in 0.086511692 seconds. Throughput is 1479.5687 records/second. Loss is 1.9463903. Sequentialb692dd65's hyper parameters: Current learning rate is 2.151925973746503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 46848/60000][Iteration 3649][Wall Clock 343.479014803s] Trained 128 records in 0.083779403 seconds. Throughput is 1527.8218 records/second. Loss is 1.9630473. Sequentialb692dd65's hyper parameters: Current learning rate is 2.151462994836489E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 46976/60000][Iteration 3650][Wall Clock 343.563127575s] Trained 128 records in 0.084112772 seconds. Throughput is 1521.7665 records/second. Loss is 2.0003033. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1510002151000216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47104/60000][Iteration 3651][Wall Clock 343.649503947s] Trained 128 records in 0.086376372 seconds. Throughput is 1481.8868 records/second. Loss is 1.9925745. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1505376344086021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47232/60000][Iteration 3652][Wall Clock 343.733590699s] Trained 128 records in 0.084086752 seconds. Throughput is 1522.2374 records/second. Loss is 1.9821119. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1500752526338424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47360/60000][Iteration 3653][Wall Clock 343.820652526s] Trained 128 records in 0.087061827 seconds. Throughput is 1470.2195 records/second. Loss is 1.9678943. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1496130696474635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47488/60000][Iteration 3654][Wall Clock 343.907089637s] Trained 128 records in 0.086437111 seconds. Throughput is 1480.8453 records/second. Loss is 1.9764496. Sequentialb692dd65's hyper parameters: Current learning rate is 2.149151085321298E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47616/60000][Iteration 3655][Wall Clock 343.992545641s] Trained 128 records in 0.085456004 seconds. Throughput is 1497.8467 records/second. Loss is 2.0253246. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1486892995272884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47744/60000][Iteration 3656][Wall Clock 344.076461758s] Trained 128 records in 0.083916117 seconds. Throughput is 1525.3326 records/second. Loss is 2.001076. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1482277121374866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 47872/60000][Iteration 3657][Wall Clock 344.165265097s] Trained 128 records in 0.088803339 seconds. Throughput is 1441.3873 records/second. Loss is 1.9882174. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1477663230240547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:07 INFO  DistriOptimizer$:408 - [Epoch 8 48000/60000][Iteration 3658][Wall Clock 344.251927863s] Trained 128 records in 0.086662766 seconds. Throughput is 1476.9895 records/second. Loss is 1.9785651. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1473051320592657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48128/60000][Iteration 3659][Wall Clock 344.336118114s] Trained 128 records in 0.084190251 seconds. Throughput is 1520.3661 records/second. Loss is 1.9872279. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1468441391155006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48256/60000][Iteration 3660][Wall Clock 344.425805477s] Trained 128 records in 0.089687363 seconds. Throughput is 1427.1799 records/second. Loss is 1.9865688. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1463833440652497E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48384/60000][Iteration 3661][Wall Clock 344.518433212s] Trained 128 records in 0.092627735 seconds. Throughput is 1381.8755 records/second. Loss is 2.0024567. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1459227467811158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48512/60000][Iteration 3662][Wall Clock 344.601096345s] Trained 128 records in 0.082663133 seconds. Throughput is 1548.4532 records/second. Loss is 1.9730892. Sequentialb692dd65's hyper parameters: Current learning rate is 2.145462347135808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48640/60000][Iteration 3663][Wall Clock 344.684694208s] Trained 128 records in 0.083597863 seconds. Throughput is 1531.1396 records/second. Loss is 1.9823287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.145002145002145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48768/60000][Iteration 3664][Wall Clock 344.76631402s] Trained 128 records in 0.081619812 seconds. Throughput is 1568.2467 records/second. Loss is 1.9865351. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1445421402530558E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 48896/60000][Iteration 3665][Wall Clock 344.849831604s] Trained 128 records in 0.083517584 seconds. Throughput is 1532.6115 records/second. Loss is 1.9490994. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1440823327615783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 49024/60000][Iteration 3666][Wall Clock 344.933090482s] Trained 128 records in 0.083258878 seconds. Throughput is 1537.3737 records/second. Loss is 1.9655632. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1436227224008576E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 49152/60000][Iteration 3667][Wall Clock 345.016512137s] Trained 128 records in 0.083421655 seconds. Throughput is 1534.3738 records/second. Loss is 1.9891788. Sequentialb692dd65's hyper parameters: Current learning rate is 2.143163309044149E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 49280/60000][Iteration 3668][Wall Clock 345.105150086s] Trained 128 records in 0.088637949 seconds. Throughput is 1444.0768 records/second. Loss is 2.004323. Sequentialb692dd65's hyper parameters: Current learning rate is 2.142704092564817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 49408/60000][Iteration 3669][Wall Clock 345.183229419s] Trained 128 records in 0.078079333 seconds. Throughput is 1639.3583 records/second. Loss is 1.9867322. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1422450728363323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:08 INFO  DistriOptimizer$:408 - [Epoch 8 49536/60000][Iteration 3670][Wall Clock 345.265031206s] Trained 128 records in 0.081801787 seconds. Throughput is 1564.7579 records/second. Loss is 1.9813774. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1417862497322766E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 49664/60000][Iteration 3671][Wall Clock 345.351880047s] Trained 128 records in 0.086848841 seconds. Throughput is 1473.8251 records/second. Loss is 2.0105746. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1413276231263385E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 49792/60000][Iteration 3672][Wall Clock 345.437599627s] Trained 128 records in 0.08571958 seconds. Throughput is 1493.2411 records/second. Loss is 1.9923706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1408691928923143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 49920/60000][Iteration 3673][Wall Clock 345.522774294s] Trained 128 records in 0.085174667 seconds. Throughput is 1502.7943 records/second. Loss is 1.9845866. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1404109589041095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50048/60000][Iteration 3674][Wall Clock 345.610211935s] Trained 128 records in 0.087437641 seconds. Throughput is 1463.9004 records/second. Loss is 2.0014617. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1399529210357372E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50176/60000][Iteration 3675][Wall Clock 345.694491851s] Trained 128 records in 0.084279916 seconds. Throughput is 1518.7485 records/second. Loss is 2.0032356. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1394950791613182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50304/60000][Iteration 3676][Wall Clock 345.784801775s] Trained 128 records in 0.090309924 seconds. Throughput is 1417.3414 records/second. Loss is 2.0280926. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1390374331550798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50432/60000][Iteration 3677][Wall Clock 345.872239046s] Trained 128 records in 0.087437271 seconds. Throughput is 1463.9066 records/second. Loss is 2.0187073. Sequentialb692dd65's hyper parameters: Current learning rate is 2.13857998289136E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50560/60000][Iteration 3678][Wall Clock 345.956067314s] Trained 128 records in 0.083828268 seconds. Throughput is 1526.9312 records/second. Loss is 1.9970814. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1381227282446015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50688/60000][Iteration 3679][Wall Clock 346.039594265s] Trained 128 records in 0.083526951 seconds. Throughput is 1532.4395 records/second. Loss is 1.9616791. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1376656690893546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50816/60000][Iteration 3680][Wall Clock 346.122618183s] Trained 128 records in 0.083023918 seconds. Throughput is 1541.7244 records/second. Loss is 1.9857098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1372088053002778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 50944/60000][Iteration 3681][Wall Clock 346.204818183s] Trained 128 records in 0.0822 seconds. Throughput is 1557.1776 records/second. Loss is 2.010104. Sequentialb692dd65's hyper parameters: Current learning rate is 2.136752136752137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:09 INFO  DistriOptimizer$:408 - [Epoch 8 51072/60000][Iteration 3682][Wall Clock 346.290057931s] Trained 128 records in 0.085239748 seconds. Throughput is 1501.6469 records/second. Loss is 1.968401. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1362956633198035E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51200/60000][Iteration 3683][Wall Clock 346.377347781s] Trained 128 records in 0.08728985 seconds. Throughput is 1466.379 records/second. Loss is 1.9936713. Sequentialb692dd65's hyper parameters: Current learning rate is 2.135839384878257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51328/60000][Iteration 3684][Wall Clock 346.459522564s] Trained 128 records in 0.082174783 seconds. Throughput is 1557.6554 records/second. Loss is 2.0195029. Sequentialb692dd65's hyper parameters: Current learning rate is 2.135383301302584E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51456/60000][Iteration 3685][Wall Clock 346.543907973s] Trained 128 records in 0.084385409 seconds. Throughput is 1516.8499 records/second. Loss is 1.9663026. Sequentialb692dd65's hyper parameters: Current learning rate is 2.134927412467976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51584/60000][Iteration 3686][Wall Clock 346.634524796s] Trained 128 records in 0.090616823 seconds. Throughput is 1412.5413 records/second. Loss is 1.9900254. Sequentialb692dd65's hyper parameters: Current learning rate is 2.134471718249733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51712/60000][Iteration 3687][Wall Clock 346.711848839s] Trained 128 records in 0.077324043 seconds. Throughput is 1655.3713 records/second. Loss is 1.9989495. Sequentialb692dd65's hyper parameters: Current learning rate is 2.134016218523261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51840/60000][Iteration 3688][Wall Clock 346.786836586s] Trained 128 records in 0.074987747 seconds. Throughput is 1706.9456 records/second. Loss is 1.9592445. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1335609131640707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 51968/60000][Iteration 3689][Wall Clock 346.871308229s] Trained 128 records in 0.084471643 seconds. Throughput is 1515.3014 records/second. Loss is 1.9768084. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1331058020477813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 52096/60000][Iteration 3690][Wall Clock 346.957979729s] Trained 128 records in 0.0866715 seconds. Throughput is 1476.8407 records/second. Loss is 1.9562714. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1326508850501172E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 52224/60000][Iteration 3691][Wall Clock 347.041812275s] Trained 128 records in 0.083832546 seconds. Throughput is 1526.8533 records/second. Loss is 1.983921. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1321961620469085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 52352/60000][Iteration 3692][Wall Clock 347.129076295s] Trained 128 records in 0.08726402 seconds. Throughput is 1466.813 records/second. Loss is 2.0133462. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1317416329140904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:10 INFO  DistriOptimizer$:408 - [Epoch 8 52480/60000][Iteration 3693][Wall Clock 347.220046169s] Trained 128 records in 0.090969874 seconds. Throughput is 1407.0592 records/second. Loss is 1.9357972. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1312872975277067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 52608/60000][Iteration 3694][Wall Clock 347.323610796s] Trained 128 records in 0.103564627 seconds. Throughput is 1235.9432 records/second. Loss is 2.0364084. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1308331557639038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 52736/60000][Iteration 3695][Wall Clock 347.4315467s] Trained 128 records in 0.107935904 seconds. Throughput is 1185.8889 records/second. Loss is 1.980483. Sequentialb692dd65's hyper parameters: Current learning rate is 2.130379207498935E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 52864/60000][Iteration 3696][Wall Clock 347.529834316s] Trained 128 records in 0.098287616 seconds. Throughput is 1302.3003 records/second. Loss is 1.9473554. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1299254526091586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 52992/60000][Iteration 3697][Wall Clock 347.65066199s] Trained 128 records in 0.120827674 seconds. Throughput is 1059.36 records/second. Loss is 1.9814984. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1294718909710395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53120/60000][Iteration 3698][Wall Clock 347.7633463s] Trained 128 records in 0.11268431 seconds. Throughput is 1135.9167 records/second. Loss is 1.9918655. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1290185224611454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53248/60000][Iteration 3699][Wall Clock 347.871643762s] Trained 128 records in 0.108297462 seconds. Throughput is 1181.9298 records/second. Loss is 2.0141256. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1285653469561513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53376/60000][Iteration 3700][Wall Clock 347.96327935s] Trained 128 records in 0.091635588 seconds. Throughput is 1396.8373 records/second. Loss is 1.962561. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1281123643328368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53504/60000][Iteration 3701][Wall Clock 348.053666289s] Trained 128 records in 0.090386939 seconds. Throughput is 1416.1338 records/second. Loss is 1.9793903. Sequentialb692dd65's hyper parameters: Current learning rate is 2.127659574468085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53632/60000][Iteration 3702][Wall Clock 348.138774012s] Trained 128 records in 0.085107723 seconds. Throughput is 1503.9763 records/second. Loss is 1.977423. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1272069772388852E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:11 INFO  DistriOptimizer$:408 - [Epoch 8 53760/60000][Iteration 3703][Wall Clock 348.22293017s] Trained 128 records in 0.084156158 seconds. Throughput is 1520.982 records/second. Loss is 1.993851. Sequentialb692dd65's hyper parameters: Current learning rate is 2.126754572522331E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 53888/60000][Iteration 3704][Wall Clock 348.304126431s] Trained 128 records in 0.081196261 seconds. Throughput is 1576.4272 records/second. Loss is 2.018598. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1263023601956197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54016/60000][Iteration 3705][Wall Clock 348.386448485s] Trained 128 records in 0.082322054 seconds. Throughput is 1554.8689 records/second. Loss is 2.0079648. Sequentialb692dd65's hyper parameters: Current learning rate is 2.125850340136054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54144/60000][Iteration 3706][Wall Clock 348.472120093s] Trained 128 records in 0.085671608 seconds. Throughput is 1494.0771 records/second. Loss is 1.9603801. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1253985122210415E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54272/60000][Iteration 3707][Wall Clock 348.556454768s] Trained 128 records in 0.084334675 seconds. Throughput is 1517.7625 records/second. Loss is 1.9739529. Sequentialb692dd65's hyper parameters: Current learning rate is 2.124946876328092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54400/60000][Iteration 3708][Wall Clock 348.645849483s] Trained 128 records in 0.089394715 seconds. Throughput is 1431.8519 records/second. Loss is 1.9804801. Sequentialb692dd65's hyper parameters: Current learning rate is 2.12449543233482E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54528/60000][Iteration 3709][Wall Clock 348.731191791s] Trained 128 records in 0.085342308 seconds. Throughput is 1499.8422 records/second. Loss is 1.9736401. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1240441801189465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54656/60000][Iteration 3710][Wall Clock 348.816101254s] Trained 128 records in 0.084909463 seconds. Throughput is 1507.488 records/second. Loss is 1.9575078. Sequentialb692dd65's hyper parameters: Current learning rate is 2.123593119558293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54784/60000][Iteration 3711][Wall Clock 348.91069536s] Trained 128 records in 0.094594106 seconds. Throughput is 1353.1499 records/second. Loss is 2.0203736. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1231422505307856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 54912/60000][Iteration 3712][Wall Clock 349.016032197s] Trained 128 records in 0.105336837 seconds. Throughput is 1215.1494 records/second. Loss is 1.9843051. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1226915729144553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 55040/60000][Iteration 3713][Wall Clock 349.125280288s] Trained 128 records in 0.109248091 seconds. Throughput is 1171.6451 records/second. Loss is 2.0041385. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1222410865874366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:12 INFO  DistriOptimizer$:408 - [Epoch 8 55168/60000][Iteration 3714][Wall Clock 349.209355723s] Trained 128 records in 0.084075435 seconds. Throughput is 1522.4423 records/second. Loss is 2.0108445. Sequentialb692dd65's hyper parameters: Current learning rate is 2.121790791427965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55296/60000][Iteration 3715][Wall Clock 349.293230218s] Trained 128 records in 0.083874495 seconds. Throughput is 1526.0897 records/second. Loss is 1.9665338. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1213406873143826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55424/60000][Iteration 3716][Wall Clock 349.378078203s] Trained 128 records in 0.084847985 seconds. Throughput is 1508.5803 records/second. Loss is 1.9448477. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1208907741251327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55552/60000][Iteration 3717][Wall Clock 349.462984828s] Trained 128 records in 0.084906625 seconds. Throughput is 1507.5385 records/second. Loss is 1.964374. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1204410517387616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55680/60000][Iteration 3718][Wall Clock 349.549769434s] Trained 128 records in 0.086784606 seconds. Throughput is 1474.9159 records/second. Loss is 1.9881202. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1199915200339196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55808/60000][Iteration 3719][Wall Clock 349.639778542s] Trained 128 records in 0.090009108 seconds. Throughput is 1422.0782 records/second. Loss is 1.9036647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.11954217888936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 55936/60000][Iteration 3720][Wall Clock 349.726956868s] Trained 128 records in 0.087178326 seconds. Throughput is 1468.2549 records/second. Loss is 1.9894484. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1190930281839377E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56064/60000][Iteration 3721][Wall Clock 349.814977714s] Trained 128 records in 0.088020846 seconds. Throughput is 1454.2009 records/second. Loss is 1.9727018. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1186440677966098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56192/60000][Iteration 3722][Wall Clock 349.901428926s] Trained 128 records in 0.086451212 seconds. Throughput is 1480.6039 records/second. Loss is 2.002793. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1181952976064393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56320/60000][Iteration 3723][Wall Clock 349.985432706s] Trained 128 records in 0.08400378 seconds. Throughput is 1523.741 records/second. Loss is 1.9812868. Sequentialb692dd65's hyper parameters: Current learning rate is 2.117746717492588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56448/60000][Iteration 3724][Wall Clock 350.071295445s] Trained 128 records in 0.085862739 seconds. Throughput is 1490.7513 records/second. Loss is 2.0081847. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1172983273343214E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56576/60000][Iteration 3725][Wall Clock 350.159023627s] Trained 128 records in 0.087728182 seconds. Throughput is 1459.0522 records/second. Loss is 1.9591875. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1168501270110075E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:13 INFO  DistriOptimizer$:408 - [Epoch 8 56704/60000][Iteration 3726][Wall Clock 350.243544051s] Trained 128 records in 0.084520424 seconds. Throughput is 1514.4269 records/second. Loss is 1.993778. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1164021164021165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 56832/60000][Iteration 3727][Wall Clock 350.328622753s] Trained 128 records in 0.085078702 seconds. Throughput is 1504.4894 records/second. Loss is 1.9777724. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1159542953872197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 56960/60000][Iteration 3728][Wall Clock 350.413575554s] Trained 128 records in 0.084952801 seconds. Throughput is 1506.719 records/second. Loss is 1.9688171. Sequentialb692dd65's hyper parameters: Current learning rate is 2.115506663845991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57088/60000][Iteration 3729][Wall Clock 350.498247729s] Trained 128 records in 0.084672175 seconds. Throughput is 1511.7126 records/second. Loss is 1.9695354. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1150592216582066E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57216/60000][Iteration 3730][Wall Clock 350.584112288s] Trained 128 records in 0.085864559 seconds. Throughput is 1490.7198 records/second. Loss is 1.9753146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1146119687037428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57344/60000][Iteration 3731][Wall Clock 350.668001704s] Trained 128 records in 0.083889416 seconds. Throughput is 1525.8182 records/second. Loss is 1.9577334. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1141649048625792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57472/60000][Iteration 3732][Wall Clock 350.753074118s] Trained 128 records in 0.085072414 seconds. Throughput is 1504.6006 records/second. Loss is 1.9899001. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1137180300147962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57600/60000][Iteration 3733][Wall Clock 350.840868347s] Trained 128 records in 0.087794229 seconds. Throughput is 1457.9546 records/second. Loss is 1.9884076. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1132713440405747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57728/60000][Iteration 3734][Wall Clock 350.928480011s] Trained 128 records in 0.087611664 seconds. Throughput is 1460.9928 records/second. Loss is 1.981334. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1128248468201983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57856/60000][Iteration 3735][Wall Clock 351.01437486s] Trained 128 records in 0.085894849 seconds. Throughput is 1490.1942 records/second. Loss is 1.9719653. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1123785382340515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 57984/60000][Iteration 3736][Wall Clock 351.098467808s] Trained 128 records in 0.084092948 seconds. Throughput is 1522.1254 records/second. Loss is 1.9540346. Sequentialb692dd65's hyper parameters: Current learning rate is 2.111932418162619E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 58112/60000][Iteration 3737][Wall Clock 351.185186958s] Trained 128 records in 0.08671915 seconds. Throughput is 1476.0293 records/second. Loss is 1.9965723. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1114864864864863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:14 INFO  DistriOptimizer$:408 - [Epoch 8 58240/60000][Iteration 3738][Wall Clock 351.269069538s] Trained 128 records in 0.08388258 seconds. Throughput is 1525.9426 records/second. Loss is 1.9596936. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1110407430863416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 58368/60000][Iteration 3739][Wall Clock 351.356909649s] Trained 128 records in 0.087840111 seconds. Throughput is 1457.1931 records/second. Loss is 1.956813. Sequentialb692dd65's hyper parameters: Current learning rate is 2.110595187842972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 58496/60000][Iteration 3740][Wall Clock 351.441495847s] Trained 128 records in 0.084586198 seconds. Throughput is 1513.2493 records/second. Loss is 1.9191995. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1101498206372655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 58624/60000][Iteration 3741][Wall Clock 351.528416812s] Trained 128 records in 0.086920965 seconds. Throughput is 1472.6022 records/second. Loss is 1.9875466. Sequentialb692dd65's hyper parameters: Current learning rate is 2.109704641350211E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 58752/60000][Iteration 3742][Wall Clock 351.611221616s] Trained 128 records in 0.082804804 seconds. Throughput is 1545.804 records/second. Loss is 1.9458997. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1092596498628984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 58880/60000][Iteration 3743][Wall Clock 351.695140213s] Trained 128 records in 0.083918597 seconds. Throughput is 1525.2877 records/second. Loss is 1.9824413. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1088148460565162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59008/60000][Iteration 3744][Wall Clock 351.7794907s] Trained 128 records in 0.084350487 seconds. Throughput is 1517.4779 records/second. Loss is 1.9761323. Sequentialb692dd65's hyper parameters: Current learning rate is 2.108370229812355E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59136/60000][Iteration 3745][Wall Clock 351.866784049s] Trained 128 records in 0.087293349 seconds. Throughput is 1466.3202 records/second. Loss is 1.9597104. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1079258010118045E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59264/60000][Iteration 3746][Wall Clock 351.947504851s] Trained 128 records in 0.080720802 seconds. Throughput is 1585.7126 records/second. Loss is 2.0156515. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1074815595363542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59392/60000][Iteration 3747][Wall Clock 352.031413871s] Trained 128 records in 0.08390902 seconds. Throughput is 1525.4618 records/second. Loss is 1.9652654. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1070375052675936E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59520/60000][Iteration 3748][Wall Clock 352.116445955s] Trained 128 records in 0.085032084 seconds. Throughput is 1505.3142 records/second. Loss is 1.9544125. Sequentialb692dd65's hyper parameters: Current learning rate is 2.106593638087213E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:15 INFO  DistriOptimizer$:408 - [Epoch 8 59648/60000][Iteration 3749][Wall Clock 352.200273169s] Trained 128 records in 0.083827214 seconds. Throughput is 1526.9504 records/second. Loss is 1.9487908. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1061499578770007E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:16 INFO  DistriOptimizer$:408 - [Epoch 8 59776/60000][Iteration 3750][Wall Clock 352.285025825s] Trained 128 records in 0.084752656 seconds. Throughput is 1510.2771 records/second. Loss is 1.9616761. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1057064645188457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:16 INFO  DistriOptimizer$:408 - [Epoch 8 59904/60000][Iteration 3751][Wall Clock 352.369180267s] Trained 128 records in 0.084154442 seconds. Throughput is 1521.013 records/second. Loss is 1.9808437. Sequentialb692dd65's hyper parameters: Current learning rate is 2.105263157894737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:16 INFO  DistriOptimizer$:408 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.451488365s] Trained 128 records in 0.082308098 seconds. Throughput is 1555.1326 records/second. Loss is 1.9768575. Sequentialb692dd65's hyper parameters: Current learning rate is 2.104820037886761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:16 INFO  DistriOptimizer$:452 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.451488365s] Epoch finished. Wall clock time is 353570.489664 ms
2019-10-15 07:52:16 INFO  DistriOptimizer$:111 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.451488365s] Validate model...
2019-10-15 07:52:17 INFO  DistriOptimizer$:178 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.451488365s] validate model throughput is 12353.592 records/second
2019-10-15 07:52:17 INFO  DistriOptimizer$:181 - [Epoch 8 60032/60000][Iteration 3752][Wall Clock 352.451488365s] Top1Accuracy is Accuracy(correct: 6013, count: 10000, accuracy: 0.6013)
2019-10-15 07:52:17 INFO  DistriOptimizer$:221 - [Wall Clock 353.570489664s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:52:17 INFO  DistriOptimizer$:226 - [Wall Clock 353.570489664s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 128/60000][Iteration 3753][Wall Clock 353.663713455s] Trained 128 records in 0.093223791 seconds. Throughput is 1373.0402 records/second. Loss is 1.9794523. Sequentialb692dd65's hyper parameters: Current learning rate is 2.104377104377104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 256/60000][Iteration 3754][Wall Clock 353.747888997s] Trained 128 records in 0.084175542 seconds. Throughput is 1520.6317 records/second. Loss is 1.9937805. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1039343572480537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 384/60000][Iteration 3755][Wall Clock 353.831662107s] Trained 128 records in 0.08377311 seconds. Throughput is 1527.9366 records/second. Loss is 1.9603999. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1034917963819945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 512/60000][Iteration 3756][Wall Clock 353.930885029s] Trained 128 records in 0.099222922 seconds. Throughput is 1290.0245 records/second. Loss is 1.9952525. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1030494216614092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 640/60000][Iteration 3757][Wall Clock 354.01460214s] Trained 128 records in 0.083717111 seconds. Throughput is 1528.9587 records/second. Loss is 1.9993602. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1026072329688813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 768/60000][Iteration 3758][Wall Clock 354.098313514s] Trained 128 records in 0.083711374 seconds. Throughput is 1529.0635 records/second. Loss is 1.9597863. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1021652301870928E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 896/60000][Iteration 3759][Wall Clock 354.189612671s] Trained 128 records in 0.091299157 seconds. Throughput is 1401.9845 records/second. Loss is 1.9896139. Sequentialb692dd65's hyper parameters: Current learning rate is 2.101723413198823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 1024/60000][Iteration 3760][Wall Clock 354.278248539s] Trained 128 records in 0.088635868 seconds. Throughput is 1444.1106 records/second. Loss is 2.0155573. Sequentialb692dd65's hyper parameters: Current learning rate is 2.101281781886951E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 1152/60000][Iteration 3761][Wall Clock 354.364653518s] Trained 128 records in 0.086404979 seconds. Throughput is 1481.3961 records/second. Loss is 1.9895844. Sequentialb692dd65's hyper parameters: Current learning rate is 2.100840336134454E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:17 INFO  DistriOptimizer$:408 - [Epoch 9 1280/60000][Iteration 3762][Wall Clock 354.461659508s] Trained 128 records in 0.09700599 seconds. Throughput is 1319.5061 records/second. Loss is 1.9368691. Sequentialb692dd65's hyper parameters: Current learning rate is 2.1003990758244065E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 1408/60000][Iteration 3763][Wall Clock 354.543469819s] Trained 128 records in 0.081810311 seconds. Throughput is 1564.595 records/second. Loss is 1.977351. Sequentialb692dd65's hyper parameters: Current learning rate is 2.099958000839983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 1536/60000][Iteration 3764][Wall Clock 354.625783606s] Trained 128 records in 0.082313787 seconds. Throughput is 1555.0251 records/second. Loss is 1.9607556. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0995171110644553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 1664/60000][Iteration 3765][Wall Clock 354.707766077s] Trained 128 records in 0.081982471 seconds. Throughput is 1561.3093 records/second. Loss is 1.9984413. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0990764063811922E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 1792/60000][Iteration 3766][Wall Clock 354.791369605s] Trained 128 records in 0.083603528 seconds. Throughput is 1531.0358 records/second. Loss is 1.9998635. Sequentialb692dd65's hyper parameters: Current learning rate is 2.098635886673662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 1920/60000][Iteration 3767][Wall Clock 354.879599986s] Trained 128 records in 0.088230381 seconds. Throughput is 1450.7474 records/second. Loss is 1.9791582. Sequentialb692dd65's hyper parameters: Current learning rate is 2.09819555182543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2048/60000][Iteration 3768][Wall Clock 354.962713075s] Trained 128 records in 0.083113089 seconds. Throughput is 1540.0703 records/second. Loss is 1.9991468. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0977554017201597E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2176/60000][Iteration 3769][Wall Clock 355.056953665s] Trained 128 records in 0.09424059 seconds. Throughput is 1358.2258 records/second. Loss is 1.981797. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0973154362416104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2304/60000][Iteration 3770][Wall Clock 355.136663458s] Trained 128 records in 0.079709793 seconds. Throughput is 1605.8253 records/second. Loss is 1.9601239. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0968756552736424E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2432/60000][Iteration 3771][Wall Clock 355.218798018s] Trained 128 records in 0.08213456 seconds. Throughput is 1558.4183 records/second. Loss is 2.0029216. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0964360587002098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2560/60000][Iteration 3772][Wall Clock 355.301198967s] Trained 128 records in 0.082400949 seconds. Throughput is 1553.3802 records/second. Loss is 1.9897146. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0959966464053657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2688/60000][Iteration 3773][Wall Clock 355.387340708s] Trained 128 records in 0.086141741 seconds. Throughput is 1485.9231 records/second. Loss is 1.9893755. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0955574182732607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:18 INFO  DistriOptimizer$:408 - [Epoch 9 2816/60000][Iteration 3774][Wall Clock 355.473468745s] Trained 128 records in 0.086128037 seconds. Throughput is 1486.1595 records/second. Loss is 1.9574109. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0951183741881418E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 2944/60000][Iteration 3775][Wall Clock 355.557753118s] Trained 128 records in 0.084284373 seconds. Throughput is 1518.6682 records/second. Loss is 1.9429755. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0946795140343527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3072/60000][Iteration 3776][Wall Clock 355.642602456s] Trained 128 records in 0.084849338 seconds. Throughput is 1508.5563 records/second. Loss is 1.9768314. Sequentialb692dd65's hyper parameters: Current learning rate is 2.094240837696335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3200/60000][Iteration 3777][Wall Clock 355.728272514s] Trained 128 records in 0.085670058 seconds. Throughput is 1494.1042 records/second. Loss is 1.9615194. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0938023450586265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3328/60000][Iteration 3778][Wall Clock 355.814888808s] Trained 128 records in 0.086616294 seconds. Throughput is 1477.782 records/second. Loss is 1.9902959. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0933640360058613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3456/60000][Iteration 3779][Wall Clock 355.899693979s] Trained 128 records in 0.084805171 seconds. Throughput is 1509.3419 records/second. Loss is 1.9457101. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0929259104227708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3584/60000][Iteration 3780][Wall Clock 355.985928307s] Trained 128 records in 0.086234328 seconds. Throughput is 1484.3276 records/second. Loss is 1.96214. Sequentialb692dd65's hyper parameters: Current learning rate is 2.092487968194183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3712/60000][Iteration 3781][Wall Clock 356.073760859s] Trained 128 records in 0.087832552 seconds. Throughput is 1457.3184 records/second. Loss is 1.960468. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0920502092050208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3840/60000][Iteration 3782][Wall Clock 356.158302173s] Trained 128 records in 0.084541314 seconds. Throughput is 1514.0526 records/second. Loss is 1.9481647. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0916126333403052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 3968/60000][Iteration 3783][Wall Clock 356.244193906s] Trained 128 records in 0.085891733 seconds. Throughput is 1490.2482 records/second. Loss is 1.990842. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0911752404851526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 4096/60000][Iteration 3784][Wall Clock 356.330362695s] Trained 128 records in 0.086168789 seconds. Throughput is 1485.4567 records/second. Loss is 1.9643197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0907380305247754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:19 INFO  DistriOptimizer$:408 - [Epoch 9 4224/60000][Iteration 3785][Wall Clock 356.424339346s] Trained 128 records in 0.093976651 seconds. Throughput is 1362.0404 records/second. Loss is 1.9670894. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0903010033444813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4352/60000][Iteration 3786][Wall Clock 356.505540558s] Trained 128 records in 0.081201212 seconds. Throughput is 1576.3312 records/second. Loss is 1.9334383. Sequentialb692dd65's hyper parameters: Current learning rate is 2.089864158829676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4480/60000][Iteration 3787][Wall Clock 356.588882903s] Trained 128 records in 0.083342345 seconds. Throughput is 1535.834 records/second. Loss is 1.9488533. Sequentialb692dd65's hyper parameters: Current learning rate is 2.089427496865859E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4608/60000][Iteration 3788][Wall Clock 356.674147604s] Trained 128 records in 0.085264701 seconds. Throughput is 1501.2074 records/second. Loss is 1.9570254. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0889910173386257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4736/60000][Iteration 3789][Wall Clock 356.758794076s] Trained 128 records in 0.084646472 seconds. Throughput is 1512.1718 records/second. Loss is 1.9716239. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0885547201336674E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4864/60000][Iteration 3790][Wall Clock 356.840630026s] Trained 128 records in 0.08183595 seconds. Throughput is 1564.1049 records/second. Loss is 1.9933195. Sequentialb692dd65's hyper parameters: Current learning rate is 2.088118605136772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 4992/60000][Iteration 3791][Wall Clock 356.925392348s] Trained 128 records in 0.084762322 seconds. Throughput is 1510.105 records/second. Loss is 1.9454703. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0876826722338206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5120/60000][Iteration 3792][Wall Clock 357.009181028s] Trained 128 records in 0.08378868 seconds. Throughput is 1527.6527 records/second. Loss is 1.9587024. Sequentialb692dd65's hyper parameters: Current learning rate is 2.087246921310791E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5248/60000][Iteration 3793][Wall Clock 357.090196091s] Trained 128 records in 0.081015063 seconds. Throughput is 1579.953 records/second. Loss is 1.9962641. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0868113522537563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5376/60000][Iteration 3794][Wall Clock 357.174401605s] Trained 128 records in 0.084205514 seconds. Throughput is 1520.0905 records/second. Loss is 1.9799459. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0863759649488838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5504/60000][Iteration 3795][Wall Clock 357.259999101s] Trained 128 records in 0.085597496 seconds. Throughput is 1495.3708 records/second. Loss is 1.9445268. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0859407592824363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5632/60000][Iteration 3796][Wall Clock 357.344457077s] Trained 128 records in 0.084457976 seconds. Throughput is 1515.5466 records/second. Loss is 1.9591315. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0855057351407716E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:20 INFO  DistriOptimizer$:408 - [Epoch 9 5760/60000][Iteration 3797][Wall Clock 357.428591672s] Trained 128 records in 0.084134595 seconds. Throughput is 1521.3718 records/second. Loss is 1.9643584. Sequentialb692dd65's hyper parameters: Current learning rate is 2.085070892410342E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 5888/60000][Iteration 3798][Wall Clock 357.512932901s] Trained 128 records in 0.084341229 seconds. Throughput is 1517.6445 records/second. Loss is 1.9791156. Sequentialb692dd65's hyper parameters: Current learning rate is 2.084636230977694E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6016/60000][Iteration 3799][Wall Clock 357.593619973s] Trained 128 records in 0.080687072 seconds. Throughput is 1586.3756 records/second. Loss is 1.9683806. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0842017507294707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6144/60000][Iteration 3800][Wall Clock 357.676394018s] Trained 128 records in 0.082774045 seconds. Throughput is 1546.3785 records/second. Loss is 1.9418795. Sequentialb692dd65's hyper parameters: Current learning rate is 2.083767451552407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6272/60000][Iteration 3801][Wall Clock 357.761675628s] Trained 128 records in 0.08528161 seconds. Throughput is 1500.9098 records/second. Loss is 1.9736224. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0833333333333332E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6400/60000][Iteration 3802][Wall Clock 357.84876149s] Trained 128 records in 0.087085862 seconds. Throughput is 1469.8137 records/second. Loss is 1.9505914. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0828993959591752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6528/60000][Iteration 3803][Wall Clock 357.932674479s] Trained 128 records in 0.083912989 seconds. Throughput is 1525.3895 records/second. Loss is 1.9400688. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0824656393169514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6656/60000][Iteration 3804][Wall Clock 358.021959123s] Trained 128 records in 0.089284644 seconds. Throughput is 1433.6172 records/second. Loss is 2.0093706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0820320632937748E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6784/60000][Iteration 3805][Wall Clock 358.106357875s] Trained 128 records in 0.084398752 seconds. Throughput is 1516.6101 records/second. Loss is 1.9975432. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0815986677768527E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 6912/60000][Iteration 3806][Wall Clock 358.193475072s] Trained 128 records in 0.087117197 seconds. Throughput is 1469.2852 records/second. Loss is 1.9896731. Sequentialb692dd65's hyper parameters: Current learning rate is 2.081165452653486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 7040/60000][Iteration 3807][Wall Clock 358.282546145s] Trained 128 records in 0.089071073 seconds. Throughput is 1437.0547 records/second. Loss is 1.9847113. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0807324178110696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 7168/60000][Iteration 3808][Wall Clock 358.367414641s] Trained 128 records in 0.084868496 seconds. Throughput is 1508.2157 records/second. Loss is 1.9939891. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0802995631370917E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:21 INFO  DistriOptimizer$:408 - [Epoch 9 7296/60000][Iteration 3809][Wall Clock 358.451493068s] Trained 128 records in 0.084078427 seconds. Throughput is 1522.3882 records/second. Loss is 1.9626629. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0798668885191348E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 7424/60000][Iteration 3810][Wall Clock 358.542408447s] Trained 128 records in 0.090915379 seconds. Throughput is 1407.9026 records/second. Loss is 2.0015345. Sequentialb692dd65's hyper parameters: Current learning rate is 2.079434393844874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 7552/60000][Iteration 3811][Wall Clock 358.625891284s] Trained 128 records in 0.083482837 seconds. Throughput is 1533.2493 records/second. Loss is 1.9934931. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0790020790020788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 7680/60000][Iteration 3812][Wall Clock 358.704875224s] Trained 128 records in 0.07898394 seconds. Throughput is 1620.5826 records/second. Loss is 1.9474859. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0785699438786117E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 7808/60000][Iteration 3813][Wall Clock 358.7821248s] Trained 128 records in 0.077249576 seconds. Throughput is 1656.9669 records/second. Loss is 1.9503332. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0781379883624273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 7936/60000][Iteration 3814][Wall Clock 358.866428759s] Trained 128 records in 0.084303959 seconds. Throughput is 1518.3154 records/second. Loss is 1.9811995. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0777062123415746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8064/60000][Iteration 3815][Wall Clock 358.952001447s] Trained 128 records in 0.085572688 seconds. Throughput is 1495.8043 records/second. Loss is 1.9904237. Sequentialb692dd65's hyper parameters: Current learning rate is 2.077274615704196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8192/60000][Iteration 3816][Wall Clock 359.036578232s] Trained 128 records in 0.084576785 seconds. Throughput is 1513.4176 records/second. Loss is 1.9343438. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0768431983385257E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8320/60000][Iteration 3817][Wall Clock 359.121200183s] Trained 128 records in 0.084621951 seconds. Throughput is 1512.6099 records/second. Loss is 1.9790707. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0764119601328901E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8448/60000][Iteration 3818][Wall Clock 359.207258437s] Trained 128 records in 0.086058254 seconds. Throughput is 1487.3646 records/second. Loss is 1.9420152. Sequentialb692dd65's hyper parameters: Current learning rate is 2.075980900975711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8576/60000][Iteration 3819][Wall Clock 359.292412692s] Trained 128 records in 0.085154255 seconds. Throughput is 1503.1544 records/second. Loss is 2.003252. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0755500207555005E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:22 INFO  DistriOptimizer$:408 - [Epoch 9 8704/60000][Iteration 3820][Wall Clock 359.377049639s] Trained 128 records in 0.084636947 seconds. Throughput is 1512.3418 records/second. Loss is 1.997629. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0751193193608634E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 8832/60000][Iteration 3821][Wall Clock 359.472001984s] Trained 128 records in 0.094952345 seconds. Throughput is 1348.0447 records/second. Loss is 1.9256994. Sequentialb692dd65's hyper parameters: Current learning rate is 2.074688796680498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 8960/60000][Iteration 3822][Wall Clock 359.583174531s] Trained 128 records in 0.111172547 seconds. Throughput is 1151.3634 records/second. Loss is 1.9844834. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0742584526031946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9088/60000][Iteration 3823][Wall Clock 359.684267634s] Trained 128 records in 0.101093103 seconds. Throughput is 1266.1595 records/second. Loss is 1.9448586. Sequentialb692dd65's hyper parameters: Current learning rate is 2.073828287017835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9216/60000][Iteration 3824][Wall Clock 359.802302326s] Trained 128 records in 0.118034692 seconds. Throughput is 1084.427 records/second. Loss is 1.9476532. Sequentialb692dd65's hyper parameters: Current learning rate is 2.073398299813394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9344/60000][Iteration 3825][Wall Clock 359.887616832s] Trained 128 records in 0.085314506 seconds. Throughput is 1500.331 records/second. Loss is 1.9786927. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0729684908789387E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9472/60000][Iteration 3826][Wall Clock 359.976918802s] Trained 128 records in 0.08930197 seconds. Throughput is 1433.339 records/second. Loss is 1.9737432. Sequentialb692dd65's hyper parameters: Current learning rate is 2.072538860103627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9600/60000][Iteration 3827][Wall Clock 360.065800572s] Trained 128 records in 0.08888177 seconds. Throughput is 1440.1154 records/second. Loss is 1.9978915. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0721094073767094E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9728/60000][Iteration 3828][Wall Clock 360.157099528s] Trained 128 records in 0.091298956 seconds. Throughput is 1401.9875 records/second. Loss is 1.9962902. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0716801325875285E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9856/60000][Iteration 3829][Wall Clock 360.241132216s] Trained 128 records in 0.084032688 seconds. Throughput is 1523.2168 records/second. Loss is 2.0003824. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0712510356255177E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 9984/60000][Iteration 3830][Wall Clock 360.326987359s] Trained 128 records in 0.085855143 seconds. Throughput is 1490.8833 records/second. Loss is 1.9715579. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0708221163802027E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:23 INFO  DistriOptimizer$:408 - [Epoch 9 10112/60000][Iteration 3831][Wall Clock 360.412447551s] Trained 128 records in 0.085460192 seconds. Throughput is 1497.7733 records/second. Loss is 1.9441471. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0703933747412008E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10240/60000][Iteration 3832][Wall Clock 360.501509595s] Trained 128 records in 0.089062044 seconds. Throughput is 1437.2003 records/second. Loss is 1.9869922. Sequentialb692dd65's hyper parameters: Current learning rate is 2.06996481059822E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10368/60000][Iteration 3833][Wall Clock 360.592502217s] Trained 128 records in 0.090992622 seconds. Throughput is 1406.7074 records/second. Loss is 1.9771192. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0695364238410593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10496/60000][Iteration 3834][Wall Clock 360.677754056s] Trained 128 records in 0.085251839 seconds. Throughput is 1501.434 records/second. Loss is 1.9386512. Sequentialb692dd65's hyper parameters: Current learning rate is 2.069108214359611E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10624/60000][Iteration 3835][Wall Clock 360.76384231s] Trained 128 records in 0.086088254 seconds. Throughput is 1486.8463 records/second. Loss is 1.9518776. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0686801820438562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10752/60000][Iteration 3836][Wall Clock 360.845165486s] Trained 128 records in 0.081323176 seconds. Throughput is 1573.967 records/second. Loss is 1.973346. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0682523267838676E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 10880/60000][Iteration 3837][Wall Clock 360.922564287s] Trained 128 records in 0.077398801 seconds. Throughput is 1653.7725 records/second. Loss is 1.9692514. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0678246484698098E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11008/60000][Iteration 3838][Wall Clock 361.007905521s] Trained 128 records in 0.085341234 seconds. Throughput is 1499.8611 records/second. Loss is 1.9857179. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0673971469919373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11136/60000][Iteration 3839][Wall Clock 361.092367775s] Trained 128 records in 0.084462254 seconds. Throughput is 1515.4698 records/second. Loss is 1.9839069. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0669698222405952E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11264/60000][Iteration 3840][Wall Clock 361.176961611s] Trained 128 records in 0.084593836 seconds. Throughput is 1513.1127 records/second. Loss is 1.9726137. Sequentialb692dd65's hyper parameters: Current learning rate is 2.06654267410622E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11392/60000][Iteration 3841][Wall Clock 361.262357251s] Trained 128 records in 0.08539564 seconds. Throughput is 1498.9055 records/second. Loss is 1.9799788. Sequentialb692dd65's hyper parameters: Current learning rate is 2.066115702479339E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11520/60000][Iteration 3842][Wall Clock 361.347563931s] Trained 128 records in 0.08520668 seconds. Throughput is 1502.2296 records/second. Loss is 1.9833409. Sequentialb692dd65's hyper parameters: Current learning rate is 2.065688907250568E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:24 INFO  DistriOptimizer$:408 - [Epoch 9 11648/60000][Iteration 3843][Wall Clock 361.432604511s] Trained 128 records in 0.08504058 seconds. Throughput is 1505.1638 records/second. Loss is 1.9767861. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0652622883106153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 11776/60000][Iteration 3844][Wall Clock 361.517907463s] Trained 128 records in 0.085302952 seconds. Throughput is 1500.5343 records/second. Loss is 1.9363343. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0648358455502787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 11904/60000][Iteration 3845][Wall Clock 361.602283423s] Trained 128 records in 0.08437596 seconds. Throughput is 1517.0198 records/second. Loss is 1.9367017. Sequentialb692dd65's hyper parameters: Current learning rate is 2.064409578860446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12032/60000][Iteration 3846][Wall Clock 361.704292201s] Trained 128 records in 0.102008778 seconds. Throughput is 1254.7941 records/second. Loss is 2.0145736. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0639834881320946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12160/60000][Iteration 3847][Wall Clock 361.786285864s] Trained 128 records in 0.081993663 seconds. Throughput is 1561.0963 records/second. Loss is 2.0037534. Sequentialb692dd65's hyper parameters: Current learning rate is 2.063557573256294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12288/60000][Iteration 3848][Wall Clock 361.872150379s] Trained 128 records in 0.085864515 seconds. Throughput is 1490.7206 records/second. Loss is 1.9529121. Sequentialb692dd65's hyper parameters: Current learning rate is 2.063131834124201E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12416/60000][Iteration 3849][Wall Clock 361.956874276s] Trained 128 records in 0.084723897 seconds. Throughput is 1510.7898 records/second. Loss is 1.9763706. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0627062706270627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12544/60000][Iteration 3850][Wall Clock 362.042959635s] Trained 128 records in 0.086085359 seconds. Throughput is 1486.8964 records/second. Loss is 1.9781141. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0622808826562179E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12672/60000][Iteration 3851][Wall Clock 362.127359682s] Trained 128 records in 0.084400047 seconds. Throughput is 1516.5868 records/second. Loss is 1.9283024. Sequentialb692dd65's hyper parameters: Current learning rate is 2.061855670103093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12800/60000][Iteration 3852][Wall Clock 362.216030775s] Trained 128 records in 0.088671093 seconds. Throughput is 1443.5369 records/second. Loss is 1.9674131. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0614306328592044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 12928/60000][Iteration 3853][Wall Clock 362.300269846s] Trained 128 records in 0.084239071 seconds. Throughput is 1519.4849 records/second. Loss is 1.9641509. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0610057708161583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:25 INFO  DistriOptimizer$:408 - [Epoch 9 13056/60000][Iteration 3854][Wall Clock 362.381698866s] Trained 128 records in 0.08142902 seconds. Throughput is 1571.9211 records/second. Loss is 2.0048556. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0605810838656503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13184/60000][Iteration 3855][Wall Clock 362.464747454s] Trained 128 records in 0.083048588 seconds. Throughput is 1541.2664 records/second. Loss is 1.9758247. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0601565718994644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13312/60000][Iteration 3856][Wall Clock 362.548249094s] Trained 128 records in 0.08350164 seconds. Throughput is 1532.904 records/second. Loss is 1.9758347. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0597322348094745E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13440/60000][Iteration 3857][Wall Clock 362.635517835s] Trained 128 records in 0.087268741 seconds. Throughput is 1466.7336 records/second. Loss is 1.9602342. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0593080724876442E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13568/60000][Iteration 3858][Wall Clock 362.719590502s] Trained 128 records in 0.084072667 seconds. Throughput is 1522.4924 records/second. Loss is 1.9410843. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0588840848260242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13696/60000][Iteration 3859][Wall Clock 362.805150845s] Trained 128 records in 0.085560343 seconds. Throughput is 1496.0201 records/second. Loss is 1.957395. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0584602717167556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13824/60000][Iteration 3860][Wall Clock 362.889585959s] Trained 128 records in 0.084435114 seconds. Throughput is 1515.957 records/second. Loss is 1.9638511. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0580366330520683E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 13952/60000][Iteration 3861][Wall Clock 362.968966327s] Trained 128 records in 0.079380368 seconds. Throughput is 1612.4894 records/second. Loss is 1.9664526. Sequentialb692dd65's hyper parameters: Current learning rate is 2.05761316872428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 14080/60000][Iteration 3862][Wall Clock 363.049628853s] Trained 128 records in 0.080662526 seconds. Throughput is 1586.8583 records/second. Loss is 1.9313557. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0571898786257969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 14208/60000][Iteration 3863][Wall Clock 363.132473863s] Trained 128 records in 0.08284501 seconds. Throughput is 1545.0538 records/second. Loss is 1.9662265. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0567667626491157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 14336/60000][Iteration 3864][Wall Clock 363.216408214s] Trained 128 records in 0.083934351 seconds. Throughput is 1525.0013 records/second. Loss is 1.9965616. Sequentialb692dd65's hyper parameters: Current learning rate is 2.056343820686819E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 14464/60000][Iteration 3865][Wall Clock 363.302797822s] Trained 128 records in 0.086389608 seconds. Throughput is 1481.6597 records/second. Loss is 1.9426852. Sequentialb692dd65's hyper parameters: Current learning rate is 2.055921052631579E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:26 INFO  DistriOptimizer$:408 - [Epoch 9 14592/60000][Iteration 3866][Wall Clock 363.387059194s] Trained 128 records in 0.084261372 seconds. Throughput is 1519.0828 records/second. Loss is 1.9775382. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0554984583761563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 14720/60000][Iteration 3867][Wall Clock 363.476944466s] Trained 128 records in 0.089885272 seconds. Throughput is 1424.0375 records/second. Loss is 1.9965502. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0550760378133993E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 14848/60000][Iteration 3868][Wall Clock 363.562488845s] Trained 128 records in 0.085544379 seconds. Throughput is 1496.2994 records/second. Loss is 1.9662108. Sequentialb692dd65's hyper parameters: Current learning rate is 2.054653790836244E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 14976/60000][Iteration 3869][Wall Clock 363.649865546s] Trained 128 records in 0.087376701 seconds. Throughput is 1464.9214 records/second. Loss is 1.9690182. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0542317173377156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15104/60000][Iteration 3870][Wall Clock 363.734811387s] Trained 128 records in 0.084945841 seconds. Throughput is 1506.8424 records/second. Loss is 1.9603577. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0538098172109265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15232/60000][Iteration 3871][Wall Clock 363.816876485s] Trained 128 records in 0.082065098 seconds. Throughput is 1559.7374 records/second. Loss is 1.9919604. Sequentialb692dd65's hyper parameters: Current learning rate is 2.053388090349076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15360/60000][Iteration 3872][Wall Clock 363.911823216s] Trained 128 records in 0.094946731 seconds. Throughput is 1348.1243 records/second. Loss is 1.950447. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0529665366454526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15488/60000][Iteration 3873][Wall Clock 363.991844037s] Trained 128 records in 0.080020821 seconds. Throughput is 1599.5836 records/second. Loss is 1.976673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.052545155993432E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15616/60000][Iteration 3874][Wall Clock 364.073823541s] Trained 128 records in 0.081979504 seconds. Throughput is 1561.3658 records/second. Loss is 2.0074866. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0521239482864764E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15744/60000][Iteration 3875][Wall Clock 364.158670147s] Trained 128 records in 0.084846606 seconds. Throughput is 1508.6047 records/second. Loss is 1.9078133. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0517029134181367E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 15872/60000][Iteration 3876][Wall Clock 364.244612385s] Trained 128 records in 0.085942238 seconds. Throughput is 1489.3724 records/second. Loss is 1.9237957. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0512820512820514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 16000/60000][Iteration 3877][Wall Clock 364.328225996s] Trained 128 records in 0.083613611 seconds. Throughput is 1530.8512 records/second. Loss is 1.9586871. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0508613617719446E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:27 INFO  DistriOptimizer$:408 - [Epoch 9 16128/60000][Iteration 3878][Wall Clock 364.412283142s] Trained 128 records in 0.084057146 seconds. Throughput is 1522.7736 records/second. Loss is 1.9276732. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0504408447816278E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16256/60000][Iteration 3879][Wall Clock 364.497676036s] Trained 128 records in 0.085392894 seconds. Throughput is 1498.9537 records/second. Loss is 1.9552495. Sequentialb692dd65's hyper parameters: Current learning rate is 2.050020500205002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16384/60000][Iteration 3880][Wall Clock 364.582682759s] Trained 128 records in 0.085006723 seconds. Throughput is 1505.7633 records/second. Loss is 1.9384577. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0496003279360528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16512/60000][Iteration 3881][Wall Clock 364.668642067s] Trained 128 records in 0.085959308 seconds. Throughput is 1489.0767 records/second. Loss is 1.9760559. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0491803278688525E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16640/60000][Iteration 3882][Wall Clock 364.755901164s] Trained 128 records in 0.087259097 seconds. Throughput is 1466.8958 records/second. Loss is 2.0052547. Sequentialb692dd65's hyper parameters: Current learning rate is 2.048760499897562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16768/60000][Iteration 3883][Wall Clock 364.842654649s] Trained 128 records in 0.086753485 seconds. Throughput is 1475.445 records/second. Loss is 1.9746275. Sequentialb692dd65's hyper parameters: Current learning rate is 2.048340843916428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 16896/60000][Iteration 3884][Wall Clock 364.931418092s] Trained 128 records in 0.088763443 seconds. Throughput is 1442.035 records/second. Loss is 1.9477327. Sequentialb692dd65's hyper parameters: Current learning rate is 2.047921359819783E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 17024/60000][Iteration 3885][Wall Clock 365.025471893s] Trained 128 records in 0.094053801 seconds. Throughput is 1360.9232 records/second. Loss is 2.0178635. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0475020475020474E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 17152/60000][Iteration 3886][Wall Clock 365.107136801s] Trained 128 records in 0.081664908 seconds. Throughput is 1567.3807 records/second. Loss is 1.9476253. Sequentialb692dd65's hyper parameters: Current learning rate is 2.047082906857728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 17280/60000][Iteration 3887][Wall Clock 365.191056318s] Trained 128 records in 0.083919517 seconds. Throughput is 1525.2709 records/second. Loss is 1.9236587. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0466639377814163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 17408/60000][Iteration 3888][Wall Clock 365.279761074s] Trained 128 records in 0.088704756 seconds. Throughput is 1442.9891 records/second. Loss is 1.9790983. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0462451401677918E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:28 INFO  DistriOptimizer$:408 - [Epoch 9 17536/60000][Iteration 3889][Wall Clock 365.369671122s] Trained 128 records in 0.089910048 seconds. Throughput is 1423.6451 records/second. Loss is 1.9654398. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0458265139116204E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 17664/60000][Iteration 3890][Wall Clock 365.453542032s] Trained 128 records in 0.08387091 seconds. Throughput is 1526.1549 records/second. Loss is 1.9450415. Sequentialb692dd65's hyper parameters: Current learning rate is 2.045408058907752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 17792/60000][Iteration 3891][Wall Clock 365.540807453s] Trained 128 records in 0.087265421 seconds. Throughput is 1466.7894 records/second. Loss is 1.9709139. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0449897750511245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 17920/60000][Iteration 3892][Wall Clock 365.624956425s] Trained 128 records in 0.084148972 seconds. Throughput is 1521.1118 records/second. Loss is 1.9269247. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0445716622367614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18048/60000][Iteration 3893][Wall Clock 365.706317322s] Trained 128 records in 0.081360897 seconds. Throughput is 1573.2373 records/second. Loss is 2.0029497. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0441537203597714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18176/60000][Iteration 3894][Wall Clock 365.789270856s] Trained 128 records in 0.082953534 seconds. Throughput is 1543.0325 records/second. Loss is 1.9810287. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0437359493153483E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18304/60000][Iteration 3895][Wall Clock 365.873689644s] Trained 128 records in 0.084418788 seconds. Throughput is 1516.2501 records/second. Loss is 1.9423548. Sequentialb692dd65's hyper parameters: Current learning rate is 2.043318348998774E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18432/60000][Iteration 3896][Wall Clock 365.960951689s] Trained 128 records in 0.087262045 seconds. Throughput is 1466.8463 records/second. Loss is 1.951272. Sequentialb692dd65's hyper parameters: Current learning rate is 2.042900919305414E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18560/60000][Iteration 3897][Wall Clock 366.042694439s] Trained 128 records in 0.08174275 seconds. Throughput is 1565.8882 records/second. Loss is 1.9920937. Sequentialb692dd65's hyper parameters: Current learning rate is 2.042483660130719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18688/60000][Iteration 3898][Wall Clock 366.13591647s] Trained 128 records in 0.093222031 seconds. Throughput is 1373.066 records/second. Loss is 1.962225. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0420665713702266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18816/60000][Iteration 3899][Wall Clock 366.218720519s] Trained 128 records in 0.082804049 seconds. Throughput is 1545.8181 records/second. Loss is 1.9625605. Sequentialb692dd65's hyper parameters: Current learning rate is 2.041649652919559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 18944/60000][Iteration 3900][Wall Clock 366.299392293s] Trained 128 records in 0.080671774 seconds. Throughput is 1586.6764 records/second. Loss is 1.9789978. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0412329046744235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:29 INFO  DistriOptimizer$:408 - [Epoch 9 19072/60000][Iteration 3901][Wall Clock 366.382445079s] Trained 128 records in 0.083052786 seconds. Throughput is 1541.1886 records/second. Loss is 1.9657077. Sequentialb692dd65's hyper parameters: Current learning rate is 2.040816326530612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19200/60000][Iteration 3902][Wall Clock 366.466628128s] Trained 128 records in 0.084183049 seconds. Throughput is 1520.4961 records/second. Loss is 1.9531713. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0403999183840033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19328/60000][Iteration 3903][Wall Clock 366.5497392s] Trained 128 records in 0.083111072 seconds. Throughput is 1540.1077 records/second. Loss is 1.9712228. Sequentialb692dd65's hyper parameters: Current learning rate is 2.039983680130559E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19456/60000][Iteration 3904][Wall Clock 366.631360305s] Trained 128 records in 0.081621105 seconds. Throughput is 1568.2219 records/second. Loss is 1.9839029. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0395676116663266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19584/60000][Iteration 3905][Wall Clock 366.717386951s] Trained 128 records in 0.086026646 seconds. Throughput is 1487.9111 records/second. Loss is 1.9675663. Sequentialb692dd65's hyper parameters: Current learning rate is 2.039151712887439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19712/60000][Iteration 3906][Wall Clock 366.802799769s] Trained 128 records in 0.085412818 seconds. Throughput is 1498.6041 records/second. Loss is 1.9701786. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0387359836901122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19840/60000][Iteration 3907][Wall Clock 366.887672254s] Trained 128 records in 0.084872485 seconds. Throughput is 1508.1449 records/second. Loss is 1.96953. Sequentialb692dd65's hyper parameters: Current learning rate is 2.038320423970648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 19968/60000][Iteration 3908][Wall Clock 366.975124477s] Trained 128 records in 0.087452223 seconds. Throughput is 1463.6562 records/second. Loss is 1.936784. Sequentialb692dd65's hyper parameters: Current learning rate is 2.037905033625433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 20096/60000][Iteration 3909][Wall Clock 367.057265982s] Trained 128 records in 0.082141505 seconds. Throughput is 1558.2865 records/second. Loss is 1.9219705. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0374898125509374E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 20224/60000][Iteration 3910][Wall Clock 367.151656847s] Trained 128 records in 0.094390865 seconds. Throughput is 1356.0635 records/second. Loss is 1.9417291. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0370747606437154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 20352/60000][Iteration 3911][Wall Clock 367.232798456s] Trained 128 records in 0.081141609 seconds. Throughput is 1577.4891 records/second. Loss is 1.9396269. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0366598778004074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 20480/60000][Iteration 3912][Wall Clock 367.316231142s] Trained 128 records in 0.083432686 seconds. Throughput is 1534.1709 records/second. Loss is 1.9647461. Sequentialb692dd65's hyper parameters: Current learning rate is 2.036245163917736E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:30 INFO  DistriOptimizer$:408 - [Epoch 9 20608/60000][Iteration 3913][Wall Clock 367.400068915s] Trained 128 records in 0.083837773 seconds. Throughput is 1526.7582 records/second. Loss is 1.9412006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0358306188925082E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 20736/60000][Iteration 3914][Wall Clock 367.484431046s] Trained 128 records in 0.084362131 seconds. Throughput is 1517.2684 records/second. Loss is 1.9490937. Sequentialb692dd65's hyper parameters: Current learning rate is 2.035416242621616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 20864/60000][Iteration 3915][Wall Clock 367.568444073s] Trained 128 records in 0.084013027 seconds. Throughput is 1523.5732 records/second. Loss is 1.948619. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0350020350020352E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 20992/60000][Iteration 3916][Wall Clock 367.65584741s] Trained 128 records in 0.087403337 seconds. Throughput is 1464.475 records/second. Loss is 1.9510094. Sequentialb692dd65's hyper parameters: Current learning rate is 2.034587995930824E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21120/60000][Iteration 3917][Wall Clock 367.742028055s] Trained 128 records in 0.086180645 seconds. Throughput is 1485.2523 records/second. Loss is 1.9342617. Sequentialb692dd65's hyper parameters: Current learning rate is 2.034174125305126E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21248/60000][Iteration 3918][Wall Clock 367.827696824s] Trained 128 records in 0.085668769 seconds. Throughput is 1494.1267 records/second. Loss is 1.9912345. Sequentialb692dd65's hyper parameters: Current learning rate is 2.033760423022168E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21376/60000][Iteration 3919][Wall Clock 367.912690427s] Trained 128 records in 0.084993603 seconds. Throughput is 1505.9957 records/second. Loss is 1.9281693. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0333468889792598E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21504/60000][Iteration 3920][Wall Clock 367.996509682s] Trained 128 records in 0.083819255 seconds. Throughput is 1527.0955 records/second. Loss is 1.9299226. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0329335230737954E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21632/60000][Iteration 3921][Wall Clock 368.082696347s] Trained 128 records in 0.086186665 seconds. Throughput is 1485.1486 records/second. Loss is 1.9258922. Sequentialb692dd65's hyper parameters: Current learning rate is 2.032520325203252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21760/60000][Iteration 3922][Wall Clock 368.16810902s] Trained 128 records in 0.085412673 seconds. Throughput is 1498.6067 records/second. Loss is 1.9379398. Sequentialb692dd65's hyper parameters: Current learning rate is 2.03210729526519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 21888/60000][Iteration 3923][Wall Clock 368.252235567s] Trained 128 records in 0.084126547 seconds. Throughput is 1521.5173 records/second. Loss is 1.9491675. Sequentialb692dd65's hyper parameters: Current learning rate is 2.031694433157253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:31 INFO  DistriOptimizer$:408 - [Epoch 9 22016/60000][Iteration 3924][Wall Clock 368.34670702s] Trained 128 records in 0.094471453 seconds. Throughput is 1354.9066 records/second. Loss is 1.9745423. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0312817387771684E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22144/60000][Iteration 3925][Wall Clock 368.429373074s] Trained 128 records in 0.082666054 seconds. Throughput is 1548.3986 records/second. Loss is 1.9673673. Sequentialb692dd65's hyper parameters: Current learning rate is 2.030869212022746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22272/60000][Iteration 3926][Wall Clock 368.514636411s] Trained 128 records in 0.085263337 seconds. Throughput is 1501.2314 records/second. Loss is 1.9495591. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0304568527918778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22400/60000][Iteration 3927][Wall Clock 368.603522235s] Trained 128 records in 0.088885824 seconds. Throughput is 1440.0497 records/second. Loss is 1.958108. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0300446609825416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22528/60000][Iteration 3928][Wall Clock 368.686682535s] Trained 128 records in 0.0831603 seconds. Throughput is 1539.1959 records/second. Loss is 1.9370804. Sequentialb692dd65's hyper parameters: Current learning rate is 2.029632636492795E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22656/60000][Iteration 3929][Wall Clock 368.774850721s] Trained 128 records in 0.088168186 seconds. Throughput is 1451.7708 records/second. Loss is 1.9318804. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0292207792207794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22784/60000][Iteration 3930][Wall Clock 368.861741865s] Trained 128 records in 0.086891144 seconds. Throughput is 1473.1075 records/second. Loss is 1.9665742. Sequentialb692dd65's hyper parameters: Current learning rate is 2.028809089064719E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 22912/60000][Iteration 3931][Wall Clock 368.950890398s] Trained 128 records in 0.089148533 seconds. Throughput is 1435.8059 records/second. Loss is 1.9585606. Sequentialb692dd65's hyper parameters: Current learning rate is 2.028397565922921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 23040/60000][Iteration 3932][Wall Clock 369.033111458s] Trained 128 records in 0.08222106 seconds. Throughput is 1556.7787 records/second. Loss is 1.9432447. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0279862096937742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 23168/60000][Iteration 3933][Wall Clock 369.121579766s] Trained 128 records in 0.088468308 seconds. Throughput is 1446.8458 records/second. Loss is 1.9708264. Sequentialb692dd65's hyper parameters: Current learning rate is 2.02757502027575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 23296/60000][Iteration 3934][Wall Clock 369.204885412s] Trained 128 records in 0.083305646 seconds. Throughput is 1536.5105 records/second. Loss is 1.9489625. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0271639975674033E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 23424/60000][Iteration 3935][Wall Clock 369.292004611s] Trained 128 records in 0.087119199 seconds. Throughput is 1469.2513 records/second. Loss is 1.9867116. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0267531414673692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:32 INFO  DistriOptimizer$:408 - [Epoch 9 23552/60000][Iteration 3936][Wall Clock 369.370827396s] Trained 128 records in 0.078822785 seconds. Throughput is 1623.896 records/second. Loss is 1.9455079. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0263424518743666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 23680/60000][Iteration 3937][Wall Clock 369.454277015s] Trained 128 records in 0.083449619 seconds. Throughput is 1533.8596 records/second. Loss is 1.955835. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0259319286871963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 23808/60000][Iteration 3938][Wall Clock 369.541042244s] Trained 128 records in 0.086765229 seconds. Throughput is 1475.2454 records/second. Loss is 1.9795895. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0255215718047395E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 23936/60000][Iteration 3939][Wall Clock 369.626680153s] Trained 128 records in 0.085637909 seconds. Throughput is 1494.6652 records/second. Loss is 1.9648827. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0251113811259617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24064/60000][Iteration 3940][Wall Clock 369.71465306s] Trained 128 records in 0.087972907 seconds. Throughput is 1454.9934 records/second. Loss is 1.9672539. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0247013565499088E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24192/60000][Iteration 3941][Wall Clock 369.802230957s] Trained 128 records in 0.087577897 seconds. Throughput is 1461.556 records/second. Loss is 1.9684545. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0242914979757087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24320/60000][Iteration 3942][Wall Clock 369.890021371s] Trained 128 records in 0.087790414 seconds. Throughput is 1458.018 records/second. Loss is 1.9505825. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0238818053025702E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24448/60000][Iteration 3943][Wall Clock 369.977712682s] Trained 128 records in 0.087691311 seconds. Throughput is 1459.6656 records/second. Loss is 1.9650322. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0234722784297855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24576/60000][Iteration 3944][Wall Clock 370.06099934s] Trained 128 records in 0.083286658 seconds. Throughput is 1536.8608 records/second. Loss is 1.9438801. Sequentialb692dd65's hyper parameters: Current learning rate is 2.023062917256727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24704/60000][Iteration 3945][Wall Clock 370.147239268s] Trained 128 records in 0.086239928 seconds. Throughput is 1484.2313 records/second. Loss is 1.909882. Sequentialb692dd65's hyper parameters: Current learning rate is 2.022653721682848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24832/60000][Iteration 3946][Wall Clock 370.235011309s] Trained 128 records in 0.087772041 seconds. Throughput is 1458.3231 records/second. Loss is 1.9740703. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0222446916076846E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:33 INFO  DistriOptimizer$:408 - [Epoch 9 24960/60000][Iteration 3947][Wall Clock 370.319948642s] Trained 128 records in 0.084937333 seconds. Throughput is 1506.9934 records/second. Loss is 1.9590116. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0218358269308534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25088/60000][Iteration 3948][Wall Clock 370.408677124s] Trained 128 records in 0.088728482 seconds. Throughput is 1442.6033 records/second. Loss is 1.9716896. Sequentialb692dd65's hyper parameters: Current learning rate is 2.021427127552052E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25216/60000][Iteration 3949][Wall Clock 370.494865247s] Trained 128 records in 0.086188123 seconds. Throughput is 1485.1234 records/second. Loss is 1.9620775. Sequentialb692dd65's hyper parameters: Current learning rate is 2.021018593371059E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25344/60000][Iteration 3950][Wall Clock 370.587555784s] Trained 128 records in 0.092690537 seconds. Throughput is 1380.9393 records/second. Loss is 1.9281334. Sequentialb692dd65's hyper parameters: Current learning rate is 2.020610224287735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25472/60000][Iteration 3951][Wall Clock 370.665873323s] Trained 128 records in 0.078317539 seconds. Throughput is 1634.3721 records/second. Loss is 1.9657035. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0202020202020202E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25600/60000][Iteration 3952][Wall Clock 370.750286039s] Trained 128 records in 0.084412716 seconds. Throughput is 1516.3593 records/second. Loss is 1.9736098. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0197939810139365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25728/60000][Iteration 3953][Wall Clock 370.836707174s] Trained 128 records in 0.086421135 seconds. Throughput is 1481.1193 records/second. Loss is 1.9907328. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0193861066235866E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25856/60000][Iteration 3954][Wall Clock 370.922108416s] Trained 128 records in 0.085401242 seconds. Throughput is 1498.8073 records/second. Loss is 1.9766269. Sequentialb692dd65's hyper parameters: Current learning rate is 2.018978396931153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 25984/60000][Iteration 3955][Wall Clock 371.011773677s] Trained 128 records in 0.089665261 seconds. Throughput is 1427.5316 records/second. Loss is 1.910689. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0185708518368994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 26112/60000][Iteration 3956][Wall Clock 371.097482091s] Trained 128 records in 0.085708414 seconds. Throughput is 1493.4355 records/second. Loss is 1.9370416. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0181634712411706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 26240/60000][Iteration 3957][Wall Clock 371.180575175s] Trained 128 records in 0.083093084 seconds. Throughput is 1540.441 records/second. Loss is 1.940402. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0177562550443908E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 26368/60000][Iteration 3958][Wall Clock 371.262003263s] Trained 128 records in 0.081428088 seconds. Throughput is 1571.9392 records/second. Loss is 1.9521848. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0173492031470646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:34 INFO  DistriOptimizer$:408 - [Epoch 9 26496/60000][Iteration 3959][Wall Clock 371.35196961s] Trained 128 records in 0.089966347 seconds. Throughput is 1422.7542 records/second. Loss is 2.0036862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.016942315449778E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 26624/60000][Iteration 3960][Wall Clock 371.444943033s] Trained 128 records in 0.092973423 seconds. Throughput is 1376.7374 records/second. Loss is 1.9431188. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0165355918531965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 26752/60000][Iteration 3961][Wall Clock 371.527922525s] Trained 128 records in 0.082979492 seconds. Throughput is 1542.5498 records/second. Loss is 2.0059369. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0161290322580645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 26880/60000][Iteration 3962][Wall Clock 371.6146464s] Trained 128 records in 0.086723875 seconds. Throughput is 1475.9489 records/second. Loss is 1.9084454. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0157226365652087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27008/60000][Iteration 3963][Wall Clock 371.699707955s] Trained 128 records in 0.085061555 seconds. Throughput is 1504.7926 records/second. Loss is 1.9389727. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0153164046755341E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27136/60000][Iteration 3964][Wall Clock 371.78599071s] Trained 128 records in 0.086282755 seconds. Throughput is 1483.4946 records/second. Loss is 1.9511892. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0149103364900262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27264/60000][Iteration 3965][Wall Clock 371.869249422s] Trained 128 records in 0.083258712 seconds. Throughput is 1537.3767 records/second. Loss is 1.9161541. Sequentialb692dd65's hyper parameters: Current learning rate is 2.01450443190975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27392/60000][Iteration 3966][Wall Clock 371.954772814s] Trained 128 records in 0.085523392 seconds. Throughput is 1496.6666 records/second. Loss is 1.941214. Sequentialb692dd65's hyper parameters: Current learning rate is 2.014098690835851E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27520/60000][Iteration 3967][Wall Clock 372.039068276s] Trained 128 records in 0.084295462 seconds. Throughput is 1518.4685 records/second. Loss is 1.9207978. Sequentialb692dd65's hyper parameters: Current learning rate is 2.013693113169553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27648/60000][Iteration 3968][Wall Clock 372.122361629s] Trained 128 records in 0.083293353 seconds. Throughput is 1536.7372 records/second. Loss is 1.9891453. Sequentialb692dd65's hyper parameters: Current learning rate is 2.01328769881216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27776/60000][Iteration 3969][Wall Clock 372.2050465s] Trained 128 records in 0.082684871 seconds. Throughput is 1548.0461 records/second. Loss is 1.9260657. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0128824476650564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 27904/60000][Iteration 3970][Wall Clock 372.290295492s] Trained 128 records in 0.085248992 seconds. Throughput is 1501.484 records/second. Loss is 1.936764. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0124773596297044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:35 INFO  DistriOptimizer$:408 - [Epoch 9 28032/60000][Iteration 3971][Wall Clock 372.375361747s] Trained 128 records in 0.085066255 seconds. Throughput is 1504.7096 records/second. Loss is 1.9594907. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0120724346076456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28160/60000][Iteration 3972][Wall Clock 372.457563843s] Trained 128 records in 0.082202096 seconds. Throughput is 1557.1378 records/second. Loss is 1.9401071. Sequentialb692dd65's hyper parameters: Current learning rate is 2.011667672500503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28288/60000][Iteration 3973][Wall Clock 372.541215684s] Trained 128 records in 0.083651841 seconds. Throughput is 1530.1516 records/second. Loss is 1.9759182. Sequentialb692dd65's hyper parameters: Current learning rate is 2.011263073209976E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28416/60000][Iteration 3974][Wall Clock 372.622687437s] Trained 128 records in 0.081471753 seconds. Throughput is 1571.0966 records/second. Loss is 2.004482. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0108586366378444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28544/60000][Iteration 3975][Wall Clock 372.705078189s] Trained 128 records in 0.082390752 seconds. Throughput is 1553.5724 records/second. Loss is 1.9635006. Sequentialb692dd65's hyper parameters: Current learning rate is 2.010454362685967E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28672/60000][Iteration 3976][Wall Clock 372.802137155s] Trained 128 records in 0.097058966 seconds. Throughput is 1318.7859 records/second. Loss is 1.9768983. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0100502512562817E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28800/60000][Iteration 3977][Wall Clock 372.887460182s] Trained 128 records in 0.085323027 seconds. Throughput is 1500.1812 records/second. Loss is 1.9788435. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0096463022508038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 28928/60000][Iteration 3978][Wall Clock 372.969800273s] Trained 128 records in 0.082340091 seconds. Throughput is 1554.5283 records/second. Loss is 1.9161936. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0092425155716293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 29056/60000][Iteration 3979][Wall Clock 373.056310894s] Trained 128 records in 0.086510621 seconds. Throughput is 1479.5872 records/second. Loss is 1.9692458. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0088388911209323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 29184/60000][Iteration 3980][Wall Clock 373.140754044s] Trained 128 records in 0.08444315 seconds. Throughput is 1515.8126 records/second. Loss is 1.9421977. Sequentialb692dd65's hyper parameters: Current learning rate is 2.008435428800964E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 29312/60000][Iteration 3981][Wall Clock 373.225485427s] Trained 128 records in 0.084731383 seconds. Throughput is 1510.6562 records/second. Loss is 1.9389678. Sequentialb692dd65's hyper parameters: Current learning rate is 2.008032128514056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:36 INFO  DistriOptimizer$:408 - [Epoch 9 29440/60000][Iteration 3982][Wall Clock 373.310667345s] Trained 128 records in 0.085181918 seconds. Throughput is 1502.6663 records/second. Loss is 1.9416087. Sequentialb692dd65's hyper parameters: Current learning rate is 2.007628990162618E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 29568/60000][Iteration 3983][Wall Clock 373.393201139s] Trained 128 records in 0.082533794 seconds. Throughput is 1550.8799 records/second. Loss is 1.9088537. Sequentialb692dd65's hyper parameters: Current learning rate is 2.007226013649137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 29696/60000][Iteration 3984][Wall Clock 373.477238211s] Trained 128 records in 0.084037072 seconds. Throughput is 1523.1373 records/second. Loss is 1.9444612. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0068231988761787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 29824/60000][Iteration 3985][Wall Clock 373.566547114s] Trained 128 records in 0.089308903 seconds. Throughput is 1433.2278 records/second. Loss is 1.9428852. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0064205457463884E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 29952/60000][Iteration 3986][Wall Clock 373.65696453s] Trained 128 records in 0.090417416 seconds. Throughput is 1415.6565 records/second. Loss is 1.9918312. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0060180541624876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30080/60000][Iteration 3987][Wall Clock 373.739109527s] Trained 128 records in 0.082144997 seconds. Throughput is 1558.2202 records/second. Loss is 1.9726216. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0056157240272763E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30208/60000][Iteration 3988][Wall Clock 373.82497117s] Trained 128 records in 0.085861643 seconds. Throughput is 1490.7704 records/second. Loss is 1.9504862. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0052135552436334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30336/60000][Iteration 3989][Wall Clock 373.910656819s] Trained 128 records in 0.085685649 seconds. Throughput is 1493.8324 records/second. Loss is 1.990644. Sequentialb692dd65's hyper parameters: Current learning rate is 2.004811547714515E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30464/60000][Iteration 3990][Wall Clock 373.994303772s] Trained 128 records in 0.083646953 seconds. Throughput is 1530.2411 records/second. Loss is 1.9720621. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0044097013429546E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30592/60000][Iteration 3991][Wall Clock 374.079127443s] Trained 128 records in 0.084823671 seconds. Throughput is 1509.0128 records/second. Loss is 1.965223. Sequentialb692dd65's hyper parameters: Current learning rate is 2.004008016032064E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30720/60000][Iteration 3992][Wall Clock 374.161598455s] Trained 128 records in 0.082471012 seconds. Throughput is 1552.0604 records/second. Loss is 1.9480972. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0036064916850334E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30848/60000][Iteration 3993][Wall Clock 374.243239694s] Trained 128 records in 0.081641239 seconds. Throughput is 1567.8351 records/second. Loss is 1.9612634. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0032051282051281E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:37 INFO  DistriOptimizer$:408 - [Epoch 9 30976/60000][Iteration 3994][Wall Clock 374.326098323s] Trained 128 records in 0.082858629 seconds. Throughput is 1544.7999 records/second. Loss is 1.909201. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0028039254956937E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31104/60000][Iteration 3995][Wall Clock 374.407864201s] Trained 128 records in 0.081765878 seconds. Throughput is 1565.4452 records/second. Loss is 1.9092004. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0024028834601524E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31232/60000][Iteration 3996][Wall Clock 374.490984342s] Trained 128 records in 0.083120141 seconds. Throughput is 1539.9397 records/second. Loss is 1.9343982. Sequentialb692dd65's hyper parameters: Current learning rate is 2.002002002002002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31360/60000][Iteration 3997][Wall Clock 374.57412921s] Trained 128 records in 0.083144868 seconds. Throughput is 1539.4817 records/second. Loss is 1.9256005. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0016012810248197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31488/60000][Iteration 3998][Wall Clock 374.658241156s] Trained 128 records in 0.084111946 seconds. Throughput is 1521.7815 records/second. Loss is 1.9373021. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0012007204322593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31616/60000][Iteration 3999][Wall Clock 374.745240107s] Trained 128 records in 0.086998951 seconds. Throughput is 1471.2821 records/second. Loss is 1.9286875. Sequentialb692dd65's hyper parameters: Current learning rate is 2.000800320128051E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31744/60000][Iteration 4000][Wall Clock 374.830613108s] Trained 128 records in 0.085373001 seconds. Throughput is 1499.3031 records/second. Loss is 1.9519197. Sequentialb692dd65's hyper parameters: Current learning rate is 2.000400080016003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 31872/60000][Iteration 4001][Wall Clock 374.918195594s] Trained 128 records in 0.087582486 seconds. Throughput is 1461.4795 records/second. Loss is 1.9754317. Sequentialb692dd65's hyper parameters: Current learning rate is 2.0E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 32000/60000][Iteration 4002][Wall Clock 375.013728504s] Trained 128 records in 0.09553291 seconds. Throughput is 1339.8524 records/second. Loss is 1.9826127. Sequentialb692dd65's hyper parameters: Current learning rate is 1.999600079984003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 32128/60000][Iteration 4003][Wall Clock 375.0944149s] Trained 128 records in 0.080686396 seconds. Throughput is 1586.3888 records/second. Loss is 1.9532778. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9992003198720512E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 32256/60000][Iteration 4004][Wall Clock 375.175751429s] Trained 128 records in 0.081336529 seconds. Throughput is 1573.7086 records/second. Loss is 1.9548256. Sequentialb692dd65's hyper parameters: Current learning rate is 1.998800719568259E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 32384/60000][Iteration 4005][Wall Clock 375.257998981s] Trained 128 records in 0.082247552 seconds. Throughput is 1556.2772 records/second. Loss is 1.9699322. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9984012789768185E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:38 INFO  DistriOptimizer$:408 - [Epoch 9 32512/60000][Iteration 4006][Wall Clock 375.340968537s] Trained 128 records in 0.082969556 seconds. Throughput is 1542.7346 records/second. Loss is 1.9738293. Sequentialb692dd65's hyper parameters: Current learning rate is 1.998001998001998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 32640/60000][Iteration 4007][Wall Clock 375.428471612s] Trained 128 records in 0.087503075 seconds. Throughput is 1462.8058 records/second. Loss is 1.9542698. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9976028765481422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 32768/60000][Iteration 4008][Wall Clock 375.517152881s] Trained 128 records in 0.088681269 seconds. Throughput is 1443.3713 records/second. Loss is 1.9655827. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9972039145196727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 32896/60000][Iteration 4009][Wall Clock 375.603295615s] Trained 128 records in 0.086142734 seconds. Throughput is 1485.9059 records/second. Loss is 1.9547704. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9968051118210862E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33024/60000][Iteration 4010][Wall Clock 375.688190472s] Trained 128 records in 0.084894857 seconds. Throughput is 1507.7474 records/second. Loss is 1.9388899. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9964064683569574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33152/60000][Iteration 4011][Wall Clock 375.782484126s] Trained 128 records in 0.094293654 seconds. Throughput is 1357.4614 records/second. Loss is 1.9431888. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9960079840319363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33280/60000][Iteration 4012][Wall Clock 375.867852785s] Trained 128 records in 0.085368659 seconds. Throughput is 1499.3794 records/second. Loss is 1.9476897. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9956096587507485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33408/60000][Iteration 4013][Wall Clock 375.951923109s] Trained 128 records in 0.084070324 seconds. Throughput is 1522.5349 records/second. Loss is 1.9680997. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9952114924181962E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33536/60000][Iteration 4014][Wall Clock 376.038836371s] Trained 128 records in 0.086913262 seconds. Throughput is 1472.7327 records/second. Loss is 1.9626652. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9948134849391582E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33664/60000][Iteration 4015][Wall Clock 376.121742001s] Trained 128 records in 0.08290563 seconds. Throughput is 1543.9242 records/second. Loss is 1.9362316. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9944156362185878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33792/60000][Iteration 4016][Wall Clock 376.206041347s] Trained 128 records in 0.084299346 seconds. Throughput is 1518.3984 records/second. Loss is 1.969978. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9940179461615156E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:39 INFO  DistriOptimizer$:408 - [Epoch 9 33920/60000][Iteration 4017][Wall Clock 376.290499612s] Trained 128 records in 0.084458265 seconds. Throughput is 1515.5415 records/second. Loss is 1.9305948. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9936204146730463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34048/60000][Iteration 4018][Wall Clock 376.376518143s] Trained 128 records in 0.086018531 seconds. Throughput is 1488.0514 records/second. Loss is 1.9493111. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9932230416583614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34176/60000][Iteration 4019][Wall Clock 376.46154996s] Trained 128 records in 0.085031817 seconds. Throughput is 1505.319 records/second. Loss is 1.9684973. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9928258270227183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34304/60000][Iteration 4020][Wall Clock 376.545809537s] Trained 128 records in 0.084259577 seconds. Throughput is 1519.1151 records/second. Loss is 1.9173146. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9924287706714485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34432/60000][Iteration 4021][Wall Clock 376.632040743s] Trained 128 records in 0.086231206 seconds. Throughput is 1484.3813 records/second. Loss is 1.9478352. Sequentialb692dd65's hyper parameters: Current learning rate is 1.99203187250996E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34560/60000][Iteration 4022][Wall Clock 376.717496625s] Trained 128 records in 0.085455882 seconds. Throughput is 1497.849 records/second. Loss is 1.9724182. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9916351324437363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34688/60000][Iteration 4023][Wall Clock 376.801598246s] Trained 128 records in 0.084101621 seconds. Throughput is 1521.9684 records/second. Loss is 1.93927. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9912385503783353E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34816/60000][Iteration 4024][Wall Clock 376.886618373s] Trained 128 records in 0.085020127 seconds. Throughput is 1505.5259 records/second. Loss is 1.9762245. Sequentialb692dd65's hyper parameters: Current learning rate is 1.990842126219391E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 34944/60000][Iteration 4025][Wall Clock 376.978014759s] Trained 128 records in 0.091396386 seconds. Throughput is 1400.493 records/second. Loss is 1.947952. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9904458598726116E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 35072/60000][Iteration 4026][Wall Clock 377.064070272s] Trained 128 records in 0.086055513 seconds. Throughput is 1487.412 records/second. Loss is 1.9371731. Sequentialb692dd65's hyper parameters: Current learning rate is 1.990049751243781E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 35200/60000][Iteration 4027][Wall Clock 377.150066098s] Trained 128 records in 0.085995826 seconds. Throughput is 1488.4443 records/second. Loss is 1.9295962. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9896538002387587E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 35328/60000][Iteration 4028][Wall Clock 377.243960356s] Trained 128 records in 0.093894258 seconds. Throughput is 1363.2356 records/second. Loss is 1.9451407. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9892580067634773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:40 INFO  DistriOptimizer$:408 - [Epoch 9 35456/60000][Iteration 4029][Wall Clock 377.325410258s] Trained 128 records in 0.081449902 seconds. Throughput is 1571.5182 records/second. Loss is 1.9649082. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9888623707239457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 35584/60000][Iteration 4030][Wall Clock 377.404931745s] Trained 128 records in 0.079521487 seconds. Throughput is 1609.6279 records/second. Loss is 1.9386203. Sequentialb692dd65's hyper parameters: Current learning rate is 1.988466892026248E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 35712/60000][Iteration 4031][Wall Clock 377.485671943s] Trained 128 records in 0.080740198 seconds. Throughput is 1585.3318 records/second. Loss is 1.9512368. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9880715705765408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 35840/60000][Iteration 4032][Wall Clock 377.569860425s] Trained 128 records in 0.084188482 seconds. Throughput is 1520.398 records/second. Loss is 1.9566324. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9876764062810577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 35968/60000][Iteration 4033][Wall Clock 377.656604397s] Trained 128 records in 0.086743972 seconds. Throughput is 1475.6068 records/second. Loss is 1.9249005. Sequentialb692dd65's hyper parameters: Current learning rate is 1.987281399046105E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36096/60000][Iteration 4034][Wall Clock 377.742028694s] Trained 128 records in 0.085424297 seconds. Throughput is 1498.4027 records/second. Loss is 1.973168. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9868865487780648E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36224/60000][Iteration 4035][Wall Clock 377.829318674s] Trained 128 records in 0.08728998 seconds. Throughput is 1466.3767 records/second. Loss is 1.9546826. Sequentialb692dd65's hyper parameters: Current learning rate is 1.986491855383393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36352/60000][Iteration 4036][Wall Clock 377.921720589s] Trained 128 records in 0.092401915 seconds. Throughput is 1385.2527 records/second. Loss is 1.94353. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9860973187686197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36480/60000][Iteration 4037][Wall Clock 378.003642486s] Trained 128 records in 0.081921897 seconds. Throughput is 1562.4637 records/second. Loss is 1.9545366. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9857029388403494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36608/60000][Iteration 4038][Wall Clock 378.089202521s] Trained 128 records in 0.085560035 seconds. Throughput is 1496.0255 records/second. Loss is 1.9463342. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9853087155052612E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36736/60000][Iteration 4039][Wall Clock 378.172818995s] Trained 128 records in 0.083616474 seconds. Throughput is 1530.7988 records/second. Loss is 1.9531798. Sequentialb692dd65's hyper parameters: Current learning rate is 1.984914648670107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36864/60000][Iteration 4040][Wall Clock 378.256547129s] Trained 128 records in 0.083728134 seconds. Throughput is 1528.7573 records/second. Loss is 1.9054484. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9845207382417147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:41 INFO  DistriOptimizer$:408 - [Epoch 9 36992/60000][Iteration 4041][Wall Clock 378.3421028s] Trained 128 records in 0.085555671 seconds. Throughput is 1496.1018 records/second. Loss is 1.9036429. Sequentialb692dd65's hyper parameters: Current learning rate is 1.984126984126984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37120/60000][Iteration 4042][Wall Clock 378.428989052s] Trained 128 records in 0.086886252 seconds. Throughput is 1473.1906 records/second. Loss is 1.9341685. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9837333862328903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37248/60000][Iteration 4043][Wall Clock 378.513989505s] Trained 128 records in 0.085000453 seconds. Throughput is 1505.8743 records/second. Loss is 1.9423126. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9833399444664816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37376/60000][Iteration 4044][Wall Clock 378.598916574s] Trained 128 records in 0.084927069 seconds. Throughput is 1507.1755 records/second. Loss is 1.9887093. Sequentialb692dd65's hyper parameters: Current learning rate is 1.98294665873488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37504/60000][Iteration 4045][Wall Clock 378.683116942s] Trained 128 records in 0.084200368 seconds. Throughput is 1520.1833 records/second. Loss is 1.9382. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9825535289452813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37632/60000][Iteration 4046][Wall Clock 378.767963899s] Trained 128 records in 0.084846957 seconds. Throughput is 1508.5985 records/second. Loss is 1.977669. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9821605550049556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37760/60000][Iteration 4047][Wall Clock 378.85098694s] Trained 128 records in 0.083023041 seconds. Throughput is 1541.7407 records/second. Loss is 1.9754027. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9817677368212444E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 37888/60000][Iteration 4048][Wall Clock 378.933690032s] Trained 128 records in 0.082703092 seconds. Throughput is 1547.7052 records/second. Loss is 1.9509972. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9813750743015655E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 38016/60000][Iteration 4049][Wall Clock 379.016315697s] Trained 128 records in 0.082625665 seconds. Throughput is 1549.1555 records/second. Loss is 1.9752913. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9809825673534074E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 38144/60000][Iteration 4050][Wall Clock 379.099280212s] Trained 128 records in 0.082964515 seconds. Throughput is 1542.8282 records/second. Loss is 1.9780179. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9805902158843335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 38272/60000][Iteration 4051][Wall Clock 379.183309696s] Trained 128 records in 0.084029484 seconds. Throughput is 1523.2749 records/second. Loss is 1.9547188. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9801980198019803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:42 INFO  DistriOptimizer$:408 - [Epoch 9 38400/60000][Iteration 4052][Wall Clock 379.271002724s] Trained 128 records in 0.087693028 seconds. Throughput is 1459.6371 records/second. Loss is 1.9929439. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9798059790140566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 38528/60000][Iteration 4053][Wall Clock 379.355179064s] Trained 128 records in 0.08417634 seconds. Throughput is 1520.6173 records/second. Loss is 1.9190376. Sequentialb692dd65's hyper parameters: Current learning rate is 1.979414093428345E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 38656/60000][Iteration 4054][Wall Clock 379.452479441s] Trained 128 records in 0.097300377 seconds. Throughput is 1315.5139 records/second. Loss is 1.962116. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9790223629527015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 38784/60000][Iteration 4055][Wall Clock 379.535065362s] Trained 128 records in 0.082585921 seconds. Throughput is 1549.9009 records/second. Loss is 1.9420793. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9786307874950534E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 38912/60000][Iteration 4056][Wall Clock 379.616920502s] Trained 128 records in 0.08185514 seconds. Throughput is 1563.738 records/second. Loss is 1.9975185. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9782393669634028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39040/60000][Iteration 4057][Wall Clock 379.698379998s] Trained 128 records in 0.081459496 seconds. Throughput is 1571.3331 records/second. Loss is 1.9749628. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9778481012658228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39168/60000][Iteration 4058][Wall Clock 379.783214016s] Trained 128 records in 0.084834018 seconds. Throughput is 1508.8287 records/second. Loss is 1.9917493. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9774569903104606E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39296/60000][Iteration 4059][Wall Clock 379.867561175s] Trained 128 records in 0.084347159 seconds. Throughput is 1517.5378 records/second. Loss is 1.9590801. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9770660340055358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39424/60000][Iteration 4060][Wall Clock 379.95446813s] Trained 128 records in 0.086906955 seconds. Throughput is 1472.8396 records/second. Loss is 1.9693851. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9766752322593396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39552/60000][Iteration 4061][Wall Clock 380.042180911s] Trained 128 records in 0.087712781 seconds. Throughput is 1459.3085 records/second. Loss is 1.9515581. Sequentialb692dd65's hyper parameters: Current learning rate is 1.976284584980237E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39680/60000][Iteration 4062][Wall Clock 380.134401369s] Trained 128 records in 0.092220458 seconds. Throughput is 1387.9784 records/second. Loss is 2.0000997. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9758940920766647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39808/60000][Iteration 4063][Wall Clock 380.219833979s] Trained 128 records in 0.08543261 seconds. Throughput is 1498.257 records/second. Loss is 1.9384273. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9755037534571315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:43 INFO  DistriOptimizer$:408 - [Epoch 9 39936/60000][Iteration 4064][Wall Clock 380.302188233s] Trained 128 records in 0.082354254 seconds. Throughput is 1554.2609 records/second. Loss is 1.9803786. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9751135690302193E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40064/60000][Iteration 4065][Wall Clock 380.384698661s] Trained 128 records in 0.082510428 seconds. Throughput is 1551.3191 records/second. Loss is 1.9446712. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9747235387045813E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40192/60000][Iteration 4066][Wall Clock 380.470568463s] Trained 128 records in 0.085869802 seconds. Throughput is 1490.6288 records/second. Loss is 1.915295. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9743336623889436E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40320/60000][Iteration 4067][Wall Clock 380.553046825s] Trained 128 records in 0.082478362 seconds. Throughput is 1551.9222 records/second. Loss is 1.9513614. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9739439399921044E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40448/60000][Iteration 4068][Wall Clock 380.637501673s] Trained 128 records in 0.084454848 seconds. Throughput is 1515.6028 records/second. Loss is 1.9683336. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9735543714229328E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40576/60000][Iteration 4069][Wall Clock 380.720898128s] Trained 128 records in 0.083396455 seconds. Throughput is 1534.8374 records/second. Loss is 1.9351954. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9731649565903707E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40704/60000][Iteration 4070][Wall Clock 380.807667478s] Trained 128 records in 0.08676935 seconds. Throughput is 1475.1753 records/second. Loss is 1.933405. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9727756954034326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40832/60000][Iteration 4071][Wall Clock 380.89519892s] Trained 128 records in 0.087531442 seconds. Throughput is 1462.3317 records/second. Loss is 1.9604857. Sequentialb692dd65's hyper parameters: Current learning rate is 1.972386587771203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 40960/60000][Iteration 4072][Wall Clock 380.980310752s] Trained 128 records in 0.085111832 seconds. Throughput is 1503.9037 records/second. Loss is 1.9155425. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9719976336028398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 41088/60000][Iteration 4073][Wall Clock 381.064327046s] Trained 128 records in 0.084016294 seconds. Throughput is 1523.514 records/second. Loss is 1.9192611. Sequentialb692dd65's hyper parameters: Current learning rate is 1.971608832807571E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 41216/60000][Iteration 4074][Wall Clock 381.148994788s] Trained 128 records in 0.084667742 seconds. Throughput is 1511.7919 records/second. Loss is 1.883792. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9712201852946972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 41344/60000][Iteration 4075][Wall Clock 381.234532854s] Trained 128 records in 0.085538066 seconds. Throughput is 1496.4098 records/second. Loss is 1.9290922. Sequentialb692dd65's hyper parameters: Current learning rate is 1.970831690973591E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:44 INFO  DistriOptimizer$:408 - [Epoch 9 41472/60000][Iteration 4076][Wall Clock 381.317100754s] Trained 128 records in 0.0825679 seconds. Throughput is 1550.2393 records/second. Loss is 1.9689573. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9704433497536944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 41600/60000][Iteration 4077][Wall Clock 381.402220776s] Trained 128 records in 0.085120022 seconds. Throughput is 1503.759 records/second. Loss is 1.9306718. Sequentialb692dd65's hyper parameters: Current learning rate is 1.970055161544523E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 41728/60000][Iteration 4078][Wall Clock 381.488371217s] Trained 128 records in 0.086150441 seconds. Throughput is 1485.7731 records/second. Loss is 1.9552833. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9696671262556627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 41856/60000][Iteration 4079][Wall Clock 381.573121707s] Trained 128 records in 0.08475049 seconds. Throughput is 1510.3158 records/second. Loss is 1.9324719. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9692792437967703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 41984/60000][Iteration 4080][Wall Clock 381.663895456s] Trained 128 records in 0.090773749 seconds. Throughput is 1410.0994 records/second. Loss is 1.9406214. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9688915140775746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42112/60000][Iteration 4081][Wall Clock 381.748253777s] Trained 128 records in 0.084358321 seconds. Throughput is 1517.337 records/second. Loss is 1.9374716. Sequentialb692dd65's hyper parameters: Current learning rate is 1.968503937007874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42240/60000][Iteration 4082][Wall Clock 381.825377025s] Trained 128 records in 0.077123248 seconds. Throughput is 1659.6812 records/second. Loss is 1.9380215. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9681165124975396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42368/60000][Iteration 4083][Wall Clock 381.909566328s] Trained 128 records in 0.084189303 seconds. Throughput is 1520.3832 records/second. Loss is 1.9664148. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9677292404565134E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42496/60000][Iteration 4084][Wall Clock 381.996662374s] Trained 128 records in 0.087096046 seconds. Throughput is 1469.642 records/second. Loss is 1.9659905. Sequentialb692dd65's hyper parameters: Current learning rate is 1.967342120794806E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42624/60000][Iteration 4085][Wall Clock 382.083985515s] Trained 128 records in 0.087323141 seconds. Throughput is 1465.8198 records/second. Loss is 1.9175222. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9669551534225017E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42752/60000][Iteration 4086][Wall Clock 382.168266472s] Trained 128 records in 0.084280957 seconds. Throughput is 1518.7297 records/second. Loss is 1.9611319. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9665683382497542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:45 INFO  DistriOptimizer$:408 - [Epoch 9 42880/60000][Iteration 4087][Wall Clock 382.263685337s] Trained 128 records in 0.095418865 seconds. Throughput is 1341.4539 records/second. Loss is 1.9275271. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9661816751867872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43008/60000][Iteration 4088][Wall Clock 382.346755471s] Trained 128 records in 0.083070134 seconds. Throughput is 1540.8666 records/second. Loss is 1.9152656. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9657951641438963E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43136/60000][Iteration 4089][Wall Clock 382.430180176s] Trained 128 records in 0.083424705 seconds. Throughput is 1534.3177 records/second. Loss is 1.9355485. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9654088050314466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43264/60000][Iteration 4090][Wall Clock 382.512865896s] Trained 128 records in 0.08268572 seconds. Throughput is 1548.0304 records/second. Loss is 1.9136285. Sequentialb692dd65's hyper parameters: Current learning rate is 1.965022597759874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43392/60000][Iteration 4091][Wall Clock 382.595244087s] Trained 128 records in 0.082378191 seconds. Throughput is 1553.8092 records/second. Loss is 1.9425828. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9646365422396858E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43520/60000][Iteration 4092][Wall Clock 382.682301188s] Trained 128 records in 0.087057101 seconds. Throughput is 1470.2994 records/second. Loss is 1.8983272. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9642506383814575E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43648/60000][Iteration 4093][Wall Clock 382.767361339s] Trained 128 records in 0.085060151 seconds. Throughput is 1504.8175 records/second. Loss is 1.9456626. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9638648860958365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43776/60000][Iteration 4094][Wall Clock 382.852445694s] Trained 128 records in 0.085084355 seconds. Throughput is 1504.3894 records/second. Loss is 1.9297266. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9634792852935403E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 43904/60000][Iteration 4095][Wall Clock 382.939540935s] Trained 128 records in 0.087095241 seconds. Throughput is 1469.6555 records/second. Loss is 1.9292235. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9630938358853554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 44032/60000][Iteration 4096][Wall Clock 383.024268983s] Trained 128 records in 0.084728048 seconds. Throughput is 1510.7158 records/second. Loss is 1.9310259. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9627085377821394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 44160/60000][Iteration 4097][Wall Clock 383.108458262s] Trained 128 records in 0.084189279 seconds. Throughput is 1520.3835 records/second. Loss is 1.9420872. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9623233908948196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 44288/60000][Iteration 4098][Wall Clock 383.19275737s] Trained 128 records in 0.084299108 seconds. Throughput is 1518.4027 records/second. Loss is 1.9418116. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9619383951343926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:46 INFO  DistriOptimizer$:408 - [Epoch 9 44416/60000][Iteration 4099][Wall Clock 383.279408133s] Trained 128 records in 0.086650763 seconds. Throughput is 1477.1941 records/second. Loss is 1.9638182. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9615535504119262E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 44544/60000][Iteration 4100][Wall Clock 383.365565559s] Trained 128 records in 0.086157426 seconds. Throughput is 1485.6526 records/second. Loss is 1.9559065. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9611688566385565E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 44672/60000][Iteration 4101][Wall Clock 383.449083444s] Trained 128 records in 0.083517885 seconds. Throughput is 1532.6058 records/second. Loss is 1.9452174. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9607843137254904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 44800/60000][Iteration 4102][Wall Clock 383.539920208s] Trained 128 records in 0.090836764 seconds. Throughput is 1409.1211 records/second. Loss is 1.9469627. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9603999215840032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 44928/60000][Iteration 4103][Wall Clock 383.626876764s] Trained 128 records in 0.086956556 seconds. Throughput is 1471.9995 records/second. Loss is 1.9390608. Sequentialb692dd65's hyper parameters: Current learning rate is 1.960015680125441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45056/60000][Iteration 4104][Wall Clock 383.71360125s] Trained 128 records in 0.086724486 seconds. Throughput is 1475.9385 records/second. Loss is 1.9541814. Sequentialb692dd65's hyper parameters: Current learning rate is 1.959631589261219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45184/60000][Iteration 4105][Wall Clock 383.814836652s] Trained 128 records in 0.101235402 seconds. Throughput is 1264.3798 records/second. Loss is 1.9157017. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9592476489028212E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45312/60000][Iteration 4106][Wall Clock 383.903889621s] Trained 128 records in 0.089052969 seconds. Throughput is 1437.3468 records/second. Loss is 1.994838. Sequentialb692dd65's hyper parameters: Current learning rate is 1.958863858961802E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45440/60000][Iteration 4107][Wall Clock 383.985630069s] Trained 128 records in 0.081740448 seconds. Throughput is 1565.9323 records/second. Loss is 1.9900053. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9584802193497848E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45568/60000][Iteration 4108][Wall Clock 384.068762942s] Trained 128 records in 0.083132873 seconds. Throughput is 1539.7039 records/second. Loss is 1.9250802. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9580967299784609E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45696/60000][Iteration 4109][Wall Clock 384.151036229s] Trained 128 records in 0.082273287 seconds. Throughput is 1555.7905 records/second. Loss is 1.9303757. Sequentialb692dd65's hyper parameters: Current learning rate is 1.957713390759593E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:47 INFO  DistriOptimizer$:408 - [Epoch 9 45824/60000][Iteration 4110][Wall Clock 384.236003432s] Trained 128 records in 0.084967203 seconds. Throughput is 1506.4636 records/second. Loss is 1.9295526. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9573302016050108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 45952/60000][Iteration 4111][Wall Clock 384.321991002s] Trained 128 records in 0.08598757 seconds. Throughput is 1488.5873 records/second. Loss is 1.9333404. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9569471624266143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46080/60000][Iteration 4112][Wall Clock 384.406702204s] Trained 128 records in 0.084711202 seconds. Throughput is 1511.0162 records/second. Loss is 1.9539905. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9565642731363727E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46208/60000][Iteration 4113][Wall Clock 384.501768117s] Trained 128 records in 0.095065913 seconds. Throughput is 1346.4342 records/second. Loss is 1.9351358. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9561815336463224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46336/60000][Iteration 4114][Wall Clock 384.582118302s] Trained 128 records in 0.080350185 seconds. Throughput is 1593.0269 records/second. Loss is 1.9161369. Sequentialb692dd65's hyper parameters: Current learning rate is 1.95579894386857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46464/60000][Iteration 4115][Wall Clock 384.660664087s] Trained 128 records in 0.078545785 seconds. Throughput is 1629.6228 records/second. Loss is 1.9502155. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9554165037152915E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46592/60000][Iteration 4116][Wall Clock 384.744528652s] Trained 128 records in 0.083864565 seconds. Throughput is 1526.2704 records/second. Loss is 1.9409866. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9550342130987292E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46720/60000][Iteration 4117][Wall Clock 384.828811694s] Trained 128 records in 0.084283042 seconds. Throughput is 1518.6923 records/second. Loss is 1.9179024. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9546520719311965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46848/60000][Iteration 4118][Wall Clock 384.911521463s] Trained 128 records in 0.082709769 seconds. Throughput is 1547.5802 records/second. Loss is 1.9266977. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9542700801250732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 46976/60000][Iteration 4119][Wall Clock 384.996065817s] Trained 128 records in 0.084544354 seconds. Throughput is 1513.9982 records/second. Loss is 1.9604547. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9538882375928096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 47104/60000][Iteration 4120][Wall Clock 385.078358739s] Trained 128 records in 0.082292922 seconds. Throughput is 1555.4193 records/second. Loss is 1.8980331. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9535065442469234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 47232/60000][Iteration 4121][Wall Clock 385.161876879s] Trained 128 records in 0.08351814 seconds. Throughput is 1532.6012 records/second. Loss is 1.9675884. Sequentialb692dd65's hyper parameters: Current learning rate is 1.953125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:48 INFO  DistriOptimizer$:408 - [Epoch 9 47360/60000][Iteration 4122][Wall Clock 385.244767637s] Trained 128 records in 0.082890758 seconds. Throughput is 1544.2012 records/second. Loss is 1.9413478. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9527436047646942E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 47488/60000][Iteration 4123][Wall Clock 385.329907282s] Trained 128 records in 0.085139645 seconds. Throughput is 1503.4124 records/second. Loss is 1.9499965. Sequentialb692dd65's hyper parameters: Current learning rate is 1.952362358453729E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 47616/60000][Iteration 4124][Wall Clock 385.414611155s] Trained 128 records in 0.084703873 seconds. Throughput is 1511.147 records/second. Loss is 1.916732. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9519812609798944E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 47744/60000][Iteration 4125][Wall Clock 385.499825401s] Trained 128 records in 0.085214246 seconds. Throughput is 1502.0963 records/second. Loss is 1.9159044. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9516003122560502E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 47872/60000][Iteration 4126][Wall Clock 385.586642364s] Trained 128 records in 0.086816963 seconds. Throughput is 1474.3662 records/second. Loss is 1.9497132. Sequentialb692dd65's hyper parameters: Current learning rate is 1.951219512195122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48000/60000][Iteration 4127][Wall Clock 385.670045993s] Trained 128 records in 0.083403629 seconds. Throughput is 1534.7053 records/second. Loss is 1.9224725. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9508388607101054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48128/60000][Iteration 4128][Wall Clock 385.754278325s] Trained 128 records in 0.084232332 seconds. Throughput is 1519.6066 records/second. Loss is 1.944359. Sequentialb692dd65's hyper parameters: Current learning rate is 1.950458357714063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48256/60000][Iteration 4129][Wall Clock 385.837297753s] Trained 128 records in 0.083019428 seconds. Throughput is 1541.8077 records/second. Loss is 1.9118415. Sequentialb692dd65's hyper parameters: Current learning rate is 1.950078003120125E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48384/60000][Iteration 4130][Wall Clock 385.926917067s] Trained 128 records in 0.089619314 seconds. Throughput is 1428.2635 records/second. Loss is 1.9342004. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9496977968414895E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48512/60000][Iteration 4131][Wall Clock 386.027410684s] Trained 128 records in 0.100493617 seconds. Throughput is 1273.7128 records/second. Loss is 1.9678478. Sequentialb692dd65's hyper parameters: Current learning rate is 1.949317738791423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48640/60000][Iteration 4132][Wall Clock 386.108280724s] Trained 128 records in 0.08087004 seconds. Throughput is 1582.7864 records/second. Loss is 1.963943. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9489378288832586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48768/60000][Iteration 4133][Wall Clock 386.190773407s] Trained 128 records in 0.082492683 seconds. Throughput is 1551.6528 records/second. Loss is 1.9629625. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9485580670303975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:49 INFO  DistriOptimizer$:408 - [Epoch 9 48896/60000][Iteration 4134][Wall Clock 386.274603939s] Trained 128 records in 0.083830532 seconds. Throughput is 1526.8899 records/second. Loss is 1.9392405. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9481784531463084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49024/60000][Iteration 4135][Wall Clock 386.361424766s] Trained 128 records in 0.086820827 seconds. Throughput is 1474.3007 records/second. Loss is 1.9393767. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9477989871445267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49152/60000][Iteration 4136][Wall Clock 386.465163209s] Trained 128 records in 0.103738443 seconds. Throughput is 1233.8724 records/second. Loss is 1.9575361. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9474196689386563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49280/60000][Iteration 4137][Wall Clock 386.551999727s] Trained 128 records in 0.086836518 seconds. Throughput is 1474.0343 records/second. Loss is 1.9283743. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9470404984423675E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49408/60000][Iteration 4138][Wall Clock 386.637556155s] Trained 128 records in 0.085556428 seconds. Throughput is 1496.0887 records/second. Loss is 1.9496706. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9466614755693983E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49536/60000][Iteration 4139][Wall Clock 386.726901626s] Trained 128 records in 0.089345471 seconds. Throughput is 1432.6412 records/second. Loss is 1.9397429. Sequentialb692dd65's hyper parameters: Current learning rate is 1.946282600233554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49664/60000][Iteration 4140][Wall Clock 386.81078679s] Trained 128 records in 0.083885164 seconds. Throughput is 1525.8956 records/second. Loss is 1.9532646. Sequentialb692dd65's hyper parameters: Current learning rate is 1.945903872348706E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49792/60000][Iteration 4141][Wall Clock 386.89507169s] Trained 128 records in 0.0842849 seconds. Throughput is 1518.6587 records/second. Loss is 1.889809. Sequentialb692dd65's hyper parameters: Current learning rate is 1.945525291828794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 49920/60000][Iteration 4142][Wall Clock 386.980454876s] Trained 128 records in 0.085383186 seconds. Throughput is 1499.1243 records/second. Loss is 1.9514736. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9451468585878235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 50048/60000][Iteration 4143][Wall Clock 387.067517031s] Trained 128 records in 0.087062155 seconds. Throughput is 1470.214 records/second. Loss is 1.9191135. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9447685725398678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 50176/60000][Iteration 4144][Wall Clock 387.153096099s] Trained 128 records in 0.085579068 seconds. Throughput is 1495.6929 records/second. Loss is 1.9616961. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9443904335990667E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:50 INFO  DistriOptimizer$:408 - [Epoch 9 50304/60000][Iteration 4145][Wall Clock 387.239469651s] Trained 128 records in 0.086373552 seconds. Throughput is 1481.935 records/second. Loss is 1.9798502. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9440124416796267E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 50432/60000][Iteration 4146][Wall Clock 387.326599798s] Trained 128 records in 0.087130147 seconds. Throughput is 1469.0668 records/second. Loss is 1.9697856. Sequentialb692dd65's hyper parameters: Current learning rate is 1.943634596695821E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 50560/60000][Iteration 4147][Wall Clock 387.412043456s] Trained 128 records in 0.085443658 seconds. Throughput is 1498.0631 records/second. Loss is 1.9387903. Sequentialb692dd65's hyper parameters: Current learning rate is 1.94325689856199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 50688/60000][Iteration 4148][Wall Clock 387.496508158s] Trained 128 records in 0.084464702 seconds. Throughput is 1515.426 records/second. Loss is 1.9230182. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9428793471925392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 50816/60000][Iteration 4149][Wall Clock 387.581633272s] Trained 128 records in 0.085125114 seconds. Throughput is 1503.6691 records/second. Loss is 1.9278584. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9425019425019428E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 50944/60000][Iteration 4150][Wall Clock 387.666821557s] Trained 128 records in 0.085188285 seconds. Throughput is 1502.5541 records/second. Loss is 1.933534. Sequentialb692dd65's hyper parameters: Current learning rate is 1.942124684404739E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51072/60000][Iteration 4151][Wall Clock 387.760857642s] Trained 128 records in 0.094036085 seconds. Throughput is 1361.1796 records/second. Loss is 1.9485426. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9417475728155338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51200/60000][Iteration 4152][Wall Clock 387.84615371s] Trained 128 records in 0.085296068 seconds. Throughput is 1500.6554 records/second. Loss is 1.9246916. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9413706076490004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51328/60000][Iteration 4153][Wall Clock 387.936611335s] Trained 128 records in 0.090457625 seconds. Throughput is 1415.0272 records/second. Loss is 1.9014391. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9409937888198756E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51456/60000][Iteration 4154][Wall Clock 388.025812629s] Trained 128 records in 0.089201294 seconds. Throughput is 1434.9568 records/second. Loss is 1.9597235. Sequentialb692dd65's hyper parameters: Current learning rate is 1.940617116242965E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51584/60000][Iteration 4155][Wall Clock 388.108491151s] Trained 128 records in 0.082678522 seconds. Throughput is 1548.1652 records/second. Loss is 1.9043444. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9402405898331394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51712/60000][Iteration 4156][Wall Clock 388.201144781s] Trained 128 records in 0.09265363 seconds. Throughput is 1381.4893 records/second. Loss is 1.9639332. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9398642095053346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:51 INFO  DistriOptimizer$:408 - [Epoch 9 51840/60000][Iteration 4157][Wall Clock 388.284085167s] Trained 128 records in 0.082940386 seconds. Throughput is 1543.2771 records/second. Loss is 1.9715279. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9394879751745542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 51968/60000][Iteration 4158][Wall Clock 388.36984161s] Trained 128 records in 0.085756443 seconds. Throughput is 1492.5992 records/second. Loss is 1.9262592. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9391118867558658E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52096/60000][Iteration 4159][Wall Clock 388.455102351s] Trained 128 records in 0.085260741 seconds. Throughput is 1501.2771 records/second. Loss is 1.9364623. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9387359441644047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52224/60000][Iteration 4160][Wall Clock 388.544354694s] Trained 128 records in 0.089252343 seconds. Throughput is 1434.136 records/second. Loss is 1.957449. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9383601473153714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52352/60000][Iteration 4161][Wall Clock 388.631657597s] Trained 128 records in 0.087302903 seconds. Throughput is 1466.1598 records/second. Loss is 1.938022. Sequentialb692dd65's hyper parameters: Current learning rate is 1.937984496124031E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52480/60000][Iteration 4162][Wall Clock 388.714552349s] Trained 128 records in 0.082894752 seconds. Throughput is 1544.1267 records/second. Loss is 1.951784. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9376089905057158E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52608/60000][Iteration 4163][Wall Clock 388.796813004s] Trained 128 records in 0.082260655 seconds. Throughput is 1556.0294 records/second. Loss is 1.9804043. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9372336303758234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52736/60000][Iteration 4164][Wall Clock 388.891084645s] Trained 128 records in 0.094271641 seconds. Throughput is 1357.7784 records/second. Loss is 1.9275514. Sequentialb692dd65's hyper parameters: Current learning rate is 1.936858415649816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52864/60000][Iteration 4165][Wall Clock 388.981326906s] Trained 128 records in 0.090242261 seconds. Throughput is 1418.4042 records/second. Loss is 1.9308066. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9364833462432224E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 52992/60000][Iteration 4166][Wall Clock 389.063209661s] Trained 128 records in 0.081882755 seconds. Throughput is 1563.2108 records/second. Loss is 1.9387351. Sequentialb692dd65's hyper parameters: Current learning rate is 1.936108422071636E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 53120/60000][Iteration 4167][Wall Clock 389.149646762s] Trained 128 records in 0.086437101 seconds. Throughput is 1480.8456 records/second. Loss is 1.9018551. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9357336430507162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:52 INFO  DistriOptimizer$:408 - [Epoch 9 53248/60000][Iteration 4168][Wall Clock 389.234739214s] Trained 128 records in 0.085092452 seconds. Throughput is 1504.2462 records/second. Loss is 1.954683. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9353590090961874E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 53376/60000][Iteration 4169][Wall Clock 389.318385469s] Trained 128 records in 0.083646255 seconds. Throughput is 1530.2539 records/second. Loss is 1.9327968. Sequentialb692dd65's hyper parameters: Current learning rate is 1.934984520123839E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 53504/60000][Iteration 4170][Wall Clock 389.401677755s] Trained 128 records in 0.083292286 seconds. Throughput is 1536.757 records/second. Loss is 1.9451877. Sequentialb692dd65's hyper parameters: Current learning rate is 1.934610176049526E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 53632/60000][Iteration 4171][Wall Clock 389.486522504s] Trained 128 records in 0.084844749 seconds. Throughput is 1508.638 records/second. Loss is 1.940319. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9342359767891682E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 53760/60000][Iteration 4172][Wall Clock 389.569393709s] Trained 128 records in 0.082871205 seconds. Throughput is 1544.5654 records/second. Loss is 1.9215646. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9338619222587506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 53888/60000][Iteration 4173][Wall Clock 389.654250245s] Trained 128 records in 0.084856536 seconds. Throughput is 1508.4283 records/second. Loss is 1.9224834. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9334880123743234E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54016/60000][Iteration 4174][Wall Clock 389.738879808s] Trained 128 records in 0.084629563 seconds. Throughput is 1512.4738 records/second. Loss is 1.9538836. Sequentialb692dd65's hyper parameters: Current learning rate is 1.933114247052001E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54144/60000][Iteration 4175][Wall Clock 389.825528574s] Trained 128 records in 0.086648766 seconds. Throughput is 1477.2281 records/second. Loss is 1.9214092. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9327406262079628E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54272/60000][Iteration 4176][Wall Clock 389.911817389s] Trained 128 records in 0.086288815 seconds. Throughput is 1483.3904 records/second. Loss is 1.9277726. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9323671497584543E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54400/60000][Iteration 4177][Wall Clock 389.996368004s] Trained 128 records in 0.084550615 seconds. Throughput is 1513.8861 records/second. Loss is 1.9214554. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9319938176197836E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54528/60000][Iteration 4178][Wall Clock 390.081604711s] Trained 128 records in 0.085236707 seconds. Throughput is 1501.7004 records/second. Loss is 1.9430952. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9316206297083252E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54656/60000][Iteration 4179][Wall Clock 390.170572115s] Trained 128 records in 0.088967404 seconds. Throughput is 1438.7291 records/second. Loss is 1.9551598. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9312475859405175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:53 INFO  DistriOptimizer$:408 - [Epoch 9 54784/60000][Iteration 4180][Wall Clock 390.256733291s] Trained 128 records in 0.086161176 seconds. Throughput is 1485.5879 records/second. Loss is 1.9195651. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9308746862328635E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 54912/60000][Iteration 4181][Wall Clock 390.3423133s] Trained 128 records in 0.085580009 seconds. Throughput is 1495.6764 records/second. Loss is 1.9526477. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9305019305019308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55040/60000][Iteration 4182][Wall Clock 390.438427088s] Trained 128 records in 0.096113788 seconds. Throughput is 1331.7549 records/second. Loss is 1.9152391. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9301293186643506E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55168/60000][Iteration 4183][Wall Clock 390.519625803s] Trained 128 records in 0.081198715 seconds. Throughput is 1576.3796 records/second. Loss is 1.9102659. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9297568506368196E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55296/60000][Iteration 4184][Wall Clock 390.595728119s] Trained 128 records in 0.076102316 seconds. Throughput is 1681.9462 records/second. Loss is 1.9495307. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9293845263360988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55424/60000][Iteration 4185][Wall Clock 390.677286472s] Trained 128 records in 0.081558353 seconds. Throughput is 1569.4285 records/second. Loss is 1.9016911. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9290123456790122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55552/60000][Iteration 4186][Wall Clock 390.760073078s] Trained 128 records in 0.082786606 seconds. Throughput is 1546.1438 records/second. Loss is 1.9057481. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9286403085824492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55680/60000][Iteration 4187][Wall Clock 390.844485351s] Trained 128 records in 0.084412273 seconds. Throughput is 1516.3672 records/second. Loss is 1.937871. Sequentialb692dd65's hyper parameters: Current learning rate is 1.928268414963363E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55808/60000][Iteration 4188][Wall Clock 390.929271409s] Trained 128 records in 0.084786058 seconds. Throughput is 1509.6821 records/second. Loss is 1.9296973. Sequentialb692dd65's hyper parameters: Current learning rate is 1.92789666473877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 55936/60000][Iteration 4189][Wall Clock 391.012451845s] Trained 128 records in 0.083180436 seconds. Throughput is 1538.8234 records/second. Loss is 1.9430866. Sequentialb692dd65's hyper parameters: Current learning rate is 1.927525057825752E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 56064/60000][Iteration 4190][Wall Clock 391.104384661s] Trained 128 records in 0.091932816 seconds. Throughput is 1392.321 records/second. Loss is 1.9106473. Sequentialb692dd65's hyper parameters: Current learning rate is 1.927153594141453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 56192/60000][Iteration 4191][Wall Clock 391.183350117s] Trained 128 records in 0.078965456 seconds. Throughput is 1620.9619 records/second. Loss is 1.9409412. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9267822736030826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:54 INFO  DistriOptimizer$:408 - [Epoch 9 56320/60000][Iteration 4192][Wall Clock 391.265912063s] Trained 128 records in 0.082561946 seconds. Throughput is 1550.3511 records/second. Loss is 1.9740249. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9264110961279138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 56448/60000][Iteration 4193][Wall Clock 391.352369326s] Trained 128 records in 0.086457263 seconds. Throughput is 1480.5004 records/second. Loss is 1.973627. Sequentialb692dd65's hyper parameters: Current learning rate is 1.926040061633282E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 56576/60000][Iteration 4194][Wall Clock 391.438471293s] Trained 128 records in 0.086101967 seconds. Throughput is 1486.6095 records/second. Loss is 1.9541541. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9256691700365877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 56704/60000][Iteration 4195][Wall Clock 391.523642455s] Trained 128 records in 0.085171162 seconds. Throughput is 1502.8561 records/second. Loss is 1.8890162. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9252984212552945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 56832/60000][Iteration 4196][Wall Clock 391.607322186s] Trained 128 records in 0.083679731 seconds. Throughput is 1529.6417 records/second. Loss is 1.9034184. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9249278152069297E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 56960/60000][Iteration 4197][Wall Clock 391.691314446s] Trained 128 records in 0.08399226 seconds. Throughput is 1523.95 records/second. Loss is 1.9554397. Sequentialb692dd65's hyper parameters: Current learning rate is 1.924557351809084E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57088/60000][Iteration 4198][Wall Clock 391.772343322s] Trained 128 records in 0.081028876 seconds. Throughput is 1579.6837 records/second. Loss is 1.928568. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9241870309794111E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57216/60000][Iteration 4199][Wall Clock 391.856306534s] Trained 128 records in 0.083963212 seconds. Throughput is 1524.477 records/second. Loss is 1.9038382. Sequentialb692dd65's hyper parameters: Current learning rate is 1.923816852635629E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57344/60000][Iteration 4200][Wall Clock 391.943111462s] Trained 128 records in 0.086804928 seconds. Throughput is 1474.5707 records/second. Loss is 1.9489468. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9234468166955186E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57472/60000][Iteration 4201][Wall Clock 392.029638614s] Trained 128 records in 0.086527152 seconds. Throughput is 1479.3044 records/second. Loss is 1.9465961. Sequentialb692dd65's hyper parameters: Current learning rate is 1.923076923076923E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57600/60000][Iteration 4202][Wall Clock 392.115403799s] Trained 128 records in 0.085765185 seconds. Throughput is 1492.4471 records/second. Loss is 1.9393748. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9227071716977504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:55 INFO  DistriOptimizer$:408 - [Epoch 9 57728/60000][Iteration 4203][Wall Clock 392.198213035s] Trained 128 records in 0.082809236 seconds. Throughput is 1545.7212 records/second. Loss is 1.9261439. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9223375624759708E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 57856/60000][Iteration 4204][Wall Clock 392.282704389s] Trained 128 records in 0.084491354 seconds. Throughput is 1514.9479 records/second. Loss is 1.9046605. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9219680953296174E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 57984/60000][Iteration 4205][Wall Clock 392.367783104s] Trained 128 records in 0.085078715 seconds. Throughput is 1504.4891 records/second. Loss is 1.9004807. Sequentialb692dd65's hyper parameters: Current learning rate is 1.921598770176787E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58112/60000][Iteration 4206][Wall Clock 392.453559846s] Trained 128 records in 0.085776742 seconds. Throughput is 1492.2461 records/second. Loss is 1.9175968. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9212295869356388E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58240/60000][Iteration 4207][Wall Clock 392.537037542s] Trained 128 records in 0.083477696 seconds. Throughput is 1533.3436 records/second. Loss is 1.9253926. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9208605455243947E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58368/60000][Iteration 4208][Wall Clock 392.6632004s] Trained 128 records in 0.126162858 seconds. Throughput is 1014.5617 records/second. Loss is 1.9154636. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9204916458613407E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58496/60000][Iteration 4209][Wall Clock 392.769299466s] Trained 128 records in 0.106099066 seconds. Throughput is 1206.4197 records/second. Loss is 1.9020916. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9201228878648233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58624/60000][Iteration 4210][Wall Clock 392.874618333s] Trained 128 records in 0.105318867 seconds. Throughput is 1215.3568 records/second. Loss is 1.9320688. Sequentialb692dd65's hyper parameters: Current learning rate is 1.919754271453254E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58752/60000][Iteration 4211][Wall Clock 392.980508319s] Trained 128 records in 0.105889986 seconds. Throughput is 1208.8018 records/second. Loss is 1.8939257. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9193857965451057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 58880/60000][Iteration 4212][Wall Clock 393.088251309s] Trained 128 records in 0.10774299 seconds. Throughput is 1188.0123 records/second. Loss is 1.954205. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9190174630589137E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:56 INFO  DistriOptimizer$:408 - [Epoch 9 59008/60000][Iteration 4213][Wall Clock 393.195481834s] Trained 128 records in 0.107230525 seconds. Throughput is 1193.69 records/second. Loss is 1.9553177. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9186492709132773E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59136/60000][Iteration 4214][Wall Clock 393.309058861s] Trained 128 records in 0.113577027 seconds. Throughput is 1126.9884 records/second. Loss is 1.9125344. Sequentialb692dd65's hyper parameters: Current learning rate is 1.918281220026856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59264/60000][Iteration 4215][Wall Clock 393.39441153s] Trained 128 records in 0.085352669 seconds. Throughput is 1499.6603 records/second. Loss is 1.9219022. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9179133103183735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59392/60000][Iteration 4216][Wall Clock 393.485596707s] Trained 128 records in 0.091185177 seconds. Throughput is 1403.7369 records/second. Loss is 1.894802. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9175455417066157E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59520/60000][Iteration 4217][Wall Clock 393.569689369s] Trained 128 records in 0.084092662 seconds. Throughput is 1522.1305 records/second. Loss is 1.9255661. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9171779141104295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59648/60000][Iteration 4218][Wall Clock 393.654829751s] Trained 128 records in 0.085140382 seconds. Throughput is 1503.3994 records/second. Loss is 1.9413297. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9168104274487253E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59776/60000][Iteration 4219][Wall Clock 393.73848559s] Trained 128 records in 0.083655839 seconds. Throughput is 1530.0785 records/second. Loss is 1.9001702. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9164430816404754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 59904/60000][Iteration 4220][Wall Clock 393.820883524s] Trained 128 records in 0.082397934 seconds. Throughput is 1553.4371 records/second. Loss is 1.9334565. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9160758766047133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:408 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.903488362s] Trained 128 records in 0.082604838 seconds. Throughput is 1549.546 records/second. Loss is 1.9214324. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9157088122605365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:57 INFO  DistriOptimizer$:452 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.903488362s] Epoch finished. Wall clock time is 395030.73568 ms
2019-10-15 07:52:57 INFO  DistriOptimizer$:111 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.903488362s] Validate model...
2019-10-15 07:52:58 INFO  DistriOptimizer$:178 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.903488362s] validate model throughput is 12447.028 records/second
2019-10-15 07:52:58 INFO  DistriOptimizer$:181 - [Epoch 9 60032/60000][Iteration 4221][Wall Clock 393.903488362s] Top1Accuracy is Accuracy(correct: 6166, count: 10000, accuracy: 0.6166)
2019-10-15 07:52:58 INFO  DistriOptimizer$:221 - [Wall Clock 395.03073568s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:52:58 INFO  DistriOptimizer$:226 - [Wall Clock 395.03073568s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
2019-10-15 07:52:58 INFO  DistriOptimizer$:408 - [Epoch 10 128/60000][Iteration 4222][Wall Clock 395.119027494s] Trained 128 records in 0.088291814 seconds. Throughput is 1449.738 records/second. Loss is 1.9622372. Sequentialb692dd65's hyper parameters: Current learning rate is 1.915341888527102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:58 INFO  DistriOptimizer$:408 - [Epoch 10 256/60000][Iteration 4223][Wall Clock 395.198925286s] Trained 128 records in 0.079897792 seconds. Throughput is 1602.0468 records/second. Loss is 1.9647161. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9149751053236308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:58 INFO  DistriOptimizer$:408 - [Epoch 10 384/60000][Iteration 4224][Wall Clock 395.282032734s] Trained 128 records in 0.083107448 seconds. Throughput is 1540.1748 records/second. Loss is 1.9401038. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9146084625694046E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:58 INFO  DistriOptimizer$:408 - [Epoch 10 512/60000][Iteration 4225][Wall Clock 395.358835484s] Trained 128 records in 0.07680275 seconds. Throughput is 1666.6069 records/second. Loss is 1.9608419. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9142419601837673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:58 INFO  DistriOptimizer$:408 - [Epoch 10 640/60000][Iteration 4226][Wall Clock 395.440321934s] Trained 128 records in 0.08148645 seconds. Throughput is 1570.8134 records/second. Loss is 1.9191633. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9138755980861245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 768/60000][Iteration 4227][Wall Clock 395.523362733s] Trained 128 records in 0.083040799 seconds. Throughput is 1541.411 records/second. Loss is 1.9609134. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9135093761959434E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 896/60000][Iteration 4228][Wall Clock 395.60190185s] Trained 128 records in 0.078539117 seconds. Throughput is 1629.7611 records/second. Loss is 1.932502. Sequentialb692dd65's hyper parameters: Current learning rate is 1.913143294432753E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1024/60000][Iteration 4229][Wall Clock 395.686325276s] Trained 128 records in 0.084423426 seconds. Throughput is 1516.1669 records/second. Loss is 1.8878692. Sequentialb692dd65's hyper parameters: Current learning rate is 1.912777352716144E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1152/60000][Iteration 4230][Wall Clock 395.769598613s] Trained 128 records in 0.083273337 seconds. Throughput is 1537.1067 records/second. Loss is 1.967568. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9124115509657678E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1280/60000][Iteration 4231][Wall Clock 395.857350757s] Trained 128 records in 0.087752144 seconds. Throughput is 1458.6538 records/second. Loss is 1.9543172. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9120458891013384E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1408/60000][Iteration 4232][Wall Clock 395.952244137s] Trained 128 records in 0.09489338 seconds. Throughput is 1348.8823 records/second. Loss is 1.9417039. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9116803670426305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1536/60000][Iteration 4233][Wall Clock 396.040477445s] Trained 128 records in 0.088233308 seconds. Throughput is 1450.6993 records/second. Loss is 1.9008493. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9113149847094801E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1664/60000][Iteration 4234][Wall Clock 396.129113921s] Trained 128 records in 0.088636476 seconds. Throughput is 1444.1008 records/second. Loss is 1.9502007. Sequentialb692dd65's hyper parameters: Current learning rate is 1.910949742021785E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1792/60000][Iteration 4235][Wall Clock 396.215731251s] Trained 128 records in 0.08661733 seconds. Throughput is 1477.7644 records/second. Loss is 1.913568. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9105846388995032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 1920/60000][Iteration 4236][Wall Clock 396.304339854s] Trained 128 records in 0.088608603 seconds. Throughput is 1444.555 records/second. Loss is 1.9298894. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9102196752626553E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 2048/60000][Iteration 4237][Wall Clock 396.389636921s] Trained 128 records in 0.085297067 seconds. Throughput is 1500.6377 records/second. Loss is 1.9303893. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9098548510313219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:52:59 INFO  DistriOptimizer$:408 - [Epoch 10 2176/60000][Iteration 4238][Wall Clock 396.474892237s] Trained 128 records in 0.085255316 seconds. Throughput is 1501.3727 records/second. Loss is 1.9125397. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9094901661256445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2304/60000][Iteration 4239][Wall Clock 396.558503843s] Trained 128 records in 0.083611606 seconds. Throughput is 1530.888 records/second. Loss is 1.9175427. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9091256204658265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2432/60000][Iteration 4240][Wall Clock 396.649870277s] Trained 128 records in 0.091366434 seconds. Throughput is 1400.9521 records/second. Loss is 1.9780123. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9087612139721323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2560/60000][Iteration 4241][Wall Clock 396.732012504s] Trained 128 records in 0.082142227 seconds. Throughput is 1558.2728 records/second. Loss is 1.9221674. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9083969465648855E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2688/60000][Iteration 4242][Wall Clock 396.815861352s] Trained 128 records in 0.083848848 seconds. Throughput is 1526.5564 records/second. Loss is 1.9077836. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9080328181644726E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2816/60000][Iteration 4243][Wall Clock 396.903960903s] Trained 128 records in 0.088099551 seconds. Throughput is 1452.9017 records/second. Loss is 1.9625573. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9076688286913393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 2944/60000][Iteration 4244][Wall Clock 396.989856018s] Trained 128 records in 0.085895115 seconds. Throughput is 1490.1896 records/second. Loss is 1.9913208. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9073049780659926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 3072/60000][Iteration 4245][Wall Clock 397.077350031s] Trained 128 records in 0.087494013 seconds. Throughput is 1462.9572 records/second. Loss is 1.8896323. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9069412662090009E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 3200/60000][Iteration 4246][Wall Clock 397.163976981s] Trained 128 records in 0.08662695 seconds. Throughput is 1477.6002 records/second. Loss is 1.9228835. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9065776930409913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 3328/60000][Iteration 4247][Wall Clock 397.2535975s] Trained 128 records in 0.089620519 seconds. Throughput is 1428.2444 records/second. Loss is 1.898411. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9062142584826535E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 3456/60000][Iteration 4248][Wall Clock 397.340111966s] Trained 128 records in 0.086514466 seconds. Throughput is 1479.5214 records/second. Loss is 1.9542121. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9058509624547362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:00 INFO  DistriOptimizer$:408 - [Epoch 10 3584/60000][Iteration 4249][Wall Clock 397.42795949s] Trained 128 records in 0.087847524 seconds. Throughput is 1457.0701 records/second. Loss is 1.9207722. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9054878048780488E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 3712/60000][Iteration 4250][Wall Clock 397.511438139s] Trained 128 records in 0.083478649 seconds. Throughput is 1533.3262 records/second. Loss is 1.9456278. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9051247856734617E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 3840/60000][Iteration 4251][Wall Clock 397.598799908s] Trained 128 records in 0.087361769 seconds. Throughput is 1465.1719 records/second. Loss is 1.985224. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9047619047619048E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 3968/60000][Iteration 4252][Wall Clock 397.683824926s] Trained 128 records in 0.085025018 seconds. Throughput is 1505.4392 records/second. Loss is 1.9374148. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9043991620643687E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4096/60000][Iteration 4253][Wall Clock 397.766165339s] Trained 128 records in 0.082340413 seconds. Throughput is 1554.5222 records/second. Loss is 1.9095813. Sequentialb692dd65's hyper parameters: Current learning rate is 1.904036557501904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4224/60000][Iteration 4254][Wall Clock 397.854998308s] Trained 128 records in 0.088832969 seconds. Throughput is 1440.9065 records/second. Loss is 1.9656171. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9036740909956216E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4352/60000][Iteration 4255][Wall Clock 397.943987231s] Trained 128 records in 0.088988923 seconds. Throughput is 1438.3812 records/second. Loss is 1.940208. Sequentialb692dd65's hyper parameters: Current learning rate is 1.903311762466692E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4480/60000][Iteration 4256][Wall Clock 398.031139385s] Trained 128 records in 0.087152154 seconds. Throughput is 1468.6958 records/second. Loss is 1.9292942. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9029495718363463E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4608/60000][Iteration 4257][Wall Clock 398.125739932s] Trained 128 records in 0.094600547 seconds. Throughput is 1353.0577 records/second. Loss is 1.9301379. Sequentialb692dd65's hyper parameters: Current learning rate is 1.902587519025875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4736/60000][Iteration 4258][Wall Clock 398.216002856s] Trained 128 records in 0.090262924 seconds. Throughput is 1418.0795 records/second. Loss is 1.906301. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9022256039566293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4864/60000][Iteration 4259][Wall Clock 398.294904194s] Trained 128 records in 0.078901338 seconds. Throughput is 1622.2793 records/second. Loss is 1.9373829. Sequentialb692dd65's hyper parameters: Current learning rate is 1.901863826550019E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 4992/60000][Iteration 4260][Wall Clock 398.378388074s] Trained 128 records in 0.08348388 seconds. Throughput is 1533.2301 records/second. Loss is 1.9440038. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9015021867275147E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:01 INFO  DistriOptimizer$:408 - [Epoch 10 5120/60000][Iteration 4261][Wall Clock 398.462350651s] Trained 128 records in 0.083962577 seconds. Throughput is 1524.4888 records/second. Loss is 1.9386913. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9011406844106465E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5248/60000][Iteration 4262][Wall Clock 398.550216838s] Trained 128 records in 0.087866187 seconds. Throughput is 1456.7606 records/second. Loss is 1.9627796. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9007793195210037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5376/60000][Iteration 4263][Wall Clock 398.633921828s] Trained 128 records in 0.08370499 seconds. Throughput is 1529.1799 records/second. Loss is 1.953763. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9004180919802356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5504/60000][Iteration 4264][Wall Clock 398.71690833s] Trained 128 records in 0.082986502 seconds. Throughput is 1542.4194 records/second. Loss is 1.9223381. Sequentialb692dd65's hyper parameters: Current learning rate is 1.9000570017100514E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5632/60000][Iteration 4265][Wall Clock 398.802430998s] Trained 128 records in 0.085522668 seconds. Throughput is 1496.6792 records/second. Loss is 1.9290713. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8996960486322188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5760/60000][Iteration 4266][Wall Clock 398.894963955s] Trained 128 records in 0.092532957 seconds. Throughput is 1383.291 records/second. Loss is 1.9049814. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8993352326685662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 5888/60000][Iteration 4267][Wall Clock 398.980347348s] Trained 128 records in 0.085383393 seconds. Throughput is 1499.1206 records/second. Loss is 1.893556. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8989745537409798E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 6016/60000][Iteration 4268][Wall Clock 399.065474411s] Trained 128 records in 0.085127063 seconds. Throughput is 1503.6346 records/second. Loss is 1.9442306. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8986140117714068E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 6144/60000][Iteration 4269][Wall Clock 399.149271542s] Trained 128 records in 0.083797131 seconds. Throughput is 1527.4985 records/second. Loss is 1.9420474. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8982536066818528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 6272/60000][Iteration 4270][Wall Clock 399.236129827s] Trained 128 records in 0.086858285 seconds. Throughput is 1473.6648 records/second. Loss is 1.9234074. Sequentialb692dd65's hyper parameters: Current learning rate is 1.897893338394382E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 6400/60000][Iteration 4271][Wall Clock 399.321507468s] Trained 128 records in 0.085377641 seconds. Throughput is 1499.2216 records/second. Loss is 1.8807571. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8975332068311195E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:02 INFO  DistriOptimizer$:408 - [Epoch 10 6528/60000][Iteration 4272][Wall Clock 399.406828905s] Trained 128 records in 0.085321437 seconds. Throughput is 1500.2092 records/second. Loss is 1.9254891. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8971732119142478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 6656/60000][Iteration 4273][Wall Clock 399.491021329s] Trained 128 records in 0.084192424 seconds. Throughput is 1520.3268 records/second. Loss is 1.9790471. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8968133535660092E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 6784/60000][Iteration 4274][Wall Clock 399.578987152s] Trained 128 records in 0.087965823 seconds. Throughput is 1455.1106 records/second. Loss is 1.9500034. Sequentialb692dd65's hyper parameters: Current learning rate is 1.896453631708705E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 6912/60000][Iteration 4275][Wall Clock 399.663535504s] Trained 128 records in 0.084548352 seconds. Throughput is 1513.9265 records/second. Loss is 1.9203384. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8960940462646946E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7040/60000][Iteration 4276][Wall Clock 399.750610894s] Trained 128 records in 0.08707539 seconds. Throughput is 1469.9906 records/second. Loss is 1.9170334. Sequentialb692dd65's hyper parameters: Current learning rate is 1.895734597156398E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7168/60000][Iteration 4277][Wall Clock 399.837267622s] Trained 128 records in 0.086656728 seconds. Throughput is 1477.0925 records/second. Loss is 1.939898. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8953752843062926E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7296/60000][Iteration 4278][Wall Clock 399.925439239s] Trained 128 records in 0.088171617 seconds. Throughput is 1451.7144 records/second. Loss is 1.9364244. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8950161076369148E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7424/60000][Iteration 4279][Wall Clock 400.007261461s] Trained 128 records in 0.081822222 seconds. Throughput is 1564.3672 records/second. Loss is 1.9507753. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8946570670708602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7552/60000][Iteration 4280][Wall Clock 400.097437624s] Trained 128 records in 0.090176163 seconds. Throughput is 1419.4438 records/second. Loss is 1.9276825. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8942981625307825E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7680/60000][Iteration 4281][Wall Clock 400.201577456s] Trained 128 records in 0.104139832 seconds. Throughput is 1229.1166 records/second. Loss is 1.9425364. Sequentialb692dd65's hyper parameters: Current learning rate is 1.893939393939394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7808/60000][Iteration 4282][Wall Clock 400.316680287s] Trained 128 records in 0.115102831 seconds. Throughput is 1112.0492 records/second. Loss is 1.945845. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8935807612194662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:03 INFO  DistriOptimizer$:408 - [Epoch 10 7936/60000][Iteration 4283][Wall Clock 400.420776792s] Trained 128 records in 0.104096505 seconds. Throughput is 1229.6283 records/second. Loss is 1.9227512. Sequentialb692dd65's hyper parameters: Current learning rate is 1.893222264293828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8064/60000][Iteration 4284][Wall Clock 400.529134421s] Trained 128 records in 0.108357629 seconds. Throughput is 1181.2736 records/second. Loss is 1.943065. Sequentialb692dd65's hyper parameters: Current learning rate is 1.892863903085368E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8192/60000][Iteration 4285][Wall Clock 400.634984053s] Trained 128 records in 0.105849632 seconds. Throughput is 1209.2626 records/second. Loss is 1.8773261. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8925056775170325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8320/60000][Iteration 4286][Wall Clock 400.744042271s] Trained 128 records in 0.109058218 seconds. Throughput is 1173.685 records/second. Loss is 1.9358987. Sequentialb692dd65's hyper parameters: Current learning rate is 1.892147587511826E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8448/60000][Iteration 4287][Wall Clock 400.83017388s] Trained 128 records in 0.086131609 seconds. Throughput is 1486.0979 records/second. Loss is 1.9048369. Sequentialb692dd65's hyper parameters: Current learning rate is 1.891789632992811E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8576/60000][Iteration 4288][Wall Clock 400.916704298s] Trained 128 records in 0.086530418 seconds. Throughput is 1479.2487 records/second. Loss is 1.9289815. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8914318138831096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8704/60000][Iteration 4289][Wall Clock 401.00017788s] Trained 128 records in 0.083473582 seconds. Throughput is 1533.4192 records/second. Loss is 1.9231625. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8910741301059002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8832/60000][Iteration 4290][Wall Clock 401.086327995s] Trained 128 records in 0.086150115 seconds. Throughput is 1485.7786 records/second. Loss is 1.9274932. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8907165815844207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 8960/60000][Iteration 4291][Wall Clock 401.175194375s] Trained 128 records in 0.08886638 seconds. Throughput is 1440.3647 records/second. Loss is 1.9589549. Sequentialb692dd65's hyper parameters: Current learning rate is 1.890359168241966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 9088/60000][Iteration 4292][Wall Clock 401.253896906s] Trained 128 records in 0.078702531 seconds. Throughput is 1626.3772 records/second. Loss is 1.9323853. Sequentialb692dd65's hyper parameters: Current learning rate is 1.89000189000189E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 9216/60000][Iteration 4293][Wall Clock 401.343484731s] Trained 128 records in 0.089587825 seconds. Throughput is 1428.7656 records/second. Loss is 1.9275781. Sequentialb692dd65's hyper parameters: Current learning rate is 1.889644746787604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:04 INFO  DistriOptimizer$:408 - [Epoch 10 9344/60000][Iteration 4294][Wall Clock 401.428755194s] Trained 128 records in 0.085270463 seconds. Throughput is 1501.106 records/second. Loss is 1.8719864. Sequentialb692dd65's hyper parameters: Current learning rate is 1.889287738522577E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 9472/60000][Iteration 4295][Wall Clock 401.514517865s] Trained 128 records in 0.085762671 seconds. Throughput is 1492.4908 records/second. Loss is 1.9243846. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8889308651303362E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 9600/60000][Iteration 4296][Wall Clock 401.600464166s] Trained 128 records in 0.085946301 seconds. Throughput is 1489.302 records/second. Loss is 1.9170939. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8885741265344666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 9728/60000][Iteration 4297][Wall Clock 401.687921084s] Trained 128 records in 0.087456918 seconds. Throughput is 1463.5778 records/second. Loss is 1.9630303. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8882175226586103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 9856/60000][Iteration 4298][Wall Clock 401.774027996s] Trained 128 records in 0.086106912 seconds. Throughput is 1486.5242 records/second. Loss is 1.9809532. Sequentialb692dd65's hyper parameters: Current learning rate is 1.887861053426468E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 9984/60000][Iteration 4299][Wall Clock 401.862580729s] Trained 128 records in 0.088552733 seconds. Throughput is 1445.4663 records/second. Loss is 1.9500899. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8875047187617969E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10112/60000][Iteration 4300][Wall Clock 401.949387774s] Trained 128 records in 0.086807045 seconds. Throughput is 1474.5348 records/second. Loss is 1.9582645. Sequentialb692dd65's hyper parameters: Current learning rate is 1.887148518588413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10240/60000][Iteration 4301][Wall Clock 402.035303608s] Trained 128 records in 0.085915834 seconds. Throughput is 1489.8302 records/second. Loss is 1.9410263. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8867924528301889E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10368/60000][Iteration 4302][Wall Clock 402.121217606s] Trained 128 records in 0.085913998 seconds. Throughput is 1489.8619 records/second. Loss is 1.8773444. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8864365214110544E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10496/60000][Iteration 4303][Wall Clock 402.204495688s] Trained 128 records in 0.083278082 seconds. Throughput is 1537.019 records/second. Loss is 1.9369286. Sequentialb692dd65's hyper parameters: Current learning rate is 1.886080724254998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10624/60000][Iteration 4304][Wall Clock 402.28969933s] Trained 128 records in 0.085203642 seconds. Throughput is 1502.2832 records/second. Loss is 1.9032468. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8857250612860644E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10752/60000][Iteration 4305][Wall Clock 402.372396788s] Trained 128 records in 0.082697458 seconds. Throughput is 1547.8105 records/second. Loss is 1.922266. Sequentialb692dd65's hyper parameters: Current learning rate is 1.885369532428356E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:05 INFO  DistriOptimizer$:408 - [Epoch 10 10880/60000][Iteration 4306][Wall Clock 402.4567301s] Trained 128 records in 0.084333312 seconds. Throughput is 1517.7869 records/second. Loss is 1.9527111. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8850141376060322E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11008/60000][Iteration 4307][Wall Clock 402.552112505s] Trained 128 records in 0.095382405 seconds. Throughput is 1341.9666 records/second. Loss is 1.9628185. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8846588767433095E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11136/60000][Iteration 4308][Wall Clock 402.634745445s] Trained 128 records in 0.08263294 seconds. Throughput is 1549.0192 records/second. Loss is 1.9495134. Sequentialb692dd65's hyper parameters: Current learning rate is 1.884303749764462E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11264/60000][Iteration 4309][Wall Clock 402.716282598s] Trained 128 records in 0.081537153 seconds. Throughput is 1569.8365 records/second. Loss is 1.9093102. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8839487565938207E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11392/60000][Iteration 4310][Wall Clock 402.797674796s] Trained 128 records in 0.081392198 seconds. Throughput is 1572.6323 records/second. Loss is 1.9678788. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8835938971557733E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11520/60000][Iteration 4311][Wall Clock 402.877140897s] Trained 128 records in 0.079466101 seconds. Throughput is 1610.7496 records/second. Loss is 1.8884618. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8832391713747646E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11648/60000][Iteration 4312][Wall Clock 402.964444681s] Trained 128 records in 0.087303784 seconds. Throughput is 1466.1449 records/second. Loss is 1.9591681. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8828845791752966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11776/60000][Iteration 4313][Wall Clock 403.054058998s] Trained 128 records in 0.089614317 seconds. Throughput is 1428.3431 records/second. Loss is 1.9290231. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8825301204819275E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 11904/60000][Iteration 4314][Wall Clock 403.14179204s] Trained 128 records in 0.087733042 seconds. Throughput is 1458.9713 records/second. Loss is 1.9243816. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8821757952192737E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 12032/60000][Iteration 4315][Wall Clock 403.226510052s] Trained 128 records in 0.084718012 seconds. Throughput is 1510.8948 records/second. Loss is 1.9145068. Sequentialb692dd65's hyper parameters: Current learning rate is 1.881821603312006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 12160/60000][Iteration 4316][Wall Clock 403.310347299s] Trained 128 records in 0.083837247 seconds. Throughput is 1526.7677 records/second. Loss is 1.928508. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8814675446848542E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:06 INFO  DistriOptimizer$:408 - [Epoch 10 12288/60000][Iteration 4317][Wall Clock 403.400891938s] Trained 128 records in 0.090544639 seconds. Throughput is 1413.6674 records/second. Loss is 1.9395471. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8811136192626037E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 12416/60000][Iteration 4318][Wall Clock 403.484453302s] Trained 128 records in 0.083561364 seconds. Throughput is 1531.8085 records/second. Loss is 1.9858627. Sequentialb692dd65's hyper parameters: Current learning rate is 1.880759826970096E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 12544/60000][Iteration 4319][Wall Clock 403.570591967s] Trained 128 records in 0.086138665 seconds. Throughput is 1485.9761 records/second. Loss is 1.8779638. Sequentialb692dd65's hyper parameters: Current learning rate is 1.88040616773223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 12672/60000][Iteration 4320][Wall Clock 403.654799621s] Trained 128 records in 0.084207654 seconds. Throughput is 1520.0519 records/second. Loss is 1.9372914. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8800526414739614E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 12800/60000][Iteration 4321][Wall Clock 403.737405529s] Trained 128 records in 0.082605908 seconds. Throughput is 1549.526 records/second. Loss is 1.8970516. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8796992481203006E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 12928/60000][Iteration 4322][Wall Clock 403.822970808s] Trained 128 records in 0.085565279 seconds. Throughput is 1495.934 records/second. Loss is 1.9457133. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8793459875963167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13056/60000][Iteration 4323][Wall Clock 403.908533895s] Trained 128 records in 0.085563087 seconds. Throughput is 1495.9722 records/second. Loss is 1.9528837. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8789928598271326E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13184/60000][Iteration 4324][Wall Clock 403.994796381s] Trained 128 records in 0.086262486 seconds. Throughput is 1483.8431 records/second. Loss is 1.8920931. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8786398647379295E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13312/60000][Iteration 4325][Wall Clock 404.080529277s] Trained 128 records in 0.085732896 seconds. Throughput is 1493.0092 records/second. Loss is 1.9221597. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8782870022539445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13440/60000][Iteration 4326][Wall Clock 404.168350903s] Trained 128 records in 0.087821626 seconds. Throughput is 1457.4998 records/second. Loss is 1.915695. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8779342723004695E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13568/60000][Iteration 4327][Wall Clock 404.257129279s] Trained 128 records in 0.088778376 seconds. Throughput is 1441.7925 records/second. Loss is 1.8906814. Sequentialb692dd65's hyper parameters: Current learning rate is 1.877581674802854E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13696/60000][Iteration 4328][Wall Clock 404.343163904s] Trained 128 records in 0.086034625 seconds. Throughput is 1487.7731 records/second. Loss is 1.9075553. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8772292096865028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:07 INFO  DistriOptimizer$:408 - [Epoch 10 13824/60000][Iteration 4329][Wall Clock 404.426271266s] Trained 128 records in 0.083107362 seconds. Throughput is 1540.1765 records/second. Loss is 1.871861. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8768768768768769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 13952/60000][Iteration 4330][Wall Clock 404.510700815s] Trained 128 records in 0.084429549 seconds. Throughput is 1516.0569 records/second. Loss is 1.9394934. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8765246762994934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14080/60000][Iteration 4331][Wall Clock 404.594979296s] Trained 128 records in 0.084278481 seconds. Throughput is 1518.7744 records/second. Loss is 1.9502739. Sequentialb692dd65's hyper parameters: Current learning rate is 1.876172607879925E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14208/60000][Iteration 4332][Wall Clock 404.68454576s] Trained 128 records in 0.089566464 seconds. Throughput is 1429.1063 records/second. Loss is 1.9292611. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8758206715438003E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14336/60000][Iteration 4333][Wall Clock 404.786012994s] Trained 128 records in 0.101467234 seconds. Throughput is 1261.491 records/second. Loss is 1.961832. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8754688672168043E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14464/60000][Iteration 4334][Wall Clock 404.876397507s] Trained 128 records in 0.090384513 seconds. Throughput is 1416.1719 records/second. Loss is 1.9296238. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8751171948246765E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14592/60000][Iteration 4335][Wall Clock 404.963152461s] Trained 128 records in 0.086754954 seconds. Throughput is 1475.42 records/second. Loss is 1.9283279. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8747656542932132E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14720/60000][Iteration 4336][Wall Clock 405.045264975s] Trained 128 records in 0.082112514 seconds. Throughput is 1558.8367 records/second. Loss is 1.9437892. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8744142455482662E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14848/60000][Iteration 4337][Wall Clock 405.129657138s] Trained 128 records in 0.084392163 seconds. Throughput is 1516.7285 records/second. Loss is 1.9279369. Sequentialb692dd65's hyper parameters: Current learning rate is 1.874062968515742E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 14976/60000][Iteration 4338][Wall Clock 405.213094831s] Trained 128 records in 0.083437693 seconds. Throughput is 1534.0787 records/second. Loss is 1.8947868. Sequentialb692dd65's hyper parameters: Current learning rate is 1.873711823121604E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 15104/60000][Iteration 4339][Wall Clock 405.299655377s] Trained 128 records in 0.086560546 seconds. Throughput is 1478.7338 records/second. Loss is 1.9007552. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8733608092918696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:08 INFO  DistriOptimizer$:408 - [Epoch 10 15232/60000][Iteration 4340][Wall Clock 405.381561717s] Trained 128 records in 0.08190634 seconds. Throughput is 1562.7606 records/second. Loss is 1.9272112. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8730099269526128E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 15360/60000][Iteration 4341][Wall Clock 405.465283731s] Trained 128 records in 0.083722014 seconds. Throughput is 1528.869 records/second. Loss is 1.9531436. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8726591760299626E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 15488/60000][Iteration 4342][Wall Clock 405.559010067s] Trained 128 records in 0.093726336 seconds. Throughput is 1365.678 records/second. Loss is 1.957677. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8723085564501028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 15616/60000][Iteration 4343][Wall Clock 405.641953488s] Trained 128 records in 0.082943421 seconds. Throughput is 1543.2206 records/second. Loss is 1.9369993. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8719580681392735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 15744/60000][Iteration 4344][Wall Clock 405.728991731s] Trained 128 records in 0.087038243 seconds. Throughput is 1470.6179 records/second. Loss is 1.9288508. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8716077110237696E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 15872/60000][Iteration 4345][Wall Clock 405.813731043s] Trained 128 records in 0.084739312 seconds. Throughput is 1510.515 records/second. Loss is 1.948164. Sequentialb692dd65's hyper parameters: Current learning rate is 1.87125748502994E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16000/60000][Iteration 4346][Wall Clock 405.896363433s] Trained 128 records in 0.08263239 seconds. Throughput is 1549.0293 records/second. Loss is 1.9257661. Sequentialb692dd65's hyper parameters: Current learning rate is 1.870907390084191E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16128/60000][Iteration 4347][Wall Clock 405.982234726s] Trained 128 records in 0.085871293 seconds. Throughput is 1490.6029 records/second. Loss is 1.9240136. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8705574261129816E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16256/60000][Iteration 4348][Wall Clock 406.063860529s] Trained 128 records in 0.081625803 seconds. Throughput is 1568.1316 records/second. Loss is 1.8812436. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8702075930428276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16384/60000][Iteration 4349][Wall Clock 406.149101177s] Trained 128 records in 0.085240648 seconds. Throughput is 1501.631 records/second. Loss is 1.9179729. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8698578908002991E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16512/60000][Iteration 4350][Wall Clock 406.233431094s] Trained 128 records in 0.084329917 seconds. Throughput is 1517.848 records/second. Loss is 1.9608111. Sequentialb692dd65's hyper parameters: Current learning rate is 1.869508319312021E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16640/60000][Iteration 4351][Wall Clock 406.318557464s] Trained 128 records in 0.08512637 seconds. Throughput is 1503.6469 records/second. Loss is 1.8704305. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8691588785046728E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:09 INFO  DistriOptimizer$:408 - [Epoch 10 16768/60000][Iteration 4352][Wall Clock 406.401415607s] Trained 128 records in 0.082858143 seconds. Throughput is 1544.8088 records/second. Loss is 1.9029845. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8688095683049897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 16896/60000][Iteration 4353][Wall Clock 406.486524221s] Trained 128 records in 0.085108614 seconds. Throughput is 1503.9606 records/second. Loss is 1.9039685. Sequentialb692dd65's hyper parameters: Current learning rate is 1.868460388639761E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17024/60000][Iteration 4354][Wall Clock 406.569326583s] Trained 128 records in 0.082802362 seconds. Throughput is 1545.8496 records/second. Loss is 1.9219913. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8681113394358306E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17152/60000][Iteration 4355][Wall Clock 406.653633834s] Trained 128 records in 0.084307251 seconds. Throughput is 1518.2561 records/second. Loss is 1.9216412. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8677624206200972E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17280/60000][Iteration 4356][Wall Clock 406.736458756s] Trained 128 records in 0.082824922 seconds. Throughput is 1545.4286 records/second. Loss is 1.9432843. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8674136321195143E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17408/60000][Iteration 4357][Wall Clock 406.822301008s] Trained 128 records in 0.085842252 seconds. Throughput is 1491.1072 records/second. Loss is 1.9088321. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8670649738610905E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17536/60000][Iteration 4358][Wall Clock 406.915534539s] Trained 128 records in 0.093233531 seconds. Throughput is 1372.8966 records/second. Loss is 1.9049054. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8667164457718873E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17664/60000][Iteration 4359][Wall Clock 406.993407772s] Trained 128 records in 0.077873233 seconds. Throughput is 1643.697 records/second. Loss is 1.9369622. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8663680477790223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17792/60000][Iteration 4360][Wall Clock 407.072288623s] Trained 128 records in 0.078880851 seconds. Throughput is 1622.7004 records/second. Loss is 1.8759229. Sequentialb692dd65's hyper parameters: Current learning rate is 1.866019779809666E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 17920/60000][Iteration 4361][Wall Clock 407.158595742s] Trained 128 records in 0.086307119 seconds. Throughput is 1483.0758 records/second. Loss is 1.9140582. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8656716417910448E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 18048/60000][Iteration 4362][Wall Clock 407.241936892s] Trained 128 records in 0.08334115 seconds. Throughput is 1535.856 records/second. Loss is 1.939905. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8653236336504386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 18176/60000][Iteration 4363][Wall Clock 407.324445357s] Trained 128 records in 0.082508465 seconds. Throughput is 1551.356 records/second. Loss is 1.8870178. Sequentialb692dd65's hyper parameters: Current learning rate is 1.864975755315181E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:10 INFO  DistriOptimizer$:408 - [Epoch 10 18304/60000][Iteration 4364][Wall Clock 407.409123185s] Trained 128 records in 0.084677828 seconds. Throughput is 1511.6117 records/second. Loss is 1.9788061. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8646280067126608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 18432/60000][Iteration 4365][Wall Clock 407.49275082s] Trained 128 records in 0.083627635 seconds. Throughput is 1530.5946 records/second. Loss is 1.9423225. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8642803877703208E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 18560/60000][Iteration 4366][Wall Clock 407.579346895s] Trained 128 records in 0.086596075 seconds. Throughput is 1478.1271 records/second. Loss is 1.9602498. Sequentialb692dd65's hyper parameters: Current learning rate is 1.863932898415657E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 18688/60000][Iteration 4367][Wall Clock 407.665372782s] Trained 128 records in 0.086025887 seconds. Throughput is 1487.9242 records/second. Loss is 1.9120669. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8635855385762209E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 18816/60000][Iteration 4368][Wall Clock 407.761110549s] Trained 128 records in 0.095737767 seconds. Throughput is 1336.9854 records/second. Loss is 1.9277416. Sequentialb692dd65's hyper parameters: Current learning rate is 1.863238308179616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 18944/60000][Iteration 4369][Wall Clock 407.844953561s] Trained 128 records in 0.083843012 seconds. Throughput is 1526.6626 records/second. Loss is 1.935084. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8628912071535022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19072/60000][Iteration 4370][Wall Clock 407.928272697s] Trained 128 records in 0.083319136 seconds. Throughput is 1536.2617 records/second. Loss is 1.918698. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8625442354255913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19200/60000][Iteration 4371][Wall Clock 408.014623947s] Trained 128 records in 0.08635125 seconds. Throughput is 1482.3177 records/second. Loss is 1.9382515. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8621973929236498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19328/60000][Iteration 4372][Wall Clock 408.104170239s] Trained 128 records in 0.089546292 seconds. Throughput is 1429.4282 records/second. Loss is 1.9371948. Sequentialb692dd65's hyper parameters: Current learning rate is 1.861850679575498E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19456/60000][Iteration 4373][Wall Clock 408.195455507s] Trained 128 records in 0.091285268 seconds. Throughput is 1402.1978 records/second. Loss is 1.8780355. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8615040953090097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19584/60000][Iteration 4374][Wall Clock 408.281345612s] Trained 128 records in 0.085890105 seconds. Throughput is 1490.2764 records/second. Loss is 1.9111178. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8611576400521124E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:11 INFO  DistriOptimizer$:408 - [Epoch 10 19712/60000][Iteration 4375][Wall Clock 408.374827122s] Trained 128 records in 0.09348151 seconds. Throughput is 1369.2548 records/second. Loss is 1.9014003. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8608113137327876E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 19840/60000][Iteration 4376][Wall Clock 408.46012367s] Trained 128 records in 0.085296548 seconds. Throughput is 1500.6469 records/second. Loss is 1.973281. Sequentialb692dd65's hyper parameters: Current learning rate is 1.86046511627907E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 19968/60000][Iteration 4377][Wall Clock 408.551472013s] Trained 128 records in 0.091348343 seconds. Throughput is 1401.2296 records/second. Loss is 1.9466219. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8601190476190475E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20096/60000][Iteration 4378][Wall Clock 408.637128462s] Trained 128 records in 0.085656449 seconds. Throughput is 1494.3417 records/second. Loss is 1.9261422. Sequentialb692dd65's hyper parameters: Current learning rate is 1.859773107680863E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20224/60000][Iteration 4379][Wall Clock 408.722970844s] Trained 128 records in 0.085842382 seconds. Throughput is 1491.105 records/second. Loss is 1.9126416. Sequentialb692dd65's hyper parameters: Current learning rate is 1.859427296392711E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20352/60000][Iteration 4380][Wall Clock 408.809940947s] Trained 128 records in 0.086970103 seconds. Throughput is 1471.7701 records/second. Loss is 1.9439998. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8590816136828406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20480/60000][Iteration 4381][Wall Clock 408.899115556s] Trained 128 records in 0.089174609 seconds. Throughput is 1435.3862 records/second. Loss is 1.9380212. Sequentialb692dd65's hyper parameters: Current learning rate is 1.858736059479554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20608/60000][Iteration 4382][Wall Clock 408.986543853s] Trained 128 records in 0.087428297 seconds. Throughput is 1464.0569 records/second. Loss is 1.9492191. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8583906337112061E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20736/60000][Iteration 4383][Wall Clock 409.087412357s] Trained 128 records in 0.100868504 seconds. Throughput is 1268.9789 records/second. Loss is 1.9093167. Sequentialb692dd65's hyper parameters: Current learning rate is 1.858045336306206E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20864/60000][Iteration 4384][Wall Clock 409.171194512s] Trained 128 records in 0.083782155 seconds. Throughput is 1527.7717 records/second. Loss is 1.914914. Sequentialb692dd65's hyper parameters: Current learning rate is 1.857700167193015E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 20992/60000][Iteration 4385][Wall Clock 409.257297649s] Trained 128 records in 0.086103137 seconds. Throughput is 1486.5894 records/second. Loss is 1.9712933. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8573551263001485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:12 INFO  DistriOptimizer$:408 - [Epoch 10 21120/60000][Iteration 4386][Wall Clock 409.35056905s] Trained 128 records in 0.093271401 seconds. Throughput is 1372.3391 records/second. Loss is 1.9525675. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8570102135561747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21248/60000][Iteration 4387][Wall Clock 409.440631189s] Trained 128 records in 0.090062139 seconds. Throughput is 1421.241 records/second. Loss is 1.9053472. Sequentialb692dd65's hyper parameters: Current learning rate is 1.856665428889714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21376/60000][Iteration 4388][Wall Clock 409.529930903s] Trained 128 records in 0.089299714 seconds. Throughput is 1433.3752 records/second. Loss is 1.926308. Sequentialb692dd65's hyper parameters: Current learning rate is 1.856320772229441E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21504/60000][Iteration 4389][Wall Clock 409.619597642s] Trained 128 records in 0.089666739 seconds. Throughput is 1427.5082 records/second. Loss is 1.9288883. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8559762435040833E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21632/60000][Iteration 4390][Wall Clock 409.707107976s] Trained 128 records in 0.087510334 seconds. Throughput is 1462.6844 records/second. Loss is 1.9291382. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8556318426424197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21760/60000][Iteration 4391][Wall Clock 409.800962803s] Trained 128 records in 0.093854827 seconds. Throughput is 1363.8083 records/second. Loss is 1.9398812. Sequentialb692dd65's hyper parameters: Current learning rate is 1.855287569573284E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 21888/60000][Iteration 4392][Wall Clock 409.8889147s] Trained 128 records in 0.087951897 seconds. Throughput is 1455.341 records/second. Loss is 1.9541627. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8549434242255613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 22016/60000][Iteration 4393][Wall Clock 409.975525663s] Trained 128 records in 0.086610963 seconds. Throughput is 1477.8729 records/second. Loss is 1.934293. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8545994065281897E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 22144/60000][Iteration 4394][Wall Clock 410.072995497s] Trained 128 records in 0.097469834 seconds. Throughput is 1313.2268 records/second. Loss is 1.9262581. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8542555164101615E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 22272/60000][Iteration 4395][Wall Clock 410.163450535s] Trained 128 records in 0.090455038 seconds. Throughput is 1415.0676 records/second. Loss is 1.9429953. Sequentialb692dd65's hyper parameters: Current learning rate is 1.853911753800519E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 22400/60000][Iteration 4396][Wall Clock 410.248398685s] Trained 128 records in 0.08494815 seconds. Throughput is 1506.8015 records/second. Loss is 1.9512755. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8535681186283596E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:13 INFO  DistriOptimizer$:408 - [Epoch 10 22528/60000][Iteration 4397][Wall Clock 410.341286939s] Trained 128 records in 0.092888254 seconds. Throughput is 1377.9999 records/second. Loss is 1.923753. Sequentialb692dd65's hyper parameters: Current learning rate is 1.853224610822832E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 22656/60000][Iteration 4398][Wall Clock 410.432484336s] Trained 128 records in 0.091197397 seconds. Throughput is 1403.5488 records/second. Loss is 1.9329163. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8528812303131369E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 22784/60000][Iteration 4399][Wall Clock 410.522366039s] Trained 128 records in 0.089881703 seconds. Throughput is 1424.0941 records/second. Loss is 1.8940127. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8525379770285293E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 22912/60000][Iteration 4400][Wall Clock 410.613258021s] Trained 128 records in 0.090891982 seconds. Throughput is 1408.265 records/second. Loss is 1.912776. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8521948508983145E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23040/60000][Iteration 4401][Wall Clock 410.700764554s] Trained 128 records in 0.087506533 seconds. Throughput is 1462.7479 records/second. Loss is 1.9257832. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8518518518518518E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23168/60000][Iteration 4402][Wall Clock 410.787779274s] Trained 128 records in 0.08701472 seconds. Throughput is 1471.0155 records/second. Loss is 1.8766557. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8515089798185522E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23296/60000][Iteration 4403][Wall Clock 410.874792384s] Trained 128 records in 0.08701311 seconds. Throughput is 1471.0427 records/second. Loss is 1.881495. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8511662347278786E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23424/60000][Iteration 4404][Wall Clock 410.962370664s] Trained 128 records in 0.08757828 seconds. Throughput is 1461.5496 records/second. Loss is 1.9183127. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8508236165093466E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23552/60000][Iteration 4405][Wall Clock 411.05005472s] Trained 128 records in 0.087684056 seconds. Throughput is 1459.7865 records/second. Loss is 1.926966. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8504811250925242E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23680/60000][Iteration 4406][Wall Clock 411.141210723s] Trained 128 records in 0.091156003 seconds. Throughput is 1404.1862 records/second. Loss is 1.9969462. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8501387604070305E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23808/60000][Iteration 4407][Wall Clock 411.230061286s] Trained 128 records in 0.088850563 seconds. Throughput is 1440.6211 records/second. Loss is 1.9467894. Sequentialb692dd65's hyper parameters: Current learning rate is 1.849796522382538E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 23936/60000][Iteration 4408][Wall Clock 411.321130909s] Trained 128 records in 0.091069623 seconds. Throughput is 1405.5181 records/second. Loss is 1.9102141. Sequentialb692dd65's hyper parameters: Current learning rate is 1.84945441094877E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:14 INFO  DistriOptimizer$:408 - [Epoch 10 24064/60000][Iteration 4409][Wall Clock 411.407502151s] Trained 128 records in 0.086371242 seconds. Throughput is 1481.9747 records/second. Loss is 1.9273573. Sequentialb692dd65's hyper parameters: Current learning rate is 1.849112426035503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24192/60000][Iteration 4410][Wall Clock 411.495459245s] Trained 128 records in 0.087957094 seconds. Throughput is 1455.255 records/second. Loss is 1.9156414. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8487705675725643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24320/60000][Iteration 4411][Wall Clock 411.587119814s] Trained 128 records in 0.091660569 seconds. Throughput is 1396.4565 records/second. Loss is 1.8887597. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8484288354898336E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24448/60000][Iteration 4412][Wall Clock 411.675496635s] Trained 128 records in 0.088376821 seconds. Throughput is 1448.3436 records/second. Loss is 1.9108032. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8480872297172425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24576/60000][Iteration 4413][Wall Clock 411.763212893s] Trained 128 records in 0.087716258 seconds. Throughput is 1459.2506 records/second. Loss is 1.8973209. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8477457501847746E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24704/60000][Iteration 4414][Wall Clock 411.856309866s] Trained 128 records in 0.093096973 seconds. Throughput is 1374.9104 records/second. Loss is 1.9010353. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8474043968224645E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24832/60000][Iteration 4415][Wall Clock 411.943930632s] Trained 128 records in 0.087620766 seconds. Throughput is 1460.841 records/second. Loss is 1.8817669. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8470631695603992E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 24960/60000][Iteration 4416][Wall Clock 412.034100722s] Trained 128 records in 0.09017009 seconds. Throughput is 1419.5394 records/second. Loss is 1.950287. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8467220683287167E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 25088/60000][Iteration 4417][Wall Clock 412.123473616s] Trained 128 records in 0.089372894 seconds. Throughput is 1432.2015 records/second. Loss is 1.9274647. Sequentialb692dd65's hyper parameters: Current learning rate is 1.846381093057607E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 25216/60000][Iteration 4418][Wall Clock 412.21378596s] Trained 128 records in 0.090312344 seconds. Throughput is 1417.3035 records/second. Loss is 1.9379711. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8460402436773122E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 25344/60000][Iteration 4419][Wall Clock 412.308920544s] Trained 128 records in 0.095134584 seconds. Throughput is 1345.4623 records/second. Loss is 1.9257878. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8456995201181247E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:15 INFO  DistriOptimizer$:408 - [Epoch 10 25472/60000][Iteration 4420][Wall Clock 412.398265168s] Trained 128 records in 0.089344624 seconds. Throughput is 1432.6548 records/second. Loss is 1.937729. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8453589223103894E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 25600/60000][Iteration 4421][Wall Clock 412.488302119s] Trained 128 records in 0.090036951 seconds. Throughput is 1421.6385 records/second. Loss is 1.9360454. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8450184501845018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 25728/60000][Iteration 4422][Wall Clock 412.577323528s] Trained 128 records in 0.089021409 seconds. Throughput is 1437.8564 records/second. Loss is 1.8876985. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8446781036709093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 25856/60000][Iteration 4423][Wall Clock 412.665265368s] Trained 128 records in 0.08794184 seconds. Throughput is 1455.5074 records/second. Loss is 1.9423465. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8443378827001107E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 25984/60000][Iteration 4424][Wall Clock 412.751429405s] Trained 128 records in 0.086164037 seconds. Throughput is 1485.5386 records/second. Loss is 1.8885432. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8439977872026554E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26112/60000][Iteration 4425][Wall Clock 412.849161623s] Trained 128 records in 0.097732218 seconds. Throughput is 1309.7012 records/second. Loss is 1.8682479. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8436578171091445E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26240/60000][Iteration 4426][Wall Clock 412.937436014s] Trained 128 records in 0.088274391 seconds. Throughput is 1450.0242 records/second. Loss is 1.9514304. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8433179723502304E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26368/60000][Iteration 4427][Wall Clock 413.023784351s] Trained 128 records in 0.086348337 seconds. Throughput is 1482.3678 records/second. Loss is 1.9117246. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8429782528566163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26496/60000][Iteration 4428][Wall Clock 413.112561662s] Trained 128 records in 0.088777311 seconds. Throughput is 1441.8098 records/second. Loss is 1.919391. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8426386585590563E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26624/60000][Iteration 4429][Wall Clock 413.202615892s] Trained 128 records in 0.09005423 seconds. Throughput is 1421.3658 records/second. Loss is 1.9252431. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8422991893883567E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26752/60000][Iteration 4430][Wall Clock 413.288770065s] Trained 128 records in 0.086154173 seconds. Throughput is 1485.7087 records/second. Loss is 1.905338. Sequentialb692dd65's hyper parameters: Current learning rate is 1.841959845275373E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:16 INFO  DistriOptimizer$:408 - [Epoch 10 26880/60000][Iteration 4431][Wall Clock 413.375191839s] Trained 128 records in 0.086421774 seconds. Throughput is 1481.1083 records/second. Loss is 1.8916708. Sequentialb692dd65's hyper parameters: Current learning rate is 1.841620626151013E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27008/60000][Iteration 4432][Wall Clock 413.469198159s] Trained 128 records in 0.09400632 seconds. Throughput is 1361.6106 records/second. Loss is 1.9593523. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8412815319462347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27136/60000][Iteration 4433][Wall Clock 413.570860002s] Trained 128 records in 0.101661843 seconds. Throughput is 1259.076 records/second. Loss is 1.9089284. Sequentialb692dd65's hyper parameters: Current learning rate is 1.840942562592047E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27264/60000][Iteration 4434][Wall Clock 413.660862994s] Trained 128 records in 0.090002992 seconds. Throughput is 1422.1749 records/second. Loss is 1.9114312. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8406037180195104E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27392/60000][Iteration 4435][Wall Clock 413.744653412s] Trained 128 records in 0.083790418 seconds. Throughput is 1527.621 records/second. Loss is 1.915. Sequentialb692dd65's hyper parameters: Current learning rate is 1.840264998159735E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27520/60000][Iteration 4436][Wall Clock 413.829802321s] Trained 128 records in 0.085148909 seconds. Throughput is 1503.2489 records/second. Loss is 1.9418081. Sequentialb692dd65's hyper parameters: Current learning rate is 1.839926402943882E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27648/60000][Iteration 4437][Wall Clock 413.919828368s] Trained 128 records in 0.090026047 seconds. Throughput is 1421.8108 records/second. Loss is 1.9196606. Sequentialb692dd65's hyper parameters: Current learning rate is 1.839587932303164E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27776/60000][Iteration 4438][Wall Clock 414.033980369s] Trained 128 records in 0.114152001 seconds. Throughput is 1121.3119 records/second. Loss is 1.9352299. Sequentialb692dd65's hyper parameters: Current learning rate is 1.839249586168843E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 27904/60000][Iteration 4439][Wall Clock 414.127058954s] Trained 128 records in 0.093078585 seconds. Throughput is 1375.1821 records/second. Loss is 1.8861922. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8389113644722325E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 28032/60000][Iteration 4440][Wall Clock 414.218064453s] Trained 128 records in 0.091005499 seconds. Throughput is 1406.5084 records/second. Loss is 1.9183592. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8385732671446958E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:17 INFO  DistriOptimizer$:408 - [Epoch 10 28160/60000][Iteration 4441][Wall Clock 414.310498173s] Trained 128 records in 0.09243372 seconds. Throughput is 1384.776 records/second. Loss is 1.9576278. Sequentialb692dd65's hyper parameters: Current learning rate is 1.838235294117647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28288/60000][Iteration 4442][Wall Clock 414.40072623s] Trained 128 records in 0.090228057 seconds. Throughput is 1418.6274 records/second. Loss is 1.8909208. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8378974453225511E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28416/60000][Iteration 4443][Wall Clock 414.490525104s] Trained 128 records in 0.089798874 seconds. Throughput is 1425.4076 records/second. Loss is 1.9503973. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8375597206909223E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28544/60000][Iteration 4444][Wall Clock 414.578265765s] Trained 128 records in 0.087740661 seconds. Throughput is 1458.8447 records/second. Loss is 1.9263233. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8372221201543265E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28672/60000][Iteration 4445][Wall Clock 414.678907364s] Trained 128 records in 0.100641599 seconds. Throughput is 1271.8398 records/second. Loss is 1.9171524. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8368846436443793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28800/60000][Iteration 4446][Wall Clock 414.765795932s] Trained 128 records in 0.086888568 seconds. Throughput is 1473.1512 records/second. Loss is 1.9159175. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8365472910927456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 28928/60000][Iteration 4447][Wall Clock 414.854365209s] Trained 128 records in 0.088569277 seconds. Throughput is 1445.1964 records/second. Loss is 1.924467. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8362100624311423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29056/60000][Iteration 4448][Wall Clock 414.946606458s] Trained 128 records in 0.092241249 seconds. Throughput is 1387.6655 records/second. Loss is 1.9073137. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8358729575913347E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29184/60000][Iteration 4449][Wall Clock 415.034408861s] Trained 128 records in 0.087802403 seconds. Throughput is 1457.8188 records/second. Loss is 1.9111637. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8355359765051394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29312/60000][Iteration 4450][Wall Clock 415.121417836s] Trained 128 records in 0.087008975 seconds. Throughput is 1471.1125 records/second. Loss is 1.9222139. Sequentialb692dd65's hyper parameters: Current learning rate is 1.835199119104423E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29440/60000][Iteration 4451][Wall Clock 415.211510624s] Trained 128 records in 0.090092788 seconds. Throughput is 1420.7574 records/second. Loss is 1.9138662. Sequentialb692dd65's hyper parameters: Current learning rate is 1.834862385321101E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29568/60000][Iteration 4452][Wall Clock 415.29845393s] Trained 128 records in 0.086943306 seconds. Throughput is 1472.2238 records/second. Loss is 1.9420358. Sequentialb692dd65's hyper parameters: Current learning rate is 1.83452577508714E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:18 INFO  DistriOptimizer$:408 - [Epoch 10 29696/60000][Iteration 4453][Wall Clock 415.386539608s] Trained 128 records in 0.088085678 seconds. Throughput is 1453.1306 records/second. Loss is 1.9237678. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8341892883345562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 29824/60000][Iteration 4454][Wall Clock 415.476120929s] Trained 128 records in 0.089581321 seconds. Throughput is 1428.8694 records/second. Loss is 1.9423627. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8338529249954154E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 29952/60000][Iteration 4455][Wall Clock 415.565891131s] Trained 128 records in 0.089770202 seconds. Throughput is 1425.8628 records/second. Loss is 1.9394889. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8335166850018335E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30080/60000][Iteration 4456][Wall Clock 415.65543593s] Trained 128 records in 0.089544799 seconds. Throughput is 1429.4521 records/second. Loss is 1.927559. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8331805682859762E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30208/60000][Iteration 4457][Wall Clock 415.741790253s] Trained 128 records in 0.086354323 seconds. Throughput is 1482.2651 records/second. Loss is 1.9245526. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8328445747800586E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30336/60000][Iteration 4458][Wall Clock 415.832171531s] Trained 128 records in 0.090381278 seconds. Throughput is 1416.2225 records/second. Loss is 1.941676. Sequentialb692dd65's hyper parameters: Current learning rate is 1.832508704416346E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30464/60000][Iteration 4459][Wall Clock 415.918155527s] Trained 128 records in 0.085983996 seconds. Throughput is 1488.649 records/second. Loss is 1.9289857. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8321729571271528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30592/60000][Iteration 4460][Wall Clock 416.006447353s] Trained 128 records in 0.088291826 seconds. Throughput is 1449.7379 records/second. Loss is 1.9440503. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8318373328448433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30720/60000][Iteration 4461][Wall Clock 416.100050016s] Trained 128 records in 0.093602663 seconds. Throughput is 1367.4824 records/second. Loss is 1.888785. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8315018315018315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30848/60000][Iteration 4462][Wall Clock 416.192024353s] Trained 128 records in 0.091974337 seconds. Throughput is 1391.6925 records/second. Loss is 1.8670825. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8311664530305805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 30976/60000][Iteration 4463][Wall Clock 416.281035144s] Trained 128 records in 0.089010791 seconds. Throughput is 1438.028 records/second. Loss is 1.9470642. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8308311973636032E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:19 INFO  DistriOptimizer$:408 - [Epoch 10 31104/60000][Iteration 4464][Wall Clock 416.371514381s] Trained 128 records in 0.090479237 seconds. Throughput is 1414.6892 records/second. Loss is 1.9152822. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8304960644334616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31232/60000][Iteration 4465][Wall Clock 416.458326446s] Trained 128 records in 0.086812065 seconds. Throughput is 1474.4495 records/second. Loss is 1.8884882. Sequentialb692dd65's hyper parameters: Current learning rate is 1.830161054172767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31360/60000][Iteration 4466][Wall Clock 416.545593277s] Trained 128 records in 0.087266831 seconds. Throughput is 1466.7657 records/second. Loss is 1.8631215. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8298261665141812E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31488/60000][Iteration 4467][Wall Clock 416.633674085s] Trained 128 records in 0.088080808 seconds. Throughput is 1453.211 records/second. Loss is 1.8959413. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8294914013904133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31616/60000][Iteration 4468][Wall Clock 416.720365853s] Trained 128 records in 0.086691768 seconds. Throughput is 1476.4955 records/second. Loss is 1.9180268. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8291567587342233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31744/60000][Iteration 4469][Wall Clock 416.807233237s] Trained 128 records in 0.086867384 seconds. Throughput is 1473.5105 records/second. Loss is 1.8792094. Sequentialb692dd65's hyper parameters: Current learning rate is 1.82882223847842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 31872/60000][Iteration 4470][Wall Clock 416.896599495s] Trained 128 records in 0.089366258 seconds. Throughput is 1432.308 records/second. Loss is 1.930945. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8284878405558602E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 32000/60000][Iteration 4471][Wall Clock 416.99551344s] Trained 128 records in 0.098913945 seconds. Throughput is 1294.0541 records/second. Loss is 1.9277946. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8281535648994517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 32128/60000][Iteration 4472][Wall Clock 417.078836018s] Trained 128 records in 0.083322578 seconds. Throughput is 1536.1982 records/second. Loss is 1.8755294. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8278194114421494E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 32256/60000][Iteration 4473][Wall Clock 417.159700007s] Trained 128 records in 0.080863989 seconds. Throughput is 1582.9048 records/second. Loss is 1.9145006. Sequentialb692dd65's hyper parameters: Current learning rate is 1.827485380116959E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 32384/60000][Iteration 4474][Wall Clock 417.244264024s] Trained 128 records in 0.084564017 seconds. Throughput is 1513.6462 records/second. Loss is 1.9209487. Sequentialb692dd65's hyper parameters: Current learning rate is 1.827151470856934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:20 INFO  DistriOptimizer$:408 - [Epoch 10 32512/60000][Iteration 4475][Wall Clock 417.333647596s] Trained 128 records in 0.089383572 seconds. Throughput is 1432.0305 records/second. Loss is 1.9495105. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8268176835951772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 32640/60000][Iteration 4476][Wall Clock 417.42302368s] Trained 128 records in 0.089376084 seconds. Throughput is 1432.1505 records/second. Loss is 1.9324567. Sequentialb692dd65's hyper parameters: Current learning rate is 1.82648401826484E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 32768/60000][Iteration 4477][Wall Clock 417.512857149s] Trained 128 records in 0.089833469 seconds. Throughput is 1424.8588 records/second. Loss is 1.9327185. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8261504747991235E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 32896/60000][Iteration 4478][Wall Clock 417.602973769s] Trained 128 records in 0.09011662 seconds. Throughput is 1420.3817 records/second. Loss is 1.8937026. Sequentialb692dd65's hyper parameters: Current learning rate is 1.825817053131276E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33024/60000][Iteration 4479][Wall Clock 417.69142924s] Trained 128 records in 0.088455471 seconds. Throughput is 1447.0558 records/second. Loss is 1.9178631. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8254837531945966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33152/60000][Iteration 4480][Wall Clock 417.782520919s] Trained 128 records in 0.091091679 seconds. Throughput is 1405.1777 records/second. Loss is 1.8978982. Sequentialb692dd65's hyper parameters: Current learning rate is 1.825150574922431E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33280/60000][Iteration 4481][Wall Clock 417.868760363s] Trained 128 records in 0.086239444 seconds. Throughput is 1484.2396 records/second. Loss is 1.844938. Sequentialb692dd65's hyper parameters: Current learning rate is 1.824817518248175E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33408/60000][Iteration 4482][Wall Clock 417.95554363s] Trained 128 records in 0.086783267 seconds. Throughput is 1474.9387 records/second. Loss is 1.9226185. Sequentialb692dd65's hyper parameters: Current learning rate is 1.824484583105273E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33536/60000][Iteration 4483][Wall Clock 418.057344478s] Trained 128 records in 0.101800848 seconds. Throughput is 1257.3568 records/second. Loss is 1.9279311. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8241517694272163E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33664/60000][Iteration 4484][Wall Clock 418.148737233s] Trained 128 records in 0.091392755 seconds. Throughput is 1400.5487 records/second. Loss is 1.9256237. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8238190771475472E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33792/60000][Iteration 4485][Wall Clock 418.237680462s] Trained 128 records in 0.088943229 seconds. Throughput is 1439.1202 records/second. Loss is 1.9040604. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8234865061998541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:21 INFO  DistriOptimizer$:408 - [Epoch 10 33920/60000][Iteration 4486][Wall Clock 418.330304035s] Trained 128 records in 0.092623573 seconds. Throughput is 1381.9376 records/second. Loss is 1.9042827. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8231540565177758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34048/60000][Iteration 4487][Wall Clock 418.421067265s] Trained 128 records in 0.09076323 seconds. Throughput is 1410.2627 records/second. Loss is 1.877624. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8228217280349984E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34176/60000][Iteration 4488][Wall Clock 418.50885053s] Trained 128 records in 0.087783265 seconds. Throughput is 1458.1367 records/second. Loss is 1.9253911. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8224895206852561E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34304/60000][Iteration 4489][Wall Clock 418.599990303s] Trained 128 records in 0.091139773 seconds. Throughput is 1404.4363 records/second. Loss is 1.9100109. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8221574344023323E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34432/60000][Iteration 4490][Wall Clock 418.689273572s] Trained 128 records in 0.089283269 seconds. Throughput is 1433.6392 records/second. Loss is 1.8696245. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8218254691200583E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34560/60000][Iteration 4491][Wall Clock 418.775356791s] Trained 128 records in 0.086083219 seconds. Throughput is 1486.9332 records/second. Loss is 1.9279845. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8214936247723133E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34688/60000][Iteration 4492][Wall Clock 418.860056519s] Trained 128 records in 0.084699728 seconds. Throughput is 1511.221 records/second. Loss is 1.8492917. Sequentialb692dd65's hyper parameters: Current learning rate is 1.821161901293025E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34816/60000][Iteration 4493][Wall Clock 418.948139047s] Trained 128 records in 0.088082528 seconds. Throughput is 1453.1826 records/second. Loss is 1.8969586. Sequentialb692dd65's hyper parameters: Current learning rate is 1.820830298616169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 34944/60000][Iteration 4494][Wall Clock 419.034023032s] Trained 128 records in 0.085883985 seconds. Throughput is 1490.3827 records/second. Loss is 1.8965973. Sequentialb692dd65's hyper parameters: Current learning rate is 1.820498816675769E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 35072/60000][Iteration 4495][Wall Clock 419.11954381s] Trained 128 records in 0.085520778 seconds. Throughput is 1496.7123 records/second. Loss is 1.9602798. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8201674554058975E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 35200/60000][Iteration 4496][Wall Clock 419.206051743s] Trained 128 records in 0.086507933 seconds. Throughput is 1479.633 records/second. Loss is 1.9282831. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8198362147406734E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:22 INFO  DistriOptimizer$:408 - [Epoch 10 35328/60000][Iteration 4497][Wall Clock 419.305924144s] Trained 128 records in 0.099872401 seconds. Throughput is 1281.6354 records/second. Loss is 1.9417806. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8195050946142647E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 35456/60000][Iteration 4498][Wall Clock 419.38118927s] Trained 128 records in 0.075265126 seconds. Throughput is 1700.6549 records/second. Loss is 1.8921964. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8191740949608878E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 35584/60000][Iteration 4499][Wall Clock 419.462393617s] Trained 128 records in 0.081204347 seconds. Throughput is 1576.2703 records/second. Loss is 1.9018377. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8188432157148054E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 35712/60000][Iteration 4500][Wall Clock 419.548853138s] Trained 128 records in 0.086459521 seconds. Throughput is 1480.4617 records/second. Loss is 1.9411558. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8185124568103294E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 35840/60000][Iteration 4501][Wall Clock 419.634088875s] Trained 128 records in 0.085235737 seconds. Throughput is 1501.7175 records/second. Loss is 1.8480724. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8181818181818183E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 35968/60000][Iteration 4502][Wall Clock 419.720300847s] Trained 128 records in 0.086211972 seconds. Throughput is 1484.7126 records/second. Loss is 1.9272661. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8178512997636792E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36096/60000][Iteration 4503][Wall Clock 419.807651399s] Trained 128 records in 0.087350552 seconds. Throughput is 1465.3599 records/second. Loss is 1.8964576. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8175209014903673E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36224/60000][Iteration 4504][Wall Clock 419.891129098s] Trained 128 records in 0.083477699 seconds. Throughput is 1533.3436 records/second. Loss is 1.9202513. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8171906232963838E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36352/60000][Iteration 4505][Wall Clock 419.973622152s] Trained 128 records in 0.082493054 seconds. Throughput is 1551.6459 records/second. Loss is 1.9281554. Sequentialb692dd65's hyper parameters: Current learning rate is 1.816860465116279E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36480/60000][Iteration 4506][Wall Clock 420.060251741s] Trained 128 records in 0.086629589 seconds. Throughput is 1477.5552 records/second. Loss is 1.916856. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8165304268846503E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36608/60000][Iteration 4507][Wall Clock 420.148582015s] Trained 128 records in 0.088330274 seconds. Throughput is 1449.1068 records/second. Loss is 1.9335136. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8162005085361425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36736/60000][Iteration 4508][Wall Clock 420.241336721s] Trained 128 records in 0.092754706 seconds. Throughput is 1379.9839 records/second. Loss is 1.909085. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8158707100054478E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:23 INFO  DistriOptimizer$:408 - [Epoch 10 36864/60000][Iteration 4509][Wall Clock 420.323373469s] Trained 128 records in 0.082036748 seconds. Throughput is 1560.2764 records/second. Loss is 1.9207095. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8155410312273057E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 36992/60000][Iteration 4510][Wall Clock 420.409638371s] Trained 128 records in 0.086264902 seconds. Throughput is 1483.8016 records/second. Loss is 1.938053. Sequentialb692dd65's hyper parameters: Current learning rate is 1.815211472136504E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37120/60000][Iteration 4511][Wall Clock 420.499615363s] Trained 128 records in 0.089976992 seconds. Throughput is 1422.5859 records/second. Loss is 1.9146513. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8148820326678767E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37248/60000][Iteration 4512][Wall Clock 420.584734756s] Trained 128 records in 0.085119393 seconds. Throughput is 1503.77 records/second. Loss is 1.8996476. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8145527127563056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37376/60000][Iteration 4513][Wall Clock 420.672182771s] Trained 128 records in 0.087448015 seconds. Throughput is 1463.7268 records/second. Loss is 1.8841503. Sequentialb692dd65's hyper parameters: Current learning rate is 1.81422351233672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37504/60000][Iteration 4514][Wall Clock 420.760670734s] Trained 128 records in 0.088487963 seconds. Throughput is 1446.5244 records/second. Loss is 1.9578259. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8138944313440957E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37632/60000][Iteration 4515][Wall Clock 420.849439131s] Trained 128 records in 0.088768397 seconds. Throughput is 1441.9546 records/second. Loss is 1.9298532. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8135654697134566E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37760/60000][Iteration 4516][Wall Clock 420.938602486s] Trained 128 records in 0.089163355 seconds. Throughput is 1435.5674 records/second. Loss is 1.8983101. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8132366273798732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 37888/60000][Iteration 4517][Wall Clock 421.023382544s] Trained 128 records in 0.084780058 seconds. Throughput is 1509.789 records/second. Loss is 1.8772963. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8129079042784627E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 38016/60000][Iteration 4518][Wall Clock 421.110665828s] Trained 128 records in 0.087283284 seconds. Throughput is 1466.4893 records/second. Loss is 1.9165016. Sequentialb692dd65's hyper parameters: Current learning rate is 1.81257930034439E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 38144/60000][Iteration 4519][Wall Clock 421.20162743s] Trained 128 records in 0.090961602 seconds. Throughput is 1407.1871 records/second. Loss is 1.8814312. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8122508155128672E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:24 INFO  DistriOptimizer$:408 - [Epoch 10 38272/60000][Iteration 4520][Wall Clock 421.288244414s] Trained 128 records in 0.086616984 seconds. Throughput is 1477.7701 records/second. Loss is 1.8947859. Sequentialb692dd65's hyper parameters: Current learning rate is 1.811922449719152E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 38400/60000][Iteration 4521][Wall Clock 421.372781826s] Trained 128 records in 0.084537412 seconds. Throughput is 1514.1226 records/second. Loss is 1.9448799. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8115942028985505E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 38528/60000][Iteration 4522][Wall Clock 421.455310052s] Trained 128 records in 0.082528226 seconds. Throughput is 1550.9845 records/second. Loss is 1.946956. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8112660749864155E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 38656/60000][Iteration 4523][Wall Clock 421.5472169s] Trained 128 records in 0.091906848 seconds. Throughput is 1392.7145 records/second. Loss is 1.9791063. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8109380659181456E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 38784/60000][Iteration 4524][Wall Clock 421.638176724s] Trained 128 records in 0.090959824 seconds. Throughput is 1407.2147 records/second. Loss is 1.8893166. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8106101756291872E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 38912/60000][Iteration 4525][Wall Clock 421.716979644s] Trained 128 records in 0.07880292 seconds. Throughput is 1624.3053 records/second. Loss is 1.9574124. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8102824040550327E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39040/60000][Iteration 4526][Wall Clock 421.802323555s] Trained 128 records in 0.085343911 seconds. Throughput is 1499.8141 records/second. Loss is 1.9039122. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8099547511312217E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39168/60000][Iteration 4527][Wall Clock 421.89104499s] Trained 128 records in 0.088721435 seconds. Throughput is 1442.7179 records/second. Loss is 1.8923868. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8096272167933406E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39296/60000][Iteration 4528][Wall Clock 421.980484165s] Trained 128 records in 0.089439175 seconds. Throughput is 1431.1401 records/second. Loss is 1.9508486. Sequentialb692dd65's hyper parameters: Current learning rate is 1.809299800977022E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39424/60000][Iteration 4529][Wall Clock 422.062836969s] Trained 128 records in 0.082352804 seconds. Throughput is 1554.2883 records/second. Loss is 1.8966243. Sequentialb692dd65's hyper parameters: Current learning rate is 1.808972503617945E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39552/60000][Iteration 4530][Wall Clock 422.149158974s] Trained 128 records in 0.086322005 seconds. Throughput is 1482.8201 records/second. Loss is 1.9153979. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8086453246518358E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39680/60000][Iteration 4531][Wall Clock 422.233989654s] Trained 128 records in 0.08483068 seconds. Throughput is 1508.8881 records/second. Loss is 1.9157284. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8083182640144665E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:25 INFO  DistriOptimizer$:408 - [Epoch 10 39808/60000][Iteration 4532][Wall Clock 422.31804332s] Trained 128 records in 0.084053666 seconds. Throughput is 1522.8367 records/second. Loss is 1.8880618. Sequentialb692dd65's hyper parameters: Current learning rate is 1.807991321641656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 39936/60000][Iteration 4533][Wall Clock 422.420689642s] Trained 128 records in 0.102646322 seconds. Throughput is 1247.0004 records/second. Loss is 1.8942535. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8076644974692697E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40064/60000][Iteration 4534][Wall Clock 422.501685085s] Trained 128 records in 0.080995443 seconds. Throughput is 1580.3358 records/second. Loss is 1.8715734. Sequentialb692dd65's hyper parameters: Current learning rate is 1.807337791433219E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40192/60000][Iteration 4535][Wall Clock 422.584102372s] Trained 128 records in 0.082417287 seconds. Throughput is 1553.0723 records/second. Loss is 1.9168211. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8070112034694616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40320/60000][Iteration 4536][Wall Clock 422.671003386s] Trained 128 records in 0.086901014 seconds. Throughput is 1472.9402 records/second. Loss is 1.9009104. Sequentialb692dd65's hyper parameters: Current learning rate is 1.806684733514002E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40448/60000][Iteration 4537][Wall Clock 422.757687461s] Trained 128 records in 0.086684075 seconds. Throughput is 1476.6265 records/second. Loss is 1.947014. Sequentialb692dd65's hyper parameters: Current learning rate is 1.80635838150289E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40576/60000][Iteration 4538][Wall Clock 422.841919835s] Trained 128 records in 0.084232374 seconds. Throughput is 1519.6057 records/second. Loss is 1.8423841. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8060321473722233E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40704/60000][Iteration 4539][Wall Clock 422.930933434s] Trained 128 records in 0.089013599 seconds. Throughput is 1437.9825 records/second. Loss is 1.884625. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8057060310581438E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40832/60000][Iteration 4540][Wall Clock 423.015911943s] Trained 128 records in 0.084978509 seconds. Throughput is 1506.2632 records/second. Loss is 1.9092915. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8053800324968408E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 40960/60000][Iteration 4541][Wall Clock 423.100549024s] Trained 128 records in 0.084637081 seconds. Throughput is 1512.3395 records/second. Loss is 1.9004639. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8050541516245486E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 41088/60000][Iteration 4542][Wall Clock 423.187973685s] Trained 128 records in 0.087424661 seconds. Throughput is 1464.1178 records/second. Loss is 1.9010719. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8047283883775492E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:26 INFO  DistriOptimizer$:408 - [Epoch 10 41216/60000][Iteration 4543][Wall Clock 423.275037909s] Trained 128 records in 0.087064224 seconds. Throughput is 1470.1791 records/second. Loss is 1.876506. Sequentialb692dd65's hyper parameters: Current learning rate is 1.804402742692169E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41344/60000][Iteration 4544][Wall Clock 423.358267889s] Trained 128 records in 0.08322998 seconds. Throughput is 1537.9073 records/second. Loss is 1.9338695. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8040772145047808E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41472/60000][Iteration 4545][Wall Clock 423.446165718s] Trained 128 records in 0.087897829 seconds. Throughput is 1456.2362 records/second. Loss is 1.9220537. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8037518037518038E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41600/60000][Iteration 4546][Wall Clock 423.532892183s] Trained 128 records in 0.086726465 seconds. Throughput is 1475.9048 records/second. Loss is 1.9198534. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8034265103697024E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41728/60000][Iteration 4547][Wall Clock 423.619073304s] Trained 128 records in 0.086181121 seconds. Throughput is 1485.2441 records/second. Loss is 1.9055101. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8031013342949875E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41856/60000][Iteration 4548][Wall Clock 423.707945407s] Trained 128 records in 0.088872103 seconds. Throughput is 1440.272 records/second. Loss is 1.9655927. Sequentialb692dd65's hyper parameters: Current learning rate is 1.802776275464215E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 41984/60000][Iteration 4549][Wall Clock 423.807982273s] Trained 128 records in 0.100036866 seconds. Throughput is 1279.5283 records/second. Loss is 1.900961. Sequentialb692dd65's hyper parameters: Current learning rate is 1.802451333813987E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42112/60000][Iteration 4550][Wall Clock 423.891479967s] Trained 128 records in 0.083497694 seconds. Throughput is 1532.9764 records/second. Loss is 1.924933. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8021265092809513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42240/60000][Iteration 4551][Wall Clock 423.971901739s] Trained 128 records in 0.080421772 seconds. Throughput is 1591.6088 records/second. Loss is 1.9453905. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8018018018018018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42368/60000][Iteration 4552][Wall Clock 424.058853377s] Trained 128 records in 0.086951638 seconds. Throughput is 1472.0828 records/second. Loss is 1.9399259. Sequentialb692dd65's hyper parameters: Current learning rate is 1.801477211313277E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42496/60000][Iteration 4553][Wall Clock 424.145095709s] Trained 128 records in 0.086242332 seconds. Throughput is 1484.19 records/second. Loss is 1.9067625. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8011527377521613E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42624/60000][Iteration 4554][Wall Clock 424.229712189s] Trained 128 records in 0.08461648 seconds. Throughput is 1512.7076 records/second. Loss is 1.941853. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8008283810552856E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:27 INFO  DistriOptimizer$:408 - [Epoch 10 42752/60000][Iteration 4555][Wall Clock 424.312486089s] Trained 128 records in 0.0827739 seconds. Throughput is 1546.3811 records/second. Loss is 1.9251798. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8005041411595245E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 42880/60000][Iteration 4556][Wall Clock 424.397964134s] Trained 128 records in 0.085478045 seconds. Throughput is 1497.4606 records/second. Loss is 1.9051138. Sequentialb692dd65's hyper parameters: Current learning rate is 1.8001800180018004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43008/60000][Iteration 4557][Wall Clock 424.483005476s] Trained 128 records in 0.085041342 seconds. Throughput is 1505.1503 records/second. Loss is 1.9474655. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7998560115190784E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43136/60000][Iteration 4558][Wall Clock 424.568739424s] Trained 128 records in 0.085733948 seconds. Throughput is 1492.9908 records/second. Loss is 1.8663303. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7995321216483713E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43264/60000][Iteration 4559][Wall Clock 424.658670679s] Trained 128 records in 0.089931255 seconds. Throughput is 1423.3093 records/second. Loss is 1.9297587. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7992083483267364E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43392/60000][Iteration 4560][Wall Clock 424.739231566s] Trained 128 records in 0.080560887 seconds. Throughput is 1588.8604 records/second. Loss is 1.9044923. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7988846914912754E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43520/60000][Iteration 4561][Wall Clock 424.819362764s] Trained 128 records in 0.080131198 seconds. Throughput is 1597.3804 records/second. Loss is 1.9001942. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7985611510791365E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43648/60000][Iteration 4562][Wall Clock 424.904342427s] Trained 128 records in 0.084979663 seconds. Throughput is 1506.2428 records/second. Loss is 1.8829153. Sequentialb692dd65's hyper parameters: Current learning rate is 1.798237727027513E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43776/60000][Iteration 4563][Wall Clock 424.987673488s] Trained 128 records in 0.083331061 seconds. Throughput is 1536.0419 records/second. Loss is 1.8715549. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7979144192736425E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 43904/60000][Iteration 4564][Wall Clock 425.073770683s] Trained 128 records in 0.086097195 seconds. Throughput is 1486.6919 records/second. Loss is 1.872032. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7975912277548087E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 44032/60000][Iteration 4565][Wall Clock 425.157001688s] Trained 128 records in 0.083231005 seconds. Throughput is 1537.8884 records/second. Loss is 1.8767073. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7972681524083394E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 44160/60000][Iteration 4566][Wall Clock 425.24050872s] Trained 128 records in 0.083507032 seconds. Throughput is 1532.805 records/second. Loss is 1.9252167. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7969451931716083E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:28 INFO  DistriOptimizer$:408 - [Epoch 10 44288/60000][Iteration 4567][Wall Clock 425.323796155s] Trained 128 records in 0.083287435 seconds. Throughput is 1536.8466 records/second. Loss is 1.8930929. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7966223499820338E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 44416/60000][Iteration 4568][Wall Clock 425.407701964s] Trained 128 records in 0.083905809 seconds. Throughput is 1525.5201 records/second. Loss is 1.8992836. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7962996227770793E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 44544/60000][Iteration 4569][Wall Clock 425.491428315s] Trained 128 records in 0.083726351 seconds. Throughput is 1528.7898 records/second. Loss is 1.9253538. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7959770114942528E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 44672/60000][Iteration 4570][Wall Clock 425.574265962s] Trained 128 records in 0.082837647 seconds. Throughput is 1545.1912 records/second. Loss is 1.8888956. Sequentialb692dd65's hyper parameters: Current learning rate is 1.795654516071108E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 44800/60000][Iteration 4571][Wall Clock 425.65797872s] Trained 128 records in 0.083712758 seconds. Throughput is 1529.0382 records/second. Loss is 1.8820719. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7953321364452422E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 44928/60000][Iteration 4572][Wall Clock 425.745091534s] Trained 128 records in 0.087112814 seconds. Throughput is 1469.359 records/second. Loss is 1.9102157. Sequentialb692dd65's hyper parameters: Current learning rate is 1.795009872554299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45056/60000][Iteration 4573][Wall Clock 425.83238625s] Trained 128 records in 0.087294716 seconds. Throughput is 1466.2972 records/second. Loss is 1.9362006. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7946877243359656E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45184/60000][Iteration 4574][Wall Clock 425.918534539s] Trained 128 records in 0.086148289 seconds. Throughput is 1485.81 records/second. Loss is 1.9327501. Sequentialb692dd65's hyper parameters: Current learning rate is 1.794365691727974E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45312/60000][Iteration 4575][Wall Clock 426.011909511s] Trained 128 records in 0.093374972 seconds. Throughput is 1370.817 records/second. Loss is 1.895869. Sequentialb692dd65's hyper parameters: Current learning rate is 1.794043774668102E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45440/60000][Iteration 4576][Wall Clock 426.097612863s] Trained 128 records in 0.085703352 seconds. Throughput is 1493.5239 records/second. Loss is 1.9031479. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7937219730941703E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45568/60000][Iteration 4577][Wall Clock 426.173968825s] Trained 128 records in 0.076355962 seconds. Throughput is 1676.3589 records/second. Loss is 1.913818. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7934002869440457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:29 INFO  DistriOptimizer$:408 - [Epoch 10 45696/60000][Iteration 4578][Wall Clock 426.253315237s] Trained 128 records in 0.079346412 seconds. Throughput is 1613.1794 records/second. Loss is 1.8701558. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7930787161556393E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 45824/60000][Iteration 4579][Wall Clock 426.337481126s] Trained 128 records in 0.084165889 seconds. Throughput is 1520.8062 records/second. Loss is 1.8710057. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7927572606669056E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 45952/60000][Iteration 4580][Wall Clock 426.421894491s] Trained 128 records in 0.084413365 seconds. Throughput is 1516.3475 records/second. Loss is 1.8614824. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7924359204158453E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46080/60000][Iteration 4581][Wall Clock 426.508112566s] Trained 128 records in 0.086218075 seconds. Throughput is 1484.6075 records/second. Loss is 1.8967881. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7921146953405018E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46208/60000][Iteration 4582][Wall Clock 426.591344985s] Trained 128 records in 0.083232419 seconds. Throughput is 1537.8623 records/second. Loss is 1.9125484. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7917935853789643E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46336/60000][Iteration 4583][Wall Clock 426.679928498s] Trained 128 records in 0.088583513 seconds. Throughput is 1444.9641 records/second. Loss is 1.927173. Sequentialb692dd65's hyper parameters: Current learning rate is 1.791472590469366E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46464/60000][Iteration 4584][Wall Clock 426.778255875s] Trained 128 records in 0.098327377 seconds. Throughput is 1301.7738 records/second. Loss is 1.9030771. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7911517105498835E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46592/60000][Iteration 4585][Wall Clock 426.857753236s] Trained 128 records in 0.079497361 seconds. Throughput is 1610.1163 records/second. Loss is 1.9392604. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7908309455587392E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46720/60000][Iteration 4586][Wall Clock 426.941635417s] Trained 128 records in 0.083882181 seconds. Throughput is 1525.9498 records/second. Loss is 1.8933837. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7905102954341988E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46848/60000][Iteration 4587][Wall Clock 427.02456283s] Trained 128 records in 0.082927413 seconds. Throughput is 1543.5186 records/second. Loss is 1.9244432. Sequentialb692dd65's hyper parameters: Current learning rate is 1.790189760114572E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 46976/60000][Iteration 4588][Wall Clock 427.109461572s] Trained 128 records in 0.084898742 seconds. Throughput is 1507.6785 records/second. Loss is 1.8817168. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7898693395382138E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 47104/60000][Iteration 4589][Wall Clock 427.194861554s] Trained 128 records in 0.085399982 seconds. Throughput is 1498.8293 records/second. Loss is 1.8955116. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7895490336435218E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:30 INFO  DistriOptimizer$:408 - [Epoch 10 47232/60000][Iteration 4590][Wall Clock 427.278523614s] Trained 128 records in 0.08366206 seconds. Throughput is 1529.9647 records/second. Loss is 1.8966902. Sequentialb692dd65's hyper parameters: Current learning rate is 1.789228842368939E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 47360/60000][Iteration 4591][Wall Clock 427.360967023s] Trained 128 records in 0.082443409 seconds. Throughput is 1552.5802 records/second. Loss is 1.9330463. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7889087656529517E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 47488/60000][Iteration 4592][Wall Clock 427.445229093s] Trained 128 records in 0.08426207 seconds. Throughput is 1519.0702 records/second. Loss is 1.90427. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7885888034340904E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 47616/60000][Iteration 4593][Wall Clock 427.529983065s] Trained 128 records in 0.084753972 seconds. Throughput is 1510.2537 records/second. Loss is 1.9226905. Sequentialb692dd65's hyper parameters: Current learning rate is 1.78826895565093E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 47744/60000][Iteration 4594][Wall Clock 427.617252647s] Trained 128 records in 0.087269582 seconds. Throughput is 1466.7195 records/second. Loss is 1.8809189. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7879492222420883E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 47872/60000][Iteration 4595][Wall Clock 427.703948685s] Trained 128 records in 0.086696038 seconds. Throughput is 1476.4227 records/second. Loss is 1.9431833. Sequentialb692dd65's hyper parameters: Current learning rate is 1.787629603146228E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48000/60000][Iteration 4596][Wall Clock 427.788922763s] Trained 128 records in 0.084974078 seconds. Throughput is 1506.3417 records/second. Loss is 1.9214396. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7873100983020556E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48128/60000][Iteration 4597][Wall Clock 427.874718884s] Trained 128 records in 0.085796121 seconds. Throughput is 1491.909 records/second. Loss is 1.8663999. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7869907076483203E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48256/60000][Iteration 4598][Wall Clock 427.960285532s] Trained 128 records in 0.085566648 seconds. Throughput is 1495.9099 records/second. Loss is 1.8843405. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7866714311238162E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48384/60000][Iteration 4599][Wall Clock 428.046009825s] Trained 128 records in 0.085724293 seconds. Throughput is 1493.1589 records/second. Loss is 1.8758243. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7863522686673814E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48512/60000][Iteration 4600][Wall Clock 428.130696035s] Trained 128 records in 0.08468621 seconds. Throughput is 1511.4622 records/second. Loss is 1.9228773. Sequentialb692dd65's hyper parameters: Current learning rate is 1.786033220217896E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48640/60000][Iteration 4601][Wall Clock 428.226010784s] Trained 128 records in 0.095314749 seconds. Throughput is 1342.9192 records/second. Loss is 1.8865924. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7857142857142857E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:31 INFO  DistriOptimizer$:408 - [Epoch 10 48768/60000][Iteration 4602][Wall Clock 428.303243123s] Trained 128 records in 0.077232339 seconds. Throughput is 1657.3368 records/second. Loss is 1.9342842. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7853954650955188E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 48896/60000][Iteration 4603][Wall Clock 428.385068037s] Trained 128 records in 0.081824914 seconds. Throughput is 1564.3158 records/second. Loss is 1.874698. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7850767583006067E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49024/60000][Iteration 4604][Wall Clock 428.464820055s] Trained 128 records in 0.079752018 seconds. Throughput is 1604.975 records/second. Loss is 1.9266051. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7847581652686063E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49152/60000][Iteration 4605][Wall Clock 428.546877923s] Trained 128 records in 0.082057868 seconds. Throughput is 1559.8748 records/second. Loss is 1.8877641. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7844396859386153E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49280/60000][Iteration 4606][Wall Clock 428.629575429s] Trained 128 records in 0.082697506 seconds. Throughput is 1547.8097 records/second. Loss is 1.9006757. Sequentialb692dd65's hyper parameters: Current learning rate is 1.784121320249777E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49408/60000][Iteration 4607][Wall Clock 428.714598297s] Trained 128 records in 0.085022868 seconds. Throughput is 1505.4773 records/second. Loss is 1.9344999. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7838030681412772E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49536/60000][Iteration 4608][Wall Clock 428.799630004s] Trained 128 records in 0.085031707 seconds. Throughput is 1505.3208 records/second. Loss is 1.9613124. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7834849295523451E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49664/60000][Iteration 4609][Wall Clock 428.891051551s] Trained 128 records in 0.091421547 seconds. Throughput is 1400.1077 records/second. Loss is 1.8740573. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7831669044222537E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49792/60000][Iteration 4610][Wall Clock 428.97374689s] Trained 128 records in 0.082695339 seconds. Throughput is 1547.8502 records/second. Loss is 1.8641983. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7828489926903192E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 49920/60000][Iteration 4611][Wall Clock 429.057458696s] Trained 128 records in 0.083711806 seconds. Throughput is 1529.0555 records/second. Loss is 1.9030974. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7825311942959E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 50048/60000][Iteration 4612][Wall Clock 429.145426734s] Trained 128 records in 0.087968038 seconds. Throughput is 1455.074 records/second. Loss is 1.9189305. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7822135091783998E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:32 INFO  DistriOptimizer$:408 - [Epoch 10 50176/60000][Iteration 4613][Wall Clock 429.231476209s] Trained 128 records in 0.086049475 seconds. Throughput is 1487.5164 records/second. Loss is 1.949123. Sequentialb692dd65's hyper parameters: Current learning rate is 1.781895937277263E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50304/60000][Iteration 4614][Wall Clock 429.319021745s] Trained 128 records in 0.087545536 seconds. Throughput is 1462.0962 records/second. Loss is 1.8921828. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7815784785319794E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50432/60000][Iteration 4615][Wall Clock 429.403826625s] Trained 128 records in 0.08480488 seconds. Throughput is 1509.3472 records/second. Loss is 1.9208744. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7812611328820805E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50560/60000][Iteration 4616][Wall Clock 429.488223176s] Trained 128 records in 0.084396551 seconds. Throughput is 1516.6497 records/second. Loss is 1.879628. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7809439002671417E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50688/60000][Iteration 4617][Wall Clock 429.573243836s] Trained 128 records in 0.08502066 seconds. Throughput is 1505.5164 records/second. Loss is 1.9442188. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7806267806267807E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50816/60000][Iteration 4618][Wall Clock 429.659104186s] Trained 128 records in 0.08586035 seconds. Throughput is 1490.793 records/second. Loss is 1.9301128. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7803097739006588E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 50944/60000][Iteration 4619][Wall Clock 429.746554383s] Trained 128 records in 0.087450197 seconds. Throughput is 1463.6902 records/second. Loss is 1.9215989. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7799928800284797E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51072/60000][Iteration 4620][Wall Clock 429.833274327s] Trained 128 records in 0.086719944 seconds. Throughput is 1476.0157 records/second. Loss is 1.9092764. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7796760989499913E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51200/60000][Iteration 4621][Wall Clock 429.91957614s] Trained 128 records in 0.086301813 seconds. Throughput is 1483.167 records/second. Loss is 1.8845253. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7793594306049823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51328/60000][Iteration 4622][Wall Clock 430.006061578s] Trained 128 records in 0.086485438 seconds. Throughput is 1480.018 records/second. Loss is 1.8743055. Sequentialb692dd65's hyper parameters: Current learning rate is 1.779042874933286E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51456/60000][Iteration 4623][Wall Clock 430.090082254s] Trained 128 records in 0.084020676 seconds. Throughput is 1523.4346 records/second. Loss is 1.9140719. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7787264318747779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51584/60000][Iteration 4624][Wall Clock 430.177553462s] Trained 128 records in 0.087471208 seconds. Throughput is 1463.3386 records/second. Loss is 1.899599. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7784101013693757E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:33 INFO  DistriOptimizer$:408 - [Epoch 10 51712/60000][Iteration 4625][Wall Clock 430.26237138s] Trained 128 records in 0.084817918 seconds. Throughput is 1509.1151 records/second. Loss is 1.9273843. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7780938833570413E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 51840/60000][Iteration 4626][Wall Clock 430.34936387s] Trained 128 records in 0.08699249 seconds. Throughput is 1471.3915 records/second. Loss is 1.8856647. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7777777777777779E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 51968/60000][Iteration 4627][Wall Clock 430.444580064s] Trained 128 records in 0.095216194 seconds. Throughput is 1344.3092 records/second. Loss is 1.9049778. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7774617845716317E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52096/60000][Iteration 4628][Wall Clock 430.518711047s] Trained 128 records in 0.074130983 seconds. Throughput is 1726.6735 records/second. Loss is 1.8889891. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7771459036786921E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52224/60000][Iteration 4629][Wall Clock 430.597273036s] Trained 128 records in 0.078561989 seconds. Throughput is 1629.2866 records/second. Loss is 1.8950053. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7768301350390902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52352/60000][Iteration 4630][Wall Clock 430.68067327s] Trained 128 records in 0.083400234 seconds. Throughput is 1534.7678 records/second. Loss is 1.8867556. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7765144785930004E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52480/60000][Iteration 4631][Wall Clock 430.765852838s] Trained 128 records in 0.085179568 seconds. Throughput is 1502.7078 records/second. Loss is 1.9072411. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7761989342806396E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52608/60000][Iteration 4632][Wall Clock 430.851177073s] Trained 128 records in 0.085324235 seconds. Throughput is 1500.1599 records/second. Loss is 1.8751279. Sequentialb692dd65's hyper parameters: Current learning rate is 1.775883502042266E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52736/60000][Iteration 4633][Wall Clock 430.93520902s] Trained 128 records in 0.084031947 seconds. Throughput is 1523.2302 records/second. Loss is 1.8849965. Sequentialb692dd65's hyper parameters: Current learning rate is 1.775568181818182E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52864/60000][Iteration 4634][Wall Clock 431.020843992s] Trained 128 records in 0.085634972 seconds. Throughput is 1494.7164 records/second. Loss is 1.9137677. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7752529735487308E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 52992/60000][Iteration 4635][Wall Clock 431.114553972s] Trained 128 records in 0.09370998 seconds. Throughput is 1365.9164 records/second. Loss is 1.8767885. Sequentialb692dd65's hyper parameters: Current learning rate is 1.774937877174299E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 53120/60000][Iteration 4636][Wall Clock 431.200748736s] Trained 128 records in 0.086194764 seconds. Throughput is 1485.009 records/second. Loss is 1.8952099. Sequentialb692dd65's hyper parameters: Current learning rate is 1.774622892635315E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:34 INFO  DistriOptimizer$:408 - [Epoch 10 53248/60000][Iteration 4637][Wall Clock 431.285069387s] Trained 128 records in 0.084320651 seconds. Throughput is 1518.0149 records/second. Loss is 1.8897182. Sequentialb692dd65's hyper parameters: Current learning rate is 1.77430801987225E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 53376/60000][Iteration 4638][Wall Clock 431.371389518s] Trained 128 records in 0.086320131 seconds. Throughput is 1482.8522 records/second. Loss is 1.8808106. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7739932588256165E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 53504/60000][Iteration 4639][Wall Clock 431.45628225s] Trained 128 records in 0.084892732 seconds. Throughput is 1507.785 records/second. Loss is 1.8778759. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7736786094359704E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 53632/60000][Iteration 4640][Wall Clock 431.539865511s] Trained 128 records in 0.083583261 seconds. Throughput is 1531.4071 records/second. Loss is 1.9000928. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7733640716439085E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 53760/60000][Iteration 4641][Wall Clock 431.623478037s] Trained 128 records in 0.083612526 seconds. Throughput is 1530.8711 records/second. Loss is 1.9428151. Sequentialb692dd65's hyper parameters: Current learning rate is 1.773049645390071E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 53888/60000][Iteration 4642][Wall Clock 431.708733014s] Trained 128 records in 0.085254977 seconds. Throughput is 1501.3787 records/second. Loss is 1.9353615. Sequentialb692dd65's hyper parameters: Current learning rate is 1.772735330615139E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54016/60000][Iteration 4643][Wall Clock 431.791982791s] Trained 128 records in 0.083249777 seconds. Throughput is 1537.5416 records/second. Loss is 1.9063243. Sequentialb692dd65's hyper parameters: Current learning rate is 1.772421127259837E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54144/60000][Iteration 4644][Wall Clock 431.877755201s] Trained 128 records in 0.08577241 seconds. Throughput is 1492.3214 records/second. Loss is 1.9606855. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7721070352649302E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54272/60000][Iteration 4645][Wall Clock 431.96258604s] Trained 128 records in 0.084830839 seconds. Throughput is 1508.8853 records/second. Loss is 1.9097416. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7717930545712261E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54400/60000][Iteration 4646][Wall Clock 432.04674706s] Trained 128 records in 0.08416102 seconds. Throughput is 1520.894 records/second. Loss is 1.9284146. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7714791851195747E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54528/60000][Iteration 4647][Wall Clock 432.133537091s] Trained 128 records in 0.086790031 seconds. Throughput is 1474.8237 records/second. Loss is 1.8813261. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7711654268508679E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:35 INFO  DistriOptimizer$:408 - [Epoch 10 54656/60000][Iteration 4648][Wall Clock 432.219502399s] Trained 128 records in 0.085965308 seconds. Throughput is 1488.9728 records/second. Loss is 1.9110147. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7708517797060386E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 54784/60000][Iteration 4649][Wall Clock 432.303616424s] Trained 128 records in 0.084114025 seconds. Throughput is 1521.7439 records/second. Loss is 1.9878747. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7705382436260624E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 54912/60000][Iteration 4650][Wall Clock 432.3896143s] Trained 128 records in 0.085997876 seconds. Throughput is 1488.4088 records/second. Loss is 1.9060339. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7702248185519562E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55040/60000][Iteration 4651][Wall Clock 432.473691781s] Trained 128 records in 0.084077481 seconds. Throughput is 1522.4053 records/second. Loss is 1.8780984. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7699115044247788E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55168/60000][Iteration 4652][Wall Clock 432.55878596s] Trained 128 records in 0.085094179 seconds. Throughput is 1504.2157 records/second. Loss is 1.9287683. Sequentialb692dd65's hyper parameters: Current learning rate is 1.769598301185631E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55296/60000][Iteration 4653][Wall Clock 432.650036038s] Trained 128 records in 0.091250078 seconds. Throughput is 1402.7385 records/second. Loss is 1.8770096. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7692852087756547E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55424/60000][Iteration 4654][Wall Clock 432.726002103s] Trained 128 records in 0.075966065 seconds. Throughput is 1684.9628 records/second. Loss is 1.850093. Sequentialb692dd65's hyper parameters: Current learning rate is 1.768972227136034E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55552/60000][Iteration 4655][Wall Clock 432.8047135s] Trained 128 records in 0.078711397 seconds. Throughput is 1626.194 records/second. Loss is 1.8678682. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7686593562079943E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55680/60000][Iteration 4656][Wall Clock 432.880936871s] Trained 128 records in 0.076223371 seconds. Throughput is 1679.2749 records/second. Loss is 1.8749338. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7683465959328028E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55808/60000][Iteration 4657][Wall Clock 432.963529335s] Trained 128 records in 0.082592464 seconds. Throughput is 1549.7782 records/second. Loss is 1.903838. Sequentialb692dd65's hyper parameters: Current learning rate is 1.768033946251768E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 55936/60000][Iteration 4658][Wall Clock 433.048841927s] Trained 128 records in 0.085312592 seconds. Throughput is 1500.3647 records/second. Loss is 1.8648903. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7677214071062401E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 56064/60000][Iteration 4659][Wall Clock 433.134085059s] Trained 128 records in 0.085243132 seconds. Throughput is 1501.5872 records/second. Loss is 1.9275292. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7674089784376103E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:36 INFO  DistriOptimizer$:408 - [Epoch 10 56192/60000][Iteration 4660][Wall Clock 433.22294178s] Trained 128 records in 0.088856721 seconds. Throughput is 1440.5214 records/second. Loss is 1.9032398. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7670966601873123E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56320/60000][Iteration 4661][Wall Clock 433.317002466s] Trained 128 records in 0.094060686 seconds. Throughput is 1360.8235 records/second. Loss is 1.9196228. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7667844522968197E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56448/60000][Iteration 4662][Wall Clock 433.395436824s] Trained 128 records in 0.078434358 seconds. Throughput is 1631.938 records/second. Loss is 1.8877021. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7664723547076487E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56576/60000][Iteration 4663][Wall Clock 433.491244946s] Trained 128 records in 0.095808122 seconds. Throughput is 1336.0037 records/second. Loss is 1.9258779. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7661603673613564E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56704/60000][Iteration 4664][Wall Clock 433.579222488s] Trained 128 records in 0.087977542 seconds. Throughput is 1454.9167 records/second. Loss is 1.9350193. Sequentialb692dd65's hyper parameters: Current learning rate is 1.765848490199541E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56832/60000][Iteration 4665][Wall Clock 433.668536388s] Trained 128 records in 0.0893139 seconds. Throughput is 1433.1476 records/second. Loss is 1.9156547. Sequentialb692dd65's hyper parameters: Current learning rate is 1.765536723163842E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 56960/60000][Iteration 4666][Wall Clock 433.756925129s] Trained 128 records in 0.088388741 seconds. Throughput is 1448.1482 records/second. Loss is 1.8496847. Sequentialb692dd65's hyper parameters: Current learning rate is 1.76522506619594E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57088/60000][Iteration 4667][Wall Clock 433.842088181s] Trained 128 records in 0.085163052 seconds. Throughput is 1502.9993 records/second. Loss is 1.8967988. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7649135192375574E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57216/60000][Iteration 4668][Wall Clock 433.926825248s] Trained 128 records in 0.084737067 seconds. Throughput is 1510.5549 records/second. Loss is 1.9407535. Sequentialb692dd65's hyper parameters: Current learning rate is 1.764602082230457E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57344/60000][Iteration 4669][Wall Clock 434.009972841s] Trained 128 records in 0.083147593 seconds. Throughput is 1539.4313 records/second. Loss is 1.8642639. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7642907551164433E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57472/60000][Iteration 4670][Wall Clock 434.09397686s] Trained 128 records in 0.084004019 seconds. Throughput is 1523.7366 records/second. Loss is 1.8894265. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7639795378373608E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57600/60000][Iteration 4671][Wall Clock 434.184133606s] Trained 128 records in 0.090156746 seconds. Throughput is 1419.7495 records/second. Loss is 1.9174464. Sequentialb692dd65's hyper parameters: Current learning rate is 1.763668430335097E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:37 INFO  DistriOptimizer$:408 - [Epoch 10 57728/60000][Iteration 4672][Wall Clock 434.269487207s] Trained 128 records in 0.085353601 seconds. Throughput is 1499.6439 records/second. Loss is 1.8593122. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7633574325515782E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 57856/60000][Iteration 4673][Wall Clock 434.354467485s] Trained 128 records in 0.084980278 seconds. Throughput is 1506.2318 records/second. Loss is 1.923381. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7630465444287732E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 57984/60000][Iteration 4674][Wall Clock 434.440227797s] Trained 128 records in 0.085760312 seconds. Throughput is 1492.5319 records/second. Loss is 1.9384296. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7627357659086903E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58112/60000][Iteration 4675][Wall Clock 434.524603048s] Trained 128 records in 0.084375251 seconds. Throughput is 1517.0326 records/second. Loss is 1.9458323. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7624250969333803E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58240/60000][Iteration 4676][Wall Clock 434.613844351s] Trained 128 records in 0.089241303 seconds. Throughput is 1434.3135 records/second. Loss is 1.8729643. Sequentialb692dd65's hyper parameters: Current learning rate is 1.762114537444934E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58368/60000][Iteration 4677][Wall Clock 434.699494881s] Trained 128 records in 0.08565053 seconds. Throughput is 1494.4448 records/second. Loss is 1.9028639. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7618040873854828E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58496/60000][Iteration 4678][Wall Clock 434.783195733s] Trained 128 records in 0.083700852 seconds. Throughput is 1529.2556 records/second. Loss is 1.9168735. Sequentialb692dd65's hyper parameters: Current learning rate is 1.761493746697199E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58624/60000][Iteration 4679][Wall Clock 434.878316831s] Trained 128 records in 0.095121098 seconds. Throughput is 1345.6531 records/second. Loss is 1.8720897. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7611835153222966E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58752/60000][Iteration 4680][Wall Clock 434.960774999s] Trained 128 records in 0.082458168 seconds. Throughput is 1552.3022 records/second. Loss is 1.934351. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7608733932030288E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 58880/60000][Iteration 4681][Wall Clock 435.047427834s] Trained 128 records in 0.086652835 seconds. Throughput is 1477.1588 records/second. Loss is 1.960414. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7605633802816902E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 59008/60000][Iteration 4682][Wall Clock 435.137299092s] Trained 128 records in 0.089871258 seconds. Throughput is 1424.2596 records/second. Loss is 1.8979945. Sequentialb692dd65's hyper parameters: Current learning rate is 1.760253476500616E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:38 INFO  DistriOptimizer$:408 - [Epoch 10 59136/60000][Iteration 4683][Wall Clock 435.22396691s] Trained 128 records in 0.086667818 seconds. Throughput is 1476.9034 records/second. Loss is 1.8931718. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7599436818021823E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59264/60000][Iteration 4684][Wall Clock 435.311120565s] Trained 128 records in 0.087153655 seconds. Throughput is 1468.6704 records/second. Loss is 1.8914415. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7596339961288053E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59392/60000][Iteration 4685][Wall Clock 435.396694425s] Trained 128 records in 0.08557386 seconds. Throughput is 1495.7839 records/second. Loss is 1.9228842. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7593244194229416E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59520/60000][Iteration 4686][Wall Clock 435.480393232s] Trained 128 records in 0.083698807 seconds. Throughput is 1529.293 records/second. Loss is 1.8547509. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7590149516270886E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59648/60000][Iteration 4687][Wall Clock 435.566245603s] Trained 128 records in 0.085852371 seconds. Throughput is 1490.9315 records/second. Loss is 1.9180603. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7587055926837847E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59776/60000][Iteration 4688][Wall Clock 435.654172421s] Trained 128 records in 0.087926818 seconds. Throughput is 1455.7561 records/second. Loss is 1.8880718. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7583963425356076E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 59904/60000][Iteration 4689][Wall Clock 435.739820863s] Trained 128 records in 0.085648442 seconds. Throughput is 1494.4814 records/second. Loss is 1.861195. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7580872011251758E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:408 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 435.827783198s] Trained 128 records in 0.087962335 seconds. Throughput is 1455.1682 records/second. Loss is 1.924331. Sequentialb692dd65's hyper parameters: Current learning rate is 1.7577781683951485E-4. Current dampening is 1.7976931348623157E308.  
2019-10-15 07:53:39 INFO  DistriOptimizer$:452 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 435.827783198s] Epoch finished. Wall clock time is 436945.585546 ms
2019-10-15 07:53:39 INFO  DistriOptimizer$:111 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 435.827783198s] Validate model...
2019-10-15 07:53:40 INFO  DistriOptimizer$:178 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 435.827783198s] validate model throughput is 12330.84 records/second
2019-10-15 07:53:40 INFO  DistriOptimizer$:181 - [Epoch 10 60032/60000][Iteration 4690][Wall Clock 435.827783198s] Top1Accuracy is Accuracy(correct: 6257, count: 10000, accuracy: 0.6257)
2019-10-15 07:53:40 INFO  DistriOptimizer$:221 - [Wall Clock 436.945585546s] Save model to /tmp/lenet5/20191015_074622
2019-10-15 07:53:40 INFO  DistriOptimizer$:226 - [Wall Clock 436.945585546s] Save optimMethod com.intel.analytics.bigdl.optim.SGD@3eb275e5 to /tmp/lenet5/20191015_074622
('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')
creating: createTop1Accuracy
creating: createTop5Accuracy
creating: createClassNLLCriterion
creating: createLoss
Evaluated result: 0.625599980354, total_num: 10000, method: Top1Accuracy
Evaluated result: 0.964699983597, total_num: 10000, method: Top5Accuracy
Evaluated result: 1.89007484913, total_num: 157, method: Loss
